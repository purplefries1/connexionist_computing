---------------------------------------------------------

Hidden units: 5
Epochs: 3000
Learning rate: 0.1

Errors during training:
Error at epoch 1 is 485.04321364374266
Train mean error at (after) epoch 1: 1.2126080341093566
Test error at (after) epoch 1: 1.1984255324705846
----------
Error at epoch 300 is 7.848403925163585
Train mean error at (after) epoch 300: 0.019621009812908964
Test error at (after) epoch 300: 0.0260877361802685
----------
Error at epoch 600 is 4.962160619085171
Train mean error at (after) epoch 600: 0.012405401547712927
Test error at (after) epoch 600: 0.016518014234582372
----------
Error at epoch 900 is 3.4557959839479255
Train mean error at (after) epoch 900: 0.008639489959869814
Test error at (after) epoch 900: 0.010707750346691644
----------
Error at epoch 1200 is 2.636124627488102
Train mean error at (after) epoch 1200: 0.0065903115687202555
Test error at (after) epoch 1200: 0.007577619210008249
----------
Error at epoch 1500 is 2.1991978480362424
Train mean error at (after) epoch 1500: 0.0054979946200906064
Test error at (after) epoch 1500: 0.005999824977786655
----------
Error at epoch 1800 is 1.970738015644914
Train mean error at (after) epoch 1800: 0.004926845039112285
Test error at (after) epoch 1800: 0.005245630624445327
----------
Error at epoch 2100 is 1.8411051464002468
Train mean error at (after) epoch 2100: 0.004602762866000617
Test error at (after) epoch 2100: 0.004877579111738521
----------
Error at epoch 2400 is 1.7547492894141974
Train mean error at (after) epoch 2400: 0.004386873223535493
Test error at (after) epoch 2400: 0.004675750202627858
----------
Error at epoch 2700 is 1.6881395148219838
Train mean error at (after) epoch 2700: 0.004220348787054959
Test error at (after) epoch 2700: 0.0045454441665952845
----------
Error at epoch 3000 is 1.631579923576667
Train mean error at (after) epoch 3000: 0.004078949808941667
Test error at (after) epoch 3000: 0.004447744951160801
----------


Outputs after training:

Input: [-0.49815014  0.41583469  0.94201245 -0.99618897] | Target: 0.8543072586148057 | Output: 0.8330775359660334
Input: [ 0.13818131  0.06095889 -0.62437142  0.40181237] | Target: -0.8128109128334502 | Output: -0.7899599999448862
Input: [-0.55703306 -0.36130396  0.43427241  0.52039419] | Target: -0.27813396526285905 | Output: -0.28917517740468696
Input: [-0.90268247 -0.77891602  0.66723982  0.70656042] | Target: -0.16236507366523303 | Output: -0.16846932768247908
Input: [-0.52071191 -0.17490864 -0.42110008  0.53739114] | Target: -0.9646980685355615 | Output: -0.8717432749963941
Input: [-0.57989232  0.41914752 -0.89430089  0.4042967 ] | Target: -0.7472772503976836 | Output: -0.8290687630514593
Input: [ 0.41123637  0.50445406 -0.39235833  0.40965961] | Target: -0.7803564461209093 | Output: -0.7954415847936279
Input: [-0.84874982 -0.91212193 -0.57126008  0.78537851] | Target: -0.961735148149663 | Output: -0.9268046325313756
Input: [-0.83942584 -0.2382192  -0.41552901 -0.41150754] | Target: -0.5689496870929982 | Output: -0.646709344692378
Input: [-0.63996411 -0.49290989  0.11924329  0.30074516] | Target: -0.32267669103540125 | Output: -0.3499072603259589
Input: [-0.08425944 -0.2955284  -0.89433919  0.83362651] | Target: -0.99853697393758 | Output: -0.9173516509019504
Input: [-0.88724799 -0.93995287  0.30061609 -0.73943079] | Target: 0.8878962036632344 | Output: 0.9152794574509111
Input: [ 0.50561153  0.84672172  0.59155033 -0.74158065] | Target: 0.8371330584929538 | Output: 0.8275075882604944
Input: [ 0.55932204 -0.69038757  0.19916301 -0.99000263] | Target: 0.6462936927156917 | Output: 0.7785255931894862
Input: [ 0.23615323 -0.64992727 -0.68035612 -0.17334199] | Target: 0.37005327868860116 | Output: 0.4321845650103441
Input: [ 0.49647156 -0.50333428 -0.40361241 -0.42994362] | Target: 0.8553038767682734 | Output: 0.799958028592948
Input: [ 0.65655691  0.00372453 -0.82991759  0.87524947] | Target: -0.8685825297023326 | Output: -0.9179979919315615
Input: [0.27223884 0.49333075 0.04959079 0.92712367] | Target: -0.890582723559241 | Output: -0.9266286721518706
Input: [ 0.84876481  0.76225924 -0.08406463  0.43691027] | Target: -0.4209290928116743 | Output: -0.5230082590464536
Input: [ 0.59751983 -0.2812373   0.78611368  0.44687436] | Target: 0.9384089629393059 | Output: 0.9123355463524068
Input: [ 0.34182235  0.5491084   0.40507799 -0.29701485] | Target: 0.47486162062233245 | Output: 0.5327497233687836
Input: [ 0.42283238  0.80968777 -0.82963418 -0.55610595] | Target: -0.6134198613415482 | Output: -0.611150664954882
Input: [-0.50187166  0.92688959  0.40075995  0.043051  ] | Target: -0.877705252953404 | Output: -0.8141921195848967
Input: [-0.41943475 -0.61215892  0.45405389 -0.34328094] | Target: 0.8360583549340252 | Output: 0.7979203050481054
Input: [ 0.96795196 -0.28914334  0.63779078  0.32553259] | Target: 0.9999989591114976 | Output: 0.9514557025519872
Input: [ 0.75002122  0.83731922  0.08750354 -0.43598446] | Target: 0.4224892766972277 | Output: 0.4744027953788994
Input: [-0.84145098  0.59019999  0.57881044 -0.10527194] | Target: -0.6798577173579573 | Output: -0.6840794299575061
Input: [-0.01354512  0.51651433  0.61839328 -0.54195236] | Target: 0.5893759863297461 | Output: 0.6254523002215692
Input: [-0.85226186  0.92039067 -0.40358247  0.82752148] | Target: -0.13740013643130405 | Output: -0.7756914803065484
Input: [-1.20208422e-04 -8.33435464e-01 -8.29094249e-01  2.57740819e-01] | Target: -0.2508128096089507 | Output: -0.25389859433683654
Input: [0.97440678 0.67632022 0.37177763 0.37898444] | Target: 0.2867951214724826 | Output: 0.3048369495797991
Input: [-0.96750271  0.40885678 -0.41633182 -0.04844435] | Target: -0.9849951142371354 | Output: -0.908600931326313
Input: [ 0.5995541   0.55368425 -0.39807429  0.74575248] | Target: -0.8902787665928441 | Output: -0.935569810784964
Input: [ 0.1147611   0.31365018 -0.33824567  0.28760157] | Target: -0.7343688350613843 | Output: -0.7245668446095982
Input: [ 0.36462015  0.58189491 -0.94305822 -0.36998795] | Target: -0.7105960731893447 | Output: -0.6969369093171289
Input: [-0.92163169 -0.48173233 -0.45552113  0.34317945] | Target: -0.9453283422404454 | Output: -0.9216415831810928
Input: [0.66100169 0.0159894  0.02375897 0.37858434] | Target: 0.2861313242993361 | Output: 0.3322678591880063
Input: [ 0.74774146 -0.40140906 -0.48244804  0.15224903] | Target: 0.4920591230971327 | Output: 0.5497580179318797
Input: [ 0.88537842  0.54493392 -0.24240907 -0.58675178] | Target: 0.6325082075942169 | Output: 0.6610785252551283
Input: [-0.89948922  0.30514915 -0.06677325 -0.23967053] | Target: -0.8581940351253253 | Output: -0.8356134482677127
Input: [ 0.67803204  0.47533682  0.26972013 -0.27476103] | Target: 0.6795700314529539 | Output: 0.7174331415480777
Input: [-0.98083192 -0.4695752  -0.31786867  0.7619386 ] | Target: -0.9997946180377792 | Output: -0.9077979517979919
Input: [-0.11448304  0.78197704 -0.07385002  0.57302441] | Target: -0.999622948135676 | Output: -0.9405000109480925
Input: [ 0.92133849  0.82507178  0.74741915 -0.58603175] | Target: 0.9900648927020624 | Output: 0.9590784438484745
Input: [-0.60553526 -0.61901846  0.14587078 -0.17473924] | Target: 0.3279126629549906 | Output: 0.3718665014006973
Input: [-0.35802134  0.73015313  0.60293073  0.02384464] | Target: -0.48738142837990606 | Output: -0.511421495862999
Input: [-0.1090036   0.16355674  0.52121077  0.26224029] | Target: -0.013589448699499802 | Output: 0.00621966503170128
Input: [0.24809978 0.13586941 0.70807115 0.35517622] | Target: 0.44853479420304265 | Output: 0.5180238596999599
Input: [-0.27152698 -0.3868816  -0.74856252  0.05681491] | Target: -0.636554775746118 | Output: -0.6696647253482684
Input: [ 0.00580885  0.59096635 -0.36767075  0.72869544] | Target: -0.993875985392774 | Output: -0.9566889123966791
Input: [ 0.35481914  0.88069484 -0.95698046 -0.367384  ] | Target: -0.8981185186955181 | Output: -0.8241157539445052
Input: [-0.41922212 -0.34126958 -0.80916346  0.63907702] | Target: -0.9990054379643346 | Output: -0.9049081913312318
Input: [ 0.67552242 -0.3586028  -0.84792242 -0.68776653] | Target: 0.7668824355727715 | Output: 0.7608036535334275
Input: [0.35026043 0.96890192 0.68031271 0.59380282] | Target: -0.507371347467531 | Output: -0.619456760615839
Input: [-0.63373294 -0.22074043 -0.97588408 -0.83528859] | Target: -0.5257427095689864 | Output: -0.6189862922382151
Input: [-0.0222767   0.1081984  -0.76884935  0.75809839] | Target: -0.9962502691004255 | Output: -0.925065179546628
Input: [ 0.87942357  0.4071619   0.30276464 -0.57790568] | Target: 0.9763612859488614 | Output: 0.8930157696779063
Input: [-0.36920023  0.30225159  0.1661646  -0.39389227] | Target: -0.11116471798811212 | Output: -0.11174207362116259
Input: [-0.06072322 -0.78714594 -0.67294101 -0.78471074] | Target: 0.7434354298423212 | Output: 0.7791481459205445
Input: [-0.34393016  0.95254504 -0.31080191  0.81068077] | Target: -0.6621129592186771 | Output: -0.9164841364418829
Input: [ 0.86965397  0.50771038 -0.95344631  0.79036643] | Target: -0.9822062805839687 | Output: -1.0413197152274052
Input: [ 0.55253134 -0.90575846  0.66876745  0.06928906] | Target: 0.8837539313124146 | Output: 0.8152324143659943
Input: [-0.8891273   0.17029516  0.07761798  0.54324158] | Target: -0.9989536393372639 | Output: -0.8772129079682812
Input: [-0.03247545  0.62848862 -0.2840394  -0.85224449] | Target: -0.09262602421897013 | Output: -0.09272104176137297
Input: [-0.17492966  0.6020377  -0.13374702  0.40160947] | Target: -0.9667815476307677 | Output: -0.8800019561288837
Input: [ 0.33321489 -0.78608966 -0.70813443 -0.59641281] | Target: 0.8455438312927052 | Output: 0.8190302929615332
Input: [-0.76627588 -0.22203148  0.14491826 -0.92464247] | Target: 0.5014867041380001 | Output: 0.5773053210358415
Input: [-0.54892582  0.20719914 -0.76681321  0.93955098] | Target: -0.6280956729056199 | Output: -0.8257599523550179
Input: [-0.64337341  0.49544423 -0.11255878 -0.01282107] | Target: -0.9453137970150551 | Output: -0.8487486607303792
Input: [-0.82728321 -0.69829701 -0.57700406  0.67442232] | Target: -0.981931689754146 | Output: -0.9278934262052978
Input: [-0.98497539 -0.72891986 -0.1836953   0.24372919] | Target: -0.631495178088639 | Output: -0.6969455309311324
Input: [ 0.70800631 -0.55628296 -0.26687532 -0.34987773] | Target: 0.9751266382188684 | Output: 0.8530236204474647
Input: [ 0.75178324 -0.01347168  0.38898314  0.14288251] | Target: 0.8475520319175844 | Output: 0.8455716434288061
Input: [ 0.41136073 -0.14618654 -0.91102637 -0.93813825] | Target: 0.5519151840967939 | Output: 0.6002650077744051
Input: [ 0.51018995 -0.37692397 -0.5011193   0.44394074] | Target: -0.05791369405285977 | Output: -0.046128916637736175
Input: [ 0.13749821 -0.37478774 -0.06327981  0.08022791] | Target: 0.3604760629800285 | Output: 0.4109545914047556
Input: [ 0.09228736 -0.27344297  0.75162068 -0.23405879] | Target: 0.9760311433779838 | Output: 0.8550658567840428
Input: [-0.50196384 -0.83118106 -0.25087767 -0.73796457] | Target: 0.7286194332234008 | Output: 0.7767933916487435
Input: [ 0.55164468 -0.25600115 -0.13504697  0.49848213] | Target: 0.17323827976742542 | Output: 0.21084427701910036
Input: [ 0.24950619  0.53158706 -0.86338517  0.47552992] | Target: -0.9987402624146927 | Output: -0.9435680438194116
Input: [ 0.51947747  0.94936431  0.43906985 -0.7269993 ] | Target: 0.6714637645748815 | Output: 0.7060711926201451
Input: [-0.6973039   0.0889062  -0.68445586 -0.75797046] | Target: -0.6538755685718755 | Output: -0.7314536106723313
Input: [-0.36976629 -0.43326151  0.66558198 -0.45645676] | Target: 0.9266998656020422 | Output: 0.8472535580231386
Input: [-0.99621318  0.45345917 -0.16715947  0.62688534] | Target: -0.7820045272552989 | Output: -0.8313959027109639
Input: [-0.66679933  0.85103131 -0.57861249  0.31616618] | Target: -0.6661117041117379 | Output: -0.8157910588304559
Input: [ 0.59984747  0.93320693 -0.64570456 -0.52073603] | Target: -0.44244927775403126 | Output: -0.46309862821441655
Input: [ 0.21660112 -0.82773408  0.18943024 -0.68955577] | Target: 0.9385039454562323 | Output: 0.856474869549859
Input: [-0.75573124 -0.99691407 -0.14209714  0.48281666] | Target: -0.3743826932963817 | Output: -0.4199808255476376
Input: [ 0.43853717 -0.39233615  0.73276518  0.89920491] | Target: 0.6166133215349328 | Output: 0.6809895650962003
Input: [-0.02872933  0.30439828  0.37363359 -0.03299186] | Target: 0.07343169029757857 | Output: 0.1049827798557748
Input: [-0.6846535   0.45758929  0.30868531 -0.58891362] | Target: -0.24221081438382674 | Output: -0.26640109805907825
Input: [-0.42854772  0.22089627 -0.61139582  0.93547015] | Target: -0.810662489719735 | Output: -0.8703104117082168
Input: [-0.85755234  0.56294522  0.8090889   0.62068266] | Target: -0.943185741161217 | Output: -0.8725003721230855
Input: [-0.50101857  0.55840577 -0.17363426 -0.488904  ] | Target: -0.67735012743423 | Output: -0.6796557817424881
Input: [ 0.6573529  -0.81043102 -0.51834698 -0.83932845] | Target: 0.9763386465210206 | Output: 0.8718733992358516
Input: [-0.12988235  0.91252681  0.09633054  0.92392102] | Target: -0.9555716234730861 | Output: -1.0160434660217172
Input: [-0.28034689  0.85840257 -0.61431171 -0.28079694] | Target: -0.9951496388594328 | Output: -0.8646652882732146
Input: [ 0.16949099 -0.60932984 -0.85814292  0.88501474] | Target: -0.821671122614376 | Output: -0.8178213110721835
Input: [ 0.61929034 -0.04625989 -0.20040199 -0.71865318] | Target: 0.9260473813814688 | Output: 0.8267936875911241
Input: [ 0.52560633 -0.27594013  0.7360011  -0.84513606] | Target: 0.6881302680119759 | Output: 0.7530148327330526
---------------------------------------------------------

Hidden units: 5
Epochs: 10000
Learning rate: 0.1

Errors during training:
Error at epoch 1 is 183.1421374071866
Train mean error at (after) epoch 1: 0.4578553435179665
Test error at (after) epoch 1: 0.48971143754658786
----------
Error at epoch 1000 is 2.493011837637611
Train mean error at (after) epoch 1000: 0.006232529594094027
Test error at (after) epoch 1000: 0.006270184280529099
----------
Error at epoch 2000 is 1.8369589554949692
Train mean error at (after) epoch 2000: 0.004592397388737423
Test error at (after) epoch 2000: 0.003952534412534727
----------
Error at epoch 3000 is 1.5702953753764408
Train mean error at (after) epoch 3000: 0.003925738438441102
Test error at (after) epoch 3000: 0.0034040116335949844
----------
Error at epoch 4000 is 1.3856752798521241
Train mean error at (after) epoch 4000: 0.0034641881996303105
Test error at (after) epoch 4000: 0.0030855332346062625
----------
Error at epoch 5000 is 1.2435231480189435
Train mean error at (after) epoch 5000: 0.0031088078700473587
Test error at (after) epoch 5000: 0.0028759333588443932
----------
Error at epoch 6000 is 1.124623783012992
Train mean error at (after) epoch 6000: 0.0028115594575324797
Test error at (after) epoch 6000: 0.0027346131299869425
----------
Error at epoch 7000 is 1.0216809023861197
Train mean error at (after) epoch 7000: 0.0025542022559652995
Test error at (after) epoch 7000: 0.0026397165290548623
----------
Error at epoch 8000 is 0.9317578564583581
Train mean error at (after) epoch 8000: 0.0023293946411458953
Test error at (after) epoch 8000: 0.002577085602263664
----------
Error at epoch 9000 is 0.8530322297637304
Train mean error at (after) epoch 9000: 0.002132580574409326
Test error at (after) epoch 9000: 0.002537462987056649
----------
Error at epoch 10000 is 0.7840887767828106
Train mean error at (after) epoch 10000: 0.0019602219419570265
Test error at (after) epoch 10000: 0.002515333113356492
----------


Outputs after training:

Input: [-0.49815014  0.41583469  0.94201245 -0.99618897] | Target: 0.8543072586148057 | Output: 0.8549524164709308
Input: [ 0.13818131  0.06095889 -0.62437142  0.40181237] | Target: -0.8128109128334502 | Output: -0.8037753316325645
Input: [-0.55703306 -0.36130396  0.43427241  0.52039419] | Target: -0.27813396526285905 | Output: -0.29795132769121135
Input: [-0.90268247 -0.77891602  0.66723982  0.70656042] | Target: -0.16236507366523303 | Output: -0.19562935468138357
Input: [-0.52071191 -0.17490864 -0.42110008  0.53739114] | Target: -0.9646980685355615 | Output: -0.9035966958830834
Input: [-0.57989232  0.41914752 -0.89430089  0.4042967 ] | Target: -0.7472772503976836 | Output: -0.8337062365299257
Input: [ 0.41123637  0.50445406 -0.39235833  0.40965961] | Target: -0.7803564461209093 | Output: -0.7905833902995258
Input: [-0.84874982 -0.91212193 -0.57126008  0.78537851] | Target: -0.961735148149663 | Output: -0.9341636534233364
Input: [-0.83942584 -0.2382192  -0.41552901 -0.41150754] | Target: -0.5689496870929982 | Output: -0.608972370848962
Input: [-0.63996411 -0.49290989  0.11924329  0.30074516] | Target: -0.32267669103540125 | Output: -0.3428439893759416
Input: [-0.08425944 -0.2955284  -0.89433919  0.83362651] | Target: -0.99853697393758 | Output: -0.9359362524467529
Input: [-0.88724799 -0.93995287  0.30061609 -0.73943079] | Target: 0.8878962036632344 | Output: 0.9084128958999929
Input: [ 0.50561153  0.84672172  0.59155033 -0.74158065] | Target: 0.8371330584929538 | Output: 0.8431817937815782
Input: [ 0.55932204 -0.69038757  0.19916301 -0.99000263] | Target: 0.6462936927156917 | Output: 0.6863871923867046
Input: [ 0.23615323 -0.64992727 -0.68035612 -0.17334199] | Target: 0.37005327868860116 | Output: 0.4114822697617269
Input: [ 0.49647156 -0.50333428 -0.40361241 -0.42994362] | Target: 0.8553038767682734 | Output: 0.8480827912332707
Input: [ 0.65655691  0.00372453 -0.82991759  0.87524947] | Target: -0.8685825297023326 | Output: -0.8949782661084167
Input: [0.27223884 0.49333075 0.04959079 0.92712367] | Target: -0.890582723559241 | Output: -0.8662750495760838
Input: [ 0.84876481  0.76225924 -0.08406463  0.43691027] | Target: -0.4209290928116743 | Output: -0.4963069967223859
Input: [ 0.59751983 -0.2812373   0.78611368  0.44687436] | Target: 0.9384089629393059 | Output: 0.9094917098656532
Input: [ 0.34182235  0.5491084   0.40507799 -0.29701485] | Target: 0.47486162062233245 | Output: 0.5235021577758514
Input: [ 0.42283238  0.80968777 -0.82963418 -0.55610595] | Target: -0.6134198613415482 | Output: -0.661136604921756
Input: [-0.50187166  0.92688959  0.40075995  0.043051  ] | Target: -0.877705252953404 | Output: -0.8430018354100358
Input: [-0.41943475 -0.61215892  0.45405389 -0.34328094] | Target: 0.8360583549340252 | Output: 0.8408268878740046
Input: [ 0.96795196 -0.28914334  0.63779078  0.32553259] | Target: 0.9999989591114976 | Output: 0.9261226842841241
Input: [ 0.75002122  0.83731922  0.08750354 -0.43598446] | Target: 0.4224892766972277 | Output: 0.45423108982672983
Input: [-0.84145098  0.59019999  0.57881044 -0.10527194] | Target: -0.6798577173579573 | Output: -0.7127049303926798
Input: [-0.01354512  0.51651433  0.61839328 -0.54195236] | Target: 0.5893759863297461 | Output: 0.6342577381917638
Input: [-0.85226186  0.92039067 -0.40358247  0.82752148] | Target: -0.13740013643130405 | Output: -0.6490719176502956
Input: [-1.20208422e-04 -8.33435464e-01 -8.29094249e-01  2.57740819e-01] | Target: -0.2508128096089507 | Output: -0.2669148361624862
Input: [0.97440678 0.67632022 0.37177763 0.37898444] | Target: 0.2867951214724826 | Output: 0.2925787434068878
Input: [-0.96750271  0.40885678 -0.41633182 -0.04844435] | Target: -0.9849951142371354 | Output: -0.9298190701508879
Input: [ 0.5995541   0.55368425 -0.39807429  0.74575248] | Target: -0.8902787665928441 | Output: -0.8994502966798015
Input: [ 0.1147611   0.31365018 -0.33824567  0.28760157] | Target: -0.7343688350613843 | Output: -0.7313432317146763
Input: [ 0.36462015  0.58189491 -0.94305822 -0.36998795] | Target: -0.7105960731893447 | Output: -0.7491714334311645
Input: [-0.92163169 -0.48173233 -0.45552113  0.34317945] | Target: -0.9453283422404454 | Output: -0.9230203024762411
Input: [0.66100169 0.0159894  0.02375897 0.37858434] | Target: 0.2861313242993361 | Output: 0.31748742925779555
Input: [ 0.74774146 -0.40140906 -0.48244804  0.15224903] | Target: 0.4920591230971327 | Output: 0.53346486082955
Input: [ 0.88537842  0.54493392 -0.24240907 -0.58675178] | Target: 0.6325082075942169 | Output: 0.6629454633653669
Input: [-0.89948922  0.30514915 -0.06677325 -0.23967053] | Target: -0.8581940351253253 | Output: -0.8443577198467749
Input: [ 0.67803204  0.47533682  0.26972013 -0.27476103] | Target: 0.6795700314529539 | Output: 0.7115007121302519
Input: [-0.98083192 -0.4695752  -0.31786867  0.7619386 ] | Target: -0.9997946180377792 | Output: -0.9573743191052073
Input: [-0.11448304  0.78197704 -0.07385002  0.57302441] | Target: -0.999622948135676 | Output: -0.9127509072487341
Input: [ 0.92133849  0.82507178  0.74741915 -0.58603175] | Target: 0.9900648927020624 | Output: 0.9401959749204278
Input: [-0.60553526 -0.61901846  0.14587078 -0.17473924] | Target: 0.3279126629549906 | Output: 0.37258749798745977
Input: [-0.35802134  0.73015313  0.60293073  0.02384464] | Target: -0.48738142837990606 | Output: -0.5120004119762303
Input: [-0.1090036   0.16355674  0.52121077  0.26224029] | Target: -0.013589448699499802 | Output: 0.0017428833824507106
Input: [0.24809978 0.13586941 0.70807115 0.35517622] | Target: 0.44853479420304265 | Output: 0.5005610218006304
Input: [-0.27152698 -0.3868816  -0.74856252  0.05681491] | Target: -0.636554775746118 | Output: -0.6591636248413577
Input: [ 0.00580885  0.59096635 -0.36767075  0.72869544] | Target: -0.993875985392774 | Output: -0.919210280827647
Input: [ 0.35481914  0.88069484 -0.95698046 -0.367384  ] | Target: -0.8981185186955181 | Output: -0.9007459769692465
Input: [-0.41922212 -0.34126958 -0.80916346  0.63907702] | Target: -0.9990054379643346 | Output: -0.933455344483485
Input: [ 0.67552242 -0.3586028  -0.84792242 -0.68776653] | Target: 0.7668824355727715 | Output: 0.7947171270817095
Input: [0.35026043 0.96890192 0.68031271 0.59380282] | Target: -0.507371347467531 | Output: -0.5515497436752714
Input: [-0.63373294 -0.22074043 -0.97588408 -0.83528859] | Target: -0.5257427095689864 | Output: -0.593409825176429
Input: [-0.0222767   0.1081984  -0.76884935  0.75809839] | Target: -0.9962502691004255 | Output: -0.9316228179106738
Input: [ 0.87942357  0.4071619   0.30276464 -0.57790568] | Target: 0.9763612859488614 | Output: 0.9256249204180371
Input: [-0.36920023  0.30225159  0.1661646  -0.39389227] | Target: -0.11116471798811212 | Output: -0.10636616267109217
Input: [-0.06072322 -0.78714594 -0.67294101 -0.78471074] | Target: 0.7434354298423212 | Output: 0.7567678497960617
Input: [-0.34393016  0.95254504 -0.31080191  0.81068077] | Target: -0.6621129592186771 | Output: -0.790354816967552
Input: [ 0.86965397  0.50771038 -0.95344631  0.79036643] | Target: -0.9822062805839687 | Output: -1.0218635815284856
Input: [ 0.55253134 -0.90575846  0.66876745  0.06928906] | Target: 0.8837539313124146 | Output: 0.8083043512491292
Input: [-0.8891273   0.17029516  0.07761798  0.54324158] | Target: -0.9989536393372639 | Output: -0.939598591392927
Input: [-0.03247545  0.62848862 -0.2840394  -0.85224449] | Target: -0.09262602421897013 | Output: -0.09181800808756835
Input: [-0.17492966  0.6020377  -0.13374702  0.40160947] | Target: -0.9667815476307677 | Output: -0.8905105558856217
Input: [ 0.33321489 -0.78608966 -0.70813443 -0.59641281] | Target: 0.8455438312927052 | Output: 0.8425580029594859
Input: [-0.76627588 -0.22203148  0.14491826 -0.92464247] | Target: 0.5014867041380001 | Output: 0.5541325020003909
Input: [-0.54892582  0.20719914 -0.76681321  0.93955098] | Target: -0.6280956729056199 | Output: -0.7937874781034772
Input: [-0.64337341  0.49544423 -0.11255878 -0.01282107] | Target: -0.9453137970150551 | Output: -0.884198486456075
Input: [-0.82728321 -0.69829701 -0.57700406  0.67442232] | Target: -0.981931689754146 | Output: -0.9424677754112731
Input: [-0.98497539 -0.72891986 -0.1836953   0.24372919] | Target: -0.631495178088639 | Output: -0.6722367297438503
Input: [ 0.70800631 -0.55628296 -0.26687532 -0.34987773] | Target: 0.9751266382188684 | Output: 0.9166703350065133
Input: [ 0.75178324 -0.01347168  0.38898314  0.14288251] | Target: 0.8475520319175844 | Output: 0.8464516110846751
Input: [ 0.41136073 -0.14618654 -0.91102637 -0.93813825] | Target: 0.5519151840967939 | Output: 0.5915979737396473
Input: [ 0.51018995 -0.37692397 -0.5011193   0.44394074] | Target: -0.05791369405285977 | Output: -0.058310686590024696
Input: [ 0.13749821 -0.37478774 -0.06327981  0.08022791] | Target: 0.3604760629800285 | Output: 0.4076043544416847
Input: [ 0.09228736 -0.27344297  0.75162068 -0.23405879] | Target: 0.9760311433779838 | Output: 0.9172361388036461
Input: [-0.50196384 -0.83118106 -0.25087767 -0.73796457] | Target: 0.7286194332234008 | Output: 0.7545872300264926
Input: [ 0.55164468 -0.25600115 -0.13504697  0.49848213] | Target: 0.17323827976742542 | Output: 0.19974437741356504
Input: [ 0.24950619  0.53158706 -0.86338517  0.47552992] | Target: -0.9987402624146927 | Output: -0.9547829283517162
Input: [ 0.51947747  0.94936431  0.43906985 -0.7269993 ] | Target: 0.6714637645748815 | Output: 0.7062817892835338
Input: [-0.6973039   0.0889062  -0.68445586 -0.75797046] | Target: -0.6538755685718755 | Output: -0.6929257214795455
Input: [-0.36976629 -0.43326151  0.66558198 -0.45645676] | Target: 0.9266998656020422 | Output: 0.9003929060110061
Input: [-0.99621318  0.45345917 -0.16715947  0.62688534] | Target: -0.7820045272552989 | Output: -0.8497576403485552
Input: [-0.66679933  0.85103131 -0.57861249  0.31616618] | Target: -0.6661117041117379 | Output: -0.7889632368598338
Input: [ 0.59984747  0.93320693 -0.64570456 -0.52073603] | Target: -0.44244927775403126 | Output: -0.5002225420248432
Input: [ 0.21660112 -0.82773408  0.18943024 -0.68955577] | Target: 0.9385039454562323 | Output: 0.8430561860809296
Input: [-0.75573124 -0.99691407 -0.14209714  0.48281666] | Target: -0.3743826932963817 | Output: -0.4021349151769802
Input: [ 0.43853717 -0.39233615  0.73276518  0.89920491] | Target: 0.6166133215349328 | Output: 0.6642461901983081
Input: [-0.02872933  0.30439828  0.37363359 -0.03299186] | Target: 0.07343169029757857 | Output: 0.09968683580984633
Input: [-0.6846535   0.45758929  0.30868531 -0.58891362] | Target: -0.24221081438382674 | Output: -0.2584603345938463
Input: [-0.42854772  0.22089627 -0.61139582  0.93547015] | Target: -0.810662489719735 | Output: -0.8465387867067855
Input: [-0.85755234  0.56294522  0.8090889   0.62068266] | Target: -0.943185741161217 | Output: -0.9442811094168646
Input: [-0.50101857  0.55840577 -0.17363426 -0.488904  ] | Target: -0.67735012743423 | Output: -0.6787778979172909
Input: [ 0.6573529  -0.81043102 -0.51834698 -0.83932845] | Target: 0.9763386465210206 | Output: 0.8980180482386686
Input: [-0.12988235  0.91252681  0.09633054  0.92392102] | Target: -0.9555716234730861 | Output: -0.9047073316847352
Input: [-0.28034689  0.85840257 -0.61431171 -0.28079694] | Target: -0.9951496388594328 | Output: -0.9119300503161512
Input: [ 0.16949099 -0.60932984 -0.85814292  0.88501474] | Target: -0.821671122614376 | Output: -0.8157097056878435
Input: [ 0.61929034 -0.04625989 -0.20040199 -0.71865318] | Target: 0.9260473813814688 | Output: 0.8949673466193713
Input: [ 0.52560633 -0.27594013  0.7360011  -0.84513606] | Target: 0.6881302680119759 | Output: 0.7132053959459856
---------------------------------------------------------

Hidden units: 5
Epochs: 3000
Learning rate: 0.3

Errors during training:
Error at epoch 1 is 132.2025838722661
Train mean error at (after) epoch 1: 0.3305064596806653
Test error at (after) epoch 1: 0.2549177018709548
----------
Error at epoch 300 is 3.181082276859227
Train mean error at (after) epoch 300: 0.007952705692148067
Test error at (after) epoch 300: 0.01149524242359729
----------
Error at epoch 600 is 1.6856035903890412
Train mean error at (after) epoch 600: 0.004214008975972603
Test error at (after) epoch 600: 0.00548543732229923
----------
Error at epoch 900 is 1.458146996137606
Train mean error at (after) epoch 900: 0.0036453674903440146
Test error at (after) epoch 900: 0.005009346708359698
----------
Error at epoch 1200 is 1.296623493901478
Train mean error at (after) epoch 1200: 0.0032415587347536952
Test error at (after) epoch 1200: 0.004953940128541949
----------
Error at epoch 1500 is 1.1624006976350856
Train mean error at (after) epoch 1500: 0.002906001744087714
Test error at (after) epoch 1500: 0.005003324307534145
----------
Error at epoch 1800 is 1.0507282703299414
Train mean error at (after) epoch 1800: 0.0026268206758248537
Test error at (after) epoch 1800: 0.005101137172798411
----------
Error at epoch 2100 is 0.9581165212981717
Train mean error at (after) epoch 2100: 0.002395291303245429
Test error at (after) epoch 2100: 0.005221215620056447
----------
Error at epoch 2400 is 0.8818805291360242
Train mean error at (after) epoch 2400: 0.0022047013228400606
Test error at (after) epoch 2400: 0.005347302715292374
----------
Error at epoch 2700 is 0.8196576754777817
Train mean error at (after) epoch 2700: 0.0020491441886944543
Test error at (after) epoch 2700: 0.005468237675208781
----------
Error at epoch 3000 is 0.7691609877355122
Train mean error at (after) epoch 3000: 0.0019229024693387805
Test error at (after) epoch 3000: 0.005576373405879865
----------


Outputs after training:

Input: [-0.49815014  0.41583469  0.94201245 -0.99618897] | Target: 0.8543072586148057 | Output: 0.8637892097508791
Input: [ 0.13818131  0.06095889 -0.62437142  0.40181237] | Target: -0.8128109128334502 | Output: -0.7817137194286597
Input: [-0.55703306 -0.36130396  0.43427241  0.52039419] | Target: -0.27813396526285905 | Output: -0.3059147320578953
Input: [-0.90268247 -0.77891602  0.66723982  0.70656042] | Target: -0.16236507366523303 | Output: -0.18693325322164211
Input: [-0.52071191 -0.17490864 -0.42110008  0.53739114] | Target: -0.9646980685355615 | Output: -0.878184887491259
Input: [-0.57989232  0.41914752 -0.89430089  0.4042967 ] | Target: -0.7472772503976836 | Output: -0.9239579660178958
Input: [ 0.41123637  0.50445406 -0.39235833  0.40965961] | Target: -0.7803564461209093 | Output: -0.776504754047074
Input: [-0.84874982 -0.91212193 -0.57126008  0.78537851] | Target: -0.961735148149663 | Output: -0.8928455331100141
Input: [-0.83942584 -0.2382192  -0.41552901 -0.41150754] | Target: -0.5689496870929982 | Output: -0.5812344465220017
Input: [-0.63996411 -0.49290989  0.11924329  0.30074516] | Target: -0.32267669103540125 | Output: -0.3536894378388481
Input: [-0.08425944 -0.2955284  -0.89433919  0.83362651] | Target: -0.99853697393758 | Output: -0.9115332284473089
Input: [-0.88724799 -0.93995287  0.30061609 -0.73943079] | Target: 0.8878962036632344 | Output: 0.8666911008885384
Input: [ 0.50561153  0.84672172  0.59155033 -0.74158065] | Target: 0.8371330584929538 | Output: 0.8644771885479857
Input: [ 0.55932204 -0.69038757  0.19916301 -0.99000263] | Target: 0.6462936927156917 | Output: 0.6478976906773083
Input: [ 0.23615323 -0.64992727 -0.68035612 -0.17334199] | Target: 0.37005327868860116 | Output: 0.4064056274565212
Input: [ 0.49647156 -0.50333428 -0.40361241 -0.42994362] | Target: 0.8553038767682734 | Output: 0.8755444549850234
Input: [ 0.65655691  0.00372453 -0.82991759  0.87524947] | Target: -0.8685825297023326 | Output: -0.844782322808845
Input: [0.27223884 0.49333075 0.04959079 0.92712367] | Target: -0.890582723559241 | Output: -0.8856418479530535
Input: [ 0.84876481  0.76225924 -0.08406463  0.43691027] | Target: -0.4209290928116743 | Output: -0.44120317697963274
Input: [ 0.59751983 -0.2812373   0.78611368  0.44687436] | Target: 0.9384089629393059 | Output: 0.9333174978236226
Input: [ 0.34182235  0.5491084   0.40507799 -0.29701485] | Target: 0.47486162062233245 | Output: 0.49861798162832505
Input: [ 0.42283238  0.80968777 -0.82963418 -0.55610595] | Target: -0.6134198613415482 | Output: -0.5904025119616657
Input: [-0.50187166  0.92688959  0.40075995  0.043051  ] | Target: -0.877705252953404 | Output: -0.8410942668736333
Input: [-0.41943475 -0.61215892  0.45405389 -0.34328094] | Target: 0.8360583549340252 | Output: 0.8694818815792998
Input: [ 0.96795196 -0.28914334  0.63779078  0.32553259] | Target: 0.9999989591114976 | Output: 0.9506564594687049
Input: [ 0.75002122  0.83731922  0.08750354 -0.43598446] | Target: 0.4224892766972277 | Output: 0.43707760982260757
Input: [-0.84145098  0.59019999  0.57881044 -0.10527194] | Target: -0.6798577173579573 | Output: -0.6770272054860642
Input: [-0.01354512  0.51651433  0.61839328 -0.54195236] | Target: 0.5893759863297461 | Output: 0.6171429718342464
Input: [-0.85226186  0.92039067 -0.40358247  0.82752148] | Target: -0.13740013643130405 | Output: -0.9185421678872491
Input: [-1.20208422e-04 -8.33435464e-01 -8.29094249e-01  2.57740819e-01] | Target: -0.2508128096089507 | Output: -0.2927840635038689
Input: [0.97440678 0.67632022 0.37177763 0.37898444] | Target: 0.2867951214724826 | Output: 0.3185787039980327
Input: [-0.96750271  0.40885678 -0.41633182 -0.04844435] | Target: -0.9849951142371354 | Output: -0.9188294953763951
Input: [ 0.5995541   0.55368425 -0.39807429  0.74575248] | Target: -0.8902787665928441 | Output: -0.8761552888603507
Input: [ 0.1147611   0.31365018 -0.33824567  0.28760157] | Target: -0.7343688350613843 | Output: -0.7309180342193358
Input: [ 0.36462015  0.58189491 -0.94305822 -0.36998795] | Target: -0.7105960731893447 | Output: -0.6791544653003184
Input: [-0.92163169 -0.48173233 -0.45552113  0.34317945] | Target: -0.9453283422404454 | Output: -0.8726082751013953
Input: [0.66100169 0.0159894  0.02375897 0.37858434] | Target: 0.2861313242993361 | Output: 0.29508607329715264
Input: [ 0.74774146 -0.40140906 -0.48244804  0.15224903] | Target: 0.4920591230971327 | Output: 0.5308710967823381
Input: [ 0.88537842  0.54493392 -0.24240907 -0.58675178] | Target: 0.6325082075942169 | Output: 0.647927795504953
Input: [-0.89948922  0.30514915 -0.06677325 -0.23967053] | Target: -0.8581940351253253 | Output: -0.7919094605236601
Input: [ 0.67803204  0.47533682  0.26972013 -0.27476103] | Target: 0.6795700314529539 | Output: 0.7156493877537929
Input: [-0.98083192 -0.4695752  -0.31786867  0.7619386 ] | Target: -0.9997946180377792 | Output: -0.9193696950448778
Input: [-0.11448304  0.78197704 -0.07385002  0.57302441] | Target: -0.999622948135676 | Output: -0.9741983151509868
Input: [ 0.92133849  0.82507178  0.74741915 -0.58603175] | Target: 0.9900648927020624 | Output: 1.0112641133350033
Input: [-0.60553526 -0.61901846  0.14587078 -0.17473924] | Target: 0.3279126629549906 | Output: 0.3537119345550538
Input: [-0.35802134  0.73015313  0.60293073  0.02384464] | Target: -0.48738142837990606 | Output: -0.5215590319416408
Input: [-0.1090036   0.16355674  0.52121077  0.26224029] | Target: -0.013589448699499802 | Output: -0.04063645750190059
Input: [0.24809978 0.13586941 0.70807115 0.35517622] | Target: 0.44853479420304265 | Output: 0.48194150381340595
Input: [-0.27152698 -0.3868816  -0.74856252  0.05681491] | Target: -0.636554775746118 | Output: -0.6376269678268534
Input: [ 0.00580885  0.59096635 -0.36767075  0.72869544] | Target: -0.993875985392774 | Output: -0.9799089256200293
Input: [ 0.35481914  0.88069484 -0.95698046 -0.367384  ] | Target: -0.8981185186955181 | Output: -0.821059191186083
Input: [-0.41922212 -0.34126958 -0.80916346  0.63907702] | Target: -0.9990054379643346 | Output: -0.9109635053469657
Input: [ 0.67552242 -0.3586028  -0.84792242 -0.68776653] | Target: 0.7668824355727715 | Output: 0.795754698042595
Input: [0.35026043 0.96890192 0.68031271 0.59380282] | Target: -0.507371347467531 | Output: -0.5210220454398751
Input: [-0.63373294 -0.22074043 -0.97588408 -0.83528859] | Target: -0.5257427095689864 | Output: -0.5389660916507415
Input: [-0.0222767   0.1081984  -0.76884935  0.75809839] | Target: -0.9962502691004255 | Output: -0.9356606901243811
Input: [ 0.87942357  0.4071619   0.30276464 -0.57790568] | Target: 0.9763612859488614 | Output: 0.9626416654937083
Input: [-0.36920023  0.30225159  0.1661646  -0.39389227] | Target: -0.11116471798811212 | Output: -0.13355252420975616
Input: [-0.06072322 -0.78714594 -0.67294101 -0.78471074] | Target: 0.7434354298423212 | Output: 0.7771142260020117
Input: [-0.34393016  0.95254504 -0.31080191  0.81068077] | Target: -0.6621129592186771 | Output: -0.994480539353111
Input: [ 0.86965397  0.50771038 -0.95344631  0.79036643] | Target: -0.9822062805839687 | Output: -0.9537078784558948
Input: [ 0.55253134 -0.90575846  0.66876745  0.06928906] | Target: 0.8837539313124146 | Output: 0.8016036851237859
Input: [-0.8891273   0.17029516  0.07761798  0.54324158] | Target: -0.9989536393372639 | Output: -0.913427399005255
Input: [-0.03247545  0.62848862 -0.2840394  -0.85224449] | Target: -0.09262602421897013 | Output: -0.11867698854390873
Input: [-0.17492966  0.6020377  -0.13374702  0.40160947] | Target: -0.9667815476307677 | Output: -0.9170158145401143
Input: [ 0.33321489 -0.78608966 -0.70813443 -0.59641281] | Target: 0.8455438312927052 | Output: 0.8701915764983609
Input: [-0.76627588 -0.22203148  0.14491826 -0.92464247] | Target: 0.5014867041380001 | Output: 0.5569179502728553
Input: [-0.54892582  0.20719914 -0.76681321  0.93955098] | Target: -0.6280956729056199 | Output: -0.9162303329929219
Input: [-0.64337341  0.49544423 -0.11255878 -0.01282107] | Target: -0.9453137970150551 | Output: -0.867018995597628
Input: [-0.82728321 -0.69829701 -0.57700406  0.67442232] | Target: -0.981931689754146 | Output: -0.9026199861816302
Input: [-0.98497539 -0.72891986 -0.1836953   0.24372919] | Target: -0.631495178088639 | Output: -0.653171846712813
Input: [ 0.70800631 -0.55628296 -0.26687532 -0.34987773] | Target: 0.9751266382188684 | Output: 0.9375772443503313
Input: [ 0.75178324 -0.01347168  0.38898314  0.14288251] | Target: 0.8475520319175844 | Output: 0.8729129813330677
Input: [ 0.41136073 -0.14618654 -0.91102637 -0.93813825] | Target: 0.5519151840967939 | Output: 0.5873338002780549
Input: [ 0.51018995 -0.37692397 -0.5011193   0.44394074] | Target: -0.05791369405285977 | Output: -0.08008302461265693
Input: [ 0.13749821 -0.37478774 -0.06327981  0.08022791] | Target: 0.3604760629800285 | Output: 0.3963401634274363
Input: [ 0.09228736 -0.27344297  0.75162068 -0.23405879] | Target: 0.9760311433779838 | Output: 0.9438048590387532
Input: [-0.50196384 -0.83118106 -0.25087767 -0.73796457] | Target: 0.7286194332234008 | Output: 0.7519914238156541
Input: [ 0.55164468 -0.25600115 -0.13504697  0.49848213] | Target: 0.17323827976742542 | Output: 0.17217750335402704
Input: [ 0.24950619  0.53158706 -0.86338517  0.47552992] | Target: -0.9987402624146927 | Output: -0.9602726353923271
Input: [ 0.51947747  0.94936431  0.43906985 -0.7269993 ] | Target: 0.6714637645748815 | Output: 0.6990399073807071
Input: [-0.6973039   0.0889062  -0.68445586 -0.75797046] | Target: -0.6538755685718755 | Output: -0.6277961669955068
Input: [-0.36976629 -0.43326151  0.66558198 -0.45645676] | Target: 0.9266998656020422 | Output: 0.9321255805332839
Input: [-0.99621318  0.45345917 -0.16715947  0.62688534] | Target: -0.7820045272552989 | Output: -0.9288941402502287
Input: [-0.66679933  0.85103131 -0.57861249  0.31616618] | Target: -0.6661117041117379 | Output: -0.9453472643575622
Input: [ 0.59984747  0.93320693 -0.64570456 -0.52073603] | Target: -0.44244927775403126 | Output: -0.44117994014488726
Input: [ 0.21660112 -0.82773408  0.18943024 -0.68955577] | Target: 0.9385039454562323 | Output: 0.858182697976079
Input: [-0.75573124 -0.99691407 -0.14209714  0.48281666] | Target: -0.3743826932963817 | Output: -0.4245372666270392
Input: [ 0.43853717 -0.39233615  0.73276518  0.89920491] | Target: 0.6166133215349328 | Output: 0.6578509604382611
Input: [-0.02872933  0.30439828  0.37363359 -0.03299186] | Target: 0.07343169029757857 | Output: 0.0556750181800284
Input: [-0.6846535   0.45758929  0.30868531 -0.58891362] | Target: -0.24221081438382674 | Output: -0.26392377124941224
Input: [-0.42854772  0.22089627 -0.61139582  0.93547015] | Target: -0.810662489719735 | Output: -0.9339613725610927
Input: [-0.85755234  0.56294522  0.8090889   0.62068266] | Target: -0.943185741161217 | Output: -0.9005592569370439
Input: [-0.50101857  0.55840577 -0.17363426 -0.488904  ] | Target: -0.67735012743423 | Output: -0.6525593178785749
Input: [ 0.6573529  -0.81043102 -0.51834698 -0.83932845] | Target: 0.9763386465210206 | Output: 0.8909434181070478
Input: [-0.12988235  0.91252681  0.09633054  0.92392102] | Target: -0.9555716234730861 | Output: -1.0231207298563667
Input: [-0.28034689  0.85840257 -0.61431171 -0.28079694] | Target: -0.9951496388594328 | Output: -0.9148948231700988
Input: [ 0.16949099 -0.60932984 -0.85814292  0.88501474] | Target: -0.821671122614376 | Output: -0.782526366301511
Input: [ 0.61929034 -0.04625989 -0.20040199 -0.71865318] | Target: 0.9260473813814688 | Output: 0.9058289157768015
Input: [ 0.52560633 -0.27594013  0.7360011  -0.84513606] | Target: 0.6881302680119759 | Output: 0.6846245584160869
---------------------------------------------------------

Hidden units: 5
Epochs: 10000
Learning rate: 0.3

Errors during training:
Error at epoch 1 is 123.08469877492338
Train mean error at (after) epoch 1: 0.30771174693730846
Test error at (after) epoch 1: 0.29264354978031115
----------
Error at epoch 1000 is 1.31881505199199
Train mean error at (after) epoch 1000: 0.003297037629979975
Test error at (after) epoch 1000: 0.003183598299058757
----------
Error at epoch 2000 is 0.8727583643221148
Train mean error at (after) epoch 2000: 0.002181895910805287
Test error at (after) epoch 2000: 0.0020757182858973508
----------
Error at epoch 3000 is 0.6774642542043979
Train mean error at (after) epoch 3000: 0.0016936606355109948
Test error at (after) epoch 3000: 0.0016241985599365963
----------
Error at epoch 4000 is 0.5520499357158597
Train mean error at (after) epoch 4000: 0.0013801248392896492
Test error at (after) epoch 4000: 0.001445565105656948
----------
Error at epoch 5000 is 0.45931311805132563
Train mean error at (after) epoch 5000: 0.0011482827951283141
Test error at (after) epoch 5000: 0.0014094449519236319
----------
Error at epoch 6000 is 0.38946054144295267
Train mean error at (after) epoch 6000: 0.0009736513536073816
Test error at (after) epoch 6000: 0.0014266704788584526
----------
Error at epoch 7000 is 0.36705250602422085
Train mean error at (after) epoch 7000: 0.0009176312650605521
Test error at (after) epoch 7000: 0.001567089754726978
----------
Error at epoch 8000 is 2.5587207614136234
Train mean error at (after) epoch 8000: 0.006396801903534058
Test error at (after) epoch 8000: 0.0077865919493943295
----------
Error at epoch 9000 is 0.3011559551701351
Train mean error at (after) epoch 9000: 0.0007528898879253377
Test error at (after) epoch 9000: 0.001755103030103849
----------
Error at epoch 10000 is 0.28807612204151345
Train mean error at (after) epoch 10000: 0.0007201903051037836
Test error at (after) epoch 10000: 0.0018901375448464627
----------


Outputs after training:

Input: [-0.49815014  0.41583469  0.94201245 -0.99618897] | Target: 0.8543072586148057 | Output: 0.81585780542381
Input: [ 0.13818131  0.06095889 -0.62437142  0.40181237] | Target: -0.8128109128334502 | Output: -0.804074415330713
Input: [-0.55703306 -0.36130396  0.43427241  0.52039419] | Target: -0.27813396526285905 | Output: -0.30955252950511025
Input: [-0.90268247 -0.77891602  0.66723982  0.70656042] | Target: -0.16236507366523303 | Output: -0.1849698257299115
Input: [-0.52071191 -0.17490864 -0.42110008  0.53739114] | Target: -0.9646980685355615 | Output: -0.9155274117535023
Input: [-0.57989232  0.41914752 -0.89430089  0.4042967 ] | Target: -0.7472772503976836 | Output: -0.8018646818661802
Input: [ 0.41123637  0.50445406 -0.39235833  0.40965961] | Target: -0.7803564461209093 | Output: -0.783072865409033
Input: [-0.84874982 -0.91212193 -0.57126008  0.78537851] | Target: -0.961735148149663 | Output: -0.9351190901430205
Input: [-0.83942584 -0.2382192  -0.41552901 -0.41150754] | Target: -0.5689496870929982 | Output: -0.5875469870071546
Input: [-0.63996411 -0.49290989  0.11924329  0.30074516] | Target: -0.32267669103540125 | Output: -0.3546144753461542
Input: [-0.08425944 -0.2955284  -0.89433919  0.83362651] | Target: -0.99853697393758 | Output: -1.0048774694156224
Input: [-0.88724799 -0.93995287  0.30061609 -0.73943079] | Target: 0.8878962036632344 | Output: 0.8962409415855362
Input: [ 0.50561153  0.84672172  0.59155033 -0.74158065] | Target: 0.8371330584929538 | Output: 0.873547601553123
Input: [ 0.55932204 -0.69038757  0.19916301 -0.99000263] | Target: 0.6462936927156917 | Output: 0.6231521300894948
Input: [ 0.23615323 -0.64992727 -0.68035612 -0.17334199] | Target: 0.37005327868860116 | Output: 0.37324684346027415
Input: [ 0.49647156 -0.50333428 -0.40361241 -0.42994362] | Target: 0.8553038767682734 | Output: 0.863695745694815
Input: [ 0.65655691  0.00372453 -0.82991759  0.87524947] | Target: -0.8685825297023326 | Output: -0.8352199558659775
Input: [0.27223884 0.49333075 0.04959079 0.92712367] | Target: -0.890582723559241 | Output: -0.881207133569046
Input: [ 0.84876481  0.76225924 -0.08406463  0.43691027] | Target: -0.4209290928116743 | Output: -0.45717218203986687
Input: [ 0.59751983 -0.2812373   0.78611368  0.44687436] | Target: 0.9384089629393059 | Output: 0.9388336852755349
Input: [ 0.34182235  0.5491084   0.40507799 -0.29701485] | Target: 0.47486162062233245 | Output: 0.5073182691746226
Input: [ 0.42283238  0.80968777 -0.82963418 -0.55610595] | Target: -0.6134198613415482 | Output: -0.630892347255743
Input: [-0.50187166  0.92688959  0.40075995  0.043051  ] | Target: -0.877705252953404 | Output: -0.8736489752628674
Input: [-0.41943475 -0.61215892  0.45405389 -0.34328094] | Target: 0.8360583549340252 | Output: 0.8588000805738863
Input: [ 0.96795196 -0.28914334  0.63779078  0.32553259] | Target: 0.9999989591114976 | Output: 0.9716213612051087
Input: [ 0.75002122  0.83731922  0.08750354 -0.43598446] | Target: 0.4224892766972277 | Output: 0.45298037100746125
Input: [-0.84145098  0.59019999  0.57881044 -0.10527194] | Target: -0.6798577173579573 | Output: -0.6701959680543519
Input: [-0.01354512  0.51651433  0.61839328 -0.54195236] | Target: 0.5893759863297461 | Output: 0.6136192890630484
Input: [-0.85226186  0.92039067 -0.40358247  0.82752148] | Target: -0.13740013643130405 | Output: -0.6170353034504675
Input: [-1.20208422e-04 -8.33435464e-01 -8.29094249e-01  2.57740819e-01] | Target: -0.2508128096089507 | Output: -0.24890822510272193
Input: [0.97440678 0.67632022 0.37177763 0.37898444] | Target: 0.2867951214724826 | Output: 0.3012867937066045
Input: [-0.96750271  0.40885678 -0.41633182 -0.04844435] | Target: -0.9849951142371354 | Output: -0.9345143850770524
Input: [ 0.5995541   0.55368425 -0.39807429  0.74575248] | Target: -0.8902787665928441 | Output: -0.8802880706716397
Input: [ 0.1147611   0.31365018 -0.33824567  0.28760157] | Target: -0.7343688350613843 | Output: -0.7430874041885753
Input: [ 0.36462015  0.58189491 -0.94305822 -0.36998795] | Target: -0.7105960731893447 | Output: -0.7094883040969663
Input: [-0.92163169 -0.48173233 -0.45552113  0.34317945] | Target: -0.9453283422404454 | Output: -0.8911621507390489
Input: [0.66100169 0.0159894  0.02375897 0.37858434] | Target: 0.2861313242993361 | Output: 0.2982320744293492
Input: [ 0.74774146 -0.40140906 -0.48244804  0.15224903] | Target: 0.4920591230971327 | Output: 0.49075289892569074
Input: [ 0.88537842  0.54493392 -0.24240907 -0.58675178] | Target: 0.6325082075942169 | Output: 0.6685586390830499
Input: [-0.89948922  0.30514915 -0.06677325 -0.23967053] | Target: -0.8581940351253253 | Output: -0.8405548966964187
Input: [ 0.67803204  0.47533682  0.26972013 -0.27476103] | Target: 0.6795700314529539 | Output: 0.722009676948505
Input: [-0.98083192 -0.4695752  -0.31786867  0.7619386 ] | Target: -0.9997946180377792 | Output: -0.930296948581716
Input: [-0.11448304  0.78197704 -0.07385002  0.57302441] | Target: -0.999622948135676 | Output: -0.9376800678873473
Input: [ 0.92133849  0.82507178  0.74741915 -0.58603175] | Target: 0.9900648927020624 | Output: 1.0031593800456662
Input: [-0.60553526 -0.61901846  0.14587078 -0.17473924] | Target: 0.3279126629549906 | Output: 0.34772618907246566
Input: [-0.35802134  0.73015313  0.60293073  0.02384464] | Target: -0.48738142837990606 | Output: -0.49699495516667436
Input: [-0.1090036   0.16355674  0.52121077  0.26224029] | Target: -0.013589448699499802 | Output: -0.028090583646801837
Input: [0.24809978 0.13586941 0.70807115 0.35517622] | Target: 0.44853479420304265 | Output: 0.4796039532173103
Input: [-0.27152698 -0.3868816  -0.74856252  0.05681491] | Target: -0.636554775746118 | Output: -0.6429230992295248
Input: [ 0.00580885  0.59096635 -0.36767075  0.72869544] | Target: -0.993875985392774 | Output: -0.9403680245757927
Input: [ 0.35481914  0.88069484 -0.95698046 -0.367384  ] | Target: -0.8981185186955181 | Output: -0.8587924164341542
Input: [-0.41922212 -0.34126958 -0.80916346  0.63907702] | Target: -0.9990054379643346 | Output: -0.9723512091628773
Input: [ 0.67552242 -0.3586028  -0.84792242 -0.68776653] | Target: 0.7668824355727715 | Output: 0.7672807909144065
Input: [0.35026043 0.96890192 0.68031271 0.59380282] | Target: -0.507371347467531 | Output: -0.5438487350560994
Input: [-0.63373294 -0.22074043 -0.97588408 -0.83528859] | Target: -0.5257427095689864 | Output: -0.543402746674047
Input: [-0.0222767   0.1081984  -0.76884935  0.75809839] | Target: -0.9962502691004255 | Output: -0.9870885491025306
Input: [ 0.87942357  0.4071619   0.30276464 -0.57790568] | Target: 0.9763612859488614 | Output: 0.9704169304767419
Input: [-0.36920023  0.30225159  0.1661646  -0.39389227] | Target: -0.11116471798811212 | Output: -0.12975715991431075
Input: [-0.06072322 -0.78714594 -0.67294101 -0.78471074] | Target: 0.7434354298423212 | Output: 0.761908090142052
Input: [-0.34393016  0.95254504 -0.31080191  0.81068077] | Target: -0.6621129592186771 | Output: -0.782883266222529
Input: [ 0.86965397  0.50771038 -0.95344631  0.79036643] | Target: -0.9822062805839687 | Output: -0.9768991542634268
Input: [ 0.55253134 -0.90575846  0.66876745  0.06928906] | Target: 0.8837539313124146 | Output: 0.8353219064949168
Input: [-0.8891273   0.17029516  0.07761798  0.54324158] | Target: -0.9989536393372639 | Output: -0.9374838490402323
Input: [-0.03247545  0.62848862 -0.2840394  -0.85224449] | Target: -0.09262602421897013 | Output: -0.11549548822265726
Input: [-0.17492966  0.6020377  -0.13374702  0.40160947] | Target: -0.9667815476307677 | Output: -0.9154692596282258
Input: [ 0.33321489 -0.78608966 -0.70813443 -0.59641281] | Target: 0.8455438312927052 | Output: 0.8469683728156888
Input: [-0.76627588 -0.22203148  0.14491826 -0.92464247] | Target: 0.5014867041380001 | Output: 0.5171138001596395
Input: [-0.54892582  0.20719914 -0.76681321  0.93955098] | Target: -0.6280956729056199 | Output: -0.7991891678246165
Input: [-0.64337341  0.49544423 -0.11255878 -0.01282107] | Target: -0.9453137970150551 | Output: -0.9064496812813159
Input: [-0.82728321 -0.69829701 -0.57700406  0.67442232] | Target: -0.981931689754146 | Output: -0.9400129025910594
Input: [-0.98497539 -0.72891986 -0.1836953   0.24372919] | Target: -0.631495178088639 | Output: -0.6463428229817874
Input: [ 0.70800631 -0.55628296 -0.26687532 -0.34987773] | Target: 0.9751266382188684 | Output: 0.9683066089625804
Input: [ 0.75178324 -0.01347168  0.38898314  0.14288251] | Target: 0.8475520319175844 | Output: 0.8693041848459963
Input: [ 0.41136073 -0.14618654 -0.91102637 -0.93813825] | Target: 0.5519151840967939 | Output: 0.5696189569973885
Input: [ 0.51018995 -0.37692397 -0.5011193   0.44394074] | Target: -0.05791369405285977 | Output: -0.06201448648107999
Input: [ 0.13749821 -0.37478774 -0.06327981  0.08022791] | Target: 0.3604760629800285 | Output: 0.38147838334861406
Input: [ 0.09228736 -0.27344297  0.75162068 -0.23405879] | Target: 0.9760311433779838 | Output: 0.9664852814339308
Input: [-0.50196384 -0.83118106 -0.25087767 -0.73796457] | Target: 0.7286194332234008 | Output: 0.7612475572330871
Input: [ 0.55164468 -0.25600115 -0.13504697  0.49848213] | Target: 0.17323827976742542 | Output: 0.17562681678694914
Input: [ 0.24950619  0.53158706 -0.86338517  0.47552992] | Target: -0.9987402624146927 | Output: -0.9675919277941661
Input: [ 0.51947747  0.94936431  0.43906985 -0.7269993 ] | Target: 0.6714637645748815 | Output: 0.7107099558766644
Input: [-0.6973039   0.0889062  -0.68445586 -0.75797046] | Target: -0.6538755685718755 | Output: -0.6630341273285066
Input: [-0.36976629 -0.43326151  0.66558198 -0.45645676] | Target: 0.9266998656020422 | Output: 0.9338574556774152
Input: [-0.99621318  0.45345917 -0.16715947  0.62688534] | Target: -0.7820045272552989 | Output: -0.8492400016567182
Input: [-0.66679933  0.85103131 -0.57861249  0.31616618] | Target: -0.6661117041117379 | Output: -0.786417721901787
Input: [ 0.59984747  0.93320693 -0.64570456 -0.52073603] | Target: -0.44244927775403126 | Output: -0.47579597036617904
Input: [ 0.21660112 -0.82773408  0.18943024 -0.68955577] | Target: 0.9385039454562323 | Output: 0.865256046144326
Input: [-0.75573124 -0.99691407 -0.14209714  0.48281666] | Target: -0.3743826932963817 | Output: -0.40185733036942006
Input: [ 0.43853717 -0.39233615  0.73276518  0.89920491] | Target: 0.6166133215349328 | Output: 0.6535628047420946
Input: [-0.02872933  0.30439828  0.37363359 -0.03299186] | Target: 0.07343169029757857 | Output: 0.06689778750913156
Input: [-0.6846535   0.45758929  0.30868531 -0.58891362] | Target: -0.24221081438382674 | Output: -0.2474144186978589
Input: [-0.42854772  0.22089627 -0.61139582  0.93547015] | Target: -0.810662489719735 | Output: -0.8689940261253156
Input: [-0.85755234  0.56294522  0.8090889   0.62068266] | Target: -0.943185741161217 | Output: -0.9329985995287567
Input: [-0.50101857  0.55840577 -0.17363426 -0.488904  ] | Target: -0.67735012743423 | Output: -0.6890317226441521
Input: [ 0.6573529  -0.81043102 -0.51834698 -0.83932845] | Target: 0.9763386465210206 | Output: 0.9637184667382469
Input: [-0.12988235  0.91252681  0.09633054  0.92392102] | Target: -0.9555716234730861 | Output: -0.9210153203418253
Input: [-0.28034689  0.85840257 -0.61431171 -0.28079694] | Target: -0.9951496388594328 | Output: -0.9263927071021975
Input: [ 0.16949099 -0.60932984 -0.85814292  0.88501474] | Target: -0.821671122614376 | Output: -0.7834594159828968
Input: [ 0.61929034 -0.04625989 -0.20040199 -0.71865318] | Target: 0.9260473813814688 | Output: 0.9283957144423728
Input: [ 0.52560633 -0.27594013  0.7360011  -0.84513606] | Target: 0.6881302680119759 | Output: 0.6747387047026153
---------------------------------------------------------

Hidden units: 5
Epochs: 3000
Learning rate: 0.5

Errors during training:
Error at epoch 1 is 281.9324601029864
Train mean error at (after) epoch 1: 0.704831150257466
Test error at (after) epoch 1: 0.3037902759081151
----------
Error at epoch 300 is 1.689902069365247
Train mean error at (after) epoch 300: 0.004224755173413117
Test error at (after) epoch 300: 0.004218718439406457
----------
Error at epoch 600 is 1.380516774020004
Train mean error at (after) epoch 600: 0.00345129193505001
Test error at (after) epoch 600: 0.003793867152003695
----------
Error at epoch 900 is 1.182606683243641
Train mean error at (after) epoch 900: 0.0029565167081091028
Test error at (after) epoch 900: 0.003629741206859037
----------
Error at epoch 1200 is 1.021366751122466
Train mean error at (after) epoch 1200: 0.002553416877806165
Test error at (after) epoch 1200: 0.003503853808557296
----------
Error at epoch 1500 is 0.88855628322926
Train mean error at (after) epoch 1500: 0.0022213907080731498
Test error at (after) epoch 1500: 0.003416092520131334
----------
Error at epoch 1800 is 0.7792314409025096
Train mean error at (after) epoch 1800: 0.0019480786022562742
Test error at (after) epoch 1800: 0.0033603322635311753
----------
Error at epoch 2100 is 26.441396651203842
Train mean error at (after) epoch 2100: 0.0661034916280096
Test error at (after) epoch 2100: 0.07150280812716873
----------
Error at epoch 2400 is 0.6998620885583001
Train mean error at (after) epoch 2400: 0.0017496552213957504
Test error at (after) epoch 2400: 0.003739325518744747
----------
Error at epoch 2700 is 0.6203479611965114
Train mean error at (after) epoch 2700: 0.0015508699029912784
Test error at (after) epoch 2700: 0.0037159313020844746
----------
Error at epoch 3000 is 0.6352179056699426
Train mean error at (after) epoch 3000: 0.0015880447641748565
Test error at (after) epoch 3000: 0.004081261669741666
----------


Outputs after training:

Input: [-0.49815014  0.41583469  0.94201245 -0.99618897] | Target: 0.8543072586148057 | Output: 0.8491347728110329
Input: [ 0.13818131  0.06095889 -0.62437142  0.40181237] | Target: -0.8128109128334502 | Output: -0.7999839029842407
Input: [-0.55703306 -0.36130396  0.43427241  0.52039419] | Target: -0.27813396526285905 | Output: -0.30821539661862396
Input: [-0.90268247 -0.77891602  0.66723982  0.70656042] | Target: -0.16236507366523303 | Output: -0.18183061304375336
Input: [-0.52071191 -0.17490864 -0.42110008  0.53739114] | Target: -0.9646980685355615 | Output: -0.9056679246730049
Input: [-0.57989232  0.41914752 -0.89430089  0.4042967 ] | Target: -0.7472772503976836 | Output: -0.8907911537748711
Input: [ 0.41123637  0.50445406 -0.39235833  0.40965961] | Target: -0.7803564461209093 | Output: -0.7767722260453535
Input: [-0.84874982 -0.91212193 -0.57126008  0.78537851] | Target: -0.961735148149663 | Output: -0.9184759253165989
Input: [-0.83942584 -0.2382192  -0.41552901 -0.41150754] | Target: -0.5689496870929982 | Output: -0.582938202497708
Input: [-0.63996411 -0.49290989  0.11924329  0.30074516] | Target: -0.32267669103540125 | Output: -0.34379667505680134
Input: [-0.08425944 -0.2955284  -0.89433919  0.83362651] | Target: -0.99853697393758 | Output: -0.9635500748252953
Input: [-0.88724799 -0.93995287  0.30061609 -0.73943079] | Target: 0.8878962036632344 | Output: 0.8762086984369862
Input: [ 0.50561153  0.84672172  0.59155033 -0.74158065] | Target: 0.8371330584929538 | Output: 0.8750644263047648
Input: [ 0.55932204 -0.69038757  0.19916301 -0.99000263] | Target: 0.6462936927156917 | Output: 0.6671957076312179
Input: [ 0.23615323 -0.64992727 -0.68035612 -0.17334199] | Target: 0.37005327868860116 | Output: 0.4037973292621341
Input: [ 0.49647156 -0.50333428 -0.40361241 -0.42994362] | Target: 0.8553038767682734 | Output: 0.8692823761955554
Input: [ 0.65655691  0.00372453 -0.82991759  0.87524947] | Target: -0.8685825297023326 | Output: -0.85956085912026
Input: [0.27223884 0.49333075 0.04959079 0.92712367] | Target: -0.890582723559241 | Output: -0.8951576725796152
Input: [ 0.84876481  0.76225924 -0.08406463  0.43691027] | Target: -0.4209290928116743 | Output: -0.45984540140038244
Input: [ 0.59751983 -0.2812373   0.78611368  0.44687436] | Target: 0.9384089629393059 | Output: 0.9293411133348947
Input: [ 0.34182235  0.5491084   0.40507799 -0.29701485] | Target: 0.47486162062233245 | Output: 0.5204775208557267
Input: [ 0.42283238  0.80968777 -0.82963418 -0.55610595] | Target: -0.6134198613415482 | Output: -0.63218165769594
Input: [-0.50187166  0.92688959  0.40075995  0.043051  ] | Target: -0.877705252953404 | Output: -0.803303472046983
Input: [-0.41943475 -0.61215892  0.45405389 -0.34328094] | Target: 0.8360583549340252 | Output: 0.8615222903566245
Input: [ 0.96795196 -0.28914334  0.63779078  0.32553259] | Target: 0.9999989591114976 | Output: 0.946038542667735
Input: [ 0.75002122  0.83731922  0.08750354 -0.43598446] | Target: 0.4224892766972277 | Output: 0.4590893244453703
Input: [-0.84145098  0.59019999  0.57881044 -0.10527194] | Target: -0.6798577173579573 | Output: -0.6375013583195835
Input: [-0.01354512  0.51651433  0.61839328 -0.54195236] | Target: 0.5893759863297461 | Output: 0.6417850097230181
Input: [-0.85226186  0.92039067 -0.40358247  0.82752148] | Target: -0.13740013643130405 | Output: -0.8055996977029268
Input: [-1.20208422e-04 -8.33435464e-01 -8.29094249e-01  2.57740819e-01] | Target: -0.2508128096089507 | Output: -0.2783602522222299
Input: [0.97440678 0.67632022 0.37177763 0.37898444] | Target: 0.2867951214724826 | Output: 0.29708674043891403
Input: [-0.96750271  0.40885678 -0.41633182 -0.04844435] | Target: -0.9849951142371354 | Output: -0.9115590800642391
Input: [ 0.5995541   0.55368425 -0.39807429  0.74575248] | Target: -0.8902787665928441 | Output: -0.8787634626407644
Input: [ 0.1147611   0.31365018 -0.33824567  0.28760157] | Target: -0.7343688350613843 | Output: -0.7340960562311433
Input: [ 0.36462015  0.58189491 -0.94305822 -0.36998795] | Target: -0.7105960731893447 | Output: -0.7107526294989907
Input: [-0.92163169 -0.48173233 -0.45552113  0.34317945] | Target: -0.9453283422404454 | Output: -0.8777459109700864
Input: [0.66100169 0.0159894  0.02375897 0.37858434] | Target: 0.2861313242993361 | Output: 0.3051215154536199
Input: [ 0.74774146 -0.40140906 -0.48244804  0.15224903] | Target: 0.4920591230971327 | Output: 0.5225681941655235
Input: [ 0.88537842  0.54493392 -0.24240907 -0.58675178] | Target: 0.6325082075942169 | Output: 0.67550959210966
Input: [-0.89948922  0.30514915 -0.06677325 -0.23967053] | Target: -0.8581940351253253 | Output: -0.7892566227286281
Input: [ 0.67803204  0.47533682  0.26972013 -0.27476103] | Target: 0.6795700314529539 | Output: 0.7212465725612606
Input: [-0.98083192 -0.4695752  -0.31786867  0.7619386 ] | Target: -0.9997946180377792 | Output: -0.9403996456479545
Input: [-0.11448304  0.78197704 -0.07385002  0.57302441] | Target: -0.999622948135676 | Output: -0.9372476269128674
Input: [ 0.92133849  0.82507178  0.74741915 -0.58603175] | Target: 0.9900648927020624 | Output: 0.9625241738033415
Input: [-0.60553526 -0.61901846  0.14587078 -0.17473924] | Target: 0.3279126629549906 | Output: 0.3674530180373333
Input: [-0.35802134  0.73015313  0.60293073  0.02384464] | Target: -0.48738142837990606 | Output: -0.4974776791040094
Input: [-0.1090036   0.16355674  0.52121077  0.26224029] | Target: -0.013589448699499802 | Output: -0.02602383786938789
Input: [0.24809978 0.13586941 0.70807115 0.35517622] | Target: 0.44853479420304265 | Output: 0.482104865927775
Input: [-0.27152698 -0.3868816  -0.74856252  0.05681491] | Target: -0.636554775746118 | Output: -0.6503866304600064
Input: [ 0.00580885  0.59096635 -0.36767075  0.72869544] | Target: -0.993875985392774 | Output: -0.9586820398795374
Input: [ 0.35481914  0.88069484 -0.95698046 -0.367384  ] | Target: -0.8981185186955181 | Output: -0.8461233691483784
Input: [-0.41922212 -0.34126958 -0.80916346  0.63907702] | Target: -0.9990054379643346 | Output: -0.9454669843174716
Input: [ 0.67552242 -0.3586028  -0.84792242 -0.68776653] | Target: 0.7668824355727715 | Output: 0.795744848525502
Input: [0.35026043 0.96890192 0.68031271 0.59380282] | Target: -0.507371347467531 | Output: -0.568407648316115
Input: [-0.63373294 -0.22074043 -0.97588408 -0.83528859] | Target: -0.5257427095689864 | Output: -0.5927974907131126
Input: [-0.0222767   0.1081984  -0.76884935  0.75809839] | Target: -0.9962502691004255 | Output: -0.9630342443812475
Input: [ 0.87942357  0.4071619   0.30276464 -0.57790568] | Target: 0.9763612859488614 | Output: 0.9528086183709915
Input: [-0.36920023  0.30225159  0.1661646  -0.39389227] | Target: -0.11116471798811212 | Output: -0.1213451784580426
Input: [-0.06072322 -0.78714594 -0.67294101 -0.78471074] | Target: 0.7434354298423212 | Output: 0.7826679524231416
Input: [-0.34393016  0.95254504 -0.31080191  0.81068077] | Target: -0.6621129592186771 | Output: -0.8947135780234067
Input: [ 0.86965397  0.50771038 -0.95344631  0.79036643] | Target: -0.9822062805839687 | Output: -0.9492745587962316
Input: [ 0.55253134 -0.90575846  0.66876745  0.06928906] | Target: 0.8837539313124146 | Output: 0.8253232278797399
Input: [-0.8891273   0.17029516  0.07761798  0.54324158] | Target: -0.9989536393372639 | Output: -0.9138895162644965
Input: [-0.03247545  0.62848862 -0.2840394  -0.85224449] | Target: -0.09262602421897013 | Output: -0.12589544972361655
Input: [-0.17492966  0.6020377  -0.13374702  0.40160947] | Target: -0.9667815476307677 | Output: -0.899178125570021
Input: [ 0.33321489 -0.78608966 -0.70813443 -0.59641281] | Target: 0.8455438312927052 | Output: 0.8647806299083284
Input: [-0.76627588 -0.22203148  0.14491826 -0.92464247] | Target: 0.5014867041380001 | Output: 0.5037057111556412
Input: [-0.54892582  0.20719914 -0.76681321  0.93955098] | Target: -0.6280956729056199 | Output: -0.9011941950089196
Input: [-0.64337341  0.49544423 -0.11255878 -0.01282107] | Target: -0.9453137970150551 | Output: -0.8568483328236899
Input: [-0.82728321 -0.69829701 -0.57700406  0.67442232] | Target: -0.981931689754146 | Output: -0.925162934637063
Input: [-0.98497539 -0.72891986 -0.1836953   0.24372919] | Target: -0.631495178088639 | Output: -0.6277551200312875
Input: [ 0.70800631 -0.55628296 -0.26687532 -0.34987773] | Target: 0.9751266382188684 | Output: 0.9331686394027382
Input: [ 0.75178324 -0.01347168  0.38898314  0.14288251] | Target: 0.8475520319175844 | Output: 0.8563048359067366
Input: [ 0.41136073 -0.14618654 -0.91102637 -0.93813825] | Target: 0.5519151840967939 | Output: 0.589501342054581
Input: [ 0.51018995 -0.37692397 -0.5011193   0.44394074] | Target: -0.05791369405285977 | Output: -0.06682064120140274
Input: [ 0.13749821 -0.37478774 -0.06327981  0.08022791] | Target: 0.3604760629800285 | Output: 0.3954359027779727
Input: [ 0.09228736 -0.27344297  0.75162068 -0.23405879] | Target: 0.9760311433779838 | Output: 0.9481879190012324
Input: [-0.50196384 -0.83118106 -0.25087767 -0.73796457] | Target: 0.7286194332234008 | Output: 0.7625640336953557
Input: [ 0.55164468 -0.25600115 -0.13504697  0.49848213] | Target: 0.17323827976742542 | Output: 0.18513859209122807
Input: [ 0.24950619  0.53158706 -0.86338517  0.47552992] | Target: -0.9987402624146927 | Output: -0.9431061765163945
Input: [ 0.51947747  0.94936431  0.43906985 -0.7269993 ] | Target: 0.6714637645748815 | Output: 0.7253960318781286
Input: [-0.6973039   0.0889062  -0.68445586 -0.75797046] | Target: -0.6538755685718755 | Output: -0.6827032847364306
Input: [-0.36976629 -0.43326151  0.66558198 -0.45645676] | Target: 0.9266998656020422 | Output: 0.9223559213853888
Input: [-0.99621318  0.45345917 -0.16715947  0.62688534] | Target: -0.7820045272552989 | Output: -0.8899232055735385
Input: [-0.66679933  0.85103131 -0.57861249  0.31616618] | Target: -0.6661117041117379 | Output: -0.8661837126335831
Input: [ 0.59984747  0.93320693 -0.64570456 -0.52073603] | Target: -0.44244927775403126 | Output: -0.4723165847915537
Input: [ 0.21660112 -0.82773408  0.18943024 -0.68955577] | Target: 0.9385039454562323 | Output: 0.8620922014452047
Input: [-0.75573124 -0.99691407 -0.14209714  0.48281666] | Target: -0.3743826932963817 | Output: -0.4007224658014087
Input: [ 0.43853717 -0.39233615  0.73276518  0.89920491] | Target: 0.6166133215349328 | Output: 0.6616469038528393
Input: [-0.02872933  0.30439828  0.37363359 -0.03299186] | Target: 0.07343169029757857 | Output: 0.07699834537366779
Input: [-0.6846535   0.45758929  0.30868531 -0.58891362] | Target: -0.24221081438382674 | Output: -0.2607129504502711
Input: [-0.42854772  0.22089627 -0.61139582  0.93547015] | Target: -0.810662489719735 | Output: -0.9364955822835578
Input: [-0.85755234  0.56294522  0.8090889   0.62068266] | Target: -0.943185741161217 | Output: -0.8712501919134893
Input: [-0.50101857  0.55840577 -0.17363426 -0.488904  ] | Target: -0.67735012743423 | Output: -0.6663532811802463
Input: [ 0.6573529  -0.81043102 -0.51834698 -0.83932845] | Target: 0.9763386465210206 | Output: 0.9049269074405709
Input: [-0.12988235  0.91252681  0.09633054  0.92392102] | Target: -0.9555716234730861 | Output: -0.9699552254808191
Input: [-0.28034689  0.85840257 -0.61431171 -0.28079694] | Target: -0.9951496388594328 | Output: -0.9058055116219007
Input: [ 0.16949099 -0.60932984 -0.85814292  0.88501474] | Target: -0.821671122614376 | Output: -0.8254580551883343
Input: [ 0.61929034 -0.04625989 -0.20040199 -0.71865318] | Target: 0.9260473813814688 | Output: 0.929034901135268
Input: [ 0.52560633 -0.27594013  0.7360011  -0.84513606] | Target: 0.6881302680119759 | Output: 0.6887883602939361
---------------------------------------------------------

Hidden units: 5
Epochs: 10000
Learning rate: 0.5

Errors during training:
Error at epoch 1 is 214.59858298792284
Train mean error at (after) epoch 1: 0.5364964574698071
Test error at (after) epoch 1: 0.43227778279398826
----------
Error at epoch 1000 is 1.3829224315030182
Train mean error at (after) epoch 1000: 0.0034573060787575455
Test error at (after) epoch 1000: 0.003596033090020858
----------
Error at epoch 2000 is 1.0321502641791744
Train mean error at (after) epoch 2000: 0.002580375660447936
Test error at (after) epoch 2000: 0.003206906785379783
----------
Error at epoch 3000 is 0.8233907555373223
Train mean error at (after) epoch 3000: 0.002058476888843306
Test error at (after) epoch 3000: 0.004095677408602744
----------
Error at epoch 4000 is 0.6661324983491071
Train mean error at (after) epoch 4000: 0.0016653312458727678
Test error at (after) epoch 4000: 0.005310814377890249
----------
Error at epoch 5000 is 0.6003368794043451
Train mean error at (after) epoch 5000: 0.0015008421985108628
Test error at (after) epoch 5000: 0.005822015979362811
----------
Error at epoch 6000 is 0.5574148593061217
Train mean error at (after) epoch 6000: 0.0013935371482653041
Test error at (after) epoch 6000: 0.0058651026779293625
----------
Error at epoch 7000 is 0.5284375207582407
Train mean error at (after) epoch 7000: 0.0013210938018956018
Test error at (after) epoch 7000: 0.005792354178826909
----------
Error at epoch 8000 is 0.6630175535154015
Train mean error at (after) epoch 8000: 0.0016575438837885038
Test error at (after) epoch 8000: 0.0057795059337667634
----------
Error at epoch 9000 is 0.4650926869252609
Train mean error at (after) epoch 9000: 0.0011627317173131522
Test error at (after) epoch 9000: 0.005377345252355852
----------
Error at epoch 10000 is 0.43809799020684864
Train mean error at (after) epoch 10000: 0.0010952449755171215
Test error at (after) epoch 10000: 0.005202835813296285
----------


Outputs after training:

Input: [-0.49815014  0.41583469  0.94201245 -0.99618897] | Target: 0.8543072586148057 | Output: 0.8825022894288972
Input: [ 0.13818131  0.06095889 -0.62437142  0.40181237] | Target: -0.8128109128334502 | Output: -0.7695547132609027
Input: [-0.55703306 -0.36130396  0.43427241  0.52039419] | Target: -0.27813396526285905 | Output: -0.3025293517691743
Input: [-0.90268247 -0.77891602  0.66723982  0.70656042] | Target: -0.16236507366523303 | Output: -0.1877704214984326
Input: [-0.52071191 -0.17490864 -0.42110008  0.53739114] | Target: -0.9646980685355615 | Output: -0.8859071144779671
Input: [-0.57989232  0.41914752 -0.89430089  0.4042967 ] | Target: -0.7472772503976836 | Output: -0.9290921152347155
Input: [ 0.41123637  0.50445406 -0.39235833  0.40965961] | Target: -0.7803564461209093 | Output: -0.7568911727093768
Input: [-0.84874982 -0.91212193 -0.57126008  0.78537851] | Target: -0.961735148149663 | Output: -0.9027812672776899
Input: [-0.83942584 -0.2382192  -0.41552901 -0.41150754] | Target: -0.5689496870929982 | Output: -0.5871017514054253
Input: [-0.63996411 -0.49290989  0.11924329  0.30074516] | Target: -0.32267669103540125 | Output: -0.3444207028220583
Input: [-0.08425944 -0.2955284  -0.89433919  0.83362651] | Target: -0.99853697393758 | Output: -0.9342940808654624
Input: [-0.88724799 -0.93995287  0.30061609 -0.73943079] | Target: 0.8878962036632344 | Output: 0.9600114441464072
Input: [ 0.50561153  0.84672172  0.59155033 -0.74158065] | Target: 0.8371330584929538 | Output: 0.8656562988286918
Input: [ 0.55932204 -0.69038757  0.19916301 -0.99000263] | Target: 0.6462936927156917 | Output: 0.6517357916947517
Input: [ 0.23615323 -0.64992727 -0.68035612 -0.17334199] | Target: 0.37005327868860116 | Output: 0.3796769499470547
Input: [ 0.49647156 -0.50333428 -0.40361241 -0.42994362] | Target: 0.8553038767682734 | Output: 0.8684740885142761
Input: [ 0.65655691  0.00372453 -0.82991759  0.87524947] | Target: -0.8685825297023326 | Output: -0.8442376950849748
Input: [0.27223884 0.49333075 0.04959079 0.92712367] | Target: -0.890582723559241 | Output: -0.8717805634751207
Input: [ 0.84876481  0.76225924 -0.08406463  0.43691027] | Target: -0.4209290928116743 | Output: -0.4587461071529544
Input: [ 0.59751983 -0.2812373   0.78611368  0.44687436] | Target: 0.9384089629393059 | Output: 0.9567132812603789
Input: [ 0.34182235  0.5491084   0.40507799 -0.29701485] | Target: 0.47486162062233245 | Output: 0.4874652418356924
Input: [ 0.42283238  0.80968777 -0.82963418 -0.55610595] | Target: -0.6134198613415482 | Output: -0.5976789629901721
Input: [-0.50187166  0.92688959  0.40075995  0.043051  ] | Target: -0.877705252953404 | Output: -0.8171622627818211
Input: [-0.41943475 -0.61215892  0.45405389 -0.34328094] | Target: 0.8360583549340252 | Output: 0.8553189352200985
Input: [ 0.96795196 -0.28914334  0.63779078  0.32553259] | Target: 0.9999989591114976 | Output: 0.9971819443564518
Input: [ 0.75002122  0.83731922  0.08750354 -0.43598446] | Target: 0.4224892766972277 | Output: 0.4336757216455538
Input: [-0.84145098  0.59019999  0.57881044 -0.10527194] | Target: -0.6798577173579573 | Output: -0.6600199372298594
Input: [-0.01354512  0.51651433  0.61839328 -0.54195236] | Target: 0.5893759863297461 | Output: 0.6054018789379547
Input: [-0.85226186  0.92039067 -0.40358247  0.82752148] | Target: -0.13740013643130405 | Output: -0.88886079769749
Input: [-1.20208422e-04 -8.33435464e-01 -8.29094249e-01  2.57740819e-01] | Target: -0.2508128096089507 | Output: -0.2717304174568891
Input: [0.97440678 0.67632022 0.37177763 0.37898444] | Target: 0.2867951214724826 | Output: 0.2992426377875954
Input: [-0.96750271  0.40885678 -0.41633182 -0.04844435] | Target: -0.9849951142371354 | Output: -0.947998027630881
Input: [ 0.5995541   0.55368425 -0.39807429  0.74575248] | Target: -0.8902787665928441 | Output: -0.869423513970558
Input: [ 0.1147611   0.31365018 -0.33824567  0.28760157] | Target: -0.7343688350613843 | Output: -0.7074235706362244
Input: [ 0.36462015  0.58189491 -0.94305822 -0.36998795] | Target: -0.7105960731893447 | Output: -0.6780330235576701
Input: [-0.92163169 -0.48173233 -0.45552113  0.34317945] | Target: -0.9453283422404454 | Output: -0.8879685414687278
Input: [0.66100169 0.0159894  0.02375897 0.37858434] | Target: 0.2861313242993361 | Output: 0.28449202957606246
Input: [ 0.74774146 -0.40140906 -0.48244804  0.15224903] | Target: 0.4920591230971327 | Output: 0.5022155782947497
Input: [ 0.88537842  0.54493392 -0.24240907 -0.58675178] | Target: 0.6325082075942169 | Output: 0.6548430897783211
Input: [-0.89948922  0.30514915 -0.06677325 -0.23967053] | Target: -0.8581940351253253 | Output: -0.8038187202887793
Input: [ 0.67803204  0.47533682  0.26972013 -0.27476103] | Target: 0.6795700314529539 | Output: 0.7090152787392017
Input: [-0.98083192 -0.4695752  -0.31786867  0.7619386 ] | Target: -0.9997946180377792 | Output: -0.9416547228259634
Input: [-0.11448304  0.78197704 -0.07385002  0.57302441] | Target: -0.999622948135676 | Output: -0.9514046740080403
Input: [ 0.92133849  0.82507178  0.74741915 -0.58603175] | Target: 0.9900648927020624 | Output: 1.0204584920921975
Input: [-0.60553526 -0.61901846  0.14587078 -0.17473924] | Target: 0.3279126629549906 | Output: 0.33612915747082894
Input: [-0.35802134  0.73015313  0.60293073  0.02384464] | Target: -0.48738142837990606 | Output: -0.5027877209872951
Input: [-0.1090036   0.16355674  0.52121077  0.26224029] | Target: -0.013589448699499802 | Output: -0.03789104295360346
Input: [0.24809978 0.13586941 0.70807115 0.35517622] | Target: 0.44853479420304265 | Output: 0.4665034850233183
Input: [-0.27152698 -0.3868816  -0.74856252  0.05681491] | Target: -0.636554775746118 | Output: -0.6307912414265314
Input: [ 0.00580885  0.59096635 -0.36767075  0.72869544] | Target: -0.993875985392774 | Output: -0.9700264267372899
Input: [ 0.35481914  0.88069484 -0.95698046 -0.367384  ] | Target: -0.8981185186955181 | Output: -0.8171256883093705
Input: [-0.41922212 -0.34126958 -0.80916346  0.63907702] | Target: -0.9990054379643346 | Output: -0.9305862808282495
Input: [ 0.67552242 -0.3586028  -0.84792242 -0.68776653] | Target: 0.7668824355727715 | Output: 0.798928575447037
Input: [0.35026043 0.96890192 0.68031271 0.59380282] | Target: -0.507371347467531 | Output: -0.5430676958888446
Input: [-0.63373294 -0.22074043 -0.97588408 -0.83528859] | Target: -0.5257427095689864 | Output: -0.5683476518103512
Input: [-0.0222767   0.1081984  -0.76884935  0.75809839] | Target: -0.9962502691004255 | Output: -0.9523792801751094
Input: [ 0.87942357  0.4071619   0.30276464 -0.57790568] | Target: 0.9763612859488614 | Output: 0.9818857476445275
Input: [-0.36920023  0.30225159  0.1661646  -0.39389227] | Target: -0.11116471798811212 | Output: -0.1351076604630761
Input: [-0.06072322 -0.78714594 -0.67294101 -0.78471074] | Target: 0.7434354298423212 | Output: 0.8060057493858246
Input: [-0.34393016  0.95254504 -0.31080191  0.81068077] | Target: -0.6621129592186771 | Output: -0.9700577674654212
Input: [ 0.86965397  0.50771038 -0.95344631  0.79036643] | Target: -0.9822062805839687 | Output: -0.9594172444127702
Input: [ 0.55253134 -0.90575846  0.66876745  0.06928906] | Target: 0.8837539313124146 | Output: 0.7964078169725168
Input: [-0.8891273   0.17029516  0.07761798  0.54324158] | Target: -0.9989536393372639 | Output: -0.9207408488451624
Input: [-0.03247545  0.62848862 -0.2840394  -0.85224449] | Target: -0.09262602421897013 | Output: -0.11610445376095124
Input: [-0.17492966  0.6020377  -0.13374702  0.40160947] | Target: -0.9667815476307677 | Output: -0.8925073713097454
Input: [ 0.33321489 -0.78608966 -0.70813443 -0.59641281] | Target: 0.8455438312927052 | Output: 0.88462352628358
Input: [-0.76627588 -0.22203148  0.14491826 -0.92464247] | Target: 0.5014867041380001 | Output: 0.5474743555019337
Input: [-0.54892582  0.20719914 -0.76681321  0.93955098] | Target: -0.6280956729056199 | Output: -0.9342601749337887
Input: [-0.64337341  0.49544423 -0.11255878 -0.01282107] | Target: -0.9453137970150551 | Output: -0.8594367723843753
Input: [-0.82728321 -0.69829701 -0.57700406  0.67442232] | Target: -0.981931689754146 | Output: -0.9189299543080882
Input: [-0.98497539 -0.72891986 -0.1836953   0.24372919] | Target: -0.631495178088639 | Output: -0.6348392856429772
Input: [ 0.70800631 -0.55628296 -0.26687532 -0.34987773] | Target: 0.9751266382188684 | Output: 0.9537789922357878
Input: [ 0.75178324 -0.01347168  0.38898314  0.14288251] | Target: 0.8475520319175844 | Output: 0.8754553613489533
Input: [ 0.41136073 -0.14618654 -0.91102637 -0.93813825] | Target: 0.5519151840967939 | Output: 0.5855805699294836
Input: [ 0.51018995 -0.37692397 -0.5011193   0.44394074] | Target: -0.05791369405285977 | Output: -0.08488650314865631
Input: [ 0.13749821 -0.37478774 -0.06327981  0.08022791] | Target: 0.3604760629800285 | Output: 0.35909584058894195
Input: [ 0.09228736 -0.27344297  0.75162068 -0.23405879] | Target: 0.9760311433779838 | Output: 0.9506226158008351
Input: [-0.50196384 -0.83118106 -0.25087767 -0.73796457] | Target: 0.7286194332234008 | Output: 0.7946129527156549
Input: [ 0.55164468 -0.25600115 -0.13504697  0.49848213] | Target: 0.17323827976742542 | Output: 0.15941392817471356
Input: [ 0.24950619  0.53158706 -0.86338517  0.47552992] | Target: -0.9987402624146927 | Output: -0.9471817417567623
Input: [ 0.51947747  0.94936431  0.43906985 -0.7269993 ] | Target: 0.6714637645748815 | Output: 0.6985554957422193
Input: [-0.6973039   0.0889062  -0.68445586 -0.75797046] | Target: -0.6538755685718755 | Output: -0.6680225719052415
Input: [-0.36976629 -0.43326151  0.66558198 -0.45645676] | Target: 0.9266998656020422 | Output: 0.9307760625188994
Input: [-0.99621318  0.45345917 -0.16715947  0.62688534] | Target: -0.7820045272552989 | Output: -0.9348528230908413
Input: [-0.66679933  0.85103131 -0.57861249  0.31616618] | Target: -0.6661117041117379 | Output: -0.9168848491854558
Input: [ 0.59984747  0.93320693 -0.64570456 -0.52073603] | Target: -0.44244927775403126 | Output: -0.45417704405952053
Input: [ 0.21660112 -0.82773408  0.18943024 -0.68955577] | Target: 0.9385039454562323 | Output: 0.8996415042592687
Input: [-0.75573124 -0.99691407 -0.14209714  0.48281666] | Target: -0.3743826932963817 | Output: -0.3963494084765622
Input: [ 0.43853717 -0.39233615  0.73276518  0.89920491] | Target: 0.6166133215349328 | Output: 0.6551318037143854
Input: [-0.02872933  0.30439828  0.37363359 -0.03299186] | Target: 0.07343169029757857 | Output: 0.053279710508863376
Input: [-0.6846535   0.45758929  0.30868531 -0.58891362] | Target: -0.24221081438382674 | Output: -0.2678714365050068
Input: [-0.42854772  0.22089627 -0.61139582  0.93547015] | Target: -0.810662489719735 | Output: -0.9570663003756521
Input: [-0.85755234  0.56294522  0.8090889   0.62068266] | Target: -0.943185741161217 | Output: -0.8831201817286521
Input: [-0.50101857  0.55840577 -0.17363426 -0.488904  ] | Target: -0.67735012743423 | Output: -0.6551371019723551
Input: [ 0.6573529  -0.81043102 -0.51834698 -0.83932845] | Target: 0.9763386465210206 | Output: 0.9618664256196652
Input: [-0.12988235  0.91252681  0.09633054  0.92392102] | Target: -0.9555716234730861 | Output: -1.0155359273894724
Input: [-0.28034689  0.85840257 -0.61431171 -0.28079694] | Target: -0.9951496388594328 | Output: -0.8999862060154241
Input: [ 0.16949099 -0.60932984 -0.85814292  0.88501474] | Target: -0.821671122614376 | Output: -0.7823986936072319
Input: [ 0.61929034 -0.04625989 -0.20040199 -0.71865318] | Target: 0.9260473813814688 | Output: 0.9314131232628002
Input: [ 0.52560633 -0.27594013  0.7360011  -0.84513606] | Target: 0.6881302680119759 | Output: 0.6625159479955667
---------------------------------------------------------

Hidden units: 5
Epochs: 3000
Learning rate: 1

Errors during training:
Error at epoch 1 is 151.00116366587363
Train mean error at (after) epoch 1: 0.3775029091646841
Test error at (after) epoch 1: 0.05640295924187853
----------
Error at epoch 300 is 1.7650233026227113
Train mean error at (after) epoch 300: 0.004412558256556778
Test error at (after) epoch 300: 0.004719413952334383
----------
Error at epoch 600 is 1.681987570310432
Train mean error at (after) epoch 600: 0.00420496892577608
Test error at (after) epoch 600: 0.004568646409305352
----------
Error at epoch 900 is 1.7397663656891709
Train mean error at (after) epoch 900: 0.004349415914222927
Test error at (after) epoch 900: 0.004739663728526231
----------
Error at epoch 1200 is 1.81299731829933
Train mean error at (after) epoch 1200: 0.0045324932957483246
Test error at (after) epoch 1200: 0.0050034985207984385
----------
Error at epoch 1500 is 2.089016007005672
Train mean error at (after) epoch 1500: 0.00522254001751418
Test error at (after) epoch 1500: 0.005431329912949906
----------
Error at epoch 1800 is 1.2021489419472857
Train mean error at (after) epoch 1800: 0.0030053723548682143
Test error at (after) epoch 1800: 0.0036757828798814397
----------
Error at epoch 2100 is 1.2084730895293796
Train mean error at (after) epoch 2100: 0.003021182723823449
Test error at (after) epoch 2100: 0.0035981017182397153
----------
Error at epoch 2400 is 1.221813361922003
Train mean error at (after) epoch 2400: 0.0030545334048050076
Test error at (after) epoch 2400: 0.0035817691097683514
----------
Error at epoch 2700 is 1.2499571957184459
Train mean error at (after) epoch 2700: 0.003124892989296115
Test error at (after) epoch 2700: 0.003588393233518079
----------
Error at epoch 3000 is 1.2777579040149751
Train mean error at (after) epoch 3000: 0.0031943947600374376
Test error at (after) epoch 3000: 0.003605938056461248
----------


Outputs after training:

Input: [-0.49815014  0.41583469  0.94201245 -0.99618897] | Target: 0.8543072586148057 | Output: 0.8803143556337019
Input: [ 0.13818131  0.06095889 -0.62437142  0.40181237] | Target: -0.8128109128334502 | Output: -0.7830067395735709
Input: [-0.55703306 -0.36130396  0.43427241  0.52039419] | Target: -0.27813396526285905 | Output: -0.30590174124278263
Input: [-0.90268247 -0.77891602  0.66723982  0.70656042] | Target: -0.16236507366523303 | Output: -0.18781179451172464
Input: [-0.52071191 -0.17490864 -0.42110008  0.53739114] | Target: -0.9646980685355615 | Output: -0.8846804258344516
Input: [-0.57989232  0.41914752 -0.89430089  0.4042967 ] | Target: -0.7472772503976836 | Output: -0.8057848937663166
Input: [ 0.41123637  0.50445406 -0.39235833  0.40965961] | Target: -0.7803564461209093 | Output: -0.7863664901737433
Input: [-0.84874982 -0.91212193 -0.57126008  0.78537851] | Target: -0.961735148149663 | Output: -0.9348806016513902
Input: [-0.83942584 -0.2382192  -0.41552901 -0.41150754] | Target: -0.5689496870929982 | Output: -0.6385568189928217
Input: [-0.63996411 -0.49290989  0.11924329  0.30074516] | Target: -0.32267669103540125 | Output: -0.3491077392136722
Input: [-0.08425944 -0.2955284  -0.89433919  0.83362651] | Target: -0.99853697393758 | Output: -0.9439239071118386
Input: [-0.88724799 -0.93995287  0.30061609 -0.73943079] | Target: 0.8878962036632344 | Output: 0.8980014191192902
Input: [ 0.50561153  0.84672172  0.59155033 -0.74158065] | Target: 0.8371330584929538 | Output: 0.7836830081414832
Input: [ 0.55932204 -0.69038757  0.19916301 -0.99000263] | Target: 0.6462936927156917 | Output: 0.728551186878807
Input: [ 0.23615323 -0.64992727 -0.68035612 -0.17334199] | Target: 0.37005327868860116 | Output: 0.4440824316633681
Input: [ 0.49647156 -0.50333428 -0.40361241 -0.42994362] | Target: 0.8553038767682734 | Output: 0.8306205743003452
Input: [ 0.65655691  0.00372453 -0.82991759  0.87524947] | Target: -0.8685825297023326 | Output: -0.916023990832064
Input: [0.27223884 0.49333075 0.04959079 0.92712367] | Target: -0.890582723559241 | Output: -0.8978261620763472
Input: [ 0.84876481  0.76225924 -0.08406463  0.43691027] | Target: -0.4209290928116743 | Output: -0.5067740244498333
Input: [ 0.59751983 -0.2812373   0.78611368  0.44687436] | Target: 0.9384089629393059 | Output: 0.9047706108022209
Input: [ 0.34182235  0.5491084   0.40507799 -0.29701485] | Target: 0.47486162062233245 | Output: 0.5145557655754318
Input: [ 0.42283238  0.80968777 -0.82963418 -0.55610595] | Target: -0.6134198613415482 | Output: -0.6357805896844029
Input: [-0.50187166  0.92688959  0.40075995  0.043051  ] | Target: -0.877705252953404 | Output: -0.8296310721707063
Input: [-0.41943475 -0.61215892  0.45405389 -0.34328094] | Target: 0.8360583549340252 | Output: 0.831173441863434
Input: [ 0.96795196 -0.28914334  0.63779078  0.32553259] | Target: 0.9999989591114976 | Output: 0.9337575829283309
Input: [ 0.75002122  0.83731922  0.08750354 -0.43598446] | Target: 0.4224892766972277 | Output: 0.43589131302254264
Input: [-0.84145098  0.59019999  0.57881044 -0.10527194] | Target: -0.6798577173579573 | Output: -0.6887212317165965
Input: [-0.01354512  0.51651433  0.61839328 -0.54195236] | Target: 0.5893759863297461 | Output: 0.6259400277689238
Input: [-0.85226186  0.92039067 -0.40358247  0.82752148] | Target: -0.13740013643130405 | Output: -0.7181480326880814
Input: [-1.20208422e-04 -8.33435464e-01 -8.29094249e-01  2.57740819e-01] | Target: -0.2508128096089507 | Output: -0.24812883597797117
Input: [0.97440678 0.67632022 0.37177763 0.37898444] | Target: 0.2867951214724826 | Output: 0.3253736224879366
Input: [-0.96750271  0.40885678 -0.41633182 -0.04844435] | Target: -0.9849951142371354 | Output: -0.9097506387098035
Input: [ 0.5995541   0.55368425 -0.39807429  0.74575248] | Target: -0.8902787665928441 | Output: -0.9115819167310215
Input: [ 0.1147611   0.31365018 -0.33824567  0.28760157] | Target: -0.7343688350613843 | Output: -0.7193877775648405
Input: [ 0.36462015  0.58189491 -0.94305822 -0.36998795] | Target: -0.7105960731893447 | Output: -0.6917110262088422
Input: [-0.92163169 -0.48173233 -0.45552113  0.34317945] | Target: -0.9453283422404454 | Output: -0.9116588463720774
Input: [0.66100169 0.0159894  0.02375897 0.37858434] | Target: 0.2861313242993361 | Output: 0.33115833295825076
Input: [ 0.74774146 -0.40140906 -0.48244804  0.15224903] | Target: 0.4920591230971327 | Output: 0.5380267290071707
Input: [ 0.88537842  0.54493392 -0.24240907 -0.58675178] | Target: 0.6325082075942169 | Output: 0.6527098862630971
Input: [-0.89948922  0.30514915 -0.06677325 -0.23967053] | Target: -0.8581940351253253 | Output: -0.8355854667276357
Input: [ 0.67803204  0.47533682  0.26972013 -0.27476103] | Target: 0.6795700314529539 | Output: 0.7000396916076539
Input: [-0.98083192 -0.4695752  -0.31786867  0.7619386 ] | Target: -0.9997946180377792 | Output: -0.9526512340162452
Input: [-0.11448304  0.78197704 -0.07385002  0.57302441] | Target: -0.999622948135676 | Output: -0.9092485518156033
Input: [ 0.92133849  0.82507178  0.74741915 -0.58603175] | Target: 0.9900648927020624 | Output: 0.8800085195406935
Input: [-0.60553526 -0.61901846  0.14587078 -0.17473924] | Target: 0.3279126629549906 | Output: 0.384214399796394
Input: [-0.35802134  0.73015313  0.60293073  0.02384464] | Target: -0.48738142837990606 | Output: -0.5172547072600706
Input: [-0.1090036   0.16355674  0.52121077  0.26224029] | Target: -0.013589448699499802 | Output: 0.004343807095417179
Input: [0.24809978 0.13586941 0.70807115 0.35517622] | Target: 0.44853479420304265 | Output: 0.513174504882518
Input: [-0.27152698 -0.3868816  -0.74856252  0.05681491] | Target: -0.636554775746118 | Output: -0.6374065705092533
Input: [ 0.00580885  0.59096635 -0.36767075  0.72869544] | Target: -0.993875985392774 | Output: -0.921861859513861
Input: [ 0.35481914  0.88069484 -0.95698046 -0.367384  ] | Target: -0.8981185186955181 | Output: -0.8370877089489674
Input: [-0.41922212 -0.34126958 -0.80916346  0.63907702] | Target: -0.9990054379643346 | Output: -0.9166786514241616
Input: [ 0.67552242 -0.3586028  -0.84792242 -0.68776653] | Target: 0.7668824355727715 | Output: 0.7789414770244358
Input: [0.35026043 0.96890192 0.68031271 0.59380282] | Target: -0.507371347467531 | Output: -0.5765095017102634
Input: [-0.63373294 -0.22074043 -0.97588408 -0.83528859] | Target: -0.5257427095689864 | Output: -0.6239832401906923
Input: [-0.0222767   0.1081984  -0.76884935  0.75809839] | Target: -0.9962502691004255 | Output: -0.9209990917754143
Input: [ 0.87942357  0.4071619   0.30276464 -0.57790568] | Target: 0.9763612859488614 | Output: 0.8813838144032182
Input: [-0.36920023  0.30225159  0.1661646  -0.39389227] | Target: -0.11116471798811212 | Output: -0.10442681194350231
Input: [-0.06072322 -0.78714594 -0.67294101 -0.78471074] | Target: 0.7434354298423212 | Output: 0.7696562860613925
Input: [-0.34393016  0.95254504 -0.31080191  0.81068077] | Target: -0.6621129592186771 | Output: -0.8365224245720841
Input: [ 0.86965397  0.50771038 -0.95344631  0.79036643] | Target: -0.9822062805839687 | Output: -1.0034736128904906
Input: [ 0.55253134 -0.90575846  0.66876745  0.06928906] | Target: 0.8837539313124146 | Output: 0.8369865017568292
Input: [-0.8891273   0.17029516  0.07761798  0.54324158] | Target: -0.9989536393372639 | Output: -0.8997631101535768
Input: [-0.03247545  0.62848862 -0.2840394  -0.85224449] | Target: -0.09262602421897013 | Output: -0.10083780730249713
Input: [-0.17492966  0.6020377  -0.13374702  0.40160947] | Target: -0.9667815476307677 | Output: -0.8697945336571231
Input: [ 0.33321489 -0.78608966 -0.70813443 -0.59641281] | Target: 0.8455438312927052 | Output: 0.8385307962724571
Input: [-0.76627588 -0.22203148  0.14491826 -0.92464247] | Target: 0.5014867041380001 | Output: 0.5602239871443249
Input: [-0.54892582  0.20719914 -0.76681321  0.93955098] | Target: -0.6280956729056199 | Output: -0.8299788646031157
Input: [-0.64337341  0.49544423 -0.11255878 -0.01282107] | Target: -0.9453137970150551 | Output: -0.8521975989810631
Input: [-0.82728321 -0.69829701 -0.57700406  0.67442232] | Target: -0.981931689754146 | Output: -0.937966422163139
Input: [-0.98497539 -0.72891986 -0.1836953   0.24372919] | Target: -0.631495178088639 | Output: -0.6846029019107782
Input: [ 0.70800631 -0.55628296 -0.26687532 -0.34987773] | Target: 0.9751266382188684 | Output: 0.8770506614377678
Input: [ 0.75178324 -0.01347168  0.38898314  0.14288251] | Target: 0.8475520319175844 | Output: 0.8406675938488049
Input: [ 0.41136073 -0.14618654 -0.91102637 -0.93813825] | Target: 0.5519151840967939 | Output: 0.6066774720436943
Input: [ 0.51018995 -0.37692397 -0.5011193   0.44394074] | Target: -0.05791369405285977 | Output: -0.06651909373635206
Input: [ 0.13749821 -0.37478774 -0.06327981  0.08022791] | Target: 0.3604760629800285 | Output: 0.42174784216704814
Input: [ 0.09228736 -0.27344297  0.75162068 -0.23405879] | Target: 0.9760311433779838 | Output: 0.8753663088172823
Input: [-0.50196384 -0.83118106 -0.25087767 -0.73796457] | Target: 0.7286194332234008 | Output: 0.7631379226469492
Input: [ 0.55164468 -0.25600115 -0.13504697  0.49848213] | Target: 0.17323827976742542 | Output: 0.1990782125280608
Input: [ 0.24950619  0.53158706 -0.86338517  0.47552992] | Target: -0.9987402624146927 | Output: -0.9052662481012956
Input: [ 0.51947747  0.94936431  0.43906985 -0.7269993 ] | Target: 0.6714637645748815 | Output: 0.6525933865901283
Input: [-0.6973039   0.0889062  -0.68445586 -0.75797046] | Target: -0.6538755685718755 | Output: -0.7177822993820122
Input: [-0.36976629 -0.43326151  0.66558198 -0.45645676] | Target: 0.9266998656020422 | Output: 0.8768227047948836
Input: [-0.99621318  0.45345917 -0.16715947  0.62688534] | Target: -0.7820045272552989 | Output: -0.8362077071016643
Input: [-0.66679933  0.85103131 -0.57861249  0.31616618] | Target: -0.6661117041117379 | Output: -0.7882341774947119
Input: [ 0.59984747  0.93320693 -0.64570456 -0.52073603] | Target: -0.44244927775403126 | Output: -0.5020499697671043
Input: [ 0.21660112 -0.82773408  0.18943024 -0.68955577] | Target: 0.9385039454562323 | Output: 0.847676024160489
Input: [-0.75573124 -0.99691407 -0.14209714  0.48281666] | Target: -0.3743826932963817 | Output: -0.400269145802421
Input: [ 0.43853717 -0.39233615  0.73276518  0.89920491] | Target: 0.6166133215349328 | Output: 0.6764254091691966
Input: [-0.02872933  0.30439828  0.37363359 -0.03299186] | Target: 0.07343169029757857 | Output: 0.1032502174364166
Input: [-0.6846535   0.45758929  0.30868531 -0.58891362] | Target: -0.24221081438382674 | Output: -0.2630820978870711
Input: [-0.42854772  0.22089627 -0.61139582  0.93547015] | Target: -0.810662489719735 | Output: -0.8729083447322763
Input: [-0.85755234  0.56294522  0.8090889   0.62068266] | Target: -0.943185741161217 | Output: -0.8750098080083499
Input: [-0.50101857  0.55840577 -0.17363426 -0.488904  ] | Target: -0.67735012743423 | Output: -0.6845273370182656
Input: [ 0.6573529  -0.81043102 -0.51834698 -0.83932845] | Target: 0.9763386465210206 | Output: 0.8612405748949299
Input: [-0.12988235  0.91252681  0.09633054  0.92392102] | Target: -0.9555716234730861 | Output: -0.9418301150254216
Input: [-0.28034689  0.85840257 -0.61431171 -0.28079694] | Target: -0.9951496388594328 | Output: -0.8772778045694465
Input: [ 0.16949099 -0.60932984 -0.85814292  0.88501474] | Target: -0.821671122614376 | Output: -0.8641736944078018
Input: [ 0.61929034 -0.04625989 -0.20040199 -0.71865318] | Target: 0.9260473813814688 | Output: 0.8625185589824882
Input: [ 0.52560633 -0.27594013  0.7360011  -0.84513606] | Target: 0.6881302680119759 | Output: 0.7338202258084263
---------------------------------------------------------

Hidden units: 5
Epochs: 10000
Learning rate: 1

Errors during training:
Error at epoch 1 is 60.95807744908454
Train mean error at (after) epoch 1: 0.15239519362271137
Test error at (after) epoch 1: 0.05460750392155912
----------
Error at epoch 1000 is 14.216072301011364
Train mean error at (after) epoch 1000: 0.03554018075252841
Test error at (after) epoch 1000: 0.032212500691354916
----------
Error at epoch 2000 is 3.376670986160664
Train mean error at (after) epoch 2000: 0.00844167746540166
Test error at (after) epoch 2000: 0.011272855622798717
----------
Error at epoch 3000 is 4.58625076790756
Train mean error at (after) epoch 3000: 0.011465626919768901
Test error at (after) epoch 3000: 0.01480189789319322
----------
Error at epoch 4000 is 5.193810371543138
Train mean error at (after) epoch 4000: 0.012984525928857843
Test error at (after) epoch 4000: 0.016505493123222362
----------
Error at epoch 5000 is 5.576346367682481
Train mean error at (after) epoch 5000: 0.013940865919206203
Test error at (after) epoch 5000: 0.017539080818554577
----------
Error at epoch 6000 is 5.837009001589505
Train mean error at (after) epoch 6000: 0.014592522503973762
Test error at (after) epoch 6000: 0.018228005562066076
----------
Error at epoch 7000 is 6.024285988921981
Train mean error at (after) epoch 7000: 0.015060714972304951
Test error at (after) epoch 7000: 0.01871633301128278
----------
Error at epoch 8000 is 6.161923847094483
Train mean error at (after) epoch 8000: 0.015404809617736208
Test error at (after) epoch 8000: 0.01907221323147752
----------
Error at epoch 9000 is 6.263257987648848
Train mean error at (after) epoch 9000: 0.01565814496912212
Test error at (after) epoch 9000: 0.0193329556389592
----------
Error at epoch 10000 is 6.336672266817777
Train mean error at (after) epoch 10000: 0.01584168066704444
Test error at (after) epoch 10000: 0.0195216294142744
----------


Outputs after training:

Input: [-0.49815014  0.41583469  0.94201245 -0.99618897] | Target: 0.8543072586148057 | Output: 0.9953526017176106
Input: [ 0.13818131  0.06095889 -0.62437142  0.40181237] | Target: -0.8128109128334502 | Output: -0.6163659007897632
Input: [-0.55703306 -0.36130396  0.43427241  0.52039419] | Target: -0.27813396526285905 | Output: -0.11591444082085645
Input: [-0.90268247 -0.77891602  0.66723982  0.70656042] | Target: -0.16236507366523303 | Output: 0.03386874678368068
Input: [-0.52071191 -0.17490864 -0.42110008  0.53739114] | Target: -0.9646980685355615 | Output: -0.7152762279858171
Input: [-0.57989232  0.41914752 -0.89430089  0.4042967 ] | Target: -0.7472772503976836 | Output: -0.7913172452785708
Input: [ 0.41123637  0.50445406 -0.39235833  0.40965961] | Target: -0.7803564461209093 | Output: -0.594199458702864
Input: [-0.84874982 -0.91212193 -0.57126008  0.78537851] | Target: -0.961735148149663 | Output: -0.69937871896192
Input: [-0.83942584 -0.2382192  -0.41552901 -0.41150754] | Target: -0.5689496870929982 | Output: -0.4158370856961097
Input: [-0.63996411 -0.49290989  0.11924329  0.30074516] | Target: -0.32267669103540125 | Output: -0.17881689447220034
Input: [-0.08425944 -0.2955284  -0.89433919  0.83362651] | Target: -0.99853697393758 | Output: -0.7548934158401193
Input: [-0.88724799 -0.93995287  0.30061609 -0.73943079] | Target: 0.8878962036632344 | Output: 1.0292056342984797
Input: [ 0.50561153  0.84672172  0.59155033 -0.74158065] | Target: 0.8371330584929538 | Output: 0.9960777646474539
Input: [ 0.55932204 -0.69038757  0.19916301 -0.99000263] | Target: 0.6462936927156917 | Output: 0.699932799751156
Input: [ 0.23615323 -0.64992727 -0.68035612 -0.17334199] | Target: 0.37005327868860116 | Output: 0.5908977890446137
Input: [ 0.49647156 -0.50333428 -0.40361241 -0.42994362] | Target: 0.8553038767682734 | Output: 1.0229332514291383
Input: [ 0.65655691  0.00372453 -0.82991759  0.87524947] | Target: -0.8685825297023326 | Output: -0.6420095522352434
Input: [0.27223884 0.49333075 0.04959079 0.92712367] | Target: -0.890582723559241 | Output: -0.655657112695892
Input: [ 0.84876481  0.76225924 -0.08406463  0.43691027] | Target: -0.4209290928116743 | Output: -0.2932702142423013
Input: [ 0.59751983 -0.2812373   0.78611368  0.44687436] | Target: 0.9384089629393059 | Output: 1.0568203283852478
Input: [ 0.34182235  0.5491084   0.40507799 -0.29701485] | Target: 0.47486162062233245 | Output: 0.7056484882644416
Input: [ 0.42283238  0.80968777 -0.82963418 -0.55610595] | Target: -0.6134198613415482 | Output: -0.41318245038551155
Input: [-0.50187166  0.92688959  0.40075995  0.043051  ] | Target: -0.877705252953404 | Output: -0.6459176809797
Input: [-0.41943475 -0.61215892  0.45405389 -0.34328094] | Target: 0.8360583549340252 | Output: 1.0154142948928637
Input: [ 0.96795196 -0.28914334  0.63779078  0.32553259] | Target: 0.9999989591114976 | Output: 1.065499579211561
Input: [ 0.75002122  0.83731922  0.08750354 -0.43598446] | Target: 0.4224892766972277 | Output: 0.6315526687364748
Input: [-0.84145098  0.59019999  0.57881044 -0.10527194] | Target: -0.6798577173579573 | Output: -0.511046376550029
Input: [-0.01354512  0.51651433  0.61839328 -0.54195236] | Target: 0.5893759863297461 | Output: 0.8102006728202975
Input: [-0.85226186  0.92039067 -0.40358247  0.82752148] | Target: -0.13740013643130405 | Output: -0.7950058301050353
Input: [-1.20208422e-04 -8.33435464e-01 -8.29094249e-01  2.57740819e-01] | Target: -0.2508128096089507 | Output: -0.11303342603070027
Input: [0.97440678 0.67632022 0.37177763 0.37898444] | Target: 0.2867951214724826 | Output: 0.505908289200163
Input: [-0.96750271  0.40885678 -0.41633182 -0.04844435] | Target: -0.9849951142371354 | Output: -0.7588194657198308
Input: [ 0.5995541   0.55368425 -0.39807429  0.74575248] | Target: -0.8902787665928441 | Output: -0.6662640823928634
Input: [ 0.1147611   0.31365018 -0.33824567  0.28760157] | Target: -0.7343688350613843 | Output: -0.5600963215734791
Input: [ 0.36462015  0.58189491 -0.94305822 -0.36998795] | Target: -0.7105960731893447 | Output: -0.5146229848434991
Input: [-0.92163169 -0.48173233 -0.45552113  0.34317945] | Target: -0.9453283422404454 | Output: -0.7002133026013899
Input: [0.66100169 0.0159894  0.02375897 0.37858434] | Target: 0.2861313242993361 | Output: 0.49796901993004306
Input: [ 0.74774146 -0.40140906 -0.48244804  0.15224903] | Target: 0.4920591230971327 | Output: 0.7242420283584923
Input: [ 0.88537842  0.54493392 -0.24240907 -0.58675178] | Target: 0.6325082075942169 | Output: 0.8285558955892554
Input: [-0.89948922  0.30514915 -0.06677325 -0.23967053] | Target: -0.8581940351253253 | Output: -0.629721379634736
Input: [ 0.67803204  0.47533682  0.26972013 -0.27476103] | Target: 0.6795700314529539 | Output: 0.9046010355306826
Input: [-0.98083192 -0.4695752  -0.31786867  0.7619386 ] | Target: -0.9997946180377792 | Output: -0.7564697115786687
Input: [-0.11448304  0.78197704 -0.07385002  0.57302441] | Target: -0.999622948135676 | Output: -0.7518378396704324
Input: [ 0.92133849  0.82507178  0.74741915 -0.58603175] | Target: 0.9900648927020624 | Output: 1.0902202277953927
Input: [-0.60553526 -0.61901846  0.14587078 -0.17473924] | Target: 0.3279126629549906 | Output: 0.5455201241238408
Input: [-0.35802134  0.73015313  0.60293073  0.02384464] | Target: -0.48738142837990606 | Output: -0.35133710926414446
Input: [-0.1090036   0.16355674  0.52121077  0.26224029] | Target: -0.013589448699499802 | Output: 0.1535727981873274
Input: [0.24809978 0.13586941 0.70807115 0.35517622] | Target: 0.44853479420304265 | Output: 0.6754141926714019
Input: [-0.27152698 -0.3868816  -0.74856252  0.05681491] | Target: -0.636554775746118 | Output: -0.4865615377731662
Input: [ 0.00580885  0.59096635 -0.36767075  0.72869544] | Target: -0.993875985392774 | Output: -0.7705188447858589
Input: [ 0.35481914  0.88069484 -0.95698046 -0.367384  ] | Target: -0.8981185186955181 | Output: -0.6446342079273388
Input: [-0.41922212 -0.34126958 -0.80916346  0.63907702] | Target: -0.9990054379643346 | Output: -0.7553075092056798
Input: [ 0.67552242 -0.3586028  -0.84792242 -0.68776653] | Target: 0.7668824355727715 | Output: 0.9435293750656548
Input: [0.35026043 0.96890192 0.68031271 0.59380282] | Target: -0.507371347467531 | Output: -0.3647929817978902
Input: [-0.63373294 -0.22074043 -0.97588408 -0.83528859] | Target: -0.5257427095689864 | Output: -0.34122556722759695
Input: [-0.0222767   0.1081984  -0.76884935  0.75809839] | Target: -0.9962502691004255 | Output: -0.7717591102919183
Input: [ 0.87942357  0.4071619   0.30276464 -0.57790568] | Target: 0.9763612859488614 | Output: 1.081460149296039
Input: [-0.36920023  0.30225159  0.1661646  -0.39389227] | Target: -0.11116471798811212 | Output: 0.04122454311239798
Input: [-0.06072322 -0.78714594 -0.67294101 -0.78471074] | Target: 0.7434354298423212 | Output: 0.9239690692356388
Input: [-0.34393016  0.95254504 -0.31080191  0.81068077] | Target: -0.6621129592186771 | Output: -0.7953614155329105
Input: [ 0.86965397  0.50771038 -0.95344631  0.79036643] | Target: -0.9822062805839687 | Output: -0.735894532256429
Input: [ 0.55253134 -0.90575846  0.66876745  0.06928906] | Target: 0.8837539313124146 | Output: 0.9104561018773571
Input: [-0.8891273   0.17029516  0.07761798  0.54324158] | Target: -0.9989536393372639 | Output: -0.7489521123895282
Input: [-0.03247545  0.62848862 -0.2840394  -0.85224449] | Target: -0.09262602421897013 | Output: 0.08663024771887096
Input: [-0.17492966  0.6020377  -0.13374702  0.40160947] | Target: -0.9667815476307677 | Output: -0.7158123004705355
Input: [ 0.33321489 -0.78608966 -0.70813443 -0.59641281] | Target: 0.8455438312927052 | Output: 1.0064451862004256
Input: [-0.76627588 -0.22203148  0.14491826 -0.92464247] | Target: 0.5014867041380001 | Output: 0.6985244881404524
Input: [-0.54892582  0.20719914 -0.76681321  0.93955098] | Target: -0.6280956729056199 | Output: -0.8038157628839517
Input: [-0.64337341  0.49544423 -0.11255878 -0.01282107] | Target: -0.9453137970150551 | Output: -0.6917058623207957
Input: [-0.82728321 -0.69829701 -0.57700406  0.67442232] | Target: -0.981931689754146 | Output: -0.7255615982013823
Input: [-0.98497539 -0.72891986 -0.1836953   0.24372919] | Target: -0.631495178088639 | Output: -0.4672955892533697
Input: [ 0.70800631 -0.55628296 -0.26687532 -0.34987773] | Target: 0.9751266382188684 | Output: 1.0716570688723852
Input: [ 0.75178324 -0.01347168  0.38898314  0.14288251] | Target: 0.8475520319175844 | Output: 1.0297373778462813
Input: [ 0.41136073 -0.14618654 -0.91102637 -0.93813825] | Target: 0.5519151840967939 | Output: 0.719232530065256
Input: [ 0.51018995 -0.37692397 -0.5011193   0.44394074] | Target: -0.05791369405285977 | Output: 0.1045185566220026
Input: [ 0.13749821 -0.37478774 -0.06327981  0.08022791] | Target: 0.3604760629800285 | Output: 0.581033153133897
Input: [ 0.09228736 -0.27344297  0.75162068 -0.23405879] | Target: 0.9760311433779838 | Output: 1.081680459832397
Input: [-0.50196384 -0.83118106 -0.25087767 -0.73796457] | Target: 0.7286194332234008 | Output: 0.9221118757545228
Input: [ 0.55164468 -0.25600115 -0.13504697  0.49848213] | Target: 0.17323827976742542 | Output: 0.3656280904840482
Input: [ 0.24950619  0.53158706 -0.86338517  0.47552992] | Target: -0.9987402624146927 | Output: -0.7664981960531116
Input: [ 0.51947747  0.94936431  0.43906985 -0.7269993 ] | Target: 0.6714637645748815 | Output: 0.8532973963682267
Input: [-0.6973039   0.0889062  -0.68445586 -0.75797046] | Target: -0.6538755685718755 | Output: -0.44621335401360546
Input: [-0.36976629 -0.43326151  0.66558198 -0.45645676] | Target: 0.9266998656020422 | Output: 1.0638593867835846
Input: [-0.99621318  0.45345917 -0.16715947  0.62688534] | Target: -0.7820045272552989 | Output: -0.7917563265749195
Input: [-0.66679933  0.85103131 -0.57861249  0.31616618] | Target: -0.6661117041117379 | Output: -0.7863852628956359
Input: [ 0.59984747  0.93320693 -0.64570456 -0.52073603] | Target: -0.44244927775403126 | Output: -0.2660792520817723
Input: [ 0.21660112 -0.82773408  0.18943024 -0.68955577] | Target: 0.9385039454562323 | Output: 0.9392055945366833
Input: [-0.75573124 -0.99691407 -0.14209714  0.48281666] | Target: -0.3743826932963817 | Output: -0.20608024154267734
Input: [ 0.43853717 -0.39233615  0.73276518  0.89920491] | Target: 0.6166133215349328 | Output: 0.7678611170078127
Input: [-0.02872933  0.30439828  0.37363359 -0.03299186] | Target: 0.07343169029757857 | Output: 0.2522158793456819
Input: [-0.6846535   0.45758929  0.30868531 -0.58891362] | Target: -0.24221081438382674 | Output: -0.08826879409381905
Input: [-0.42854772  0.22089627 -0.61139582  0.93547015] | Target: -0.810662489719735 | Output: -0.7996016921649469
Input: [-0.85755234  0.56294522  0.8090889   0.62068266] | Target: -0.943185741161217 | Output: -0.6947933619293316
Input: [-0.50101857  0.55840577 -0.17363426 -0.488904  ] | Target: -0.67735012743423 | Output: -0.4789611340539438
Input: [ 0.6573529  -0.81043102 -0.51834698 -0.83932845] | Target: 0.9763386465210206 | Output: 0.9791647608131111
Input: [-0.12988235  0.91252681  0.09633054  0.92392102] | Target: -0.9555716234730861 | Output: -0.7816963903676848
Input: [-0.28034689  0.85840257 -0.61431171 -0.28079694] | Target: -0.9951496388594328 | Output: -0.7229236373629513
Input: [ 0.16949099 -0.60932984 -0.85814292  0.88501474] | Target: -0.821671122614376 | Output: -0.5934300785928341
Input: [ 0.61929034 -0.04625989 -0.20040199 -0.71865318] | Target: 0.9260473813814688 | Output: 1.0481370157136598
Input: [ 0.52560633 -0.27594013  0.7360011  -0.84513606] | Target: 0.6881302680119759 | Output: 0.755803436793121
=========================================================

---------------------------------------------------------

Hidden units: 12
Epochs: 3000
Learning rate: 0.1

Errors during training:
Error at epoch 1 is 79.94463292352401
Train mean error at (after) epoch 1: 0.19986158230881002
Test error at (after) epoch 1: 0.19647241378453972
----------
Error at epoch 300 is 6.608818696321529
Train mean error at (after) epoch 300: 0.016522046740803823
Test error at (after) epoch 300: 0.022420892305158185
----------
Error at epoch 600 is 3.6339592601653754
Train mean error at (after) epoch 600: 0.009084898150413438
Test error at (after) epoch 600: 0.010773967064327263
----------
Error at epoch 900 is 2.406580022861225
Train mean error at (after) epoch 900: 0.006016450057153062
Test error at (after) epoch 900: 0.006629685997732108
----------
Error at epoch 1200 is 1.8209462408789026
Train mean error at (after) epoch 1200: 0.0045523656021972565
Test error at (after) epoch 1200: 0.004930116442223031
----------
Error at epoch 1500 is 1.4930190185344678
Train mean error at (after) epoch 1500: 0.0037325475463361696
Test error at (after) epoch 1500: 0.004023014451010331
----------
Error at epoch 1800 is 1.2854501633848523
Train mean error at (after) epoch 1800: 0.0032136254084621308
Test error at (after) epoch 1800: 0.0034387159221394505
----------
Error at epoch 2100 is 1.142228903107605
Train mean error at (after) epoch 2100: 0.0028555722577690125
Test error at (after) epoch 2100: 0.0030221664449514548
----------
Error at epoch 2400 is 1.0367595443040196
Train mean error at (after) epoch 2400: 0.002591898860760049
Test error at (after) epoch 2400: 0.002706958141074738
----------
Error at epoch 2700 is 0.955030862343896
Train mean error at (after) epoch 2700: 0.00238757715585974
Test error at (after) epoch 2700: 0.002458498459848993
----------
Error at epoch 3000 is 0.8891277369208206
Train mean error at (after) epoch 3000: 0.0022228193423020513
Test error at (after) epoch 3000: 0.0022565727019963964
----------


Outputs after training:

Input: [-0.49815014  0.41583469  0.94201245 -0.99618897] | Target: 0.8543072586148057 | Output: 0.9288930203870289
Input: [ 0.13818131  0.06095889 -0.62437142  0.40181237] | Target: -0.8128109128334502 | Output: -0.7748570805078414
Input: [-0.55703306 -0.36130396  0.43427241  0.52039419] | Target: -0.27813396526285905 | Output: -0.2891259949754357
Input: [-0.90268247 -0.77891602  0.66723982  0.70656042] | Target: -0.16236507366523303 | Output: -0.16231658729619433
Input: [-0.52071191 -0.17490864 -0.42110008  0.53739114] | Target: -0.9646980685355615 | Output: -0.877223610906326
Input: [-0.57989232  0.41914752 -0.89430089  0.4042967 ] | Target: -0.7472772503976836 | Output: -0.7946711888526539
Input: [ 0.41123637  0.50445406 -0.39235833  0.40965961] | Target: -0.7803564461209093 | Output: -0.7978153555242168
Input: [-0.84874982 -0.91212193 -0.57126008  0.78537851] | Target: -0.961735148149663 | Output: -0.9889011238919114
Input: [-0.83942584 -0.2382192  -0.41552901 -0.41150754] | Target: -0.5689496870929982 | Output: -0.5968438308077353
Input: [-0.63996411 -0.49290989  0.11924329  0.30074516] | Target: -0.32267669103540125 | Output: -0.33769115225951807
Input: [-0.08425944 -0.2955284  -0.89433919  0.83362651] | Target: -0.99853697393758 | Output: -0.9835284651988316
Input: [-0.88724799 -0.93995287  0.30061609 -0.73943079] | Target: 0.8878962036632344 | Output: 0.9622358471441352
Input: [ 0.50561153  0.84672172  0.59155033 -0.74158065] | Target: 0.8371330584929538 | Output: 0.8869355839669315
Input: [ 0.55932204 -0.69038757  0.19916301 -0.99000263] | Target: 0.6462936927156917 | Output: 0.6256560554779053
Input: [ 0.23615323 -0.64992727 -0.68035612 -0.17334199] | Target: 0.37005327868860116 | Output: 0.4059500805788935
Input: [ 0.49647156 -0.50333428 -0.40361241 -0.42994362] | Target: 0.8553038767682734 | Output: 0.8757233693422606
Input: [ 0.65655691  0.00372453 -0.82991759  0.87524947] | Target: -0.8685825297023326 | Output: -0.8972401903943983
Input: [0.27223884 0.49333075 0.04959079 0.92712367] | Target: -0.890582723559241 | Output: -0.9539856043032257
Input: [ 0.84876481  0.76225924 -0.08406463  0.43691027] | Target: -0.4209290928116743 | Output: -0.473170148258795
Input: [ 0.59751983 -0.2812373   0.78611368  0.44687436] | Target: 0.9384089629393059 | Output: 0.9177583452388054
Input: [ 0.34182235  0.5491084   0.40507799 -0.29701485] | Target: 0.47486162062233245 | Output: 0.5146150635048881
Input: [ 0.42283238  0.80968777 -0.82963418 -0.55610595] | Target: -0.6134198613415482 | Output: -0.5325690221767367
Input: [-0.50187166  0.92688959  0.40075995  0.043051  ] | Target: -0.877705252953404 | Output: -0.8897070787412604
Input: [-0.41943475 -0.61215892  0.45405389 -0.34328094] | Target: 0.8360583549340252 | Output: 0.8754980929795706
Input: [ 0.96795196 -0.28914334  0.63779078  0.32553259] | Target: 0.9999989591114976 | Output: 0.9683023669329698
Input: [ 0.75002122  0.83731922  0.08750354 -0.43598446] | Target: 0.4224892766972277 | Output: 0.4717187522451862
Input: [-0.84145098  0.59019999  0.57881044 -0.10527194] | Target: -0.6798577173579573 | Output: -0.686358192325899
Input: [-0.01354512  0.51651433  0.61839328 -0.54195236] | Target: 0.5893759863297461 | Output: 0.6274070161280165
Input: [-0.85226186  0.92039067 -0.40358247  0.82752148] | Target: -0.13740013643130405 | Output: -0.5331512479537284
Input: [-1.20208422e-04 -8.33435464e-01 -8.29094249e-01  2.57740819e-01] | Target: -0.2508128096089507 | Output: -0.29216411928781794
Input: [0.97440678 0.67632022 0.37177763 0.37898444] | Target: 0.2867951214724826 | Output: 0.33037529168308444
Input: [-0.96750271  0.40885678 -0.41633182 -0.04844435] | Target: -0.9849951142371354 | Output: -0.9426119209568303
Input: [ 0.5995541   0.55368425 -0.39807429  0.74575248] | Target: -0.8902787665928441 | Output: -0.9332843758157092
Input: [ 0.1147611   0.31365018 -0.33824567  0.28760157] | Target: -0.7343688350613843 | Output: -0.7356917905813422
Input: [ 0.36462015  0.58189491 -0.94305822 -0.36998795] | Target: -0.7105960731893447 | Output: -0.6406054358926544
Input: [-0.92163169 -0.48173233 -0.45552113  0.34317945] | Target: -0.9453283422404454 | Output: -0.8504117093919784
Input: [0.66100169 0.0159894  0.02375897 0.37858434] | Target: 0.2861313242993361 | Output: 0.32247385812586304
Input: [ 0.74774146 -0.40140906 -0.48244804  0.15224903] | Target: 0.4920591230971327 | Output: 0.5013174583422427
Input: [ 0.88537842  0.54493392 -0.24240907 -0.58675178] | Target: 0.6325082075942169 | Output: 0.6780512513048186
Input: [-0.89948922  0.30514915 -0.06677325 -0.23967053] | Target: -0.8581940351253253 | Output: -0.834349481953455
Input: [ 0.67803204  0.47533682  0.26972013 -0.27476103] | Target: 0.6795700314529539 | Output: 0.7078856456412896
Input: [-0.98083192 -0.4695752  -0.31786867  0.7619386 ] | Target: -0.9997946180377792 | Output: -0.9447126644528752
Input: [-0.11448304  0.78197704 -0.07385002  0.57302441] | Target: -0.999622948135676 | Output: -0.9709776772610839
Input: [ 0.92133849  0.82507178  0.74741915 -0.58603175] | Target: 0.9900648927020624 | Output: 0.9694496918474442
Input: [-0.60553526 -0.61901846  0.14587078 -0.17473924] | Target: 0.3279126629549906 | Output: 0.3813861203032356
Input: [-0.35802134  0.73015313  0.60293073  0.02384464] | Target: -0.48738142837990606 | Output: -0.5290221626896618
Input: [-0.1090036   0.16355674  0.52121077  0.26224029] | Target: -0.013589448699499802 | Output: -0.018819371510839983
Input: [0.24809978 0.13586941 0.70807115 0.35517622] | Target: 0.44853479420304265 | Output: 0.47498214663359994
Input: [-0.27152698 -0.3868816  -0.74856252  0.05681491] | Target: -0.636554775746118 | Output: -0.6150057977408152
Input: [ 0.00580885  0.59096635 -0.36767075  0.72869544] | Target: -0.993875985392774 | Output: -0.922144955627556
Input: [ 0.35481914  0.88069484 -0.95698046 -0.367384  ] | Target: -0.8981185186955181 | Output: -0.7938127231148739
Input: [-0.41922212 -0.34126958 -0.80916346  0.63907702] | Target: -0.9990054379643346 | Output: -0.9258089728550937
Input: [ 0.67552242 -0.3586028  -0.84792242 -0.68776653] | Target: 0.7668824355727715 | Output: 0.7930027323555702
Input: [0.35026043 0.96890192 0.68031271 0.59380282] | Target: -0.507371347467531 | Output: -0.600233392194227
Input: [-0.63373294 -0.22074043 -0.97588408 -0.83528859] | Target: -0.5257427095689864 | Output: -0.6302926300879551
Input: [-0.0222767   0.1081984  -0.76884935  0.75809839] | Target: -0.9962502691004255 | Output: -0.9195802684647759
Input: [ 0.87942357  0.4071619   0.30276464 -0.57790568] | Target: 0.9763612859488614 | Output: 0.9276344245527188
Input: [-0.36920023  0.30225159  0.1661646  -0.39389227] | Target: -0.11116471798811212 | Output: -0.10378098979948938
Input: [-0.06072322 -0.78714594 -0.67294101 -0.78471074] | Target: 0.7434354298423212 | Output: 0.848428369430952
Input: [-0.34393016  0.95254504 -0.31080191  0.81068077] | Target: -0.6621129592186771 | Output: -0.757431735110303
Input: [ 0.86965397  0.50771038 -0.95344631  0.79036643] | Target: -0.9822062805839687 | Output: -0.9691825659040665
Input: [ 0.55253134 -0.90575846  0.66876745  0.06928906] | Target: 0.8837539313124146 | Output: 0.962032476932364
Input: [-0.8891273   0.17029516  0.07761798  0.54324158] | Target: -0.9989536393372639 | Output: -0.8702073558674144
Input: [-0.03247545  0.62848862 -0.2840394  -0.85224449] | Target: -0.09262602421897013 | Output: -0.1257916044235314
Input: [-0.17492966  0.6020377  -0.13374702  0.40160947] | Target: -0.9667815476307677 | Output: -0.9274644902200968
Input: [ 0.33321489 -0.78608966 -0.70813443 -0.59641281] | Target: 0.8455438312927052 | Output: 0.9319721732860116
Input: [-0.76627588 -0.22203148  0.14491826 -0.92464247] | Target: 0.5014867041380001 | Output: 0.5387139724433233
Input: [-0.54892582  0.20719914 -0.76681321  0.93955098] | Target: -0.6280956729056199 | Output: -0.7249533934868573
Input: [-0.64337341  0.49544423 -0.11255878 -0.01282107] | Target: -0.9453137970150551 | Output: -0.9025273793840358
Input: [-0.82728321 -0.69829701 -0.57700406  0.67442232] | Target: -0.981931689754146 | Output: -0.9502039704817757
Input: [-0.98497539 -0.72891986 -0.1836953   0.24372919] | Target: -0.631495178088639 | Output: -0.6309361931835454
Input: [ 0.70800631 -0.55628296 -0.26687532 -0.34987773] | Target: 0.9751266382188684 | Output: 0.9034795433887666
Input: [ 0.75178324 -0.01347168  0.38898314  0.14288251] | Target: 0.8475520319175844 | Output: 0.8233373746382179
Input: [ 0.41136073 -0.14618654 -0.91102637 -0.93813825] | Target: 0.5519151840967939 | Output: 0.47963014873730436
Input: [ 0.51018995 -0.37692397 -0.5011193   0.44394074] | Target: -0.05791369405285977 | Output: -0.05005872522668367
Input: [ 0.13749821 -0.37478774 -0.06327981  0.08022791] | Target: 0.3604760629800285 | Output: 0.4153069692815944
Input: [ 0.09228736 -0.27344297  0.75162068 -0.23405879] | Target: 0.9760311433779838 | Output: 0.9013738035426615
Input: [-0.50196384 -0.83118106 -0.25087767 -0.73796457] | Target: 0.7286194332234008 | Output: 0.824774460594988
Input: [ 0.55164468 -0.25600115 -0.13504697  0.49848213] | Target: 0.17323827976742542 | Output: 0.20224583809671673
Input: [ 0.24950619  0.53158706 -0.86338517  0.47552992] | Target: -0.9987402624146927 | Output: -0.8990875949293039
Input: [ 0.51947747  0.94936431  0.43906985 -0.7269993 ] | Target: 0.6714637645748815 | Output: 0.7111974772226873
Input: [-0.6973039   0.0889062  -0.68445586 -0.75797046] | Target: -0.6538755685718755 | Output: -0.679148790752594
Input: [-0.36976629 -0.43326151  0.66558198 -0.45645676] | Target: 0.9266998656020422 | Output: 0.9296238962197347
Input: [-0.99621318  0.45345917 -0.16715947  0.62688534] | Target: -0.7820045272552989 | Output: -0.7247492200945869
Input: [-0.66679933  0.85103131 -0.57861249  0.31616618] | Target: -0.6661117041117379 | Output: -0.8316162866307885
Input: [ 0.59984747  0.93320693 -0.64570456 -0.52073603] | Target: -0.44244927775403126 | Output: -0.36256117058863746
Input: [ 0.21660112 -0.82773408  0.18943024 -0.68955577] | Target: 0.9385039454562323 | Output: 0.873331732664951
Input: [-0.75573124 -0.99691407 -0.14209714  0.48281666] | Target: -0.3743826932963817 | Output: -0.4084674019392842
Input: [ 0.43853717 -0.39233615  0.73276518  0.89920491] | Target: 0.6166133215349328 | Output: 0.6333820475700724
Input: [-0.02872933  0.30439828  0.37363359 -0.03299186] | Target: 0.07343169029757857 | Output: 0.09020603511568198
Input: [-0.6846535   0.45758929  0.30868531 -0.58891362] | Target: -0.24221081438382674 | Output: -0.2566978520832952
Input: [-0.42854772  0.22089627 -0.61139582  0.93547015] | Target: -0.810662489719735 | Output: -0.7953509447831617
Input: [-0.85755234  0.56294522  0.8090889   0.62068266] | Target: -0.943185741161217 | Output: -0.9612083529183986
Input: [-0.50101857  0.55840577 -0.17363426 -0.488904  ] | Target: -0.67735012743423 | Output: -0.6651651587713645
Input: [ 0.6573529  -0.81043102 -0.51834698 -0.83932845] | Target: 0.9763386465210206 | Output: 0.9565790386059245
Input: [-0.12988235  0.91252681  0.09633054  0.92392102] | Target: -0.9555716234730861 | Output: -0.9805801161269305
Input: [-0.28034689  0.85840257 -0.61431171 -0.28079694] | Target: -0.9951496388594328 | Output: -0.9780903582339209
Input: [ 0.16949099 -0.60932984 -0.85814292  0.88501474] | Target: -0.821671122614376 | Output: -0.8636963278813093
Input: [ 0.61929034 -0.04625989 -0.20040199 -0.71865318] | Target: 0.9260473813814688 | Output: 0.8975018835805735
Input: [ 0.52560633 -0.27594013  0.7360011  -0.84513606] | Target: 0.6881302680119759 | Output: 0.6752832060881736
---------------------------------------------------------

Hidden units: 12
Epochs: 10000
Learning rate: 0.1

Errors during training:
Error at epoch 1 is 381.4698808344442
Train mean error at (after) epoch 1: 0.9536747020861105
Test error at (after) epoch 1: 0.7002276098105499
----------
Error at epoch 1000 is 1.358804674214348
Train mean error at (after) epoch 1000: 0.00339701168553587
Test error at (after) epoch 1000: 0.003572232928371936
----------
Error at epoch 2000 is 1.0151199421528405
Train mean error at (after) epoch 2000: 0.0025377998553821014
Test error at (after) epoch 2000: 0.0028495690756119574
----------
Error at epoch 3000 is 0.8660785033933027
Train mean error at (after) epoch 3000: 0.002165196258483257
Test error at (after) epoch 3000: 0.002530480948878582
----------
Error at epoch 4000 is 0.7682159401992753
Train mean error at (after) epoch 4000: 0.0019205398504981883
Test error at (after) epoch 4000: 0.0022759559922048535
----------
Error at epoch 5000 is 0.6940871640528923
Train mean error at (after) epoch 5000: 0.0017352179101322307
Test error at (after) epoch 5000: 0.0020556219951911076
----------
Error at epoch 6000 is 0.6337877825205568
Train mean error at (after) epoch 6000: 0.0015844694563013919
Test error at (after) epoch 6000: 0.0018653014202080162
----------
Error at epoch 7000 is 0.5829441331642361
Train mean error at (after) epoch 7000: 0.0014573603329105901
Test error at (after) epoch 7000: 0.0017034463177002838
----------
Error at epoch 8000 is 0.5393497055357663
Train mean error at (after) epoch 8000: 0.0013483742638394159
Test error at (after) epoch 8000: 0.0015678251259130475
----------
Error at epoch 9000 is 0.501776447613851
Train mean error at (after) epoch 9000: 0.0012544411190346274
Test error at (after) epoch 9000: 0.0014555986953340694
----------
Error at epoch 10000 is 0.46943233650070837
Train mean error at (after) epoch 10000: 0.001173580841251771
Test error at (after) epoch 10000: 0.0013636774798291146
----------


Outputs after training:

Input: [-0.49815014  0.41583469  0.94201245 -0.99618897] | Target: 0.8543072586148057 | Output: 0.9285103821858954
Input: [ 0.13818131  0.06095889 -0.62437142  0.40181237] | Target: -0.8128109128334502 | Output: -0.7980590916046405
Input: [-0.55703306 -0.36130396  0.43427241  0.52039419] | Target: -0.27813396526285905 | Output: -0.2946145698349203
Input: [-0.90268247 -0.77891602  0.66723982  0.70656042] | Target: -0.16236507366523303 | Output: -0.1646094713703709
Input: [-0.52071191 -0.17490864 -0.42110008  0.53739114] | Target: -0.9646980685355615 | Output: -0.9129187338888076
Input: [-0.57989232  0.41914752 -0.89430089  0.4042967 ] | Target: -0.7472772503976836 | Output: -0.7205307896157384
Input: [ 0.41123637  0.50445406 -0.39235833  0.40965961] | Target: -0.7803564461209093 | Output: -0.7605675945119877
Input: [-0.84874982 -0.91212193 -0.57126008  0.78537851] | Target: -0.961735148149663 | Output: -0.9186780196165454
Input: [-0.83942584 -0.2382192  -0.41552901 -0.41150754] | Target: -0.5689496870929982 | Output: -0.6086131523632801
Input: [-0.63996411 -0.49290989  0.11924329  0.30074516] | Target: -0.32267669103540125 | Output: -0.33996680320131445
Input: [-0.08425944 -0.2955284  -0.89433919  0.83362651] | Target: -0.99853697393758 | Output: -0.9601557410145773
Input: [-0.88724799 -0.93995287  0.30061609 -0.73943079] | Target: 0.8878962036632344 | Output: 0.9073201142709796
Input: [ 0.50561153  0.84672172  0.59155033 -0.74158065] | Target: 0.8371330584929538 | Output: 0.8322833684147554
Input: [ 0.55932204 -0.69038757  0.19916301 -0.99000263] | Target: 0.6462936927156917 | Output: 0.6715942873654497
Input: [ 0.23615323 -0.64992727 -0.68035612 -0.17334199] | Target: 0.37005327868860116 | Output: 0.39891638966228427
Input: [ 0.49647156 -0.50333428 -0.40361241 -0.42994362] | Target: 0.8553038767682734 | Output: 0.8454241046105021
Input: [ 0.65655691  0.00372453 -0.82991759  0.87524947] | Target: -0.8685825297023326 | Output: -0.889829596592382
Input: [0.27223884 0.49333075 0.04959079 0.92712367] | Target: -0.890582723559241 | Output: -0.9187362060584756
Input: [ 0.84876481  0.76225924 -0.08406463  0.43691027] | Target: -0.4209290928116743 | Output: -0.4347077631316091
Input: [ 0.59751983 -0.2812373   0.78611368  0.44687436] | Target: 0.9384089629393059 | Output: 0.9160362766019846
Input: [ 0.34182235  0.5491084   0.40507799 -0.29701485] | Target: 0.47486162062233245 | Output: 0.5062974401821987
Input: [ 0.42283238  0.80968777 -0.82963418 -0.55610595] | Target: -0.6134198613415482 | Output: -0.6116798147882284
Input: [-0.50187166  0.92688959  0.40075995  0.043051  ] | Target: -0.877705252953404 | Output: -0.9179481669101722
Input: [-0.41943475 -0.61215892  0.45405389 -0.34328094] | Target: 0.8360583549340252 | Output: 0.835103475750354
Input: [ 0.96795196 -0.28914334  0.63779078  0.32553259] | Target: 0.9999989591114976 | Output: 0.925943562968829
Input: [ 0.75002122  0.83731922  0.08750354 -0.43598446] | Target: 0.4224892766972277 | Output: 0.4404635231733358
Input: [-0.84145098  0.59019999  0.57881044 -0.10527194] | Target: -0.6798577173579573 | Output: -0.6754297971012013
Input: [-0.01354512  0.51651433  0.61839328 -0.54195236] | Target: 0.5893759863297461 | Output: 0.632098147037386
Input: [-0.85226186  0.92039067 -0.40358247  0.82752148] | Target: -0.13740013643130405 | Output: -0.47035479436057026
Input: [-1.20208422e-04 -8.33435464e-01 -8.29094249e-01  2.57740819e-01] | Target: -0.2508128096089507 | Output: -0.24320605834440562
Input: [0.97440678 0.67632022 0.37177763 0.37898444] | Target: 0.2867951214724826 | Output: 0.3303119704360923
Input: [-0.96750271  0.40885678 -0.41633182 -0.04844435] | Target: -0.9849951142371354 | Output: -0.8721185840285718
Input: [ 0.5995541   0.55368425 -0.39807429  0.74575248] | Target: -0.8902787665928441 | Output: -0.864944812579724
Input: [ 0.1147611   0.31365018 -0.33824567  0.28760157] | Target: -0.7343688350613843 | Output: -0.7177551448589219
Input: [ 0.36462015  0.58189491 -0.94305822 -0.36998795] | Target: -0.7105960731893447 | Output: -0.7197015626948758
Input: [-0.92163169 -0.48173233 -0.45552113  0.34317945] | Target: -0.9453283422404454 | Output: -0.9018899250559523
Input: [0.66100169 0.0159894  0.02375897 0.37858434] | Target: 0.2861313242993361 | Output: 0.3259398219310068
Input: [ 0.74774146 -0.40140906 -0.48244804  0.15224903] | Target: 0.4920591230971327 | Output: 0.5159970998683878
Input: [ 0.88537842  0.54493392 -0.24240907 -0.58675178] | Target: 0.6325082075942169 | Output: 0.6509086661212649
Input: [-0.89948922  0.30514915 -0.06677325 -0.23967053] | Target: -0.8581940351253253 | Output: -0.8249423249580456
Input: [ 0.67803204  0.47533682  0.26972013 -0.27476103] | Target: 0.6795700314529539 | Output: 0.707460019922012
Input: [-0.98083192 -0.4695752  -0.31786867  0.7619386 ] | Target: -0.9997946180377792 | Output: -0.9835423552568944
Input: [-0.11448304  0.78197704 -0.07385002  0.57302441] | Target: -0.999622948135676 | Output: -0.9480161493436955
Input: [ 0.92133849  0.82507178  0.74741915 -0.58603175] | Target: 0.9900648927020624 | Output: 0.9548160693999318
Input: [-0.60553526 -0.61901846  0.14587078 -0.17473924] | Target: 0.3279126629549906 | Output: 0.3394726022956378
Input: [-0.35802134  0.73015313  0.60293073  0.02384464] | Target: -0.48738142837990606 | Output: -0.5288964682940767
Input: [-0.1090036   0.16355674  0.52121077  0.26224029] | Target: -0.013589448699499802 | Output: -0.00866583792423159
Input: [0.24809978 0.13586941 0.70807115 0.35517622] | Target: 0.44853479420304265 | Output: 0.4874774028841323
Input: [-0.27152698 -0.3868816  -0.74856252  0.05681491] | Target: -0.636554775746118 | Output: -0.6661570916393337
Input: [ 0.00580885  0.59096635 -0.36767075  0.72869544] | Target: -0.993875985392774 | Output: -0.907619938278058
Input: [ 0.35481914  0.88069484 -0.95698046 -0.367384  ] | Target: -0.8981185186955181 | Output: -0.9086579202163046
Input: [-0.41922212 -0.34126958 -0.80916346  0.63907702] | Target: -0.9990054379643346 | Output: -0.9425618107133752
Input: [ 0.67552242 -0.3586028  -0.84792242 -0.68776653] | Target: 0.7668824355727715 | Output: 0.7477362660181048
Input: [0.35026043 0.96890192 0.68031271 0.59380282] | Target: -0.507371347467531 | Output: -0.6172133008234054
Input: [-0.63373294 -0.22074043 -0.97588408 -0.83528859] | Target: -0.5257427095689864 | Output: -0.6035367235706443
Input: [-0.0222767   0.1081984  -0.76884935  0.75809839] | Target: -0.9962502691004255 | Output: -0.9245214515798968
Input: [ 0.87942357  0.4071619   0.30276464 -0.57790568] | Target: 0.9763612859488614 | Output: 0.9518214775713466
Input: [-0.36920023  0.30225159  0.1661646  -0.39389227] | Target: -0.11116471798811212 | Output: -0.11462491681152534
Input: [-0.06072322 -0.78714594 -0.67294101 -0.78471074] | Target: 0.7434354298423212 | Output: 0.8033189174676391
Input: [-0.34393016  0.95254504 -0.31080191  0.81068077] | Target: -0.6621129592186771 | Output: -0.7284587804543046
Input: [ 0.86965397  0.50771038 -0.95344631  0.79036643] | Target: -0.9822062805839687 | Output: -0.9694337967228536
Input: [ 0.55253134 -0.90575846  0.66876745  0.06928906] | Target: 0.8837539313124146 | Output: 0.8809117052120544
Input: [-0.8891273   0.17029516  0.07761798  0.54324158] | Target: -0.9989536393372639 | Output: -0.9738625849233329
Input: [-0.03247545  0.62848862 -0.2840394  -0.85224449] | Target: -0.09262602421897013 | Output: -0.08162485248707338
Input: [-0.17492966  0.6020377  -0.13374702  0.40160947] | Target: -0.9667815476307677 | Output: -0.9052229991741146
Input: [ 0.33321489 -0.78608966 -0.70813443 -0.59641281] | Target: 0.8455438312927052 | Output: 0.8658312381722643
Input: [-0.76627588 -0.22203148  0.14491826 -0.92464247] | Target: 0.5014867041380001 | Output: 0.5424729802455054
Input: [-0.54892582  0.20719914 -0.76681321  0.93955098] | Target: -0.6280956729056199 | Output: -0.7418405453570421
Input: [-0.64337341  0.49544423 -0.11255878 -0.01282107] | Target: -0.9453137970150551 | Output: -0.8807024917681332
Input: [-0.82728321 -0.69829701 -0.57700406  0.67442232] | Target: -0.981931689754146 | Output: -0.9385219670423796
Input: [-0.98497539 -0.72891986 -0.1836953   0.24372919] | Target: -0.631495178088639 | Output: -0.6290099814063573
Input: [ 0.70800631 -0.55628296 -0.26687532 -0.34987773] | Target: 0.9751266382188684 | Output: 0.9114873790151466
Input: [ 0.75178324 -0.01347168  0.38898314  0.14288251] | Target: 0.8475520319175844 | Output: 0.8380573650459925
Input: [ 0.41136073 -0.14618654 -0.91102637 -0.93813825] | Target: 0.5519151840967939 | Output: 0.5480556010012574
Input: [ 0.51018995 -0.37692397 -0.5011193   0.44394074] | Target: -0.05791369405285977 | Output: -0.05780115433682853
Input: [ 0.13749821 -0.37478774 -0.06327981  0.08022791] | Target: 0.3604760629800285 | Output: 0.3888080444739921
Input: [ 0.09228736 -0.27344297  0.75162068 -0.23405879] | Target: 0.9760311433779838 | Output: 0.9265717162227901
Input: [-0.50196384 -0.83118106 -0.25087767 -0.73796457] | Target: 0.7286194332234008 | Output: 0.7890461452832241
Input: [ 0.55164468 -0.25600115 -0.13504697  0.49848213] | Target: 0.17323827976742542 | Output: 0.1959280300327945
Input: [ 0.24950619  0.53158706 -0.86338517  0.47552992] | Target: -0.9987402624146927 | Output: -0.9199330868986794
Input: [ 0.51947747  0.94936431  0.43906985 -0.7269993 ] | Target: 0.6714637645748815 | Output: 0.6738169939209725
Input: [-0.6973039   0.0889062  -0.68445586 -0.75797046] | Target: -0.6538755685718755 | Output: -0.6925699408486994
Input: [-0.36976629 -0.43326151  0.66558198 -0.45645676] | Target: 0.9266998656020422 | Output: 0.9094718978973274
Input: [-0.99621318  0.45345917 -0.16715947  0.62688534] | Target: -0.7820045272552989 | Output: -0.8300359159256843
Input: [-0.66679933  0.85103131 -0.57861249  0.31616618] | Target: -0.6661117041117379 | Output: -0.6928401537039434
Input: [ 0.59984747  0.93320693 -0.64570456 -0.52073603] | Target: -0.44244927775403126 | Output: -0.42973294253808636
Input: [ 0.21660112 -0.82773408  0.18943024 -0.68955577] | Target: 0.9385039454562323 | Output: 0.8555408746652718
Input: [-0.75573124 -0.99691407 -0.14209714  0.48281666] | Target: -0.3743826932963817 | Output: -0.36833439264074286
Input: [ 0.43853717 -0.39233615  0.73276518  0.89920491] | Target: 0.6166133215349328 | Output: 0.617264935271049
Input: [-0.02872933  0.30439828  0.37363359 -0.03299186] | Target: 0.07343169029757857 | Output: 0.09106466440840802
Input: [-0.6846535   0.45758929  0.30868531 -0.58891362] | Target: -0.24221081438382674 | Output: -0.2579290287287507
Input: [-0.42854772  0.22089627 -0.61139582  0.93547015] | Target: -0.810662489719735 | Output: -0.8380573188390259
Input: [-0.85755234  0.56294522  0.8090889   0.62068266] | Target: -0.943185741161217 | Output: -0.9277693873379856
Input: [-0.50101857  0.55840577 -0.17363426 -0.488904  ] | Target: -0.67735012743423 | Output: -0.6920483638980118
Input: [ 0.6573529  -0.81043102 -0.51834698 -0.83932845] | Target: 0.9763386465210206 | Output: 0.9596148141060624
Input: [-0.12988235  0.91252681  0.09633054  0.92392102] | Target: -0.9555716234730861 | Output: -0.9917265476587179
Input: [-0.28034689  0.85840257 -0.61431171 -0.28079694] | Target: -0.9951496388594328 | Output: -0.9750204930850387
Input: [ 0.16949099 -0.60932984 -0.85814292  0.88501474] | Target: -0.821671122614376 | Output: -0.8236547528010546
Input: [ 0.61929034 -0.04625989 -0.20040199 -0.71865318] | Target: 0.9260473813814688 | Output: 0.9225171276095493
Input: [ 0.52560633 -0.27594013  0.7360011  -0.84513606] | Target: 0.6881302680119759 | Output: 0.6787754010171138
---------------------------------------------------------

Hidden units: 12
Epochs: 3000
Learning rate: 0.3

Errors during training:
Error at epoch 1 is 444.9214539502908
Train mean error at (after) epoch 1: 1.112303634875727
Test error at (after) epoch 1: 0.46787170649134535
----------
Error at epoch 300 is 1.978990161538941
Train mean error at (after) epoch 300: 0.004947475403847352
Test error at (after) epoch 300: 0.00500615371392738
----------
Error at epoch 600 is 1.16681721254896
Train mean error at (after) epoch 600: 0.0029170430313724
Test error at (after) epoch 600: 0.002719534839774486
----------
Error at epoch 900 is 0.9331926270019575
Train mean error at (after) epoch 900: 0.002332981567504894
Test error at (after) epoch 900: 0.0023368755464445996
----------
Error at epoch 1200 is 0.7979484842191741
Train mean error at (after) epoch 1200: 0.001994871210547935
Test error at (after) epoch 1200: 0.0021564793385633937
----------
Error at epoch 1500 is 0.6986966947365574
Train mean error at (after) epoch 1500: 0.0017467417368413935
Test error at (after) epoch 1500: 0.002021171428890546
----------
Error at epoch 1800 is 0.6201292980966592
Train mean error at (after) epoch 1800: 0.0015503232452416479
Test error at (after) epoch 1800: 0.0019068199522735035
----------
Error at epoch 2100 is 0.5557645330821167
Train mean error at (after) epoch 2100: 0.0013894113327052918
Test error at (after) epoch 2100: 0.0018064779127611875
----------
Error at epoch 2400 is 0.5017318027898917
Train mean error at (after) epoch 2400: 0.0012543295069747293
Test error at (after) epoch 2400: 0.0017165794373201967
----------
Error at epoch 2700 is 0.45547447140678937
Train mean error at (after) epoch 2700: 0.0011386861785169734
Test error at (after) epoch 2700: 0.001635061358851285
----------
Error at epoch 3000 is 0.4152955535927561
Train mean error at (after) epoch 3000: 0.0010382388839818902
Test error at (after) epoch 3000: 0.0015608508682376913
----------


Outputs after training:

Input: [-0.49815014  0.41583469  0.94201245 -0.99618897] | Target: 0.8543072586148057 | Output: 0.835835374046226
Input: [ 0.13818131  0.06095889 -0.62437142  0.40181237] | Target: -0.8128109128334502 | Output: -0.7992776894142651
Input: [-0.55703306 -0.36130396  0.43427241  0.52039419] | Target: -0.27813396526285905 | Output: -0.29647348337020085
Input: [-0.90268247 -0.77891602  0.66723982  0.70656042] | Target: -0.16236507366523303 | Output: -0.18174876044763766
Input: [-0.52071191 -0.17490864 -0.42110008  0.53739114] | Target: -0.9646980685355615 | Output: -0.9143528303071656
Input: [-0.57989232  0.41914752 -0.89430089  0.4042967 ] | Target: -0.7472772503976836 | Output: -0.7444006140753456
Input: [ 0.41123637  0.50445406 -0.39235833  0.40965961] | Target: -0.7803564461209093 | Output: -0.7826434747696549
Input: [-0.84874982 -0.91212193 -0.57126008  0.78537851] | Target: -0.961735148149663 | Output: -0.9722303002431806
Input: [-0.83942584 -0.2382192  -0.41552901 -0.41150754] | Target: -0.5689496870929982 | Output: -0.5864784152431853
Input: [-0.63996411 -0.49290989  0.11924329  0.30074516] | Target: -0.32267669103540125 | Output: -0.33414699947752846
Input: [-0.08425944 -0.2955284  -0.89433919  0.83362651] | Target: -0.99853697393758 | Output: -0.9609052523879112
Input: [-0.88724799 -0.93995287  0.30061609 -0.73943079] | Target: 0.8878962036632344 | Output: 0.9192059181515461
Input: [ 0.50561153  0.84672172  0.59155033 -0.74158065] | Target: 0.8371330584929538 | Output: 0.904670274071823
Input: [ 0.55932204 -0.69038757  0.19916301 -0.99000263] | Target: 0.6462936927156917 | Output: 0.6214235290138211
Input: [ 0.23615323 -0.64992727 -0.68035612 -0.17334199] | Target: 0.37005327868860116 | Output: 0.41432252487744825
Input: [ 0.49647156 -0.50333428 -0.40361241 -0.42994362] | Target: 0.8553038767682734 | Output: 0.8774066976664469
Input: [ 0.65655691  0.00372453 -0.82991759  0.87524947] | Target: -0.8685825297023326 | Output: -0.8368210355591615
Input: [0.27223884 0.49333075 0.04959079 0.92712367] | Target: -0.890582723559241 | Output: -0.8650170097524494
Input: [ 0.84876481  0.76225924 -0.08406463  0.43691027] | Target: -0.4209290928116743 | Output: -0.46330619728550265
Input: [ 0.59751983 -0.2812373   0.78611368  0.44687436] | Target: 0.9384089629393059 | Output: 0.9223468164616274
Input: [ 0.34182235  0.5491084   0.40507799 -0.29701485] | Target: 0.47486162062233245 | Output: 0.5317088243657777
Input: [ 0.42283238  0.80968777 -0.82963418 -0.55610595] | Target: -0.6134198613415482 | Output: -0.6261978209495902
Input: [-0.50187166  0.92688959  0.40075995  0.043051  ] | Target: -0.877705252953404 | Output: -0.8953841257783482
Input: [-0.41943475 -0.61215892  0.45405389 -0.34328094] | Target: 0.8360583549340252 | Output: 0.856409165629061
Input: [ 0.96795196 -0.28914334  0.63779078  0.32553259] | Target: 0.9999989591114976 | Output: 0.9500099074673926
Input: [ 0.75002122  0.83731922  0.08750354 -0.43598446] | Target: 0.4224892766972277 | Output: 0.4519762220611687
Input: [-0.84145098  0.59019999  0.57881044 -0.10527194] | Target: -0.6798577173579573 | Output: -0.6693761824542628
Input: [-0.01354512  0.51651433  0.61839328 -0.54195236] | Target: 0.5893759863297461 | Output: 0.6485310411488562
Input: [-0.85226186  0.92039067 -0.40358247  0.82752148] | Target: -0.13740013643130405 | Output: -0.5556506481782573
Input: [-1.20208422e-04 -8.33435464e-01 -8.29094249e-01  2.57740819e-01] | Target: -0.2508128096089507 | Output: -0.2651341771679654
Input: [0.97440678 0.67632022 0.37177763 0.37898444] | Target: 0.2867951214724826 | Output: 0.27615423402751627
Input: [-0.96750271  0.40885678 -0.41633182 -0.04844435] | Target: -0.9849951142371354 | Output: -0.947166524243708
Input: [ 0.5995541   0.55368425 -0.39807429  0.74575248] | Target: -0.8902787665928441 | Output: -0.8777471813624896
Input: [ 0.1147611   0.31365018 -0.33824567  0.28760157] | Target: -0.7343688350613843 | Output: -0.7419599126903439
Input: [ 0.36462015  0.58189491 -0.94305822 -0.36998795] | Target: -0.7105960731893447 | Output: -0.7027750115920486
Input: [-0.92163169 -0.48173233 -0.45552113  0.34317945] | Target: -0.9453283422404454 | Output: -0.9029939506554857
Input: [0.66100169 0.0159894  0.02375897 0.37858434] | Target: 0.2861313242993361 | Output: 0.29797697192230743
Input: [ 0.74774146 -0.40140906 -0.48244804  0.15224903] | Target: 0.4920591230971327 | Output: 0.4976938630415435
Input: [ 0.88537842  0.54493392 -0.24240907 -0.58675178] | Target: 0.6325082075942169 | Output: 0.628459559537279
Input: [-0.89948922  0.30514915 -0.06677325 -0.23967053] | Target: -0.8581940351253253 | Output: -0.8358713583500308
Input: [ 0.67803204  0.47533682  0.26972013 -0.27476103] | Target: 0.6795700314529539 | Output: 0.7128893737966476
Input: [-0.98083192 -0.4695752  -0.31786867  0.7619386 ] | Target: -0.9997946180377792 | Output: -0.957773622640047
Input: [-0.11448304  0.78197704 -0.07385002  0.57302441] | Target: -0.999622948135676 | Output: -0.9360315435489704
Input: [ 0.92133849  0.82507178  0.74741915 -0.58603175] | Target: 0.9900648927020624 | Output: 0.9996021099061706
Input: [-0.60553526 -0.61901846  0.14587078 -0.17473924] | Target: 0.3279126629549906 | Output: 0.36035770594432237
Input: [-0.35802134  0.73015313  0.60293073  0.02384464] | Target: -0.48738142837990606 | Output: -0.5271328360993173
Input: [-0.1090036   0.16355674  0.52121077  0.26224029] | Target: -0.013589448699499802 | Output: -0.025109247472013763
Input: [0.24809978 0.13586941 0.70807115 0.35517622] | Target: 0.44853479420304265 | Output: 0.4728365839807209
Input: [-0.27152698 -0.3868816  -0.74856252  0.05681491] | Target: -0.636554775746118 | Output: -0.6463807069513042
Input: [ 0.00580885  0.59096635 -0.36767075  0.72869544] | Target: -0.993875985392774 | Output: -0.9248702847618561
Input: [ 0.35481914  0.88069484 -0.95698046 -0.367384  ] | Target: -0.8981185186955181 | Output: -0.8690295577387964
Input: [-0.41922212 -0.34126958 -0.80916346  0.63907702] | Target: -0.9990054379643346 | Output: -0.9446233700353365
Input: [ 0.67552242 -0.3586028  -0.84792242 -0.68776653] | Target: 0.7668824355727715 | Output: 0.7699391472653941
Input: [0.35026043 0.96890192 0.68031271 0.59380282] | Target: -0.507371347467531 | Output: -0.5186796121851195
Input: [-0.63373294 -0.22074043 -0.97588408 -0.83528859] | Target: -0.5257427095689864 | Output: -0.5773379821512046
Input: [-0.0222767   0.1081984  -0.76884935  0.75809839] | Target: -0.9962502691004255 | Output: -0.9344233326954171
Input: [ 0.87942357  0.4071619   0.30276464 -0.57790568] | Target: 0.9763612859488614 | Output: 0.9469048787172801
Input: [-0.36920023  0.30225159  0.1661646  -0.39389227] | Target: -0.11116471798811212 | Output: -0.11011684797128835
Input: [-0.06072322 -0.78714594 -0.67294101 -0.78471074] | Target: 0.7434354298423212 | Output: 0.7433916601701295
Input: [-0.34393016  0.95254504 -0.31080191  0.81068077] | Target: -0.6621129592186771 | Output: -0.7539742869894801
Input: [ 0.86965397  0.50771038 -0.95344631  0.79036643] | Target: -0.9822062805839687 | Output: -0.9774585212942447
Input: [ 0.55253134 -0.90575846  0.66876745  0.06928906] | Target: 0.8837539313124146 | Output: 0.829690307673174
Input: [-0.8891273   0.17029516  0.07761798  0.54324158] | Target: -0.9989536393372639 | Output: -0.9581439609086898
Input: [-0.03247545  0.62848862 -0.2840394  -0.85224449] | Target: -0.09262602421897013 | Output: -0.10005472922412528
Input: [-0.17492966  0.6020377  -0.13374702  0.40160947] | Target: -0.9667815476307677 | Output: -0.9193496912663659
Input: [ 0.33321489 -0.78608966 -0.70813443 -0.59641281] | Target: 0.8455438312927052 | Output: 0.8437321506720007
Input: [-0.76627588 -0.22203148  0.14491826 -0.92464247] | Target: 0.5014867041380001 | Output: 0.5069555705719128
Input: [-0.54892582  0.20719914 -0.76681321  0.93955098] | Target: -0.6280956729056199 | Output: -0.7195040779084673
Input: [-0.64337341  0.49544423 -0.11255878 -0.01282107] | Target: -0.9453137970150551 | Output: -0.9192348097676865
Input: [-0.82728321 -0.69829701 -0.57700406  0.67442232] | Target: -0.981931689754146 | Output: -0.9587726556719857
Input: [-0.98497539 -0.72891986 -0.1836953   0.24372919] | Target: -0.631495178088639 | Output: -0.6489696575656982
Input: [ 0.70800631 -0.55628296 -0.26687532 -0.34987773] | Target: 0.9751266382188684 | Output: 0.9632297472942645
Input: [ 0.75178324 -0.01347168  0.38898314  0.14288251] | Target: 0.8475520319175844 | Output: 0.8446396250610814
Input: [ 0.41136073 -0.14618654 -0.91102637 -0.93813825] | Target: 0.5519151840967939 | Output: 0.5900897400868659
Input: [ 0.51018995 -0.37692397 -0.5011193   0.44394074] | Target: -0.05791369405285977 | Output: -0.054918137836409975
Input: [ 0.13749821 -0.37478774 -0.06327981  0.08022791] | Target: 0.3604760629800285 | Output: 0.4280762617662103
Input: [ 0.09228736 -0.27344297  0.75162068 -0.23405879] | Target: 0.9760311433779838 | Output: 0.9504903888289274
Input: [-0.50196384 -0.83118106 -0.25087767 -0.73796457] | Target: 0.7286194332234008 | Output: 0.7537472561264922
Input: [ 0.55164468 -0.25600115 -0.13504697  0.49848213] | Target: 0.17323827976742542 | Output: 0.19716360855937332
Input: [ 0.24950619  0.53158706 -0.86338517  0.47552992] | Target: -0.9987402624146927 | Output: -0.9416354588982612
Input: [ 0.51947747  0.94936431  0.43906985 -0.7269993 ] | Target: 0.6714637645748815 | Output: 0.749210320775038
Input: [-0.6973039   0.0889062  -0.68445586 -0.75797046] | Target: -0.6538755685718755 | Output: -0.6766567731631975
Input: [-0.36976629 -0.43326151  0.66558198 -0.45645676] | Target: 0.9266998656020422 | Output: 0.9194127419555881
Input: [-0.99621318  0.45345917 -0.16715947  0.62688534] | Target: -0.7820045272552989 | Output: -0.86047683252175
Input: [-0.66679933  0.85103131 -0.57861249  0.31616618] | Target: -0.6661117041117379 | Output: -0.7388381243848291
Input: [ 0.59984747  0.93320693 -0.64570456 -0.52073603] | Target: -0.44244927775403126 | Output: -0.47535320692768335
Input: [ 0.21660112 -0.82773408  0.18943024 -0.68955577] | Target: 0.9385039454562323 | Output: 0.8528122661768717
Input: [-0.75573124 -0.99691407 -0.14209714  0.48281666] | Target: -0.3743826932963817 | Output: -0.43102488504144887
Input: [ 0.43853717 -0.39233615  0.73276518  0.89920491] | Target: 0.6166133215349328 | Output: 0.653088416722667
Input: [-0.02872933  0.30439828  0.37363359 -0.03299186] | Target: 0.07343169029757857 | Output: 0.0838905293223543
Input: [-0.6846535   0.45758929  0.30868531 -0.58891362] | Target: -0.24221081438382674 | Output: -0.23781284072805325
Input: [-0.42854772  0.22089627 -0.61139582  0.93547015] | Target: -0.810662489719735 | Output: -0.8095152858854521
Input: [-0.85755234  0.56294522  0.8090889   0.62068266] | Target: -0.943185741161217 | Output: -0.9385395263263506
Input: [-0.50101857  0.55840577 -0.17363426 -0.488904  ] | Target: -0.67735012743423 | Output: -0.7040767213511501
Input: [ 0.6573529  -0.81043102 -0.51834698 -0.83932845] | Target: 0.9763386465210206 | Output: 0.9213527950652202
Input: [-0.12988235  0.91252681  0.09633054  0.92392102] | Target: -0.9555716234730861 | Output: -0.9197016502813192
Input: [-0.28034689  0.85840257 -0.61431171 -0.28079694] | Target: -0.9951496388594328 | Output: -0.9348288889879561
Input: [ 0.16949099 -0.60932984 -0.85814292  0.88501474] | Target: -0.821671122614376 | Output: -0.8138821001449886
Input: [ 0.61929034 -0.04625989 -0.20040199 -0.71865318] | Target: 0.9260473813814688 | Output: 0.9211855569101247
Input: [ 0.52560633 -0.27594013  0.7360011  -0.84513606] | Target: 0.6881302680119759 | Output: 0.6647948063049839
---------------------------------------------------------

Hidden units: 12
Epochs: 10000
Learning rate: 0.3

Errors during training:
Error at epoch 1 is 177.40800056571007
Train mean error at (after) epoch 1: 0.44352000141427517
Test error at (after) epoch 1: 0.16197808119318272
----------
Error at epoch 1000 is 0.5962583746705075
Train mean error at (after) epoch 1000: 0.0014906459366762687
Test error at (after) epoch 1000: 0.0015421778850481696
----------
Error at epoch 2000 is 0.4312859972935303
Train mean error at (after) epoch 2000: 0.0010782149932338258
Test error at (after) epoch 2000: 0.0011805104612569487
----------
Error at epoch 3000 is 0.34746276662889986
Train mean error at (after) epoch 3000: 0.0008686569165722496
Test error at (after) epoch 3000: 0.0009756262486539886
----------
Error at epoch 4000 is 0.29642983278984936
Train mean error at (after) epoch 4000: 0.0007410745819746234
Test error at (after) epoch 4000: 0.0008575212996421586
----------
Error at epoch 5000 is 0.2618157407778249
Train mean error at (after) epoch 5000: 0.0006545393519445622
Test error at (after) epoch 5000: 0.0007844371073108792
----------
Error at epoch 6000 is 0.23631237404464178
Train mean error at (after) epoch 6000: 0.0005907809351116044
Test error at (after) epoch 6000: 0.0007337927071222369
----------
Error at epoch 7000 is 0.21625172186227232
Train mean error at (after) epoch 7000: 0.0005406293046556808
Test error at (after) epoch 7000: 0.0006944810847710339
----------
Error at epoch 8000 is 0.2164199270328507
Train mean error at (after) epoch 8000: 0.0005410498175821267
Test error at (after) epoch 8000: 0.0007195834892627819
----------
Error at epoch 9000 is 0.1997932224360167
Train mean error at (after) epoch 9000: 0.0004994830560900417
Test error at (after) epoch 9000: 0.0006815917025202131
----------
Error at epoch 10000 is 0.20009230984344067
Train mean error at (after) epoch 10000: 0.0005002307746086017
Test error at (after) epoch 10000: 0.000703699556400499
----------


Outputs after training:

Input: [-0.49815014  0.41583469  0.94201245 -0.99618897] | Target: 0.8543072586148057 | Output: 0.8428151002029995
Input: [ 0.13818131  0.06095889 -0.62437142  0.40181237] | Target: -0.8128109128334502 | Output: -0.8028376508777678
Input: [-0.55703306 -0.36130396  0.43427241  0.52039419] | Target: -0.27813396526285905 | Output: -0.2812626962574295
Input: [-0.90268247 -0.77891602  0.66723982  0.70656042] | Target: -0.16236507366523303 | Output: -0.18218136890478703
Input: [-0.52071191 -0.17490864 -0.42110008  0.53739114] | Target: -0.9646980685355615 | Output: -0.9343925389576255
Input: [-0.57989232  0.41914752 -0.89430089  0.4042967 ] | Target: -0.7472772503976836 | Output: -0.6729854436973008
Input: [ 0.41123637  0.50445406 -0.39235833  0.40965961] | Target: -0.7803564461209093 | Output: -0.7739004109014948
Input: [-0.84874982 -0.91212193 -0.57126008  0.78537851] | Target: -0.961735148149663 | Output: -0.9506789028709517
Input: [-0.83942584 -0.2382192  -0.41552901 -0.41150754] | Target: -0.5689496870929982 | Output: -0.5776606428690332
Input: [-0.63996411 -0.49290989  0.11924329  0.30074516] | Target: -0.32267669103540125 | Output: -0.33449503721450535
Input: [-0.08425944 -0.2955284  -0.89433919  0.83362651] | Target: -0.99853697393758 | Output: -0.9785546527475716
Input: [-0.88724799 -0.93995287  0.30061609 -0.73943079] | Target: 0.8878962036632344 | Output: 0.8759646748413998
Input: [ 0.50561153  0.84672172  0.59155033 -0.74158065] | Target: 0.8371330584929538 | Output: 0.8793963480377023
Input: [ 0.55932204 -0.69038757  0.19916301 -0.99000263] | Target: 0.6462936927156917 | Output: 0.6342149134724941
Input: [ 0.23615323 -0.64992727 -0.68035612 -0.17334199] | Target: 0.37005327868860116 | Output: 0.40252572099123374
Input: [ 0.49647156 -0.50333428 -0.40361241 -0.42994362] | Target: 0.8553038767682734 | Output: 0.8720425736436326
Input: [ 0.65655691  0.00372453 -0.82991759  0.87524947] | Target: -0.8685825297023326 | Output: -0.8092362106445632
Input: [0.27223884 0.49333075 0.04959079 0.92712367] | Target: -0.890582723559241 | Output: -0.8891324001473
Input: [ 0.84876481  0.76225924 -0.08406463  0.43691027] | Target: -0.4209290928116743 | Output: -0.41360482880798555
Input: [ 0.59751983 -0.2812373   0.78611368  0.44687436] | Target: 0.9384089629393059 | Output: 0.9481081766800941
Input: [ 0.34182235  0.5491084   0.40507799 -0.29701485] | Target: 0.47486162062233245 | Output: 0.5249874174875557
Input: [ 0.42283238  0.80968777 -0.82963418 -0.55610595] | Target: -0.6134198613415482 | Output: -0.6275561512654692
Input: [-0.50187166  0.92688959  0.40075995  0.043051  ] | Target: -0.877705252953404 | Output: -0.9090739396608922
Input: [-0.41943475 -0.61215892  0.45405389 -0.34328094] | Target: 0.8360583549340252 | Output: 0.8483421473808388
Input: [ 0.96795196 -0.28914334  0.63779078  0.32553259] | Target: 0.9999989591114976 | Output: 1.0453257291752132
Input: [ 0.75002122  0.83731922  0.08750354 -0.43598446] | Target: 0.4224892766972277 | Output: 0.4399012838540173
Input: [-0.84145098  0.59019999  0.57881044 -0.10527194] | Target: -0.6798577173579573 | Output: -0.6940612843319447
Input: [-0.01354512  0.51651433  0.61839328 -0.54195236] | Target: 0.5893759863297461 | Output: 0.6417743394846077
Input: [-0.85226186  0.92039067 -0.40358247  0.82752148] | Target: -0.13740013643130405 | Output: -0.3848380121158017
Input: [-1.20208422e-04 -8.33435464e-01 -8.29094249e-01  2.57740819e-01] | Target: -0.2508128096089507 | Output: -0.25975393715504225
Input: [0.97440678 0.67632022 0.37177763 0.37898444] | Target: 0.2867951214724826 | Output: 0.28774239042337735
Input: [-0.96750271  0.40885678 -0.41633182 -0.04844435] | Target: -0.9849951142371354 | Output: -0.9688977039853383
Input: [ 0.5995541   0.55368425 -0.39807429  0.74575248] | Target: -0.8902787665928441 | Output: -0.8633059355093446
Input: [ 0.1147611   0.31365018 -0.33824567  0.28760157] | Target: -0.7343688350613843 | Output: -0.7424639388241508
Input: [ 0.36462015  0.58189491 -0.94305822 -0.36998795] | Target: -0.7105960731893447 | Output: -0.7230831071644557
Input: [-0.92163169 -0.48173233 -0.45552113  0.34317945] | Target: -0.9453283422404454 | Output: -0.9137609291832965
Input: [0.66100169 0.0159894  0.02375897 0.37858434] | Target: 0.2861313242993361 | Output: 0.2956845359686966
Input: [ 0.74774146 -0.40140906 -0.48244804  0.15224903] | Target: 0.4920591230971327 | Output: 0.5088710230686168
Input: [ 0.88537842  0.54493392 -0.24240907 -0.58675178] | Target: 0.6325082075942169 | Output: 0.6268176100725893
Input: [-0.89948922  0.30514915 -0.06677325 -0.23967053] | Target: -0.8581940351253253 | Output: -0.8581302819778713
Input: [ 0.67803204  0.47533682  0.26972013 -0.27476103] | Target: 0.6795700314529539 | Output: 0.7148996909147063
Input: [-0.98083192 -0.4695752  -0.31786867  0.7619386 ] | Target: -0.9997946180377792 | Output: -0.9702727392248958
Input: [-0.11448304  0.78197704 -0.07385002  0.57302441] | Target: -0.999622948135676 | Output: -0.9456653783163317
Input: [ 0.92133849  0.82507178  0.74741915 -0.58603175] | Target: 0.9900648927020624 | Output: 0.995980880550335
Input: [-0.60553526 -0.61901846  0.14587078 -0.17473924] | Target: 0.3279126629549906 | Output: 0.3443840659633862
Input: [-0.35802134  0.73015313  0.60293073  0.02384464] | Target: -0.48738142837990606 | Output: -0.5295645504458895
Input: [-0.1090036   0.16355674  0.52121077  0.26224029] | Target: -0.013589448699499802 | Output: -0.0023084024079585985
Input: [0.24809978 0.13586941 0.70807115 0.35517622] | Target: 0.44853479420304265 | Output: 0.49137486980536027
Input: [-0.27152698 -0.3868816  -0.74856252  0.05681491] | Target: -0.636554775746118 | Output: -0.6655074677559365
Input: [ 0.00580885  0.59096635 -0.36767075  0.72869544] | Target: -0.993875985392774 | Output: -0.9527130518688242
Input: [ 0.35481914  0.88069484 -0.95698046 -0.367384  ] | Target: -0.8981185186955181 | Output: -0.8895331398443121
Input: [-0.41922212 -0.34126958 -0.80916346  0.63907702] | Target: -0.9990054379643346 | Output: -0.9520995265830732
Input: [ 0.67552242 -0.3586028  -0.84792242 -0.68776653] | Target: 0.7668824355727715 | Output: 0.7591309740120133
Input: [0.35026043 0.96890192 0.68031271 0.59380282] | Target: -0.507371347467531 | Output: -0.5317860330801347
Input: [-0.63373294 -0.22074043 -0.97588408 -0.83528859] | Target: -0.5257427095689864 | Output: -0.5275893972923861
Input: [-0.0222767   0.1081984  -0.76884935  0.75809839] | Target: -0.9962502691004255 | Output: -0.9636871995792553
Input: [ 0.87942357  0.4071619   0.30276464 -0.57790568] | Target: 0.9763612859488614 | Output: 0.9609523592678157
Input: [-0.36920023  0.30225159  0.1661646  -0.39389227] | Target: -0.11116471798811212 | Output: -0.12077826757985394
Input: [-0.06072322 -0.78714594 -0.67294101 -0.78471074] | Target: 0.7434354298423212 | Output: 0.7708704816578091
Input: [-0.34393016  0.95254504 -0.31080191  0.81068077] | Target: -0.6621129592186771 | Output: -0.6921455436757715
Input: [ 0.86965397  0.50771038 -0.95344631  0.79036643] | Target: -0.9822062805839687 | Output: -0.9842817848358032
Input: [ 0.55253134 -0.90575846  0.66876745  0.06928906] | Target: 0.8837539313124146 | Output: 0.882785863609483
Input: [-0.8891273   0.17029516  0.07761798  0.54324158] | Target: -0.9989536393372639 | Output: -0.9646578275958477
Input: [-0.03247545  0.62848862 -0.2840394  -0.85224449] | Target: -0.09262602421897013 | Output: -0.1147048718689751
Input: [-0.17492966  0.6020377  -0.13374702  0.40160947] | Target: -0.9667815476307677 | Output: -0.925965003741587
Input: [ 0.33321489 -0.78608966 -0.70813443 -0.59641281] | Target: 0.8455438312927052 | Output: 0.8645707069076296
Input: [-0.76627588 -0.22203148  0.14491826 -0.92464247] | Target: 0.5014867041380001 | Output: 0.494714532599661
Input: [-0.54892582  0.20719914 -0.76681321  0.93955098] | Target: -0.6280956729056199 | Output: -0.7030052741999331
Input: [-0.64337341  0.49544423 -0.11255878 -0.01282107] | Target: -0.9453137970150551 | Output: -0.935234507663026
Input: [-0.82728321 -0.69829701 -0.57700406  0.67442232] | Target: -0.981931689754146 | Output: -0.9591989253511357
Input: [-0.98497539 -0.72891986 -0.1836953   0.24372919] | Target: -0.631495178088639 | Output: -0.634088821743291
Input: [ 0.70800631 -0.55628296 -0.26687532 -0.34987773] | Target: 0.9751266382188684 | Output: 0.9725426953168317
Input: [ 0.75178324 -0.01347168  0.38898314  0.14288251] | Target: 0.8475520319175844 | Output: 0.872707306322867
Input: [ 0.41136073 -0.14618654 -0.91102637 -0.93813825] | Target: 0.5519151840967939 | Output: 0.5435565451855877
Input: [ 0.51018995 -0.37692397 -0.5011193   0.44394074] | Target: -0.05791369405285977 | Output: -0.05269840632770545
Input: [ 0.13749821 -0.37478774 -0.06327981  0.08022791] | Target: 0.3604760629800285 | Output: 0.4013190639212886
Input: [ 0.09228736 -0.27344297  0.75162068 -0.23405879] | Target: 0.9760311433779838 | Output: 0.9457844079243609
Input: [-0.50196384 -0.83118106 -0.25087767 -0.73796457] | Target: 0.7286194332234008 | Output: 0.7441226117459792
Input: [ 0.55164468 -0.25600115 -0.13504697  0.49848213] | Target: 0.17323827976742542 | Output: 0.17899999538788314
Input: [ 0.24950619  0.53158706 -0.86338517  0.47552992] | Target: -0.9987402624146927 | Output: -0.9574577412472561
Input: [ 0.51947747  0.94936431  0.43906985 -0.7269993 ] | Target: 0.6714637645748815 | Output: 0.7054137707521313
Input: [-0.6973039   0.0889062  -0.68445586 -0.75797046] | Target: -0.6538755685718755 | Output: -0.6516744038615903
Input: [-0.36976629 -0.43326151  0.66558198 -0.45645676] | Target: 0.9266998656020422 | Output: 0.9273944911708729
Input: [-0.99621318  0.45345917 -0.16715947  0.62688534] | Target: -0.7820045272552989 | Output: -0.817307712072211
Input: [-0.66679933  0.85103131 -0.57861249  0.31616618] | Target: -0.6661117041117379 | Output: -0.6628805811927773
Input: [ 0.59984747  0.93320693 -0.64570456 -0.52073603] | Target: -0.44244927775403126 | Output: -0.4642909483734853
Input: [ 0.21660112 -0.82773408  0.18943024 -0.68955577] | Target: 0.9385039454562323 | Output: 0.8514311441875986
Input: [-0.75573124 -0.99691407 -0.14209714  0.48281666] | Target: -0.3743826932963817 | Output: -0.3809418858399056
Input: [ 0.43853717 -0.39233615  0.73276518  0.89920491] | Target: 0.6166133215349328 | Output: 0.5963117279980658
Input: [-0.02872933  0.30439828  0.37363359 -0.03299186] | Target: 0.07343169029757857 | Output: 0.08884243046246504
Input: [-0.6846535   0.45758929  0.30868531 -0.58891362] | Target: -0.24221081438382674 | Output: -0.2353997108443708
Input: [-0.42854772  0.22089627 -0.61139582  0.93547015] | Target: -0.810662489719735 | Output: -0.8373925458231741
Input: [-0.85755234  0.56294522  0.8090889   0.62068266] | Target: -0.943185741161217 | Output: -0.933874289738825
Input: [-0.50101857  0.55840577 -0.17363426 -0.488904  ] | Target: -0.67735012743423 | Output: -0.7033139845872309
Input: [ 0.6573529  -0.81043102 -0.51834698 -0.83932845] | Target: 0.9763386465210206 | Output: 0.9471974237075436
Input: [-0.12988235  0.91252681  0.09633054  0.92392102] | Target: -0.9555716234730861 | Output: -0.9601128534173379
Input: [-0.28034689  0.85840257 -0.61431171 -0.28079694] | Target: -0.9951496388594328 | Output: -0.9343898119496983
Input: [ 0.16949099 -0.60932984 -0.85814292  0.88501474] | Target: -0.821671122614376 | Output: -0.7839930908819166
Input: [ 0.61929034 -0.04625989 -0.20040199 -0.71865318] | Target: 0.9260473813814688 | Output: 0.9186818908342431
Input: [ 0.52560633 -0.27594013  0.7360011  -0.84513606] | Target: 0.6881302680119759 | Output: 0.6542384810143617
---------------------------------------------------------

Hidden units: 12
Epochs: 3000
Learning rate: 0.5

Errors during training:
Error at epoch 1 is 99.70359766528573
Train mean error at (after) epoch 1: 0.24925899416321431
Test error at (after) epoch 1: 0.10978609600273542
----------
Error at epoch 300 is 1.2038642374123296
Train mean error at (after) epoch 300: 0.0030096605935308243
Test error at (after) epoch 300: 0.003435712822058315
----------
Error at epoch 600 is 0.8318829237424902
Train mean error at (after) epoch 600: 0.0020797073093562256
Test error at (after) epoch 600: 0.0024845999720220398
----------
Error at epoch 900 is 0.6400279512738106
Train mean error at (after) epoch 900: 0.0016000698781845266
Test error at (after) epoch 900: 0.001922172161122421
----------
Error at epoch 1200 is 0.5274117023431553
Train mean error at (after) epoch 1200: 0.0013185292558578882
Test error at (after) epoch 1200: 0.0015741547930798164
----------
Error at epoch 1500 is 0.5326835761752536
Train mean error at (after) epoch 1500: 0.001331708940438134
Test error at (after) epoch 1500: 0.0015834536150226626
----------
Error at epoch 1800 is 0.4615918631408999
Train mean error at (after) epoch 1800: 0.0011539796578522497
Test error at (after) epoch 1800: 0.0013857573426473652
----------
Error at epoch 2100 is 0.4114186241665475
Train mean error at (after) epoch 2100: 0.0010285465604163687
Test error at (after) epoch 2100: 0.0012703738904726188
----------
Error at epoch 2400 is 0.4295368750854088
Train mean error at (after) epoch 2400: 0.001073842187713522
Test error at (after) epoch 2400: 0.0013630400414547125
----------
Error at epoch 2700 is 0.3847002459203243
Train mean error at (after) epoch 2700: 0.0009617506148008108
Test error at (after) epoch 2700: 0.001267206008869835
----------
Error at epoch 3000 is 0.3497600249028396
Train mean error at (after) epoch 3000: 0.000874400062257099
Test error at (after) epoch 3000: 0.0012038528709480518
----------


Outputs after training:

Input: [-0.49815014  0.41583469  0.94201245 -0.99618897] | Target: 0.8543072586148057 | Output: 0.8625358832756479
Input: [ 0.13818131  0.06095889 -0.62437142  0.40181237] | Target: -0.8128109128334502 | Output: -0.8082337741384862
Input: [-0.55703306 -0.36130396  0.43427241  0.52039419] | Target: -0.27813396526285905 | Output: -0.3046888863931013
Input: [-0.90268247 -0.77891602  0.66723982  0.70656042] | Target: -0.16236507366523303 | Output: -0.17678186791463418
Input: [-0.52071191 -0.17490864 -0.42110008  0.53739114] | Target: -0.9646980685355615 | Output: -0.9117014340137427
Input: [-0.57989232  0.41914752 -0.89430089  0.4042967 ] | Target: -0.7472772503976836 | Output: -0.7086251848925912
Input: [ 0.41123637  0.50445406 -0.39235833  0.40965961] | Target: -0.7803564461209093 | Output: -0.7853431138294373
Input: [-0.84874982 -0.91212193 -0.57126008  0.78537851] | Target: -0.961735148149663 | Output: -0.9226223022991168
Input: [-0.83942584 -0.2382192  -0.41552901 -0.41150754] | Target: -0.5689496870929982 | Output: -0.5880100517617624
Input: [-0.63996411 -0.49290989  0.11924329  0.30074516] | Target: -0.32267669103540125 | Output: -0.3400860442734183
Input: [-0.08425944 -0.2955284  -0.89433919  0.83362651] | Target: -0.99853697393758 | Output: -0.9278712657646954
Input: [-0.88724799 -0.93995287  0.30061609 -0.73943079] | Target: 0.8878962036632344 | Output: 0.8915906323505364
Input: [ 0.50561153  0.84672172  0.59155033 -0.74158065] | Target: 0.8371330584929538 | Output: 0.8498293916076612
Input: [ 0.55932204 -0.69038757  0.19916301 -0.99000263] | Target: 0.6462936927156917 | Output: 0.6167581977107867
Input: [ 0.23615323 -0.64992727 -0.68035612 -0.17334199] | Target: 0.37005327868860116 | Output: 0.3870518808334059
Input: [ 0.49647156 -0.50333428 -0.40361241 -0.42994362] | Target: 0.8553038767682734 | Output: 0.8811748037086823
Input: [ 0.65655691  0.00372453 -0.82991759  0.87524947] | Target: -0.8685825297023326 | Output: -0.864203325917629
Input: [0.27223884 0.49333075 0.04959079 0.92712367] | Target: -0.890582723559241 | Output: -0.899320937888231
Input: [ 0.84876481  0.76225924 -0.08406463  0.43691027] | Target: -0.4209290928116743 | Output: -0.3992814824589471
Input: [ 0.59751983 -0.2812373   0.78611368  0.44687436] | Target: 0.9384089629393059 | Output: 0.9474734367156278
Input: [ 0.34182235  0.5491084   0.40507799 -0.29701485] | Target: 0.47486162062233245 | Output: 0.5170692950331981
Input: [ 0.42283238  0.80968777 -0.82963418 -0.55610595] | Target: -0.6134198613415482 | Output: -0.603909109292487
Input: [-0.50187166  0.92688959  0.40075995  0.043051  ] | Target: -0.877705252953404 | Output: -0.883701951096532
Input: [-0.41943475 -0.61215892  0.45405389 -0.34328094] | Target: 0.8360583549340252 | Output: 0.8546642637448102
Input: [ 0.96795196 -0.28914334  0.63779078  0.32553259] | Target: 0.9999989591114976 | Output: 0.990572146345723
Input: [ 0.75002122  0.83731922  0.08750354 -0.43598446] | Target: 0.4224892766972277 | Output: 0.4058432757995496
Input: [-0.84145098  0.59019999  0.57881044 -0.10527194] | Target: -0.6798577173579573 | Output: -0.7003967382010199
Input: [-0.01354512  0.51651433  0.61839328 -0.54195236] | Target: 0.5893759863297461 | Output: 0.6490314215280232
Input: [-0.85226186  0.92039067 -0.40358247  0.82752148] | Target: -0.13740013643130405 | Output: -0.48539849981832023
Input: [-1.20208422e-04 -8.33435464e-01 -8.29094249e-01  2.57740819e-01] | Target: -0.2508128096089507 | Output: -0.2535879041473178
Input: [0.97440678 0.67632022 0.37177763 0.37898444] | Target: 0.2867951214724826 | Output: 0.31596278680423306
Input: [-0.96750271  0.40885678 -0.41633182 -0.04844435] | Target: -0.9849951142371354 | Output: -0.9262108342370629
Input: [ 0.5995541   0.55368425 -0.39807429  0.74575248] | Target: -0.8902787665928441 | Output: -0.8921324240784113
Input: [ 0.1147611   0.31365018 -0.33824567  0.28760157] | Target: -0.7343688350613843 | Output: -0.7466586498532857
Input: [ 0.36462015  0.58189491 -0.94305822 -0.36998795] | Target: -0.7105960731893447 | Output: -0.7202918038857977
Input: [-0.92163169 -0.48173233 -0.45552113  0.34317945] | Target: -0.9453283422404454 | Output: -0.8884087826234681
Input: [0.66100169 0.0159894  0.02375897 0.37858434] | Target: 0.2861313242993361 | Output: 0.29117276378614265
Input: [ 0.74774146 -0.40140906 -0.48244804  0.15224903] | Target: 0.4920591230971327 | Output: 0.5002110099658402
Input: [ 0.88537842  0.54493392 -0.24240907 -0.58675178] | Target: 0.6325082075942169 | Output: 0.605841513602036
Input: [-0.89948922  0.30514915 -0.06677325 -0.23967053] | Target: -0.8581940351253253 | Output: -0.851532149047169
Input: [ 0.67803204  0.47533682  0.26972013 -0.27476103] | Target: 0.6795700314529539 | Output: 0.6902663827446519
Input: [-0.98083192 -0.4695752  -0.31786867  0.7619386 ] | Target: -0.9997946180377792 | Output: -0.979028977564976
Input: [-0.11448304  0.78197704 -0.07385002  0.57302441] | Target: -0.999622948135676 | Output: -0.9520960394577865
Input: [ 0.92133849  0.82507178  0.74741915 -0.58603175] | Target: 0.9900648927020624 | Output: 0.9682939207039288
Input: [-0.60553526 -0.61901846  0.14587078 -0.17473924] | Target: 0.3279126629549906 | Output: 0.3365333557716913
Input: [-0.35802134  0.73015313  0.60293073  0.02384464] | Target: -0.48738142837990606 | Output: -0.5092251912419716
Input: [-0.1090036   0.16355674  0.52121077  0.26224029] | Target: -0.013589448699499802 | Output: -0.011597052570285815
Input: [0.24809978 0.13586941 0.70807115 0.35517622] | Target: 0.44853479420304265 | Output: 0.5110199452232861
Input: [-0.27152698 -0.3868816  -0.74856252  0.05681491] | Target: -0.636554775746118 | Output: -0.6672475491317119
Input: [ 0.00580885  0.59096635 -0.36767075  0.72869544] | Target: -0.993875985392774 | Output: -0.9312598475211119
Input: [ 0.35481914  0.88069484 -0.95698046 -0.367384  ] | Target: -0.8981185186955181 | Output: -0.8994704452282679
Input: [-0.41922212 -0.34126958 -0.80916346  0.63907702] | Target: -0.9990054379643346 | Output: -0.9277668178924953
Input: [ 0.67552242 -0.3586028  -0.84792242 -0.68776653] | Target: 0.7668824355727715 | Output: 0.7554401750896663
Input: [0.35026043 0.96890192 0.68031271 0.59380282] | Target: -0.507371347467531 | Output: -0.5514978207527677
Input: [-0.63373294 -0.22074043 -0.97588408 -0.83528859] | Target: -0.5257427095689864 | Output: -0.5992008378155259
Input: [-0.0222767   0.1081984  -0.76884935  0.75809839] | Target: -0.9962502691004255 | Output: -0.9186974506095552
Input: [ 0.87942357  0.4071619   0.30276464 -0.57790568] | Target: 0.9763612859488614 | Output: 0.9313855178857114
Input: [-0.36920023  0.30225159  0.1661646  -0.39389227] | Target: -0.11116471798811212 | Output: -0.10157079116932405
Input: [-0.06072322 -0.78714594 -0.67294101 -0.78471074] | Target: 0.7434354298423212 | Output: 0.7801859894766753
Input: [-0.34393016  0.95254504 -0.31080191  0.81068077] | Target: -0.6621129592186771 | Output: -0.7605847499394278
Input: [ 0.86965397  0.50771038 -0.95344631  0.79036643] | Target: -0.9822062805839687 | Output: -0.9980124114436185
Input: [ 0.55253134 -0.90575846  0.66876745  0.06928906] | Target: 0.8837539313124146 | Output: 0.8631590874387497
Input: [-0.8891273   0.17029516  0.07761798  0.54324158] | Target: -0.9989536393372639 | Output: -0.9604675117779765
Input: [-0.03247545  0.62848862 -0.2840394  -0.85224449] | Target: -0.09262602421897013 | Output: -0.1057545192451515
Input: [-0.17492966  0.6020377  -0.13374702  0.40160947] | Target: -0.9667815476307677 | Output: -0.9165949838290931
Input: [ 0.33321489 -0.78608966 -0.70813443 -0.59641281] | Target: 0.8455438312927052 | Output: 0.8706021910851526
Input: [-0.76627588 -0.22203148  0.14491826 -0.92464247] | Target: 0.5014867041380001 | Output: 0.5270507951532025
Input: [-0.54892582  0.20719914 -0.76681321  0.93955098] | Target: -0.6280956729056199 | Output: -0.7097560087640926
Input: [-0.64337341  0.49544423 -0.11255878 -0.01282107] | Target: -0.9453137970150551 | Output: -0.9050997272067272
Input: [-0.82728321 -0.69829701 -0.57700406  0.67442232] | Target: -0.981931689754146 | Output: -0.9466429543575511
Input: [-0.98497539 -0.72891986 -0.1836953   0.24372919] | Target: -0.631495178088639 | Output: -0.5843510108646643
Input: [ 0.70800631 -0.55628296 -0.26687532 -0.34987773] | Target: 0.9751266382188684 | Output: 0.9786313034112598
Input: [ 0.75178324 -0.01347168  0.38898314  0.14288251] | Target: 0.8475520319175844 | Output: 0.8586165947681054
Input: [ 0.41136073 -0.14618654 -0.91102637 -0.93813825] | Target: 0.5519151840967939 | Output: 0.5434908930552395
Input: [ 0.51018995 -0.37692397 -0.5011193   0.44394074] | Target: -0.05791369405285977 | Output: -0.07543282387035721
Input: [ 0.13749821 -0.37478774 -0.06327981  0.08022791] | Target: 0.3604760629800285 | Output: 0.38519888280516656
Input: [ 0.09228736 -0.27344297  0.75162068 -0.23405879] | Target: 0.9760311433779838 | Output: 0.9491695615455192
Input: [-0.50196384 -0.83118106 -0.25087767 -0.73796457] | Target: 0.7286194332234008 | Output: 0.7693364706827456
Input: [ 0.55164468 -0.25600115 -0.13504697  0.49848213] | Target: 0.17323827976742542 | Output: 0.16301896241056413
Input: [ 0.24950619  0.53158706 -0.86338517  0.47552992] | Target: -0.9987402624146927 | Output: -0.9640788574924594
Input: [ 0.51947747  0.94936431  0.43906985 -0.7269993 ] | Target: 0.6714637645748815 | Output: 0.6545230960276557
Input: [-0.6973039   0.0889062  -0.68445586 -0.75797046] | Target: -0.6538755685718755 | Output: -0.6816826674096412
Input: [-0.36976629 -0.43326151  0.66558198 -0.45645676] | Target: 0.9266998656020422 | Output: 0.9320655007119686
Input: [-0.99621318  0.45345917 -0.16715947  0.62688534] | Target: -0.7820045272552989 | Output: -0.8194319570981423
Input: [-0.66679933  0.85103131 -0.57861249  0.31616618] | Target: -0.6661117041117379 | Output: -0.7154804202548153
Input: [ 0.59984747  0.93320693 -0.64570456 -0.52073603] | Target: -0.44244927775403126 | Output: -0.4212250736499688
Input: [ 0.21660112 -0.82773408  0.18943024 -0.68955577] | Target: 0.9385039454562323 | Output: 0.8642031830010694
Input: [-0.75573124 -0.99691407 -0.14209714  0.48281666] | Target: -0.3743826932963817 | Output: -0.3221495226682979
Input: [ 0.43853717 -0.39233615  0.73276518  0.89920491] | Target: 0.6166133215349328 | Output: 0.6403053843817753
Input: [-0.02872933  0.30439828  0.37363359 -0.03299186] | Target: 0.07343169029757857 | Output: 0.09603194354393407
Input: [-0.6846535   0.45758929  0.30868531 -0.58891362] | Target: -0.24221081438382674 | Output: -0.24346751209314066
Input: [-0.42854772  0.22089627 -0.61139582  0.93547015] | Target: -0.810662489719735 | Output: -0.7968306262139508
Input: [-0.85755234  0.56294522  0.8090889   0.62068266] | Target: -0.943185741161217 | Output: -0.9603880019041818
Input: [-0.50101857  0.55840577 -0.17363426 -0.488904  ] | Target: -0.67735012743423 | Output: -0.6759112441610169
Input: [ 0.6573529  -0.81043102 -0.51834698 -0.83932845] | Target: 0.9763386465210206 | Output: 0.9645517232005242
Input: [-0.12988235  0.91252681  0.09633054  0.92392102] | Target: -0.9555716234730861 | Output: -0.9465516169853037
Input: [-0.28034689  0.85840257 -0.61431171 -0.28079694] | Target: -0.9951496388594328 | Output: -0.9500458763766182
Input: [ 0.16949099 -0.60932984 -0.85814292  0.88501474] | Target: -0.821671122614376 | Output: -0.7743173558690399
Input: [ 0.61929034 -0.04625989 -0.20040199 -0.71865318] | Target: 0.9260473813814688 | Output: 0.9137897998678685
Input: [ 0.52560633 -0.27594013  0.7360011  -0.84513606] | Target: 0.6881302680119759 | Output: 0.6392317717248538
---------------------------------------------------------

Hidden units: 12
Epochs: 10000
Learning rate: 0.5

Errors during training:
Error at epoch 1 is 292.19150616676393
Train mean error at (after) epoch 1: 0.7304787654169098
Test error at (after) epoch 1: 0.11064491791855989
----------
Error at epoch 1000 is 0.6718581797363269
Train mean error at (after) epoch 1000: 0.0016796454493408172
Test error at (after) epoch 1000: 0.001740112625085889
----------
Error at epoch 2000 is 0.5335227372580561
Train mean error at (after) epoch 2000: 0.0013338068431451402
Test error at (after) epoch 2000: 0.0016074771483490045
----------
Error at epoch 3000 is 0.409475804027237
Train mean error at (after) epoch 3000: 0.0010236895100680925
Test error at (after) epoch 3000: 0.0015034112712522224
----------
Error at epoch 4000 is 0.34472916905500356
Train mean error at (after) epoch 4000: 0.0008618229226375089
Test error at (after) epoch 4000: 0.0014572686586864086
----------
Error at epoch 5000 is 14.840607880822924
Train mean error at (after) epoch 5000: 0.03710151970205731
Test error at (after) epoch 5000: 0.02806664771176197
----------
Error at epoch 6000 is 0.3180830457896961
Train mean error at (after) epoch 6000: 0.0007952076144742402
Test error at (after) epoch 6000: 0.0015482930549090936
----------
Error at epoch 7000 is 0.285830703020562
Train mean error at (after) epoch 7000: 0.000714576757551405
Test error at (after) epoch 7000: 0.0014998991792045785
----------
Error at epoch 8000 is 0.2590093328401262
Train mean error at (after) epoch 8000: 0.0006475233321003156
Test error at (after) epoch 8000: 0.0014615656266682541
----------
Error at epoch 9000 is 0.258880620695673
Train mean error at (after) epoch 9000: 0.0006472015517391826
Test error at (after) epoch 9000: 0.0015373134346340714
----------
Error at epoch 10000 is 1.6742896932735947
Train mean error at (after) epoch 10000: 0.004185724233183987
Test error at (after) epoch 10000: 0.004709838197404112
----------


Outputs after training:

Input: [-0.49815014  0.41583469  0.94201245 -0.99618897] | Target: 0.8543072586148057 | Output: 0.901886592529834
Input: [ 0.13818131  0.06095889 -0.62437142  0.40181237] | Target: -0.8128109128334502 | Output: -0.7321898530250592
Input: [-0.55703306 -0.36130396  0.43427241  0.52039419] | Target: -0.27813396526285905 | Output: -0.20378294829656585
Input: [-0.90268247 -0.77891602  0.66723982  0.70656042] | Target: -0.16236507366523303 | Output: -0.06356522653336277
Input: [-0.52071191 -0.17490864 -0.42110008  0.53739114] | Target: -0.9646980685355615 | Output: -0.8542000481403336
Input: [-0.57989232  0.41914752 -0.89430089  0.4042967 ] | Target: -0.7472772503976836 | Output: -0.7126286852733246
Input: [ 0.41123637  0.50445406 -0.39235833  0.40965961] | Target: -0.7803564461209093 | Output: -0.7114679034698995
Input: [-0.84874982 -0.91212193 -0.57126008  0.78537851] | Target: -0.961735148149663 | Output: -0.8695421351084469
Input: [-0.83942584 -0.2382192  -0.41552901 -0.41150754] | Target: -0.5689496870929982 | Output: -0.5164428229362794
Input: [-0.63996411 -0.49290989  0.11924329  0.30074516] | Target: -0.32267669103540125 | Output: -0.2626533648991317
Input: [-0.08425944 -0.2955284  -0.89433919  0.83362651] | Target: -0.99853697393758 | Output: -0.9013680296819822
Input: [-0.88724799 -0.93995287  0.30061609 -0.73943079] | Target: 0.8878962036632344 | Output: 0.9809552439689977
Input: [ 0.50561153  0.84672172  0.59155033 -0.74158065] | Target: 0.8371330584929538 | Output: 0.9352816150289698
Input: [ 0.55932204 -0.69038757  0.19916301 -0.99000263] | Target: 0.6462936927156917 | Output: 0.7121100700303007
Input: [ 0.23615323 -0.64992727 -0.68035612 -0.17334199] | Target: 0.37005327868860116 | Output: 0.4627433492934137
Input: [ 0.49647156 -0.50333428 -0.40361241 -0.42994362] | Target: 0.8553038767682734 | Output: 0.9370830596658646
Input: [ 0.65655691  0.00372453 -0.82991759  0.87524947] | Target: -0.8685825297023326 | Output: -0.7835138798064571
Input: [0.27223884 0.49333075 0.04959079 0.92712367] | Target: -0.890582723559241 | Output: -0.7823029806323132
Input: [ 0.84876481  0.76225924 -0.08406463  0.43691027] | Target: -0.4209290928116743 | Output: -0.3141497764286414
Input: [ 0.59751983 -0.2812373   0.78611368  0.44687436] | Target: 0.9384089629393059 | Output: 1.0311871932620735
Input: [ 0.34182235  0.5491084   0.40507799 -0.29701485] | Target: 0.47486162062233245 | Output: 0.6120060044348155
Input: [ 0.42283238  0.80968777 -0.82963418 -0.55610595] | Target: -0.6134198613415482 | Output: -0.5128876517706059
Input: [-0.50187166  0.92688959  0.40075995  0.043051  ] | Target: -0.877705252953404 | Output: -0.7926766757488106
Input: [-0.41943475 -0.61215892  0.45405389 -0.34328094] | Target: 0.8360583549340252 | Output: 0.9434861582462533
Input: [ 0.96795196 -0.28914334  0.63779078  0.32553259] | Target: 0.9999989591114976 | Output: 1.0383731433598564
Input: [ 0.75002122  0.83731922  0.08750354 -0.43598446] | Target: 0.4224892766972277 | Output: 0.54857637991738
Input: [-0.84145098  0.59019999  0.57881044 -0.10527194] | Target: -0.6798577173579573 | Output: -0.6083649349251552
Input: [-0.01354512  0.51651433  0.61839328 -0.54195236] | Target: 0.5893759863297461 | Output: 0.7063804945768604
Input: [-0.85226186  0.92039067 -0.40358247  0.82752148] | Target: -0.13740013643130405 | Output: -0.5177113315734783
Input: [-1.20208422e-04 -8.33435464e-01 -8.29094249e-01  2.57740819e-01] | Target: -0.2508128096089507 | Output: -0.18301116448992608
Input: [0.97440678 0.67632022 0.37177763 0.37898444] | Target: 0.2867951214724826 | Output: 0.43119500821050377
Input: [-0.96750271  0.40885678 -0.41633182 -0.04844435] | Target: -0.9849951142371354 | Output: -0.8550897387468577
Input: [ 0.5995541   0.55368425 -0.39807429  0.74575248] | Target: -0.8902787665928441 | Output: -0.8120212024530187
Input: [ 0.1147611   0.31365018 -0.33824567  0.28760157] | Target: -0.7343688350613843 | Output: -0.6744318655079939
Input: [ 0.36462015  0.58189491 -0.94305822 -0.36998795] | Target: -0.7105960731893447 | Output: -0.5861649161481003
Input: [-0.92163169 -0.48173233 -0.45552113  0.34317945] | Target: -0.9453283422404454 | Output: -0.8342036541957587
Input: [0.66100169 0.0159894  0.02375897 0.37858434] | Target: 0.2861313242993361 | Output: 0.4178878749193348
Input: [ 0.74774146 -0.40140906 -0.48244804  0.15224903] | Target: 0.4920591230971327 | Output: 0.5883616394764708
Input: [ 0.88537842  0.54493392 -0.24240907 -0.58675178] | Target: 0.6325082075942169 | Output: 0.7260050127585225
Input: [-0.89948922  0.30514915 -0.06677325 -0.23967053] | Target: -0.8581940351253253 | Output: -0.7475668908331188
Input: [ 0.67803204  0.47533682  0.26972013 -0.27476103] | Target: 0.6795700314529539 | Output: 0.8219539702475531
Input: [-0.98083192 -0.4695752  -0.31786867  0.7619386 ] | Target: -0.9997946180377792 | Output: -0.8727017603032181
Input: [-0.11448304  0.78197704 -0.07385002  0.57302441] | Target: -0.999622948135676 | Output: -0.8973485142343169
Input: [ 0.92133849  0.82507178  0.74741915 -0.58603175] | Target: 0.9900648927020624 | Output: 1.027149545509333
Input: [-0.60553526 -0.61901846  0.14587078 -0.17473924] | Target: 0.3279126629549906 | Output: 0.4401936710646806
Input: [-0.35802134  0.73015313  0.60293073  0.02384464] | Target: -0.48738142837990606 | Output: -0.4156393546359712
Input: [-0.1090036   0.16355674  0.52121077  0.26224029] | Target: -0.013589448699499802 | Output: 0.07919830878482076
Input: [0.24809978 0.13586941 0.70807115 0.35517622] | Target: 0.44853479420304265 | Output: 0.5624335360470201
Input: [-0.27152698 -0.3868816  -0.74856252  0.05681491] | Target: -0.636554775746118 | Output: -0.5644657209655424
Input: [ 0.00580885  0.59096635 -0.36767075  0.72869544] | Target: -0.993875985392774 | Output: -0.9014478753515449
Input: [ 0.35481914  0.88069484 -0.95698046 -0.367384  ] | Target: -0.8981185186955181 | Output: -0.7563366338464539
Input: [-0.41922212 -0.34126958 -0.80916346  0.63907702] | Target: -0.9990054379643346 | Output: -0.894992067456539
Input: [ 0.67552242 -0.3586028  -0.84792242 -0.68776653] | Target: 0.7668824355727715 | Output: 0.8086617880127598
Input: [0.35026043 0.96890192 0.68031271 0.59380282] | Target: -0.507371347467531 | Output: -0.36632097204275405
Input: [-0.63373294 -0.22074043 -0.97588408 -0.83528859] | Target: -0.5257427095689864 | Output: -0.4751954005073701
Input: [-0.0222767   0.1081984  -0.76884935  0.75809839] | Target: -0.9962502691004255 | Output: -0.8888280229983652
Input: [ 0.87942357  0.4071619   0.30276464 -0.57790568] | Target: 0.9763612859488614 | Output: 1.0377793324467959
Input: [-0.36920023  0.30225159  0.1661646  -0.39389227] | Target: -0.11116471798811212 | Output: -0.041886428029433154
Input: [-0.06072322 -0.78714594 -0.67294101 -0.78471074] | Target: 0.7434354298423212 | Output: 0.7661817508663518
Input: [-0.34393016  0.95254504 -0.31080191  0.81068077] | Target: -0.6621129592186771 | Output: -0.7718904912273601
Input: [ 0.86965397  0.50771038 -0.95344631  0.79036643] | Target: -0.9822062805839687 | Output: -0.9000362973792693
Input: [ 0.55253134 -0.90575846  0.66876745  0.06928906] | Target: 0.8837539313124146 | Output: 0.877828596510452
Input: [-0.8891273   0.17029516  0.07761798  0.54324158] | Target: -0.9989536393372639 | Output: -0.8735076784287084
Input: [-0.03247545  0.62848862 -0.2840394  -0.85224449] | Target: -0.09262602421897013 | Output: -0.026477046850355623
Input: [-0.17492966  0.6020377  -0.13374702  0.40160947] | Target: -0.9667815476307677 | Output: -0.8574985441420725
Input: [ 0.33321489 -0.78608966 -0.70813443 -0.59641281] | Target: 0.8455438312927052 | Output: 0.8922239139868455
Input: [-0.76627588 -0.22203148  0.14491826 -0.92464247] | Target: 0.5014867041380001 | Output: 0.5752634286613569
Input: [-0.54892582  0.20719914 -0.76681321  0.93955098] | Target: -0.6280956729056199 | Output: -0.6718886881375178
Input: [-0.64337341  0.49544423 -0.11255878 -0.01282107] | Target: -0.9453137970150551 | Output: -0.8246180422053864
Input: [-0.82728321 -0.69829701 -0.57700406  0.67442232] | Target: -0.981931689754146 | Output: -0.8790752214785575
Input: [-0.98497539 -0.72891986 -0.1836953   0.24372919] | Target: -0.631495178088639 | Output: -0.5755324070299662
Input: [ 0.70800631 -0.55628296 -0.26687532 -0.34987773] | Target: 0.9751266382188684 | Output: 1.0180787951262693
Input: [ 0.75178324 -0.01347168  0.38898314  0.14288251] | Target: 0.8475520319175844 | Output: 0.9570631086701837
Input: [ 0.41136073 -0.14618654 -0.91102637 -0.93813825] | Target: 0.5519151840967939 | Output: 0.5753608155437075
Input: [ 0.51018995 -0.37692397 -0.5011193   0.44394074] | Target: -0.05791369405285977 | Output: 0.0226897132442499
Input: [ 0.13749821 -0.37478774 -0.06327981  0.08022791] | Target: 0.3604760629800285 | Output: 0.5104986539792504
Input: [ 0.09228736 -0.27344297  0.75162068 -0.23405879] | Target: 0.9760311433779838 | Output: 1.0462238646566377
Input: [-0.50196384 -0.83118106 -0.25087767 -0.73796457] | Target: 0.7286194332234008 | Output: 0.79169752861484
Input: [ 0.55164468 -0.25600115 -0.13504697  0.49848213] | Target: 0.17323827976742542 | Output: 0.28418571433433754
Input: [ 0.24950619  0.53158706 -0.86338517  0.47552992] | Target: -0.9987402624146927 | Output: -0.8821232054603213
Input: [ 0.51947747  0.94936431  0.43906985 -0.7269993 ] | Target: 0.6714637645748815 | Output: 0.7770454014901074
Input: [-0.6973039   0.0889062  -0.68445586 -0.75797046] | Target: -0.6538755685718755 | Output: -0.6045615546546013
Input: [-0.36976629 -0.43326151  0.66558198 -0.45645676] | Target: 0.9266998656020422 | Output: 0.9977570105289217
Input: [-0.99621318  0.45345917 -0.16715947  0.62688534] | Target: -0.7820045272552989 | Output: -0.743214249140349
Input: [-0.66679933  0.85103131 -0.57861249  0.31616618] | Target: -0.6661117041117379 | Output: -0.6535486613322543
Input: [ 0.59984747  0.93320693 -0.64570456 -0.52073603] | Target: -0.44244927775403126 | Output: -0.3704314997954919
Input: [ 0.21660112 -0.82773408  0.18943024 -0.68955577] | Target: 0.9385039454562323 | Output: 0.9386700651927744
Input: [-0.75573124 -0.99691407 -0.14209714  0.48281666] | Target: -0.3743826932963817 | Output: -0.3219311594781413
Input: [ 0.43853717 -0.39233615  0.73276518  0.89920491] | Target: 0.6166133215349328 | Output: 0.7074604014575776
Input: [-0.02872933  0.30439828  0.37363359 -0.03299186] | Target: 0.07343169029757857 | Output: 0.17227935445608505
Input: [-0.6846535   0.45758929  0.30868531 -0.58891362] | Target: -0.24221081438382674 | Output: -0.1578093246217594
Input: [-0.42854772  0.22089627 -0.61139582  0.93547015] | Target: -0.810662489719735 | Output: -0.7722351497639649
Input: [-0.85755234  0.56294522  0.8090889   0.62068266] | Target: -0.943185741161217 | Output: -0.8676400620002855
Input: [-0.50101857  0.55840577 -0.17363426 -0.488904  ] | Target: -0.67735012743423 | Output: -0.6075814496762406
Input: [ 0.6573529  -0.81043102 -0.51834698 -0.83932845] | Target: 0.9763386465210206 | Output: 1.0405077742313469
Input: [-0.12988235  0.91252681  0.09633054  0.92392102] | Target: -0.9555716234730861 | Output: -0.9278983993914234
Input: [-0.28034689  0.85840257 -0.61431171 -0.28079694] | Target: -0.9951496388594328 | Output: -0.858164759462537
Input: [ 0.16949099 -0.60932984 -0.85814292  0.88501474] | Target: -0.821671122614376 | Output: -0.7455645099194972
Input: [ 0.61929034 -0.04625989 -0.20040199 -0.71865318] | Target: 0.9260473813814688 | Output: 0.9851356162202629
Input: [ 0.52560633 -0.27594013  0.7360011  -0.84513606] | Target: 0.6881302680119759 | Output: 0.7036842137484918
---------------------------------------------------------

Hidden units: 12
Epochs: 3000
Learning rate: 1

Errors during training:
Error at epoch 1 is 151.099718305915
Train mean error at (after) epoch 1: 0.3777492957647875
Test error at (after) epoch 1: 0.08270464410604138
----------
Error at epoch 300 is 3.89890836585678
Train mean error at (after) epoch 300: 0.00974727091464195
Test error at (after) epoch 300: 0.00722197214131481
----------
Error at epoch 600 is 0.8916067779781369
Train mean error at (after) epoch 600: 0.0022290169449453424
Test error at (after) epoch 600: 0.002432194063541007
----------
Error at epoch 900 is 1.0736547698038261
Train mean error at (after) epoch 900: 0.0026841369245095654
Test error at (after) epoch 900: 0.00278122816125679
----------
Error at epoch 1200 is 1.8155951891935889
Train mean error at (after) epoch 1200: 0.0045389879729839724
Test error at (after) epoch 1200: 0.004661641102803282
----------
Error at epoch 1500 is 1.6552255646666099
Train mean error at (after) epoch 1500: 0.004138063911666524
Test error at (after) epoch 1500: 0.004340037180941973
----------
Error at epoch 1800 is 1.5363401734718358
Train mean error at (after) epoch 1800: 0.0038408504336795895
Test error at (after) epoch 1800: 0.004047673463811328
----------
Error at epoch 2100 is 1.4926991722317209
Train mean error at (after) epoch 2100: 0.003731747930579302
Test error at (after) epoch 2100: 0.003931269489659147
----------
Error at epoch 2400 is 1.4778617169938866
Train mean error at (after) epoch 2400: 0.0036946542924847165
Test error at (after) epoch 2400: 0.0038850228074748076
----------
Error at epoch 2700 is 1.4708529164261537
Train mean error at (after) epoch 2700: 0.003677132291065384
Test error at (after) epoch 2700: 0.0038574124244245916
----------
Error at epoch 3000 is 1.4650631737316686
Train mean error at (after) epoch 3000: 0.0036626579343291715
Test error at (after) epoch 3000: 0.00383207502477676
----------


Outputs after training:

Input: [-0.49815014  0.41583469  0.94201245 -0.99618897] | Target: 0.8543072586148057 | Output: 0.9292804870305478
Input: [ 0.13818131  0.06095889 -0.62437142  0.40181237] | Target: -0.8128109128334502 | Output: -0.7517590644785341
Input: [-0.55703306 -0.36130396  0.43427241  0.52039419] | Target: -0.27813396526285905 | Output: -0.21789991970060535
Input: [-0.90268247 -0.77891602  0.66723982  0.70656042] | Target: -0.16236507366523303 | Output: -0.08758110562685519
Input: [-0.52071191 -0.17490864 -0.42110008  0.53739114] | Target: -0.9646980685355615 | Output: -0.8363725998586561
Input: [-0.57989232  0.41914752 -0.89430089  0.4042967 ] | Target: -0.7472772503976836 | Output: -0.6577559111132887
Input: [ 0.41123637  0.50445406 -0.39235833  0.40965961] | Target: -0.7803564461209093 | Output: -0.7276570937202492
Input: [-0.84874982 -0.91212193 -0.57126008  0.78537851] | Target: -0.961735148149663 | Output: -0.8886700069746049
Input: [-0.83942584 -0.2382192  -0.41552901 -0.41150754] | Target: -0.5689496870929982 | Output: -0.5446346634221624
Input: [-0.63996411 -0.49290989  0.11924329  0.30074516] | Target: -0.32267669103540125 | Output: -0.28521474987559814
Input: [-0.08425944 -0.2955284  -0.89433919  0.83362651] | Target: -0.99853697393758 | Output: -0.9584680606872851
Input: [-0.88724799 -0.93995287  0.30061609 -0.73943079] | Target: 0.8878962036632344 | Output: 0.945509559418324
Input: [ 0.50561153  0.84672172  0.59155033 -0.74158065] | Target: 0.8371330584929538 | Output: 0.9204856194284947
Input: [ 0.55932204 -0.69038757  0.19916301 -0.99000263] | Target: 0.6462936927156917 | Output: 0.7156921028215749
Input: [ 0.23615323 -0.64992727 -0.68035612 -0.17334199] | Target: 0.37005327868860116 | Output: 0.451197083101578
Input: [ 0.49647156 -0.50333428 -0.40361241 -0.42994362] | Target: 0.8553038767682734 | Output: 0.9094530529834454
Input: [ 0.65655691  0.00372453 -0.82991759  0.87524947] | Target: -0.8685825297023326 | Output: -0.8554883862150504
Input: [0.27223884 0.49333075 0.04959079 0.92712367] | Target: -0.890582723559241 | Output: -0.8070282532990751
Input: [ 0.84876481  0.76225924 -0.08406463  0.43691027] | Target: -0.4209290928116743 | Output: -0.3823337337804981
Input: [ 0.59751983 -0.2812373   0.78611368  0.44687436] | Target: 0.9384089629393059 | Output: 0.9928647911830759
Input: [ 0.34182235  0.5491084   0.40507799 -0.29701485] | Target: 0.47486162062233245 | Output: 0.6158300926247575
Input: [ 0.42283238  0.80968777 -0.82963418 -0.55610595] | Target: -0.6134198613415482 | Output: -0.556108460531157
Input: [-0.50187166  0.92688959  0.40075995  0.043051  ] | Target: -0.877705252953404 | Output: -0.8349063826831585
Input: [-0.41943475 -0.61215892  0.45405389 -0.34328094] | Target: 0.8360583549340252 | Output: 0.912420099787798
Input: [ 0.96795196 -0.28914334  0.63779078  0.32553259] | Target: 0.9999989591114976 | Output: 1.032462805920834
Input: [ 0.75002122  0.83731922  0.08750354 -0.43598446] | Target: 0.4224892766972277 | Output: 0.561893114383527
Input: [-0.84145098  0.59019999  0.57881044 -0.10527194] | Target: -0.6798577173579573 | Output: -0.6241605988703288
Input: [-0.01354512  0.51651433  0.61839328 -0.54195236] | Target: 0.5893759863297461 | Output: 0.7025160260824861
Input: [-0.85226186  0.92039067 -0.40358247  0.82752148] | Target: -0.13740013643130405 | Output: -0.5107854193898935
Input: [-1.20208422e-04 -8.33435464e-01 -8.29094249e-01  2.57740819e-01] | Target: -0.2508128096089507 | Output: -0.1766039943117137
Input: [0.97440678 0.67632022 0.37177763 0.37898444] | Target: 0.2867951214724826 | Output: 0.41033402143531134
Input: [-0.96750271  0.40885678 -0.41633182 -0.04844435] | Target: -0.9849951142371354 | Output: -0.8433614452776776
Input: [ 0.5995541   0.55368425 -0.39807429  0.74575248] | Target: -0.8902787665928441 | Output: -0.8314377386158474
Input: [ 0.1147611   0.31365018 -0.33824567  0.28760157] | Target: -0.7343688350613843 | Output: -0.6813740951857382
Input: [ 0.36462015  0.58189491 -0.94305822 -0.36998795] | Target: -0.7105960731893447 | Output: -0.6249422317892198
Input: [-0.92163169 -0.48173233 -0.45552113  0.34317945] | Target: -0.9453283422404454 | Output: -0.843622056772644
Input: [0.66100169 0.0159894  0.02375897 0.37858434] | Target: 0.2861313242993361 | Output: 0.4069646944783804
Input: [ 0.74774146 -0.40140906 -0.48244804  0.15224903] | Target: 0.4920591230971327 | Output: 0.577536147090799
Input: [ 0.88537842  0.54493392 -0.24240907 -0.58675178] | Target: 0.6325082075942169 | Output: 0.7358471086972252
Input: [-0.89948922  0.30514915 -0.06677325 -0.23967053] | Target: -0.8581940351253253 | Output: -0.7824123202126383
Input: [ 0.67803204  0.47533682  0.26972013 -0.27476103] | Target: 0.6795700314529539 | Output: 0.8093254631692939
Input: [-0.98083192 -0.4695752  -0.31786867  0.7619386 ] | Target: -0.9997946180377792 | Output: -0.8526978173268828
Input: [-0.11448304  0.78197704 -0.07385002  0.57302441] | Target: -0.999622948135676 | Output: -0.8815397906868377
Input: [ 0.92133849  0.82507178  0.74741915 -0.58603175] | Target: 0.9900648927020624 | Output: 1.025844518276631
Input: [-0.60553526 -0.61901846  0.14587078 -0.17473924] | Target: 0.3279126629549906 | Output: 0.4562273614383543
Input: [-0.35802134  0.73015313  0.60293073  0.02384464] | Target: -0.48738142837990606 | Output: -0.44305716626344566
Input: [-0.1090036   0.16355674  0.52121077  0.26224029] | Target: -0.013589448699499802 | Output: 0.07897679691199128
Input: [0.24809978 0.13586941 0.70807115 0.35517622] | Target: 0.44853479420304265 | Output: 0.5474639305407593
Input: [-0.27152698 -0.3868816  -0.74856252  0.05681491] | Target: -0.636554775746118 | Output: -0.58730865288581
Input: [ 0.00580885  0.59096635 -0.36767075  0.72869544] | Target: -0.993875985392774 | Output: -0.847292294139052
Input: [ 0.35481914  0.88069484 -0.95698046 -0.367384  ] | Target: -0.8981185186955181 | Output: -0.8054770077601228
Input: [-0.41922212 -0.34126958 -0.80916346  0.63907702] | Target: -0.9990054379643346 | Output: -0.9033644276616799
Input: [ 0.67552242 -0.3586028  -0.84792242 -0.68776653] | Target: 0.7668824355727715 | Output: 0.7927165632643368
Input: [0.35026043 0.96890192 0.68031271 0.59380282] | Target: -0.507371347467531 | Output: -0.4290579047635974
Input: [-0.63373294 -0.22074043 -0.97588408 -0.83528859] | Target: -0.5257427095689864 | Output: -0.451018836654862
Input: [-0.0222767   0.1081984  -0.76884935  0.75809839] | Target: -0.9962502691004255 | Output: -0.8965309217814035
Input: [ 0.87942357  0.4071619   0.30276464 -0.57790568] | Target: 0.9763612859488614 | Output: 0.9590316087440964
Input: [-0.36920023  0.30225159  0.1661646  -0.39389227] | Target: -0.11116471798811212 | Output: -0.0443588051312528
Input: [-0.06072322 -0.78714594 -0.67294101 -0.78471074] | Target: 0.7434354298423212 | Output: 0.758475524827254
Input: [-0.34393016  0.95254504 -0.31080191  0.81068077] | Target: -0.6621129592186771 | Output: -0.7060724274680421
Input: [ 0.86965397  0.50771038 -0.95344631  0.79036643] | Target: -0.9822062805839687 | Output: -0.9686937156578626
Input: [ 0.55253134 -0.90575846  0.66876745  0.06928906] | Target: 0.8837539313124146 | Output: 0.9209972769114074
Input: [-0.8891273   0.17029516  0.07761798  0.54324158] | Target: -0.9989536393372639 | Output: -0.8473199228449189
Input: [-0.03247545  0.62848862 -0.2840394  -0.85224449] | Target: -0.09262602421897013 | Output: -0.0341746147719854
Input: [-0.17492966  0.6020377  -0.13374702  0.40160947] | Target: -0.9667815476307677 | Output: -0.8452246994535736
Input: [ 0.33321489 -0.78608966 -0.70813443 -0.59641281] | Target: 0.8455438312927052 | Output: 0.8910922195269736
Input: [-0.76627588 -0.22203148  0.14491826 -0.92464247] | Target: 0.5014867041380001 | Output: 0.5604564733887085
Input: [-0.54892582  0.20719914 -0.76681321  0.93955098] | Target: -0.6280956729056199 | Output: -0.6747609203539932
Input: [-0.64337341  0.49544423 -0.11255878 -0.01282107] | Target: -0.9453137970150551 | Output: -0.8376083899414338
Input: [-0.82728321 -0.69829701 -0.57700406  0.67442232] | Target: -0.981931689754146 | Output: -0.8888177083671126
Input: [-0.98497539 -0.72891986 -0.1836953   0.24372919] | Target: -0.631495178088639 | Output: -0.6246071634888335
Input: [ 0.70800631 -0.55628296 -0.26687532 -0.34987773] | Target: 0.9751266382188684 | Output: 0.9762045892094997
Input: [ 0.75178324 -0.01347168  0.38898314  0.14288251] | Target: 0.8475520319175844 | Output: 0.9156749191066527
Input: [ 0.41136073 -0.14618654 -0.91102637 -0.93813825] | Target: 0.5519151840967939 | Output: 0.5356381955520222
Input: [ 0.51018995 -0.37692397 -0.5011193   0.44394074] | Target: -0.05791369405285977 | Output: 0.02085039432728175
Input: [ 0.13749821 -0.37478774 -0.06327981  0.08022791] | Target: 0.3604760629800285 | Output: 0.4985282388815433
Input: [ 0.09228736 -0.27344297  0.75162068 -0.23405879] | Target: 0.9760311433779838 | Output: 0.9568120403081564
Input: [-0.50196384 -0.83118106 -0.25087767 -0.73796457] | Target: 0.7286194332234008 | Output: 0.7799190711471324
Input: [ 0.55164468 -0.25600115 -0.13504697  0.49848213] | Target: 0.17323827976742542 | Output: 0.2712416618159138
Input: [ 0.24950619  0.53158706 -0.86338517  0.47552992] | Target: -0.9987402624146927 | Output: -0.8453138494214478
Input: [ 0.51947747  0.94936431  0.43906985 -0.7269993 ] | Target: 0.6714637645748815 | Output: 0.7681884164028183
Input: [-0.6973039   0.0889062  -0.68445586 -0.75797046] | Target: -0.6538755685718755 | Output: -0.6067684462088938
Input: [-0.36976629 -0.43326151  0.66558198 -0.45645676] | Target: 0.9266998656020422 | Output: 0.9682251514855089
Input: [-0.99621318  0.45345917 -0.16715947  0.62688534] | Target: -0.7820045272552989 | Output: -0.7122676792659092
Input: [-0.66679933  0.85103131 -0.57861249  0.31616618] | Target: -0.6661117041117379 | Output: -0.6616620554838396
Input: [ 0.59984747  0.93320693 -0.64570456 -0.52073603] | Target: -0.44244927775403126 | Output: -0.40154836056275484
Input: [ 0.21660112 -0.82773408  0.18943024 -0.68955577] | Target: 0.9385039454562323 | Output: 0.8775470659477098
Input: [-0.75573124 -0.99691407 -0.14209714  0.48281666] | Target: -0.3743826932963817 | Output: -0.3296141912058407
Input: [ 0.43853717 -0.39233615  0.73276518  0.89920491] | Target: 0.6166133215349328 | Output: 0.6739170009794598
Input: [-0.02872933  0.30439828  0.37363359 -0.03299186] | Target: 0.07343169029757857 | Output: 0.18075757693100142
Input: [-0.6846535   0.45758929  0.30868531 -0.58891362] | Target: -0.24221081438382674 | Output: -0.18836232735202074
Input: [-0.42854772  0.22089627 -0.61139582  0.93547015] | Target: -0.810662489719735 | Output: -0.7559408372445784
Input: [-0.85755234  0.56294522  0.8090889   0.62068266] | Target: -0.943185741161217 | Output: -0.8891893688753624
Input: [-0.50101857  0.55840577 -0.17363426 -0.488904  ] | Target: -0.67735012743423 | Output: -0.6317153446533443
Input: [ 0.6573529  -0.81043102 -0.51834698 -0.83932845] | Target: 0.9763386465210206 | Output: 1.0169393198943957
Input: [-0.12988235  0.91252681  0.09633054  0.92392102] | Target: -0.9555716234730861 | Output: -0.9240950593793699
Input: [-0.28034689  0.85840257 -0.61431171 -0.28079694] | Target: -0.9951496388594328 | Output: -0.891086020713743
Input: [ 0.16949099 -0.60932984 -0.85814292  0.88501474] | Target: -0.821671122614376 | Output: -0.781259673036937
Input: [ 0.61929034 -0.04625989 -0.20040199 -0.71865318] | Target: 0.9260473813814688 | Output: 0.9237812741432949
Input: [ 0.52560633 -0.27594013  0.7360011  -0.84513606] | Target: 0.6881302680119759 | Output: 0.7170752537643116
---------------------------------------------------------

Hidden units: 12
Epochs: 10000
Learning rate: 1

Errors during training:
Error at epoch 1 is 945.900080767929
Train mean error at (after) epoch 1: 2.3647502019198225
Test error at (after) epoch 1: 0.4216332765102955
----------
Error at epoch 1000 is 1.0624256794780935
Train mean error at (after) epoch 1000: 0.002656064198695234
Test error at (after) epoch 1000: 0.00315848561242187
----------
Error at epoch 2000 is 1.0447232605648453
Train mean error at (after) epoch 2000: 0.0026118081514121135
Test error at (after) epoch 2000: 0.002789726030014866
----------
Error at epoch 3000 is 1.464945446552847
Train mean error at (after) epoch 3000: 0.0036623636163821177
Test error at (after) epoch 3000: 0.003571526863169728
----------
Error at epoch 4000 is 1.3436097494048462
Train mean error at (after) epoch 4000: 0.0033590243735121157
Test error at (after) epoch 4000: 0.0030405976532890287
----------
Error at epoch 5000 is 1.2782718648490714
Train mean error at (after) epoch 5000: 0.0031956796621226786
Test error at (after) epoch 5000: 0.002864365370671186
----------
Error at epoch 6000 is 1.2429489686744006
Train mean error at (after) epoch 6000: 0.0031073724216860014
Test error at (after) epoch 6000: 0.00283549407229608
----------
Error at epoch 7000 is 1.2127875790259417
Train mean error at (after) epoch 7000: 0.003031968947564854
Test error at (after) epoch 7000: 0.0028170045302637076
----------
Error at epoch 8000 is 1.1851548551438482
Train mean error at (after) epoch 8000: 0.0029628871378596204
Test error at (after) epoch 8000: 0.002789035362571111
----------
Error at epoch 9000 is 1.162764099850332
Train mean error at (after) epoch 9000: 0.00290691024962583
Test error at (after) epoch 9000: 0.0027604831815561982
----------
Error at epoch 10000 is 1.146277079605408
Train mean error at (after) epoch 10000: 0.0028656926990135202
Test error at (after) epoch 10000: 0.002738652913946853
----------


Outputs after training:

Input: [-0.49815014  0.41583469  0.94201245 -0.99618897] | Target: 0.8543072586148057 | Output: 0.8698402122866761
Input: [ 0.13818131  0.06095889 -0.62437142  0.40181237] | Target: -0.8128109128334502 | Output: -0.8630628858225494
Input: [-0.55703306 -0.36130396  0.43427241  0.52039419] | Target: -0.27813396526285905 | Output: -0.3591531767949953
Input: [-0.90268247 -0.77891602  0.66723982  0.70656042] | Target: -0.16236507366523303 | Output: -0.21459355523839121
Input: [-0.52071191 -0.17490864 -0.42110008  0.53739114] | Target: -0.9646980685355615 | Output: -0.9459733232562421
Input: [-0.57989232  0.41914752 -0.89430089  0.4042967 ] | Target: -0.7472772503976836 | Output: -0.694612648871863
Input: [ 0.41123637  0.50445406 -0.39235833  0.40965961] | Target: -0.7803564461209093 | Output: -0.8309866767676148
Input: [-0.84874982 -0.91212193 -0.57126008  0.78537851] | Target: -0.961735148149663 | Output: -0.9482541575602251
Input: [-0.83942584 -0.2382192  -0.41552901 -0.41150754] | Target: -0.5689496870929982 | Output: -0.6503928553627918
Input: [-0.63996411 -0.49290989  0.11924329  0.30074516] | Target: -0.32267669103540125 | Output: -0.3977807077014298
Input: [-0.08425944 -0.2955284  -0.89433919  0.83362651] | Target: -0.99853697393758 | Output: -1.0913659913792146
Input: [-0.88724799 -0.93995287  0.30061609 -0.73943079] | Target: 0.8878962036632344 | Output: 0.7790581439711184
Input: [ 0.50561153  0.84672172  0.59155033 -0.74158065] | Target: 0.8371330584929538 | Output: 0.7406548218893382
Input: [ 0.55932204 -0.69038757  0.19916301 -0.99000263] | Target: 0.6462936927156917 | Output: 0.5729690616377446
Input: [ 0.23615323 -0.64992727 -0.68035612 -0.17334199] | Target: 0.37005327868860116 | Output: 0.3314401901213535
Input: [ 0.49647156 -0.50333428 -0.40361241 -0.42994362] | Target: 0.8553038767682734 | Output: 0.8137295783119379
Input: [ 0.65655691  0.00372453 -0.82991759  0.87524947] | Target: -0.8685825297023326 | Output: -0.9460089813320384
Input: [0.27223884 0.49333075 0.04959079 0.92712367] | Target: -0.890582723559241 | Output: -0.9385035941768848
Input: [ 0.84876481  0.76225924 -0.08406463  0.43691027] | Target: -0.4209290928116743 | Output: -0.5059374528935321
Input: [ 0.59751983 -0.2812373   0.78611368  0.44687436] | Target: 0.9384089629393059 | Output: 0.867908472666619
Input: [ 0.34182235  0.5491084   0.40507799 -0.29701485] | Target: 0.47486162062233245 | Output: 0.46763240500930525
Input: [ 0.42283238  0.80968777 -0.82963418 -0.55610595] | Target: -0.6134198613415482 | Output: -0.6703179290002281
Input: [-0.50187166  0.92688959  0.40075995  0.043051  ] | Target: -0.877705252953404 | Output: -0.9117794091191627
Input: [-0.41943475 -0.61215892  0.45405389 -0.34328094] | Target: 0.8360583549340252 | Output: 0.7955501292025419
Input: [ 0.96795196 -0.28914334  0.63779078  0.32553259] | Target: 0.9999989591114976 | Output: 0.9555978432102136
Input: [ 0.75002122  0.83731922  0.08750354 -0.43598446] | Target: 0.4224892766972277 | Output: 0.36317023446033236
Input: [-0.84145098  0.59019999  0.57881044 -0.10527194] | Target: -0.6798577173579573 | Output: -0.7086811443962163
Input: [-0.01354512  0.51651433  0.61839328 -0.54195236] | Target: 0.5893759863297461 | Output: 0.5754308765407249
Input: [-0.85226186  0.92039067 -0.40358247  0.82752148] | Target: -0.13740013643130405 | Output: -0.5354328486741504
Input: [-1.20208422e-04 -8.33435464e-01 -8.29094249e-01  2.57740819e-01] | Target: -0.2508128096089507 | Output: -0.32762608041372665
Input: [0.97440678 0.67632022 0.37177763 0.37898444] | Target: 0.2867951214724826 | Output: 0.2014310325324404
Input: [-0.96750271  0.40885678 -0.41633182 -0.04844435] | Target: -0.9849951142371354 | Output: -1.0111202963879833
Input: [ 0.5995541   0.55368425 -0.39807429  0.74575248] | Target: -0.8902787665928441 | Output: -0.9134374466834682
Input: [ 0.1147611   0.31365018 -0.33824567  0.28760157] | Target: -0.7343688350613843 | Output: -0.7945343183820571
Input: [ 0.36462015  0.58189491 -0.94305822 -0.36998795] | Target: -0.7105960731893447 | Output: -0.753521383294992
Input: [-0.92163169 -0.48173233 -0.45552113  0.34317945] | Target: -0.9453283422404454 | Output: -0.9706291682055223
Input: [0.66100169 0.0159894  0.02375897 0.37858434] | Target: 0.2861313242993361 | Output: 0.2686523762203862
Input: [ 0.74774146 -0.40140906 -0.48244804  0.15224903] | Target: 0.4920591230971327 | Output: 0.47340179340550015
Input: [ 0.88537842  0.54493392 -0.24240907 -0.58675178] | Target: 0.6325082075942169 | Output: 0.5950434072954703
Input: [-0.89948922  0.30514915 -0.06677325 -0.23967053] | Target: -0.8581940351253253 | Output: -0.9226619888350268
Input: [ 0.67803204  0.47533682  0.26972013 -0.27476103] | Target: 0.6795700314529539 | Output: 0.6749119858347251
Input: [-0.98083192 -0.4695752  -0.31786867  0.7619386 ] | Target: -0.9997946180377792 | Output: -0.9968725608949824
Input: [-0.11448304  0.78197704 -0.07385002  0.57302441] | Target: -0.999622948135676 | Output: -1.0175908218856249
Input: [ 0.92133849  0.82507178  0.74741915 -0.58603175] | Target: 0.9900648927020624 | Output: 0.912541392565206
Input: [-0.60553526 -0.61901846  0.14587078 -0.17473924] | Target: 0.3279126629549906 | Output: 0.3199978135925169
Input: [-0.35802134  0.73015313  0.60293073  0.02384464] | Target: -0.48738142837990606 | Output: -0.5472077824911701
Input: [-0.1090036   0.16355674  0.52121077  0.26224029] | Target: -0.013589448699499802 | Output: -0.046895004936314266
Input: [0.24809978 0.13586941 0.70807115 0.35517622] | Target: 0.44853479420304265 | Output: 0.445494057366458
Input: [-0.27152698 -0.3868816  -0.74856252  0.05681491] | Target: -0.636554775746118 | Output: -0.7055087897825749
Input: [ 0.00580885  0.59096635 -0.36767075  0.72869544] | Target: -0.993875985392774 | Output: -0.9751649883144836
Input: [ 0.35481914  0.88069484 -0.95698046 -0.367384  ] | Target: -0.8981185186955181 | Output: -0.9456536367069241
Input: [-0.41922212 -0.34126958 -0.80916346  0.63907702] | Target: -0.9990054379643346 | Output: -1.0002114767107249
Input: [ 0.67552242 -0.3586028  -0.84792242 -0.68776653] | Target: 0.7668824355727715 | Output: 0.6936065120404249
Input: [0.35026043 0.96890192 0.68031271 0.59380282] | Target: -0.507371347467531 | Output: -0.6013256405368351
Input: [-0.63373294 -0.22074043 -0.97588408 -0.83528859] | Target: -0.5257427095689864 | Output: -0.5815170245349472
Input: [-0.0222767   0.1081984  -0.76884935  0.75809839] | Target: -0.9962502691004255 | Output: -1.001304063604699
Input: [ 0.87942357  0.4071619   0.30276464 -0.57790568] | Target: 0.9763612859488614 | Output: 0.9126223918125861
Input: [-0.36920023  0.30225159  0.1661646  -0.39389227] | Target: -0.11116471798811212 | Output: -0.15771921852551277
Input: [-0.06072322 -0.78714594 -0.67294101 -0.78471074] | Target: 0.7434354298423212 | Output: 0.7161450412305949
Input: [-0.34393016  0.95254504 -0.31080191  0.81068077] | Target: -0.6621129592186771 | Output: -0.8173397275130458
Input: [ 0.86965397  0.50771038 -0.95344631  0.79036643] | Target: -0.9822062805839687 | Output: -1.0425451572587894
Input: [ 0.55253134 -0.90575846  0.66876745  0.06928906] | Target: 0.8837539313124146 | Output: 0.8033463846537412
Input: [-0.8891273   0.17029516  0.07761798  0.54324158] | Target: -0.9989536393372639 | Output: -1.019945532372945
Input: [-0.03247545  0.62848862 -0.2840394  -0.85224449] | Target: -0.09262602421897013 | Output: -0.1307402178041492
Input: [-0.17492966  0.6020377  -0.13374702  0.40160947] | Target: -0.9667815476307677 | Output: -0.9593372570701681
Input: [ 0.33321489 -0.78608966 -0.70813443 -0.59641281] | Target: 0.8455438312927052 | Output: 0.7982243482664969
Input: [-0.76627588 -0.22203148  0.14491826 -0.92464247] | Target: 0.5014867041380001 | Output: 0.4402454362243695
Input: [-0.54892582  0.20719914 -0.76681321  0.93955098] | Target: -0.6280956729056199 | Output: -0.7430160842565412
Input: [-0.64337341  0.49544423 -0.11255878 -0.01282107] | Target: -0.9453137970150551 | Output: -0.9455110408469082
Input: [-0.82728321 -0.69829701 -0.57700406  0.67442232] | Target: -0.981931689754146 | Output: -0.9718098599025019
Input: [-0.98497539 -0.72891986 -0.1836953   0.24372919] | Target: -0.631495178088639 | Output: -0.6864504714767727
Input: [ 0.70800631 -0.55628296 -0.26687532 -0.34987773] | Target: 0.9751266382188684 | Output: 0.9122203205270468
Input: [ 0.75178324 -0.01347168  0.38898314  0.14288251] | Target: 0.8475520319175844 | Output: 0.8378178649909631
Input: [ 0.41136073 -0.14618654 -0.91102637 -0.93813825] | Target: 0.5519151840967939 | Output: 0.45486023593373004
Input: [ 0.51018995 -0.37692397 -0.5011193   0.44394074] | Target: -0.05791369405285977 | Output: -0.09470778081355649
Input: [ 0.13749821 -0.37478774 -0.06327981  0.08022791] | Target: 0.3604760629800285 | Output: 0.36754398541631017
Input: [ 0.09228736 -0.27344297  0.75162068 -0.23405879] | Target: 0.9760311433779838 | Output: 0.8335119368634626
Input: [-0.50196384 -0.83118106 -0.25087767 -0.73796457] | Target: 0.7286194332234008 | Output: 0.6771467019286782
Input: [ 0.55164468 -0.25600115 -0.13504697  0.49848213] | Target: 0.17323827976742542 | Output: 0.14431357984894436
Input: [ 0.24950619  0.53158706 -0.86338517  0.47552992] | Target: -0.9987402624146927 | Output: -1.0115350183904843
Input: [ 0.51947747  0.94936431  0.43906985 -0.7269993 ] | Target: 0.6714637645748815 | Output: 0.5714736444636958
Input: [-0.6973039   0.0889062  -0.68445586 -0.75797046] | Target: -0.6538755685718755 | Output: -0.6982319687021206
Input: [-0.36976629 -0.43326151  0.66558198 -0.45645676] | Target: 0.9266998656020422 | Output: 0.8743811077806048
Input: [-0.99621318  0.45345917 -0.16715947  0.62688534] | Target: -0.7820045272552989 | Output: -0.8638265994366541
Input: [-0.66679933  0.85103131 -0.57861249  0.31616618] | Target: -0.6661117041117379 | Output: -0.701689200177273
Input: [ 0.59984747  0.93320693 -0.64570456 -0.52073603] | Target: -0.44244927775403126 | Output: -0.502096277289054
Input: [ 0.21660112 -0.82773408  0.18943024 -0.68955577] | Target: 0.9385039454562323 | Output: 0.7950555711916284
Input: [-0.75573124 -0.99691407 -0.14209714  0.48281666] | Target: -0.3743826932963817 | Output: -0.41508700831129486
Input: [ 0.43853717 -0.39233615  0.73276518  0.89920491] | Target: 0.6166133215349328 | Output: 0.558254027025682
Input: [-0.02872933  0.30439828  0.37363359 -0.03299186] | Target: 0.07343169029757857 | Output: 0.058357604205162866
Input: [-0.6846535   0.45758929  0.30868531 -0.58891362] | Target: -0.24221081438382674 | Output: -0.30232358280299126
Input: [-0.42854772  0.22089627 -0.61139582  0.93547015] | Target: -0.810662489719735 | Output: -0.831443184442621
Input: [-0.85755234  0.56294522  0.8090889   0.62068266] | Target: -0.943185741161217 | Output: -0.9550322299157613
Input: [-0.50101857  0.55840577 -0.17363426 -0.488904  ] | Target: -0.67735012743423 | Output: -0.7317350354591442
Input: [ 0.6573529  -0.81043102 -0.51834698 -0.83932845] | Target: 0.9763386465210206 | Output: 0.9232242357441344
Input: [-0.12988235  0.91252681  0.09633054  0.92392102] | Target: -0.9555716234730861 | Output: -1.0792691212188434
Input: [-0.28034689  0.85840257 -0.61431171 -0.28079694] | Target: -0.9951496388594328 | Output: -0.9869696388370233
Input: [ 0.16949099 -0.60932984 -0.85814292  0.88501474] | Target: -0.821671122614376 | Output: -0.9700139643281531
Input: [ 0.61929034 -0.04625989 -0.20040199 -0.71865318] | Target: 0.9260473813814688 | Output: 0.8501359965614986
Input: [ 0.52560633 -0.27594013  0.7360011  -0.84513606] | Target: 0.6881302680119759 | Output: 0.5631386016855174
=========================================================


==================== GLOBAL SUMMARY ====================

HU=12 | LR=0.3 | Epochs=10000 | Test Error=0.000703699556400499
HU=12 | LR=0.5 | Epochs=3000 | Test Error=0.0012038528709480518
HU=12 | LR=0.1 | Epochs=10000 | Test Error=0.0013636774798291146
HU=12 | LR=0.3 | Epochs=3000 | Test Error=0.0015608508682376913
HU=5 | LR=0.3 | Epochs=10000 | Test Error=0.0018901375448464627
HU=12 | LR=0.1 | Epochs=3000 | Test Error=0.0022565727019963964
HU=5 | LR=0.1 | Epochs=10000 | Test Error=0.002515333113356492
HU=12 | LR=1 | Epochs=10000 | Test Error=0.002738652913946853
HU=5 | LR=1 | Epochs=3000 | Test Error=0.003605938056461248
HU=12 | LR=1 | Epochs=3000 | Test Error=0.00383207502477676
HU=5 | LR=0.5 | Epochs=3000 | Test Error=0.004081261669741666
HU=5 | LR=0.1 | Epochs=3000 | Test Error=0.004447744951160801
HU=12 | LR=0.5 | Epochs=10000 | Test Error=0.004709838197404112
HU=5 | LR=0.5 | Epochs=10000 | Test Error=0.005202835813296285
HU=5 | LR=0.3 | Epochs=3000 | Test Error=0.005576373405879865
HU=5 | LR=1 | Epochs=10000 | Test Error=0.0195216294142744
