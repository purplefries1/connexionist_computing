---------------------------------------------------------

Hidden units: 5
Epochs: 100
Learning rate: 0.05

Errors during training:
Error at epoch 1 is 140.05704269673762
Train mean error at (after) epoch 1: 0.35014260674184405
Test error at (after) epoch 1: 0.3912465062462406
----------
Error at epoch 10 is 120.85907235512538
Train mean error at (after) epoch 10: 0.30214768088781346
Test error at (after) epoch 10: 0.3399475007115331
----------
Error at epoch 20 is 106.10662537085753
Train mean error at (after) epoch 20: 0.26526656342714383
Test error at (after) epoch 20: 0.30121400993338776
----------
Error at epoch 30 is 95.20361482724903
Train mean error at (after) epoch 30: 0.23800903706812257
Test error at (after) epoch 30: 0.27282876978707354
----------
Error at epoch 40 is 86.25365377052454
Train mean error at (after) epoch 40: 0.21563413442631135
Test error at (after) epoch 40: 0.24940270985081
----------
Error at epoch 50 is 78.22748102148687
Train mean error at (after) epoch 50: 0.19556870255371717
Test error at (after) epoch 50: 0.22806008103445488
----------
Error at epoch 60 is 70.62227364787513
Train mean error at (after) epoch 60: 0.17655568411968783
Test error at (after) epoch 60: 0.20743198890998457
----------
Error at epoch 70 is 63.26446177295594
Train mean error at (after) epoch 70: 0.15816115443238984
Test error at (after) epoch 70: 0.18707817508395547
----------
Error at epoch 80 is 56.17805344605628
Train mean error at (after) epoch 80: 0.14044513361514072
Test error at (after) epoch 80: 0.16711149834456943
----------
Error at epoch 90 is 49.48181354931789
Train mean error at (after) epoch 90: 0.12370453387329473
Test error at (after) epoch 90: 0.14791382725980745
----------
Error at epoch 100 is 43.31033346051424
Train mean error at (after) epoch 100: 0.1082758336512856
Test error at (after) epoch 100: 0.12992100945084264
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.509050412562654
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: 0.0541182872003801
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.23856865383706377
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.2136874662760301
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.5376081465829253
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.5425295994358078
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.010174901099590803
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: 0.032996762436747
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.44178579464903645
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.3382949820063211
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.3368411675917566
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.32518576129495846
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.17644406004728447
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.3525060313208301
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.2595582552874538
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.1821018020891322
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.2668308721118922
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.3272701335558438
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: -0.034861928124354916
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.4333745963390539
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.3405404160639157
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.256083985221888
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.43057039279573633
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.22263740520415048
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: 0.11182846538126892
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.22826129989123498
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.08795846383745125
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.25768334652208225
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.4384216656639247
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.23393762197747076
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.2476497907502537
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.39985285330210096
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.4966642581827512
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.47126830669354486
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.5069293038256192
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.3310239721695166
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.4150687580768694
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.4784226145219337
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.06333282479879274
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.6345837442886398
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.3957292321684665
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.5377371419554283
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.18922639803303148
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.3003786228435846
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.27451966425391233
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.4857361478452176
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: 0.1388441784053621
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.49443444294979033
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: 0.042903812754333914
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.16142126496186943
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.5911609314907633
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.03985164222249161
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.2583542553649436
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.617269602149574
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.5364721836085559
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.3251754584925675
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.48871350330686836
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.5859413199092267
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.3288586945735861
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.41378513451803833
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.15381183461268896
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: -0.20653586149507136
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: -0.006689610172701999
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.3371476437745212
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.4531494524864111
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.08395829141858513
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.08883136447700449
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.1569786517286655
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.45153617775721344
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.19903704349020332
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.5604372293104782
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.44422649319363106
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.3859959681454198
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.030804900520079958
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.4649816507961561
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.586085137840012
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.18461246570634407
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.23366942135845692
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.1379051311346736
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.2653145929455304
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.6193188413190462
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.2913784134131174
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.10333556769432696
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.30389089831610544
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: -0.10533137174064809
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.3401313260830606
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.26342125215080087
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.4098554031664418
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.4093864781216334
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: -0.040300433895025106
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.3916509361447201
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: 0.08600598473756439
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.5852453974789107
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: -0.14784379441164924
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.2316269997936702
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.18222911967638064
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.22709500294328017
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.23705960797507822
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.19113958881054186
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.26020058563866516
---------------------------------------------------------

Hidden units: 5
Epochs: 1000
Learning rate: 0.05

Errors during training:
Error at epoch 1 is 74.90496068270105
Train mean error at (after) epoch 1: 0.18726240170675262
Test error at (after) epoch 1: 0.22511099078265967
----------
Error at epoch 100 is 20.02493282409003
Train mean error at (after) epoch 100: 0.050062332060225076
Test error at (after) epoch 100: 0.055190775708799704
----------
Error at epoch 200 is 8.386254769554945
Train mean error at (after) epoch 200: 0.020965636923887362
Test error at (after) epoch 200: 0.021094019246350366
----------
Error at epoch 300 is 6.071484848664598
Train mean error at (after) epoch 300: 0.015178712121661496
Test error at (after) epoch 300: 0.014114318644741362
----------
Error at epoch 400 is 5.407668710028054
Train mean error at (after) epoch 400: 0.013519171775070137
Test error at (after) epoch 400: 0.012008875671029975
----------
Error at epoch 500 is 5.17184282341452
Train mean error at (after) epoch 500: 0.012929607058536302
Test error at (after) epoch 500: 0.01121257682667731
----------
Error at epoch 600 is 5.077937350990717
Train mean error at (after) epoch 600: 0.012694843377476792
Test error at (after) epoch 600: 0.010868754206298587
----------
Error at epoch 700 is 5.037754951366515
Train mean error at (after) epoch 700: 0.012594387378416288
Test error at (after) epoch 700: 0.010705998285413642
----------
Error at epoch 800 is 5.019510587926965
Train mean error at (after) epoch 800: 0.012548776469817413
Test error at (after) epoch 800: 0.01062311359985691
----------
Error at epoch 900 is 5.010651412841507
Train mean error at (after) epoch 900: 0.012526628532103767
Test error at (after) epoch 900: 0.010578172330233638
----------
Error at epoch 1000 is 5.005928863229752
Train mean error at (after) epoch 1000: 0.012514822158074378
Test error at (after) epoch 1000: 0.01055241650833558
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.9252697698878536
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.2440135020806759
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.8623315690012249
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.372635170421263
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.9661165306206997
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.9672286556882219
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.3511708193212622
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.6540180143384687
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.9574832470133148
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6367818479512409
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.9042250222572834
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.8227504821452656
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.8316311298807375
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.9621741959779623
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.8507938821942342
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.7021085841050346
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.8609514538674474
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.5382355249500533
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.41622321026717685
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.7225904349367327
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.8236186973711637
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.7503215797420406
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.8906970311384914
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.8400870007252954
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.36719985424842194
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.8694715582273612
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.5918717833384454
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.453704096173694
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.912397548655258
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.8581593269397764
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.8676807450541639
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.6293117842924998
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.6711565319955215
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.9599768242600052
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.9098724640567222
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.44141453777653156
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.9490982159114311
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.9567186042304544
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.6891671287582842
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.9792036320264309
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.9063132946955086
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.9429144264614766
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.872867892833832
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.5011754527591785
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.9345790288629814
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.8551399701271086
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.3182740391675057
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.8980657879202862
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.6992642995056892
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.7157235460136976
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.9801409597612051
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.49347461087585043
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.7732843136982582
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.9842744094550474
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.966244815144807
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.8834266730759597
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.9540942575227859
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.9742122176133139
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.7399746803024967
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.850569471219544
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.3192943158113142
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.21953947730131249
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.32008185188422755
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.8625770310092149
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.9606528124170778
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.8807721702987569
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.8291510446528795
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.7124815335912495
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.9673381524101485
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.608666260634698
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.8887417721590426
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.9455347918206697
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.8631056730434155
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.5848224549242992
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.9184500306924823
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.9514196963459639
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.02163049372349578
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.6467301255885095
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.7814173435087713
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.8625024031291977
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.9733230635549214
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.7832443952803002
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.3413796967558239
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.8382635203776347
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.6956016353845798
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.6897126486565097
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.8595632970443166
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.4090921081195719
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.9219008361138433
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.5447696626407457
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.20958122848440133
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.6874078511033551
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.9515722812476852
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.2990700939678173
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.7983072281125058
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.4918581361985193
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.85328133012774
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.7929803968690403
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.8545376721246486
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.35766593459665497
---------------------------------------------------------

Hidden units: 5
Epochs: 3000
Learning rate: 0.05

Errors during training:
Error at epoch 1 is 107.39514477299556
Train mean error at (after) epoch 1: 0.2684878619324889
Test error at (after) epoch 1: 0.32370299445575673
----------
Error at epoch 300 is 6.247932274872558
Train mean error at (after) epoch 300: 0.015619830687181395
Test error at (after) epoch 300: 0.014873812996993118
----------
Error at epoch 600 is 5.0580475148554385
Train mean error at (after) epoch 600: 0.012645118787138596
Test error at (after) epoch 600: 0.010910664368294692
----------
Error at epoch 900 is 4.980404827867796
Train mean error at (after) epoch 900: 0.01245101206966949
Test error at (after) epoch 900: 0.010563311002177823
----------
Error at epoch 1200 is 4.9694092530102285
Train mean error at (after) epoch 1200: 0.012423523132525571
Test error at (after) epoch 1200: 0.010501310354974565
----------
Error at epoch 1500 is 4.964270616040817
Train mean error at (after) epoch 1500: 0.012410676540102044
Test error at (after) epoch 1500: 0.01048407949360811
----------
Error at epoch 1800 is 4.959682344330973
Train mean error at (after) epoch 1800: 0.012399205860827434
Test error at (after) epoch 1800: 0.010477427025258845
----------
Error at epoch 2100 is 4.955125244582418
Train mean error at (after) epoch 2100: 0.012387813111456045
Test error at (after) epoch 2100: 0.010473929717857298
----------
Error at epoch 2400 is 4.950542060309144
Train mean error at (after) epoch 2400: 0.01237635515077286
Test error at (after) epoch 2400: 0.010471527886143311
----------
Error at epoch 2700 is 4.94592142497532
Train mean error at (after) epoch 2700: 0.0123648035624383
Test error at (after) epoch 2700: 0.010469584178858042
----------
Error at epoch 3000 is 4.94125670088972
Train mean error at (after) epoch 3000: 0.0123531417522243
Test error at (after) epoch 3000: 0.010467890839258072
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.9161127430603551
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.24273280710482018
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.8789217635850451
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.38356792404596785
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.9647823039538618
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.9626520085376346
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.343531478139528
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.6534341250865305
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.9585641202988413
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6211262172216326
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.9050055776379273
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.8138388649763812
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.8310659206823379
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.9591556048742981
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.8572918903346911
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.7060628927545285
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.8590471670332631
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.5780907949241244
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.42238050031979496
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.7174344552472655
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.825035819719075
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.7464329661876498
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.8862998177101483
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.8364945890033342
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.3660191555574252
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.8695486690300221
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.595444460857936
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.46931140717510134
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.9134127786458287
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.859528051476287
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.8615310657455746
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.598485034486907
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.6471636143926326
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.955254267089696
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.9020134095252165
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.42361791474616667
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.9485753315252137
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.9501865104354368
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.6881168675650707
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.9739060577266699
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.903665438289884
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.9348675782941708
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.8761342727922796
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.5224049043762756
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.9316889651999812
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.8329188419395208
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.3197388614447294
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.8840509876986077
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.7191466653396074
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.731383057345243
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.9766020324991042
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.5069419047315524
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.7947376696838984
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.981510310468238
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.9590709700573533
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.8829349247078019
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.9502798859909859
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.9696040568212689
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.7313565429093553
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.85329503806295
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.3327569587875067
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.20427391854068663
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.32119229990514275
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.86006238669636
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.9645952877661389
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.8798067642989715
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.8456067488784956
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.7269704654909842
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.9652001827703232
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.6356121098989241
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.8656292577049929
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.9397619396539214
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.8804867771320801
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.6023966273055406
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.9172097933270097
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.937845624648359
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.07054157025755543
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.6422612535051255
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.8015323221521639
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.8693165193322894
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.9666907478479471
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.7836831476273336
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.35216355092113577
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.8351473927459808
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.6890869377165645
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.6887457384961364
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.8634140531207399
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.3992392779436024
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.9182524939129446
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.5483371523324587
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.21402712925071332
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.677928440751219
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.9385060134312079
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.2858599342246535
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.7972460617003374
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.5024984916369948
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.8520380569173309
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.802743994250041
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.8547929011151767
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.3634037822272962
---------------------------------------------------------

Hidden units: 5
Epochs: 10000
Learning rate: 0.05

Errors during training:
Error at epoch 1 is 117.57695828630652
Train mean error at (after) epoch 1: 0.2939423957157663
Test error at (after) epoch 1: 0.34328871646832576
----------
Error at epoch 1000 is 4.931129156142851
Train mean error at (after) epoch 1000: 0.012327822890357127
Test error at (after) epoch 1000: 0.01040176770309382
----------
Error at epoch 2000 is 4.907740206364896
Train mean error at (after) epoch 2000: 0.01226935051591224
Test error at (after) epoch 2000: 0.01035502676032722
----------
Error at epoch 3000 is 4.886882689239589
Train mean error at (after) epoch 3000: 0.012217206723098973
Test error at (after) epoch 3000: 0.010349576192127095
----------
Error at epoch 4000 is 4.865175236088712
Train mean error at (after) epoch 4000: 0.01216293809022178
Test error at (after) epoch 4000: 0.01034665685808291
----------
Error at epoch 5000 is 4.842178351434524
Train mean error at (after) epoch 5000: 0.012105445878586309
Test error at (after) epoch 5000: 0.010345512321225492
----------
Error at epoch 6000 is 4.817508025418901
Train mean error at (after) epoch 6000: 0.012043770063547253
Test error at (after) epoch 6000: 0.010346123700245876
----------
Error at epoch 7000 is 4.790814485171978
Train mean error at (after) epoch 7000: 0.011977036212929946
Test error at (after) epoch 7000: 0.010348504716457015
----------
Error at epoch 8000 is 4.761772987546328
Train mean error at (after) epoch 8000: 0.01190443246886582
Test error at (after) epoch 8000: 0.010352645428841083
----------
Error at epoch 9000 is 4.730081620410176
Train mean error at (after) epoch 9000: 0.01182520405102544
Test error at (after) epoch 9000: 0.010358462313826209
----------
Error at epoch 10000 is 4.695462262580704
Train mean error at (after) epoch 10000: 0.01173865565645176
Test error at (after) epoch 10000: 0.010365738462178775
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.8718718347727424
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.2377041560113488
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.8712726878825615
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.3837622343664196
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.945433792057915
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.920923653029825
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.38887042992775817
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.6591503168568127
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.9378180152510546
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6362021231965002
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.913336835828151
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.814170493469537
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.8200685103392242
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.9315945094867554
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.83820480254515
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.6998185013033432
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.8481608501945511
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.5433569892074184
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.41722843767260637
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.7096526941390416
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.7904406654593009
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.7248017653011497
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.8635971537788969
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.7988657291853744
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.3704013993824156
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.8627061875621354
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.5859093537675737
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.49131378776033663
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.8882666603141011
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.8195098582271397
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.8348691643743097
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.6286065396062901
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.6481721350256965
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.908609746385695
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.8982501293160762
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.43181595701858905
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.9365905552570122
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.898453586495017
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.6882551213104188
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.9392485258503588
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.8787857794394692
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.9154269688215242
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.8461166631727186
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.5122902275189568
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.9081551025162035
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.8294864965019866
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.3128422441568321
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.8511003283435888
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.7188348804332916
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.7278258623695756
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.9412471144461085
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.5023895469117907
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.7826581691375079
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.9627249777733284
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.9129086411288168
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.901041240528233
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.9327496341894951
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.9509314062312417
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.7244829056252968
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.8256418823132861
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.3493717815122972
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.2096015944906434
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.33616190552310066
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.815828276612813
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.9496787182798507
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.8762694824570761
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.8347690302478142
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.7094491757978881
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.9490382640216191
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.6164606300366802
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.8446209211066441
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.8863196016475077
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.8559201024584212
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.5974675610379099
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.875200081379605
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.9064563026942634
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.08766691321491009
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.6435697858639055
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.7833216450882449
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.821955415810158
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.9309595933981731
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.7644043154871913
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.358704435277273
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.7928434245597994
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.6807309737971438
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.696568243620912
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.8418384923684151
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.4253237235131475
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.895644839389925
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.5517941482381137
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.23801337316776847
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.7051777787659728
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.9016088385465849
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.27496733029218623
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.7920496931322198
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.5188788694201784
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.81635115752231
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.7811504905910913
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.8309236798005681
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.3684551678231695
---------------------------------------------------------

Hidden units: 5
Epochs: 100
Learning rate: 0.1

Errors during training:
Error at epoch 1 is 106.4944385381488
Train mean error at (after) epoch 1: 0.266236096345372
Test error at (after) epoch 1: 0.30978804859166725
----------
Error at epoch 10 is 89.12604143667056
Train mean error at (after) epoch 10: 0.22281510359167642
Test error at (after) epoch 10: 0.26035858544643176
----------
Error at epoch 20 is 74.61306047937221
Train mean error at (after) epoch 20: 0.18653265119843052
Test error at (after) epoch 20: 0.21852800037626569
----------
Error at epoch 30 is 61.5192604268669
Train mean error at (after) epoch 30: 0.15379815106716724
Test error at (after) epoch 30: 0.17991523347573984
----------
Error at epoch 40 is 49.66012866999245
Train mean error at (after) epoch 40: 0.12415032167498113
Test error at (after) epoch 40: 0.14424161728898593
----------
Error at epoch 50 is 39.489019132107465
Train mean error at (after) epoch 50: 0.09872254783026867
Test error at (after) epoch 50: 0.11330930178382934
----------
Error at epoch 60 is 31.18893661812498
Train mean error at (after) epoch 60: 0.07797234154531245
Test error at (after) epoch 60: 0.08806153098608945
----------
Error at epoch 70 is 24.653125480701494
Train mean error at (after) epoch 70: 0.06163281370175373
Test error at (after) epoch 70: 0.06836325657134751
----------
Error at epoch 80 is 19.637075511059695
Train mean error at (after) epoch 80: 0.04909268877764924
Test error at (after) epoch 80: 0.05347310985059339
----------
Error at epoch 90 is 15.860965348026467
Train mean error at (after) epoch 90: 0.03965241337006617
Test error at (after) epoch 90: 0.04244966737025092
----------
Error at epoch 100 is 13.05856805305879
Train mean error at (after) epoch 100: 0.03264642013264698
Test error at (after) epoch 100: 0.034385747711082354
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.7631658583510237
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: 0.16310803446919425
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.6480512649506636
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.20108961276279974
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.8441124787131289
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.8469364629841255
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.3785614875111493
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.2770915943299705
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.8250812400562686
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.4006845410923131
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.6593609926092232
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.5389533389869627
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.544272894637625
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.8239740384719855
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.6222334765837683
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.5626857891073264
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.5725218882810618
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.3874248315761634
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.2838681022297591
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.6458663460781867
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.7087562627094336
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.4392668777836518
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.6921650105832584
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.5959386298852468
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.13176168194593044
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.5869682830910617
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.372826066450816
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.3730598481977194
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.7403003408399523
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.6236345577088004
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.5755040236046026
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.34337543173451535
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.5900202131525947
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.8279949513522896
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.7299898171503632
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.495630766729531
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.7710849211911586
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.7982388790976226
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.4579951661485605
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.8781830342276147
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.7295527406549607
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.7764738434311459
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.6531572792204929
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.2720260476489731
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.7507972408556299
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.6240741765697753
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.06286549834966185
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.6704109476137267
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.40127133429178036
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.5263028372622485
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.883116350195038
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.39291251700021307
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.6072295024716924
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.8914762620615769
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.8290772071766686
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.616958570804865
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.7899659102154079
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.8530286539700305
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.49211227010917696
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.6368617995900451
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.25098973120813667
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.062179775090299774
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.1569017038527872
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.7202109930871748
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.8306553673492036
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.5631149308646012
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.5696132889360928
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.5741597909574813
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.8192027154876804
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.3067089158196055
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.6952914318647465
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.7717357900050197
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.7442205075478795
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.43423106005118406
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.7930389757312319
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.7913147912656606
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: -0.00776689320773081
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.3809494075748954
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.5880784951082436
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.6381242106045841
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.860430070343846
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.5575092503382851
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.1914910802392374
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.6193662040412282
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.2634626917722339
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.40534392728101926
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.6257917593330186
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.36779900941018356
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.7107195936832565
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.16541147274350573
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.33513860926395983
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.31285688964333636
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.7919902796708244
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.14621577299915423
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.4858011487195538
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.32065636837149136
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.6410831725188796
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.5941425366967475
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.5886155551483079
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.3031357803865161
---------------------------------------------------------

Hidden units: 5
Epochs: 1000
Learning rate: 0.1

Errors during training:
Error at epoch 1 is 128.00691546642432
Train mean error at (after) epoch 1: 0.3200172886660608
Test error at (after) epoch 1: 0.3792928315300893
----------
Error at epoch 100 is 14.103119288159432
Train mean error at (after) epoch 100: 0.03525779822039858
Test error at (after) epoch 100: 0.038947560159762265
----------
Error at epoch 200 is 5.8528107020159545
Train mean error at (after) epoch 200: 0.014632026755039886
Test error at (after) epoch 200: 0.013755176319404632
----------
Error at epoch 300 is 5.147586998470978
Train mean error at (after) epoch 300: 0.012868967496177447
Test error at (after) epoch 300: 0.011329129305859297
----------
Error at epoch 400 is 5.0307237901470145
Train mean error at (after) epoch 400: 0.012576809475367537
Test error at (after) epoch 400: 0.010844628902797675
----------
Error at epoch 500 is 5.0047019839216995
Train mean error at (after) epoch 500: 0.012511754959804248
Test error at (after) epoch 500: 0.010707828838524718
----------
Error at epoch 600 is 4.996231620732087
Train mean error at (after) epoch 600: 0.012490579051830217
Test error at (after) epoch 600: 0.010658351297135903
----------
Error at epoch 700 is 4.991492956697425
Train mean error at (after) epoch 700: 0.012478732391743564
Test error at (after) epoch 700: 0.010636533628334534
----------
Error at epoch 800 is 4.987593838665857
Train mean error at (after) epoch 800: 0.012468984596664644
Test error at (after) epoch 800: 0.01062517106503901
----------
Error at epoch 900 is 4.983898775203213
Train mean error at (after) epoch 900: 0.012459746938008031
Test error at (after) epoch 900: 0.0106182973364482
----------
Error at epoch 1000 is 4.980263644193049
Train mean error at (after) epoch 1000: 0.012450659110482622
Test error at (after) epoch 1000: 0.010613534522339091
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.9148370803237771
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.2607177473342539
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.8849984839227242
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.38010229121859695
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.9648367970115801
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.9649141563977152
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.32561892142234694
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.6643397381189685
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.9586206389239764
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6164544372373851
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.902617281595526
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.812343423888151
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.8390170063258618
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.9680948043602242
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.8610033157557178
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.7014946151405034
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.858306460880251
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.5624811033920435
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.409091238321887
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.7325009135949488
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.8177886928272992
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.7435656614978235
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.8863147018660764
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.8530037171153774
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.3698139497118706
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.8719567575062452
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.5960951465558394
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.47929432265546323
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.9150223721250956
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.8876169560193592
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.8678865948638451
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.5697051610114335
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.6612101151439477
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.9594301844883114
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.8949220066884441
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.4438415454314928
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.9486671249499535
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.9505903522323883
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.6958443303561516
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.9750831600453703
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.9051583167000745
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.9182631142818476
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.8780738958876919
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.4957115347845868
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.9432429818609611
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.8134464691733797
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.3149544880372124
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.8548176764803793
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.7142793902466552
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.7288922545381651
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.9800534357777823
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.4993819046848497
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.7943374842730222
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.9826895332796071
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.9587906617457461
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.8795517726475002
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.9473952426642852
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.9669997559487473
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.729168099606701
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.8330726680937791
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.3384242655294863
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.19272005586443774
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.33041635554100873
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.8599991264719543
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.9647423523872265
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.8893278304718593
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.8509765934536431
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.7131702023136535
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.9669048860389242
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.6356584375189508
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.8292894040583015
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.9416317914826386
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.8743620557257077
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.5903629064164437
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.9152064438374133
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.918243844997999
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.06298124583892095
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.6431294436889469
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.793877169038604
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.894742865642508
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.9666408589947741
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.7863948218798632
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.3690976409643855
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.8424450247356324
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.7007065547659256
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.6562754575189317
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.8674808212977745
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.4063347247737213
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.9129605950821102
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.5544564126030905
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.238452170642399
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.7136922754644597
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.9137460868986105
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.2660679010981205
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.7945614129003633
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.5095335859031803
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.8560355165289592
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.8024434096880599
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.861548949677641
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.37649047469913133
---------------------------------------------------------

Hidden units: 5
Epochs: 3000
Learning rate: 0.1

Errors during training:
Error at epoch 1 is 111.10120796095072
Train mean error at (after) epoch 1: 0.2777530199023768
Test error at (after) epoch 1: 0.32787126915321063
----------
Error at epoch 300 is 5.028834325561524
Train mean error at (after) epoch 300: 0.012572085813903811
Test error at (after) epoch 300: 0.010814384027140984
----------
Error at epoch 600 is 4.9371504007368925
Train mean error at (after) epoch 600: 0.01234287600184223
Test error at (after) epoch 600: 0.010399521655170446
----------
Error at epoch 900 is 4.927079484488463
Train mean error at (after) epoch 900: 0.012317698711221157
Test error at (after) epoch 900: 0.010375905124437
----------
Error at epoch 1200 is 4.91762149800361
Train mean error at (after) epoch 1200: 0.012294053745009026
Test error at (after) epoch 1200: 0.010370114558902119
----------
Error at epoch 1500 is 4.908017385341855
Train mean error at (after) epoch 1500: 0.012270043463354639
Test error at (after) epoch 1500: 0.010366523809145
----------
Error at epoch 1800 is 4.8982012942904625
Train mean error at (after) epoch 1800: 0.012245503235726157
Test error at (after) epoch 1800: 0.01036366900923812
----------
Error at epoch 2100 is 4.888121368991374
Train mean error at (after) epoch 2100: 0.012220303422478436
Test error at (after) epoch 2100: 0.010361373156700316
----------
Error at epoch 2400 is 4.877732579057102
Train mean error at (after) epoch 2400: 0.012194331447642754
Test error at (after) epoch 2400: 0.01035960285892235
----------
Error at epoch 2700 is 4.866995811329451
Train mean error at (after) epoch 2700: 0.012167489528323628
Test error at (after) epoch 2700: 0.010358349890180085
----------
Error at epoch 3000 is 4.85587732066975
Train mean error at (after) epoch 3000: 0.012139693301674375
Test error at (after) epoch 3000: 0.010357616993901055
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.9032854743999632
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.24610609538529182
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.8718739200686999
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.37466516894113633
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.9573100226857113
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.9509381331909171
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.39081289633984745
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.6594016774258864
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.9516277793780754
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6384062305258491
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.9147163389633565
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.8232094044367912
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.8300603951255723
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.958920134397755
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.8472923717123323
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.700210519648788
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.8562472829342875
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.546733723702516
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.4036821903687277
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.7092877731985513
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.810586275408387
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.7389884210635308
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.8790254808763105
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.8348195385124105
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.36735712666705717
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.8696957209467969
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.5883575231691862
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.47256253191642356
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.9017993234957214
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.8605443928474655
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.8593112956469898
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.6356800388637299
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.669155193468115
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.9449366062461335
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.9054109539024471
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.43786238122068566
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.946685037610048
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.9374044705889439
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.695030545051486
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.9638409195895079
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.8957805192459893
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.9323285306179979
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.8648221238823363
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.5055092943294883
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.9340959116162842
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.8474099270191062
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.3146305882327846
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.8801117633384963
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.7099297145479901
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.716655545816262
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.969412260407651
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.4898595156110227
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.7696935227379607
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.9759283953044504
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.9474116175028966
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.899351345588128
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.9456221989411115
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.9641405408884075
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.7324090988579111
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.8418135011434001
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.33447889886203286
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.21185728559573766
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.32870664535311594
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.8518475796139109
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.9581227162632816
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.8877909441897234
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.8368657262959132
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.6988263835455055
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.9632345094543415
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.6076938194924147
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.8756536109983274
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.9264061856447503
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.8493017743207424
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.5816084061518112
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.9001512368378934
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.9348591225569328
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.040007587753587544
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.6446923535414334
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.7732650532404646
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.862624139377326
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.956064532850694
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.7735738855859481
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.3385783221977005
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.8243242270983683
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.701093232752559
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.6919413926353314
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.8546073946947903
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.42719690779181596
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.9113060860440937
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.5559845655543835
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.23454073054883393
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.7073542281418721
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.9335693313569591
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.2765923006692864
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.7946320996246206
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.5090399452584085
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.8434134183751216
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.7843534978524124
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.8499468185934523
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.36252806272627375
---------------------------------------------------------

Hidden units: 5
Epochs: 10000
Learning rate: 0.1

Errors during training:
Error at epoch 1 is 130.59908548601825
Train mean error at (after) epoch 1: 0.32649771371504566
Test error at (after) epoch 1: 0.3822939863322853
----------
Error at epoch 1000 is 4.830366545449802
Train mean error at (after) epoch 1000: 0.012075916363624506
Test error at (after) epoch 1000: 0.010485307956426528
----------
Error at epoch 2000 is 4.726051226522484
Train mean error at (after) epoch 2000: 0.011815128066306212
Test error at (after) epoch 2000: 0.010473944201629323
----------
Error at epoch 3000 is 4.613108579352544
Train mean error at (after) epoch 3000: 0.01153277144838136
Test error at (after) epoch 3000: 0.010456962465823965
----------
Error at epoch 4000 is 4.498070637823405
Train mean error at (after) epoch 4000: 0.011245176594558513
Test error at (after) epoch 4000: 0.010443231057601617
----------
Error at epoch 5000 is 4.388773890961669
Train mean error at (after) epoch 5000: 0.010971934727404174
Test error at (after) epoch 5000: 0.010437186010068352
----------
Error at epoch 6000 is 4.2873900636119835
Train mean error at (after) epoch 6000: 0.01071847515902996
Test error at (after) epoch 6000: 0.010440064014728847
----------
Error at epoch 7000 is 4.190543376910008
Train mean error at (after) epoch 7000: 0.01047635844227502
Test error at (after) epoch 7000: 0.010451991650016517
----------
Error at epoch 8000 is 4.091891470745714
Train mean error at (after) epoch 8000: 0.010229728676864286
Test error at (after) epoch 8000: 0.010466749796345886
----------
Error at epoch 9000 is 3.982742953434773
Train mean error at (after) epoch 9000: 0.009956857383586933
Test error at (after) epoch 9000: 0.010465709122208074
----------
Error at epoch 10000 is 3.8519654753903354
Train mean error at (after) epoch 10000: 0.00962991368847584
Test error at (after) epoch 10000: 0.010415658022906851
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.7632528173027562
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.2742655691365571
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.8520949668784324
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.4157734122466395
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.8422339978272769
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.7973904986194988
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.4343745434319669
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.6895161243095724
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.8671308496133593
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6357459846742675
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.8612168019811646
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.7805503160790406
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.8081725416021056
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.8648418274776658
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.8192820026543737
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.7216610499284759
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.8135950879006195
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.5584974882717635
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.45662567449351665
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.6994460773133092
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.7792135028104096
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.71440703441993
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.7946746372713508
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.788715460059541
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.3955680645169999
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.8351888550630653
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.6236484869432103
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.5333552883069784
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.817943241434417
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.7992617505176621
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.8102197148741486
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.6213503444000817
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.6188861259145337
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.8143663619385524
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.8075990552105347
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.4743780228536378
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.8630546834057896
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.7756183958682213
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.7155041756623464
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.7560636349328475
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.8208878105338324
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.7905195528381457
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.8419237369685728
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.5307260526090658
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.865654076636732
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.7439322171510082
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.33823950786512
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.7405410546259437
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.75855267660913
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.7443814390311474
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.7992837920127938
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.5450608416341535
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.77888280168746
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.81456387377767
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.7677878123636664
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.8538533359262213
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.8330252481380439
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.8082861926476133
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.7065351308727813
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.7622094731186296
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.3952781625565046
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.22160786239036648
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.3623603081993965
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.7933957509167617
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.877680396287085
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.8689048291316686
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.8497224957698366
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.7356805933296497
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.8627284158253347
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.6306263201106093
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.7107811823267853
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.7818997578436174
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.8219296951867195
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.6380449147755872
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.8088990367831308
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.7374271845120275
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.14103898629843575
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.655771815216264
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.7991208101465832
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.7913742223609381
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.7542319144338618
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.7500896730169365
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.40436324165538196
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.7674823620972584
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.7438975370860081
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.6855101586995926
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.8206240973630227
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.45248669535030883
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.8183434253441816
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.6045184440530262
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.29531378861981095
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.7345375761265757
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.7240017206609175
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.30131456193445916
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.7745462708362049
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.5615063555900539
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.8098990415231915
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.7795213979361183
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.824527974631182
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.410153375186338
---------------------------------------------------------

Hidden units: 5
Epochs: 100
Learning rate: 0.3

Errors during training:
Error at epoch 1 is 58.38612206213834
Train mean error at (after) epoch 1: 0.14596530515534586
Test error at (after) epoch 1: 0.15212954802227657
----------
Error at epoch 10 is 21.229165097024683
Train mean error at (after) epoch 10: 0.053072912742561706
Test error at (after) epoch 10: 0.05638781875708838
----------
Error at epoch 20 is 10.893065833050933
Train mean error at (after) epoch 20: 0.027232664582627332
Test error at (after) epoch 20: 0.028180456200329017
----------
Error at epoch 30 is 7.604429025850413
Train mean error at (after) epoch 30: 0.019011072564626034
Test error at (after) epoch 30: 0.018685143422904216
----------
Error at epoch 40 is 6.2753239882477185
Train mean error at (after) epoch 40: 0.015688309970619298
Test error at (after) epoch 40: 0.014717895804834024
----------
Error at epoch 50 is 5.659500029265316
Train mean error at (after) epoch 50: 0.01414875007316329
Test error at (after) epoch 50: 0.012823350032862287
----------
Error at epoch 60 is 5.349020761202058
Train mean error at (after) epoch 60: 0.013372551903005146
Test error at (after) epoch 60: 0.01183373958208924
----------
Error at epoch 70 is 5.183317801147582
Train mean error at (after) epoch 70: 0.012958294502868955
Test error at (after) epoch 70: 0.011282190092629301
----------
Error at epoch 80 is 5.0912125389943474
Train mean error at (after) epoch 80: 0.012728031347485869
Test error at (after) epoch 80: 0.01095912311264315
----------
Error at epoch 90 is 5.038437226279259
Train mean error at (after) epoch 90: 0.01259609306569815
Test error at (after) epoch 90: 0.010762159771142518
----------
Error at epoch 100 is 5.007466102998073
Train mean error at (after) epoch 100: 0.012518665257495183
Test error at (after) epoch 100: 0.010637968989591528
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.9070053632444721
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.22996319928055164
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.8774556300368934
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.359478728838962
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.9588103335162014
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.9591035541227254
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.3751508074284568
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.6295352677911896
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.9500105640328806
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6244761122291195
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.9126528877565995
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.8251133489612903
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.8108032481712479
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.9557783628209388
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.8465543168119957
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.6778852679600503
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.8422346059556671
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.5252353827712961
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.3784702218822003
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.7104211294456473
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.8065639940386712
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.7278017813010246
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.8852974739726897
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.8256116033112485
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.3470311159648313
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.8559035368312218
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.5648645770355951
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.46717267691682685
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.9107614477696023
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.8599856810933152
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.8552132211780987
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.6116197367841617
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.6416018433353201
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.9502200363138604
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.9004386471062782
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.4205719291622185
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.9457325728985834
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.9432255604370754
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.6678389782455705
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.9747862868336975
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.8858522834678944
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.9264928434723039
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.8576817655784612
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.4865584489048662
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.9260002443848091
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.8487369292813371
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.29514960489259534
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.8808868368890632
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.6770941283474742
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.6958233691441882
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.9786845581435949
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.46427959308882283
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.7697493320768213
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.9796644979856658
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.9550886104280872
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.8969618076467236
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.9447024104511715
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.9666323735329833
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.7240040183347972
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.8190778333473461
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.32367538615550384
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.19711702102275613
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.3109501662698764
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.8464440901610226
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.9591551008074419
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.8694884293068781
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.8295070527194082
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.6849423089103737
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.9636215436895821
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.6062814878551417
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.8716600080284223
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.930767786671511
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.8598320686331888
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.552782997406482
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.9057771435822118
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.9442228635148409
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.07119190578021295
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.6308709167506183
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.7635851192732178
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.8657190724701284
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.9669635506843949
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.7671100656874216
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.33865317871166006
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.8163084883715016
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.6694652039387778
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.6621430888150525
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.8533628379066871
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.3967549154690969
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.903531101392274
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.5291929945319734
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.2033993486437015
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.6798644906207919
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.9414445958056206
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.2555076189318911
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.7763289810353599
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.4925705292025113
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.8336940901647609
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.7777150117114873
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.8429090010754958
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.3394938273692395
---------------------------------------------------------

Hidden units: 5
Epochs: 1000
Learning rate: 0.3

Errors during training:
Error at epoch 1 is 115.8649795822784
Train mean error at (after) epoch 1: 0.289662448955696
Test error at (after) epoch 1: 0.3022361518220927
----------
Error at epoch 100 is 5.042501774996475
Train mean error at (after) epoch 100: 0.012606254437491186
Test error at (after) epoch 100: 0.010955238401759193
----------
Error at epoch 200 is 4.953762743452683
Train mean error at (after) epoch 200: 0.012384406858631706
Test error at (after) epoch 200: 0.010560654398149263
----------
Error at epoch 300 is 4.93912571599723
Train mean error at (after) epoch 300: 0.012347814289993075
Test error at (after) epoch 300: 0.010537173910488536
----------
Error at epoch 400 is 4.924730920846281
Train mean error at (after) epoch 400: 0.012311827302115703
Test error at (after) epoch 400: 0.010532039616545544
----------
Error at epoch 500 is 4.909834563062556
Train mean error at (after) epoch 500: 0.01227458640765639
Test error at (after) epoch 500: 0.010529287996782506
----------
Error at epoch 600 is 4.894303183578852
Train mean error at (after) epoch 600: 0.012235757958947132
Test error at (after) epoch 600: 0.010527339290378225
----------
Error at epoch 700 is 4.878013540126355
Train mean error at (after) epoch 700: 0.012195033850315888
Test error at (after) epoch 700: 0.010525943604711565
----------
Error at epoch 800 is 4.8608463064959695
Train mean error at (after) epoch 800: 0.012152115766239924
Test error at (after) epoch 800: 0.010525000448444385
----------
Error at epoch 900 is 4.842685646111142
Train mean error at (after) epoch 900: 0.012106714115277854
Test error at (after) epoch 900: 0.01052443545947913
----------
Error at epoch 1000 is 4.823419646178349
Train mean error at (after) epoch 1000: 0.012058549115445873
Test error at (after) epoch 1000: 0.01052418406693477
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.9048412320101203
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.25737763137451425
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.8491628643511256
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.385077833541562
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.9595868786471419
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.9473725578293691
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.3879017460812103
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.6526099449961805
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.9526362916957825
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6310638972967468
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.8969804184096796
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.799014535527355
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.8245726101815218
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.9493184584489629
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.8344736030816339
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.7110849273807338
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.8508829055965953
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.5731831001073384
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.4240360551286011
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.7061344665654729
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.8228778225414304
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.7295859804317308
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.870951726519023
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.8171080261478719
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.37085738034169974
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.8604554797535923
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.5933583442551111
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.47088617010428413
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.8953781665775219
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.832040459305328
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.8323737389634606
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.6263141582077931
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.654562473728441
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.9381321270937043
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.9055776365135443
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.41889479675509017
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.9380119183337748
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.9279346593073184
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.6971403619766108
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.9602668292325224
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.9007678507048491
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.9368232786713738
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.8541819278560154
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.5254924032234181
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.9235261030425209
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.8359997004209102
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.32357744933607346
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.8757373363066014
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.7131955977858514
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.7286584840442971
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.9557966918937757
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.5051080226094402
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.7766352317946772
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.9750704913092466
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.9409937619501074
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.8786031326821174
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.9438481820703896
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.9649289771542131
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.7271257216590099
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.855718768922623
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.337678178281886
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.22318041196694222
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.32497013664405516
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.8564505677499518
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.9561585766111538
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.8653122822316394
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.8124255579427341
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.7213215477947765
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.9523825781428933
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.6063189889627812
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.8757460628656573
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.9164906148219045
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.862908368414452
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.6011306232290062
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.9067874946446821
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.928563552849312
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.05809784690170025
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.639005133690542
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.7817775692058262
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.8384609598256042
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.9542701099802731
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.7711934597158104
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.33733643941508545
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.8202835074133491
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.6714285939097634
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.7034811081868598
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.8402257801604301
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.4149551728121186
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.9118621413026587
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.5432781035851783
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.1946267558563979
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.6816418786467884
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.9296747316080033
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.2974570143723198
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.7926004688272108
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.5082364298574072
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.8377019692388338
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.7877341998930669
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.8288655746447184
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.3563621298719761
---------------------------------------------------------

Hidden units: 5
Epochs: 3000
Learning rate: 0.3

Errors during training:
Error at epoch 1 is 129.87686187904865
Train mean error at (after) epoch 1: 0.32469215469762164
Test error at (after) epoch 1: 0.3198022357913562
----------
Error at epoch 300 is 4.950429197468294
Train mean error at (after) epoch 300: 0.012376072993670734
Test error at (after) epoch 300: 0.010429438128153246
----------
Error at epoch 600 is 4.92238354121118
Train mean error at (after) epoch 600: 0.01230595885302795
Test error at (after) epoch 600: 0.01043232844895997
----------
Error at epoch 900 is 4.889862300688902
Train mean error at (after) epoch 900: 0.012224655751722255
Test error at (after) epoch 900: 0.010439434843525355
----------
Error at epoch 1200 is 4.851352083643417
Train mean error at (after) epoch 1200: 0.012128380209108542
Test error at (after) epoch 1200: 0.010449728942095584
----------
Error at epoch 1500 is 4.805198588583685
Train mean error at (after) epoch 1500: 0.012012996471459212
Test error at (after) epoch 1500: 0.010463888062828011
----------
Error at epoch 1800 is 4.74961632286737
Train mean error at (after) epoch 1800: 0.011874040807168425
Test error at (after) epoch 1800: 0.010481984730645606
----------
Error at epoch 2100 is 4.6829126132167405
Train mean error at (after) epoch 2100: 0.011707281533041852
Test error at (after) epoch 2100: 0.010502795732507642
----------
Error at epoch 2400 is 4.604090551572999
Train mean error at (after) epoch 2400: 0.011510226378932498
Test error at (after) epoch 2400: 0.01052313756053117
----------
Error at epoch 2700 is 4.513889946363985
Train mean error at (after) epoch 2700: 0.011284724865909963
Test error at (after) epoch 2700: 0.010538183478202585
----------
Error at epoch 3000 is 4.415817687552397
Train mean error at (after) epoch 3000: 0.011039544218880992
Test error at (after) epoch 3000: 0.010544084599837888
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.8226871216856957
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.2549785107203811
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.8315850721964126
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.3944828942179215
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.9115235584579543
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.873658224935135
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.41192286811373685
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.6704937136958349
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.9134704249144864
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6187216279968311
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.883219438096809
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.7753764465499657
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.8198179818410174
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.9275204291051954
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.8074440172733087
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.7044967825538047
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.8382225370119614
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.5548634239566066
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.43457214566499675
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.6901289761348858
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.7727789878815909
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.714610453173866
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.8147749933198773
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.8010778836156391
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.37421511808811997
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.850959859946286
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.5942362585296992
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.49606133420446014
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.8372871399437196
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.8283926547000139
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.8169557630959352
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.6103162924354165
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.636785889064872
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.8768576384409847
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.8644362953084983
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.44769654447235574
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.9090450680751403
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.8604340410153282
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.7019672668204402
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.8747988504308314
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.8625128105216252
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.8797375200681896
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.8293496495362238
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.5188941398343166
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.9079459326033276
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.7743052143216143
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.3214258851881337
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.7993575910684698
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.7266766154994828
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.7233014276617034
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.897599577243591
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.5088589832260082
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.7505187737795365
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.9272985183396123
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.8631899899230325
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.8702763152850392
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.9012158696629471
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.9110581488944406
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.6994179588180569
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.8149140712446327
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.3636299113709964
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.2213288299628946
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.34569252934193534
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.8046410029993926
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.9199114965121621
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.8731273155708025
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.8164023409867432
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.6986124360070116
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.9249343571093643
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.6277815258952356
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.7825647477591677
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.8549894714399293
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.8092950803675101
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.6016466319832285
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.8352491793207828
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.8340038326057816
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.09687989522475218
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.63308162730149
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.763391989396952
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.8291782265703
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.8636627937462705
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.740388007442506
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.36052637731546655
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.7820195924946184
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.70562239568695
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.6953544886464139
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.8126523332626533
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.43602803864627454
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.8751165892398817
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.5710437415617661
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.2729385244347992
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.7171634684989063
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.8296722772449007
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.30084335164777815
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.7867280146470746
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.5310758792027042
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.8070034068656582
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.7587797659441792
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.8141580611181802
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.37654960779670266
---------------------------------------------------------

Hidden units: 5
Epochs: 10000
Learning rate: 0.3

Errors during training:
Error at epoch 1 is 108.64309765608807
Train mean error at (after) epoch 1: 0.2716077441402202
Test error at (after) epoch 1: 0.3075369886373989
----------
Error at epoch 1000 is 4.568153428808753
Train mean error at (after) epoch 1000: 0.011420383572021882
Test error at (after) epoch 1000: 0.010397368543901934
----------
Error at epoch 2000 is 4.232776096724396
Train mean error at (after) epoch 2000: 0.01058194024181099
Test error at (after) epoch 2000: 0.010559059059654213
----------
Error at epoch 3000 is 3.9065857625349407
Train mean error at (after) epoch 3000: 0.009766464406337352
Test error at (after) epoch 3000: 0.010643657044133788
----------
Error at epoch 4000 is 3.4855833713094326
Train mean error at (after) epoch 4000: 0.008713958428273582
Test error at (after) epoch 4000: 0.01012206674066108
----------
Error at epoch 5000 is 3.057689224249578
Train mean error at (after) epoch 5000: 0.007644223060623945
Test error at (after) epoch 5000: 0.009154163558967816
----------
Error at epoch 6000 is 2.745342674256377
Train mean error at (after) epoch 6000: 0.006863356685640943
Test error at (after) epoch 6000: 0.00840401085854321
----------
Error at epoch 7000 is 2.5178568300954627
Train mean error at (after) epoch 7000: 0.006294642075238657
Test error at (after) epoch 7000: 0.00782300780724365
----------
Error at epoch 8000 is 2.358548400121232
Train mean error at (after) epoch 8000: 0.00589637100030308
Test error at (after) epoch 8000: 0.0073583926440198245
----------
Error at epoch 9000 is 2.2424671514104437
Train mean error at (after) epoch 9000: 0.005606167878526109
Test error at (after) epoch 9000: 0.0069844096160080315
----------
Error at epoch 10000 is 2.1461760378078636
Train mean error at (after) epoch 10000: 0.0053654400945196586
Test error at (after) epoch 10000: 0.0066690300581081115
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.822999821426305
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.3220635220616295
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.8713456184498329
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.43143649786349925
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.7946263777406932
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.7437793239867103
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.4401648053641904
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.692493029025795
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.7802133248408792
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6764132324243536
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.861097029056912
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.8134340625612139
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.7838284379788468
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.8191647932907828
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.8453796811119013
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.68430827317535
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.7976488916858628
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.6066502481974159
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.5150602644799277
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.7644565707310447
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.8319696040837835
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.7515347086681268
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.8410692797378178
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.8226039731435529
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.43000641536147455
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.8087316530903813
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.6476260215585842
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.5021360489520782
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.8555148547323491
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.8746205460305733
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.8227180199196876
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.6708818536720726
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.7052603427598897
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.7741015056808518
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.8730729522700804
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.4971630982615735
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.8177877561365516
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.7638234369530796
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.6937590056237628
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.5813333511185474
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.798832620219359
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.8427072094496645
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.8539743700919555
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.567585958601851
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.8367826481660143
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.8170382167278243
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.3558454490022028
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.803707605287177
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.7481159601293502
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.7309980876949052
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.4581841987529873
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.5432065659449364
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.8262683519783446
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.6196432557593966
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.7155578524949885
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.8673907682359582
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.8099084610438165
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.7768904756405297
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.754317530419178
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.7935515715326329
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.37033555504350996
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.2009993920311295
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.37295185547434734
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.8267444254095193
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.8038055855294632
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.8355725110382539
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.8634895040468734
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.7900237732385358
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.7694379274082779
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.7032088464882839
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.8205634453699142
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.7947920465489354
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.8822313234612482
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.6309094386206068
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.8585621099478019
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.7610027892979025
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.0972210041905042
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.6881899319266265
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.8408783444503078
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.8807799890571203
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.6996828449414068
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.7921224232739849
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.45303330629383515
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.8032293174811794
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.723743923910326
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.7122045773961891
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.8433233375425214
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.442085626146527
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.8086030606975981
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.6014765431388672
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.4069902739599884
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.8018802041942562
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.7488842737122877
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.34091660541392516
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.7632694265326259
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.593976214435606
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.8285990555544434
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.8194186448811159
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.8342901167572926
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.4106784738590222
---------------------------------------------------------

Hidden units: 5
Epochs: 100
Learning rate: 0.5

Errors during training:
Error at epoch 1 is 78.38960409806015
Train mean error at (after) epoch 1: 0.19597401024515038
Test error at (after) epoch 1: 0.2065589009314867
----------
Error at epoch 10 is 25.33016011134398
Train mean error at (after) epoch 10: 0.06332540027835995
Test error at (after) epoch 10: 0.06103375792869462
----------
Error at epoch 20 is 8.952157046613705
Train mean error at (after) epoch 20: 0.02238039261653426
Test error at (after) epoch 20: 0.021239237660938763
----------
Error at epoch 30 is 6.125713228720811
Train mean error at (after) epoch 30: 0.015314283071802028
Test error at (after) epoch 30: 0.013934804728253711
----------
Error at epoch 40 is 5.405251305183836
Train mean error at (after) epoch 40: 0.01351312826295959
Test error at (after) epoch 40: 0.011877744213845312
----------
Error at epoch 50 is 5.163463628578767
Train mean error at (after) epoch 50: 0.012908659071446917
Test error at (after) epoch 50: 0.011119874325802599
----------
Error at epoch 60 is 5.070557798834853
Train mean error at (after) epoch 60: 0.012676394497087134
Test error at (after) epoch 60: 0.010796480031578452
----------
Error at epoch 70 is 5.031973865947371
Train mean error at (after) epoch 70: 0.012579934664868429
Test error at (after) epoch 70: 0.010644272791618345
----------
Error at epoch 80 is 5.014970220539491
Train mean error at (after) epoch 80: 0.012537425551348727
Test error at (after) epoch 80: 0.01056689537714361
----------
Error at epoch 90 is 5.006979577934169
Train mean error at (after) epoch 90: 0.012517448944835424
Test error at (after) epoch 90: 0.010524874932739353
----------
Error at epoch 100 is 5.002872362140039
Train mean error at (after) epoch 100: 0.012507180905350097
Test error at (after) epoch 100: 0.010500686371914154
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.9220595589714258
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.23168094301088196
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.8751848193629659
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.37744287237108776
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.9646525994651782
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.9646799535831339
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.37461477132873405
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.6565976614179857
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.9542818555167605
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6397312439710828
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.9163992627404055
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.8349651928951485
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.828414505789821
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.9526934877831366
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.8549666667807972
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.6967413842048475
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.8620811420416898
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.5517113517191334
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.3943130521288852
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.7283096288501568
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.8166412873340125
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.7529918172675213
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.8964666796679864
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.8325786078878529
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.37395761810811645
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.8709178137063671
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.5862403875291586
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.4753674483660749
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.9179250478114896
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.8471020929473382
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.8702121905925361
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.6282493978577349
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.662489235648368
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.9545803995634541
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.9152914145302344
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.43057655404406103
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.9519727940837385
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.9537251216386923
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.6852780775979582
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.9795702410258286
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.8989939733403881
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.9455850356952138
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.8673136727595383
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.5204981002505625
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.925602019575873
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.8657973793419093
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.3170533650860244
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.9066960267756772
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.6857227239294043
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.7153091860768911
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.980933447455217
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.4873021696188012
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.7823915306379716
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.9835915049378546
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.9646792057314476
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.8991183399987975
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.9550098722314834
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.974568574222632
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.743412988094639
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.8514198491587857
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.3318736418415016
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.2272711953582844
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.32174504312142976
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.8506246774106019
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.961281873939162
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.880232293527277
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.8270475325258896
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.7054460205631099
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.9684249321151972
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.6168242916383284
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.8976863665159834
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.9412028050164223
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.8706740793461757
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.5757631895508998
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.913306484065257
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.958295037758551
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.06415755103712933
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.6491405495704748
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.7758309013721411
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.848498123628192
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.973659014766483
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.7840644587703245
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.3199487499961842
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.8295695924873546
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.6787005260601702
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.7005577217730073
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.862536870483096
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.3973166576236301
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.9209805681659147
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.5416406297570725
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.19376221963738197
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.7000253510068339
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.9583694696267362
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.27080886903121426
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.8004613861459766
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.5044393857541078
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.8462574533803103
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.7922510197664294
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.8538334621593376
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.3600828426626027
---------------------------------------------------------

Hidden units: 5
Epochs: 1000
Learning rate: 0.5

Errors during training:
Error at epoch 1 is 93.73368565135466
Train mean error at (after) epoch 1: 0.23433421412838665
Test error at (after) epoch 1: 0.2113747487610694
----------
Error at epoch 100 is 4.899234540728383
Train mean error at (after) epoch 100: 0.012248086351820958
Test error at (after) epoch 100: 0.010370660558605636
----------
Error at epoch 200 is 4.8740342993563495
Train mean error at (after) epoch 200: 0.012185085748390874
Test error at (after) epoch 200: 0.010337603137079281
----------
Error at epoch 300 is 4.848058892432492
Train mean error at (after) epoch 300: 0.01212014723108123
Test error at (after) epoch 300: 0.01033745424923358
----------
Error at epoch 400 is 4.8191703140640385
Train mean error at (after) epoch 400: 0.012047925785160096
Test error at (after) epoch 400: 0.01033818659523284
----------
Error at epoch 500 is 4.787121054442979
Train mean error at (after) epoch 500: 0.011967802636107448
Test error at (after) epoch 500: 0.010339426305081327
----------
Error at epoch 600 is 4.75174731371496
Train mean error at (after) epoch 600: 0.011879368284287399
Test error at (after) epoch 600: 0.010341345111001996
----------
Error at epoch 700 is 4.712989594394249
Train mean error at (after) epoch 700: 0.011782473985985621
Test error at (after) epoch 700: 0.010344061522696988
----------
Error at epoch 800 is 4.6708834300439355
Train mean error at (after) epoch 800: 0.011677208575109838
Test error at (after) epoch 800: 0.01034751654649517
----------
Error at epoch 900 is 4.625495992905167
Train mean error at (after) epoch 900: 0.011563739982262917
Test error at (after) epoch 900: 0.010351326542455755
----------
Error at epoch 1000 is 4.576793433927812
Train mean error at (after) epoch 1000: 0.01144198358481953
Test error at (after) epoch 1000: 0.010354634524410523
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.857220106407573
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.2480698795753924
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.843018807033974
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.3825266621401185
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.9363712498190155
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.902345933765086
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.4030463598483539
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.6598539525871617
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.9336870586596254
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6246719036852173
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.9065313611682009
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.7960728643854954
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.8275431151032288
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.9472850747995076
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.8162789284039995
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.7009523625545442
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.8534872038475848
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.5615114788228138
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.4241093398205227
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.6962812087977239
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.7728599631958748
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.7244466152563463
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.8381094165656325
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.8089578903786453
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.36657326883594743
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.8643678302389549
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.5822395752167849
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.48031520572639536
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.8579382163686499
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.8431627058053766
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.8313723497077167
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.6301345130629922
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.665805159808334
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.9005871117945466
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.8919663170423382
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.4408349396605306
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.9327927654926832
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.9002311525676003
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.6977435038320844
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.9131846694470708
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.8815630146205125
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.91865064947064
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.8334985904587533
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.5186834780149857
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.9243145736809237
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.8143487863410485
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.31456682319717016
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.8489968364211309
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.7236137631762786
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.7219713573958157
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.9261916371953726
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.5033569862426805
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.7484139654167372
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.9549447249758896
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.904353227191212
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.8935102111803558
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.9297842545798375
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.9442885503641915
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.7088004713036441
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.8415082091325838
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.34490264114241215
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.22174572619410954
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.33804629790586077
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.8104705973728674
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.940584895171021
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.8793698173935678
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.8177477703905189
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.6885814108050891
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.9486832924878693
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.6299128322081129
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.8431010591541384
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.8911335864873684
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.8142281516783424
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.5987575577011921
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.8505105088125069
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.8931398815396082
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.07030102130955827
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.6317378264359734
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.7599034943976849
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.8496271877334859
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.9051259451728128
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.7451540835060905
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.34898760439357285
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.7925648264679299
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.6850412764157484
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.6999212294630035
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.8226333424951733
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.4412257986360619
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.901830154338872
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.557262761700985
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.2642028372333307
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.7026216316711064
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.8938453035393912
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.2977113037606125
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.7958088755894068
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.515194510250116
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.8107990179357262
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.758197416168265
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.8206739814241817
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.3586555744367227
---------------------------------------------------------

Hidden units: 5
Epochs: 3000
Learning rate: 0.5

Errors during training:
Error at epoch 1 is 109.76798320823282
Train mean error at (after) epoch 1: 0.27441995802058206
Test error at (after) epoch 1: 0.2740378022562275
----------
Error at epoch 300 is 4.7985648475632425
Train mean error at (after) epoch 300: 0.011996412118908107
Test error at (after) epoch 300: 0.010243492397406313
----------
Error at epoch 600 is 4.6718265721736465
Train mean error at (after) epoch 600: 0.011679566430434116
Test error at (after) epoch 600: 0.01022496621781304
----------
Error at epoch 900 is 4.533282194400895
Train mean error at (after) epoch 900: 0.011333205486002237
Test error at (after) epoch 900: 0.010252983078636868
----------
Error at epoch 1200 is 4.407378959106762
Train mean error at (after) epoch 1200: 0.011018447397766903
Test error at (after) epoch 1200: 0.010284898051867815
----------
Error at epoch 1500 is 4.2944413879104
Train mean error at (after) epoch 1500: 0.010736103469776
Test error at (after) epoch 1500: 0.01026701609080665
----------
Error at epoch 1800 is 4.175316069336135
Train mean error at (after) epoch 1800: 0.010438290173340336
Test error at (after) epoch 1800: 0.010195173111634055
----------
Error at epoch 2100 is 4.028392460274705
Train mean error at (after) epoch 2100: 0.010070981150686761
Test error at (after) epoch 2100: 0.010079605911728549
----------
Error at epoch 2400 is 3.8277651216877016
Train mean error at (after) epoch 2400: 0.009569412804219253
Test error at (after) epoch 2400: 0.009894570818590997
----------
Error at epoch 2700 is 3.5535811175106833
Train mean error at (after) epoch 2700: 0.008883952793776708
Test error at (after) epoch 2700: 0.009611276174558701
----------
Error at epoch 3000 is 3.246819489599879
Train mean error at (after) epoch 3000: 0.008117048723999699
Test error at (after) epoch 3000: 0.009249667144398266
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.7954584453922957
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.3041419967284892
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.806830226838017
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.4281851804426661
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.8262112233127141
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.77285503639149
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.4493357694468338
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.6790140153803618
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.8393761956241178
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6634304856294038
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.8046398252828565
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.7695949051536686
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.8022597672938685
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.8562176496927641
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.8031022750824734
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.7350403039223747
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.8079295947516012
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.5512513507561289
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.4653298345698048
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.7377375295889608
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.8161506893042676
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.7382009985013133
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.7953486018900471
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.8108974225127538
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.4099815553194074
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.8104543653227851
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.643731223499183
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.5616211098527759
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.8050702937458467
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.8249672950686431
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.7983230283174652
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.6382642459811549
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.6454102656694892
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.8031966554908193
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.8155537864642852
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.47129336373846603
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.8147840100622723
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.7757824692617702
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.7240326733322544
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.6679298499442758
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.8397649280185259
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.8216559161316721
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.8206730116578419
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.5427352577334353
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.8583277543601934
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.7537185861984037
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.35428645586565544
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.7546734711597419
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.709934635466498
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.7381856287642601
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.6579150914561636
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.5524864281753564
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.7848237432380987
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.7639390695862169
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.7520859799906701
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.7979785358047934
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.8190785124990815
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.7979705385659731
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.7318389546672602
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.8067095436022709
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.4206783446547063
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.23569537713176725
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.384152926748438
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.8297336321142169
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.8177700198383359
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.816122224378435
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.7938834841434855
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.7516201475073077
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.8021671381855675
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.6560224064576479
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.7380828848577782
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.7927934655958019
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.8335938620041813
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.6341909436003849
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.8353319920782454
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.710973558999201
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.04814556719427075
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.6786776953559107
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.7845098093876964
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.8208279774312456
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.709963794556494
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.7688631598163108
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.3983001966671357
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.798869988077927
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.6796961240213385
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.707086634221359
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.8046615874534224
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.45797999638827386
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.8299352482009978
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.5853536673785139
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.26350549386973987
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.7264323454347467
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.708935293542957
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.3083013426226051
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.7755124580870386
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.5680513643696221
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.8178057686639222
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.7871287690352893
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.8033898750078986
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.4117237063378255
---------------------------------------------------------

Hidden units: 5
Epochs: 10000
Learning rate: 0.5

Errors during training:
Error at epoch 1 is 120.5681829036695
Train mean error at (after) epoch 1: 0.3014204572591737
Test error at (after) epoch 1: 0.26416386381964163
----------
Error at epoch 1000 is 4.869025436839923
Train mean error at (after) epoch 1000: 0.012172563592099808
Test error at (after) epoch 1000: 0.010443193075734396
----------
Error at epoch 2000 is 4.447905950505352
Train mean error at (after) epoch 2000: 0.01111976487626338
Test error at (after) epoch 2000: 0.01038520839022975
----------
Error at epoch 3000 is 3.344998824831628
Train mean error at (after) epoch 3000: 0.00836249706207907
Test error at (after) epoch 3000: 0.009495085934110827
----------
Error at epoch 4000 is 2.4081916044374454
Train mean error at (after) epoch 4000: 0.0060204790110936135
Test error at (after) epoch 4000: 0.007486251685944654
----------
Error at epoch 5000 is 1.2657794811838738
Train mean error at (after) epoch 5000: 0.0031644487029596846
Test error at (after) epoch 5000: 0.004253794396442828
----------
Error at epoch 6000 is 0.6589812776800779
Train mean error at (after) epoch 6000: 0.0016474531942001947
Test error at (after) epoch 6000: 0.002242004713358549
----------
Error at epoch 7000 is 0.4995150710100057
Train mean error at (after) epoch 7000: 0.0012487876775250143
Test error at (after) epoch 7000: 0.0015813971676587684
----------
Error at epoch 8000 is 0.8245668998400133
Train mean error at (after) epoch 8000: 0.002061417249600033
Test error at (after) epoch 8000: 0.0021254403031694905
----------
Error at epoch 9000 is 0.730186390149248
Train mean error at (after) epoch 9000: 0.00182546597537312
Test error at (after) epoch 9000: 0.0018657144141307517
----------
Error at epoch 10000 is 0.6070426170164758
Train mean error at (after) epoch 10000: 0.0015176065425411894
Test error at (after) epoch 10000: 0.001572011605271576
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.9233905332408008
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.18095481175147518
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.9418726646489234
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.35076455887489194
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.7721204706385376
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.8123082090271385
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.3762016793854819
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.6336233420352322
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.8123529619574198
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.709218124794018
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.9246093487403426
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.916855884071224
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.8587602883050595
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.8585049545710182
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.9211426315608543
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.7033049743601013
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.8798757456750943
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.5926980206291758
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.37652230321937646
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.8015654644483421
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.9029244862470743
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.8201803956549063
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.9326154560375832
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.9209918294021346
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.24096402392382424
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.8877104629843772
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.6073201805057139
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.49581247377632853
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.9318795366582857
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.9456906184574818
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.9216533586968472
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.7455449745596785
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.7403977378083023
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.8787164250130625
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.91827826195392
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.410996667201112
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.8510134758932748
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.8783872798011996
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.7023077002616209
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.5075989995526645
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.8925696990580446
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.8833168627413028
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.9280010885438618
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.5193223701948206
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.9035671374833696
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.936059621116514
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.1760402483421443
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.9289077601031147
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.7428293911343542
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.7358180539382944
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.3042127674386202
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.3855893450108885
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.8720814492638554
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.33418005451549776
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.819122399121104
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.9350316738579035
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.8465180810300301
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.7066007018182112
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.8180876243738507
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.8786090216323467
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.3101194257525546
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.2351710060271967
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.3224464454456947
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.9295945443318386
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.7712509202249047
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.8908094123638046
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.924541355070028
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.7863530941270304
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.7238767945017219
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.6903101932990896
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.9388494536563209
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.9101917004519983
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.9274470367159396
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.527392165561736
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.931185246017064
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.8850673075858829
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.10170167493930399
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.6920457685577289
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.8740719975116035
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.9475586419697122
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.7130587684370597
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.85831952730376
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.2510846387420369
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.9060078817032633
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.7671754314894015
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.7277660203623629
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.9230167013247607
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.4224615713471848
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.8894862622599442
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.5530420965969548
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.09508342026119165
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.741290430525921
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.8768076535068718
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.2675307947660639
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.8301599207510081
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.45935342893591585
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.9194854986258487
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.8733758941794514
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.9186714580866363
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.2277001460847265
---------------------------------------------------------

Hidden units: 5
Epochs: 100
Learning rate: 1

Errors during training:
Error at epoch 1 is 111.36836330452365
Train mean error at (after) epoch 1: 0.27842090826130916
Test error at (after) epoch 1: 0.23514394237742728
----------
Error at epoch 10 is 10.596637490691949
Train mean error at (after) epoch 10: 0.02649159372672987
Test error at (after) epoch 10: 0.02430393130016459
----------
Error at epoch 20 is 5.447864403241494
Train mean error at (after) epoch 20: 0.013619661008103735
Test error at (after) epoch 20: 0.012029141006110628
----------
Error at epoch 30 is 5.016999832239601
Train mean error at (after) epoch 30: 0.012542499580599003
Test error at (after) epoch 30: 0.010777209412993018
----------
Error at epoch 40 is 4.948921977339413
Train mean error at (after) epoch 40: 0.012372304943348534
Test error at (after) epoch 40: 0.010530010968696315
----------
Error at epoch 50 is 4.933486508841466
Train mean error at (after) epoch 50: 0.012333716272103666
Test error at (after) epoch 50: 0.010461989971251622
----------
Error at epoch 60 is 4.927344137121409
Train mean error at (after) epoch 60: 0.012318360342803522
Test error at (after) epoch 60: 0.01043831843465571
----------
Error at epoch 70 is 4.922945664111159
Train mean error at (after) epoch 70: 0.012307364160277898
Test error at (after) epoch 70: 0.010428556994743193
----------
Error at epoch 80 is 4.918855124267531
Train mean error at (after) epoch 80: 0.012297137810668829
Test error at (after) epoch 80: 0.010423987075196806
----------
Error at epoch 90 is 4.914787600824435
Train mean error at (after) epoch 90: 0.012286969002061087
Test error at (after) epoch 90: 0.010421589513558293
----------
Error at epoch 100 is 4.910683981186429
Train mean error at (after) epoch 100: 0.012276709952966071
Test error at (after) epoch 100: 0.010420172742208656
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.9010161835667213
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.25063197751278704
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.8991982654404895
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.3723317948300212
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.9597276935415417
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.9544883068145307
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.3934058567783564
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.6591937364998841
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.9547675496275735
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6413918517347516
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.9242968738334718
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.8390611978245179
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.822727441753361
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.9405879634799426
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.8672348592866799
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.7083472524045116
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.8494282894460855
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.5584793520280394
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.4032188553352341
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.7243262336646261
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.824953548298756
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.7334362917446663
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.8926012760605688
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.8182227933765827
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.3767070388456194
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.8700827189829763
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.5945083266041803
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.4829211183107072
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.9196945136972624
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.8232957571163225
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.8617406592344105
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.6385452755781136
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.6550369396019192
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.9435997660508395
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.9049265369044359
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.4280372918215919
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.9503715342143005
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.9246210663428771
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.691623363132241
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.9697938859675517
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.8885401005420605
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.9209735750761912
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.8796252685104411
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.512734545649415
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.9163828325526431
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.8533996555307988
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.3217687574143131
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.8754804108493598
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.7107251940970886
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.7312108127055125
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.9766803922120028
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.49945868806415306
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.8016384503776255
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.9769038354330466
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.9425773464213122
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.9106632508496295
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.9436871707589942
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.9618212148492655
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.7385300463079968
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.8235749286406895
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.3393489774505395
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.2174662255516239
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.3246597546437696
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.8508871364765923
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.9656888962139774
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.8865961092196298
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.8585548004468385
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.7263130719901538
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.9641566740598363
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.594175841988558
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.8720776897219826
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.9107354012351225
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.8855501255409267
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.5918047121540332
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.9114552565893769
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.9345255316843053
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.11815947668385121
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.651158781681242
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.801510500219603
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.8195725586299015
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.9605773147881348
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.785335086622881
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.34324615710762113
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.814840574031983
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.6996370203881549
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.6872701288419452
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.8718600885336898
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.41002272619048924
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.8994925157308704
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.5611664633389268
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.2107582633915893
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.6976874495294461
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.9292223026146438
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.265898089682456
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.7894886938036042
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.5156636048125735
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.8484086332327103
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.8054277917348132
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.8616100148107005
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.3642702513937066
---------------------------------------------------------

Hidden units: 5
Epochs: 1000
Learning rate: 1

Errors during training:
Error at epoch 1 is 109.31726908101777
Train mean error at (after) epoch 1: 0.27329317270254444
Test error at (after) epoch 1: 0.25538459515954776
----------
Error at epoch 100 is 4.820013692719279
Train mean error at (after) epoch 100: 0.012050034231798196
Test error at (after) epoch 100: 0.010329342656178431
----------
Error at epoch 200 is 4.754164259626355
Train mean error at (after) epoch 200: 0.011885410649065889
Test error at (after) epoch 200: 0.010327121583379673
----------
Error at epoch 300 is 4.680452794516463
Train mean error at (after) epoch 300: 0.011701131986291158
Test error at (after) epoch 300: 0.010339242147207368
----------
Error at epoch 400 is 4.602711177908264
Train mean error at (after) epoch 400: 0.01150677794477066
Test error at (after) epoch 400: 0.010366348634173406
----------
Error at epoch 500 is 4.525949186381638
Train mean error at (after) epoch 500: 0.011314872965954095
Test error at (after) epoch 500: 0.010403768436734432
----------
Error at epoch 600 is 4.453183851141621
Train mean error at (after) epoch 600: 0.011132959627854053
Test error at (after) epoch 600: 0.010441887652563138
----------
Error at epoch 700 is 4.384145673353222
Train mean error at (after) epoch 700: 0.010960364183383055
Test error at (after) epoch 700: 0.010472727621393734
----------
Error at epoch 800 is 4.316743894216796
Train mean error at (after) epoch 800: 0.010791859735541991
Test error at (after) epoch 800: 0.010494376919681102
----------
Error at epoch 900 is 4.248677383868444
Train mean error at (after) epoch 900: 0.010621693459671112
Test error at (after) epoch 900: 0.010509387348059547
----------
Error at epoch 1000 is 4.177565491970744
Train mean error at (after) epoch 1000: 0.01044391372992686
Test error at (after) epoch 1000: 0.010520485066247816
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.8152337732329772
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.2819833145169002
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.8228536811938426
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.397400563291989
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.9120606437996852
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.8627553057540893
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.4226609721256212
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.6753064945092249
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.9196059163643733
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6106398093794864
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.8647535584043766
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.7503026358661398
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.817489114086412
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.9169851014012055
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.804526573615548
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.7254330717967062
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.8261833586001547
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.5433874889113492
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.4408851782008406
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.7247617481012778
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.8090974770597701
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.6978070021380596
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.8034970610946331
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.7961701391936994
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.3858489180692025
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.8432280128238623
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.6061666820318787
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.505421267301629
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.8331723145913114
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.812122774706772
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.7920272074401842
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.6002636780017387
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.6448097415867106
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.8683153368851955
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.8512664842785038
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.47223339777358947
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.8938948489219986
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.8268942186374946
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.7168239817729174
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.842210042223469
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.8648065618622399
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.8557702089728026
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.8349637473505537
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.5138861183876139
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.9025075768903705
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.7470990320148765
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.3283439239994362
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.7652460763507483
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.7429193180278544
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.7446095640584389
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.854397358453065
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.52392496916087
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.7741094187538661
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.9082604883166442
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.8315260760380442
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.8512615431493137
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.8850157705182309
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.8911618109749055
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.6913820441075984
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.790340414304815
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.36865459805622275
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.23212527688572537
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.35934864269788896
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.8300053450403967
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.920566252416289
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.8644276024298169
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.8109692942051734
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.7297682684303265
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.9038199333371845
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.6132548505575619
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.7510153389614231
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.8249622527831278
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.8472808773947262
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.6231421349676282
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.8626377435549717
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.791650971952434
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.10742275093954501
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.627289683378922
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.7860132892401448
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.8069698129748045
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.8375326867352638
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.7434645470988586
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.36617070793366724
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.7821857272440617
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.681387247979108
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.680892489622984
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.806817033866341
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.4360277421987451
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.8577372390659798
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.5522478528291128
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.25115677721463897
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.7256378827265025
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.787180031745543
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.30059158396702645
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.7775909704479238
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.534411541413273
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.8166670892300116
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.7754144637078754
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.803941145252695
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.374196177349148
---------------------------------------------------------

Hidden units: 5
Epochs: 3000
Learning rate: 1

Errors during training:
Error at epoch 1 is 109.56630010613624
Train mean error at (after) epoch 1: 0.2739157502653406
Test error at (after) epoch 1: 0.22892953107522618
----------
Error at epoch 300 is 4.790298645335279
Train mean error at (after) epoch 300: 0.011975746613338199
Test error at (after) epoch 300: 0.010350746336502323
----------
Error at epoch 600 is 4.528023317685948
Train mean error at (after) epoch 600: 0.01132005829421487
Test error at (after) epoch 600: 0.010356433996980436
----------
Error at epoch 900 is 4.172889191372591
Train mean error at (after) epoch 900: 0.010432222978431478
Test error at (after) epoch 900: 0.01022275437983223
----------
Error at epoch 1200 is 3.5969911016574887
Train mean error at (after) epoch 1200: 0.008992477754143722
Test error at (after) epoch 1200: 0.009701345227017169
----------
Error at epoch 1500 is 3.0777391153417897
Train mean error at (after) epoch 1500: 0.007694347788354474
Test error at (after) epoch 1500: 0.008889629129858665
----------
Error at epoch 1800 is 2.6353231636568766
Train mean error at (after) epoch 1800: 0.006588307909142191
Test error at (after) epoch 1800: 0.00788086035088351
----------
Error at epoch 2100 is 4.088030447728413
Train mean error at (after) epoch 2100: 0.010220076119321034
Test error at (after) epoch 2100: 0.009803208811993513
----------
Error at epoch 2400 is 2.563305538120629
Train mean error at (after) epoch 2400: 0.006408263845301573
Test error at (after) epoch 2400: 0.006895256378040322
----------
Error at epoch 2700 is 2.0438396424276974
Train mean error at (after) epoch 2700: 0.005109599106069244
Test error at (after) epoch 2700: 0.005309974519551495
----------
Error at epoch 3000 is 1.695691969516
Train mean error at (after) epoch 3000: 0.00423922992379
Test error at (after) epoch 3000: 0.004244386903406982
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.8594098525677084
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.3775247987740793
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.9409665175844064
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.2319749889375964
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.8092400557339945
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.7369973598391406
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.34874931257007863
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.6865118443589513
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.8306911501255757
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6287061787408539
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.9295084233605598
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.8910152127226961
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.834448337988071
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.9439860251006045
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.8706928650191401
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.7400911924265143
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.8459033767987079
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.5179490490994103
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.25239256912738944
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.6770476799594054
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.8553348881042213
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.7064064782981915
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.8954126561082839
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.8734441104431734
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.40898390723698047
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.8587421729571628
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.48744397358588987
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.4182806135400504
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.9039311983485693
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.9120606653194253
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.838124288773158
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.694176453282429
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.6040777461742455
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.8214675656580325
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.9062051055398181
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.31740575712554386
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.8681076611930774
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.7862501729028093
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.7560178425298404
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.5054425859614845
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.8685078801799732
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.8668083188748077
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.8583045907718377
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.39077117931024596
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.9317608294702837
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.9153711184118732
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.3553688194891253
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.8695867636254554
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.7879698759738837
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.7592302741004904
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.29221553642222925
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.5365218032129173
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.7960667177057983
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.6361086598955478
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.7100742734762192
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.9359335225791456
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.847282766584363
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.7911443657734153
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.7254917378799985
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.8453395338474862
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.22625499965995152
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.12385459941150656
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.24846142435255522
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.8975141453430487
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.830987383090625
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.8616890015316833
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.9060686177605991
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.6704775978601695
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.79491528046299
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.6300812596355512
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.9096147026870265
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.8361470188462329
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.8750848281004938
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.6321253142790448
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.8919703117275861
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.8688640756741384
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: -0.04958840109039138
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.5855308075400716
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.7917018297911794
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.9144188357571381
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.6805148720225166
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.761740611311092
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.44226346424541846
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.8425081219066054
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.6807961925178028
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.753757212581358
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.8678247889470866
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.3130030068439035
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.8566471983533573
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.4652777708133295
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.29722070143421264
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.7948879827948306
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.8344441189899771
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.13005206247731924
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.8117551306183546
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.6077415496216262
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.8539471033153331
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.7809351115301092
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.8459793695638393
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.40583721557922603
---------------------------------------------------------

Hidden units: 5
Epochs: 10000
Learning rate: 1

Errors during training:
Error at epoch 1 is 111.12455949142434
Train mean error at (after) epoch 1: 0.27781139872856087
Test error at (after) epoch 1: 0.20709049400525142
----------
Error at epoch 1000 is 4.307338982477093
Train mean error at (after) epoch 1000: 0.010768347456192732
Test error at (after) epoch 1000: 0.010263775832439816
----------
Error at epoch 2000 is 2.551689895865276
Train mean error at (after) epoch 2000: 0.006379224739663189
Test error at (after) epoch 2000: 0.008026440911959221
----------
Error at epoch 3000 is 2.738108406404189
Train mean error at (after) epoch 3000: 0.0068452710160104725
Test error at (after) epoch 3000: 0.007443951356321502
----------
Error at epoch 4000 is 1.7469118719943157
Train mean error at (after) epoch 4000: 0.004367279679985789
Test error at (after) epoch 4000: 0.00458702811019023
----------
Error at epoch 5000 is 1.3660906600752032
Train mean error at (after) epoch 5000: 0.003415226650188008
Test error at (after) epoch 5000: 0.003532544851934862
----------
Error at epoch 6000 is 1.203241278150368
Train mean error at (after) epoch 6000: 0.00300810319537592
Test error at (after) epoch 6000: 0.0029849583494454997
----------
Error at epoch 7000 is 0.7336708022000029
Train mean error at (after) epoch 7000: 0.0018341770055000073
Test error at (after) epoch 7000: 0.0019030712888694
----------
Error at epoch 8000 is 0.36358492414678206
Train mean error at (after) epoch 8000: 0.0009089623103669551
Test error at (after) epoch 8000: 0.0009945244990214556
----------
Error at epoch 9000 is 0.24638462786515283
Train mean error at (after) epoch 9000: 0.0006159615696628821
Test error at (after) epoch 9000: 0.0006688697557208605
----------
Error at epoch 10000 is 0.20192777674972753
Train mean error at (after) epoch 10000: 0.0005048194418743188
Test error at (after) epoch 10000: 0.0005568766827848885
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.9292504128830542
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.1789489454111346
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.9337334035109233
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.3194752839743889
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.8409507414604431
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.8342902243598926
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.3255303677544675
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.6567009535786441
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.8891420281246215
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6686598660103913
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.9407312554025101
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.9010458902848594
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.8893051941960995
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.8556101890937224
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.9167148540480582
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.7180570221191379
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.9162209715732971
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.5478122085885927
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.34997332029214606
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.7719446016089383
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.876119701424899
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.7994786256523134
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.9296203021906866
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.895351543397449
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.2966428661812606
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.9257440841351132
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.5723293711279048
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.44369214397082035
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.9326616400375193
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.9190617391319066
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.9208129496820762
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.6808545522069652
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.6981063068844524
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.8893811754612021
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.9404622402354312
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.36881914086871864
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.9047202187628448
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.8993575448734522
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.7014993618663055
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.4449721315546198
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.9362567311013427
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.9259377808737675
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.9256860139440277
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.4929147351660296
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.9330600643644426
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.9168654100335774
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.24509137482697307
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.9294331226838339
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.7660938828187341
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.7604344595940911
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.2243023479759185
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.4347944322821262
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.8563358086740287
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.14986574906620798
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.8495048105164302
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.941920854120021
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.9056090451585322
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.7171495102467992
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.79528491184307
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.9092728943154644
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.2710928485917461
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.16796731827396275
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.26630244235930345
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.906989637025422
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.8292360582215712
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.935090482874405
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.9185866892352493
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.7575998069154046
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.7807944815245578
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.635194544793586
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.9258479041861358
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.9218457516996106
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.9219850978295867
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.5652073507478312
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.9304589414258854
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.8772316737568386
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.06508871609260035
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.668778711750478
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.8617065228143496
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.9221901204095598
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.701594177075616
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.8425870561776223
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.28883427996424316
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.8860322709360241
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.7549166999760579
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.7278825394983167
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.9201803158670464
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.36702495573146476
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.9393888510453637
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.540135383943036
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.15356879819879626
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.727549985590034
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.8775743744053947
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.2164415583149315
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.8561277865379555
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.45925314555717445
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.9051865133123752
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.8592827531584671
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.915813196216647
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.2854974518763274
=========================================================

---------------------------------------------------------

Hidden units: 6
Epochs: 100
Learning rate: 0.05

Errors during training:
Error at epoch 1 is 81.96350970017383
Train mean error at (after) epoch 1: 0.20490877425043458
Test error at (after) epoch 1: 0.24926654687264782
----------
Error at epoch 10 is 65.00999990373153
Train mean error at (after) epoch 10: 0.16252499975932883
Test error at (after) epoch 10: 0.19788783976575444
----------
Error at epoch 20 is 51.895525283507574
Train mean error at (after) epoch 20: 0.12973881320876893
Test error at (after) epoch 20: 0.15797728304513903
----------
Error at epoch 30 is 42.421244774641806
Train mean error at (after) epoch 30: 0.10605311193660452
Test error at (after) epoch 30: 0.12893313536802875
----------
Error at epoch 40 is 35.309987494834445
Train mean error at (after) epoch 40: 0.08827496873708611
Test error at (after) epoch 40: 0.10693394878092198
----------
Error at epoch 50 is 29.83458167431836
Train mean error at (after) epoch 50: 0.0745864541857959
Test error at (after) epoch 50: 0.08984097914782925
----------
Error at epoch 60 is 25.540568854162032
Train mean error at (after) epoch 60: 0.06385142213540508
Test error at (after) epoch 60: 0.07633115681630849
----------
Error at epoch 70 is 22.12531048036837
Train mean error at (after) epoch 70: 0.05531327620092093
Test error at (after) epoch 70: 0.06552192500281481
----------
Error at epoch 80 is 19.37821973380563
Train mean error at (after) epoch 80: 0.048445549334514074
Test error at (after) epoch 80: 0.05679196488105375
----------
Error at epoch 90 is 17.147952418602852
Train mean error at (after) epoch 90: 0.04286988104650713
Test error at (after) epoch 90: 0.04968699596339544
----------
Error at epoch 100 is 15.322963120158024
Train mean error at (after) epoch 100: 0.03830740780039506
Test error at (after) epoch 100: 0.04386594776221403
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.7701458712290598
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: 0.14376821428714004
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.5529706506154958
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.2505421070615266
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.859673975740114
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.8636732546264841
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.28961944900428294
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.26075444421389665
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.8173464884349002
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.37333561088738015
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.6203672279745701
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.5029589347882748
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.5369826198549394
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.8190553354554567
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.5684503884428137
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.5012059694771059
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.5716849081328228
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.41320519184738536
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.14492368687004578
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.6180963718255181
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.6573423551657979
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.4474778713525435
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.6768375204225069
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.5873816487577032
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.1108014810877022
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.5724590585182942
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.327859157435994
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.32093192402792153
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.7209400781754707
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.6070679068983739
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.5684635055175133
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.28086667878866856
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.5718723390431092
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.8376107827884746
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.7100152131678904
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.4894658556605971
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.7666451458543583
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.7970134541668109
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.4150762083299707
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.8973745636932794
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.7382033311317755
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.7348165766382995
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.5732264735015012
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.30458023465076534
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.7366767784131879
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.5559919004321735
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.025300352268527396
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.5993661790821465
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.25015522519900796
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.44159534504901515
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.8990189346360306
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.2615466960718935
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.5097170509408098
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.9163227997799454
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.8357893902199125
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.5667278838487585
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.7935598813501124
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.8637190654629713
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.47407545785118993
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.60488217312816
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.19468519674783855
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.022243752167300748
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.1634788029027391
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.6929445174730982
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.8116675755266364
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.524279275585981
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.4247594686206238
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.4393654261200608
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.8263438826646196
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.36023687819977984
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.5856776934231498
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.7716131186771906
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.6522649069096828
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.2857357696421442
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.7819280397450804
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.7242480607777215
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.15825114107398308
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.3651106976853343
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.4367773758193337
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.6214954183849756
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.8756166523526002
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.5341583563074869
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.24897523699657007
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.6216300300158161
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.1802887267427479
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.37475879155286634
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.5810308348032732
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.34241044046161473
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.7070686362718532
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.1204358822820173
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.3196270699156114
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.2848031387604928
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.7095420391407878
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.047757463796824405
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.48494424306667433
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.27607393285531234
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.5983586953213594
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.5266329491169796
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.543872176420487
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.32947147601514953
---------------------------------------------------------

Hidden units: 6
Epochs: 1000
Learning rate: 0.05

Errors during training:
Error at epoch 1 is 69.70206930615404
Train mean error at (after) epoch 1: 0.17425517326538512
Test error at (after) epoch 1: 0.20223964762214244
----------
Error at epoch 100 is 15.222439653797474
Train mean error at (after) epoch 100: 0.03805609913449368
Test error at (after) epoch 100: 0.04191883623994569
----------
Error at epoch 200 is 7.486167699933208
Train mean error at (after) epoch 200: 0.01871541924983302
Test error at (after) epoch 200: 0.018696850881186264
----------
Error at epoch 300 is 5.837673227878639
Train mean error at (after) epoch 300: 0.014594183069696598
Test error at (after) epoch 300: 0.013479588338122395
----------
Error at epoch 400 is 5.3311203129665605
Train mean error at (after) epoch 400: 0.013327800782416402
Test error at (after) epoch 400: 0.01179488360230458
----------
Error at epoch 500 is 5.145829295665936
Train mean error at (after) epoch 500: 0.01286457323916484
Test error at (after) epoch 500: 0.011134333736867681
----------
Error at epoch 600 is 5.071092692653261
Train mean error at (after) epoch 600: 0.012677731731633153
Test error at (after) epoch 600: 0.010841702619695056
----------
Error at epoch 700 is 5.038828107712984
Train mean error at (after) epoch 700: 0.01259707026928246
Test error at (after) epoch 700: 0.010699990868497407
----------
Error at epoch 800 is 5.024000556702185
Train mean error at (after) epoch 800: 0.012560001391755463
Test error at (after) epoch 800: 0.010626280889752688
----------
Error at epoch 900 is 5.016639020585866
Train mean error at (after) epoch 900: 0.012541597551464665
Test error at (after) epoch 900: 0.01058556978871581
----------
Error at epoch 1000 is 5.012562355771675
Train mean error at (after) epoch 1000: 0.012531405889429187
Test error at (after) epoch 1000: 0.010561917445585635
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.9232542331222355
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.2169810977594642
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.8840050022080448
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.37803475427687033
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.9670151271619744
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.9670152265607285
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.3683998873070189
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.6447652951476406
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.9595086108057787
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6354686797016285
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.9076538582956153
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.8225417152193164
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.823977876856635
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.9515462025971488
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.8601592212840079
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.7050630833749166
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.8545143996014521
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.5669212908338797
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.41391404027365225
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.6834031913677775
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.8211975352146091
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.7431116124764412
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.8930412292000371
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.8270951676865033
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.3582552904517723
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.8664942240288935
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.5919987405481382
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.46464783712156066
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.9171446813719325
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.840302390844044
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.8591031000305775
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.6133924286203846
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.6557932872820756
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.9577683751221866
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.9096646405185153
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.411040535223923
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.9496482830131834
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.9499580379207361
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.6827270275711186
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.9794447049312888
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.9049467819843199
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.9430235039233745
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.8765078327923413
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.5214816679950789
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.9229861668922807
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.8510283197076357
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.3155179497655725
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.8933481085702558
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.7200883053548747
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.723240706717731
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.9801661962472457
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.48958594759534213
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.783561850098536
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.9848857661230307
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.9628756463138328
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.8870724503105806
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.953246855255735
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.974144683147632
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.7396039825505046
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.8557315639864116
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.3335749064809518
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.19289882303094968
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.30831358748368237
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.8626610225314408
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.9652362489485373
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.8731599382291276
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.8511574175262905
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.7115746053643058
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.96527521184001
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.6268075168389032
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.887797577454405
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.9377294648487043
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.8585751304007186
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.5868213944918874
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.9161697805760665
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.9488274991159136
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.07764074669624477
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.6470328345631282
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.793623915276809
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.8477579096966359
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.9730960739991915
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.7864737464446947
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.3293567187882127
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.8324950675230296
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.6873890087671221
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.6937761701507683
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.8662227558027127
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.4172491322262003
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.9179650766617198
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.5463522077247122
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.21997964461678632
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.6680078153707703
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.9491020707341699
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.28186060471934477
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.7930330406405247
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.5076958493745802
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.8514418635699705
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.8003645157088526
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.8553547069485605
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.36666252801186394
---------------------------------------------------------

Hidden units: 6
Epochs: 3000
Learning rate: 0.05

Errors during training:
Error at epoch 1 is 75.17142052337626
Train mean error at (after) epoch 1: 0.18792855130844063
Test error at (after) epoch 1: 0.21369204817890491
----------
Error at epoch 300 is 6.106367367705512
Train mean error at (after) epoch 300: 0.01526591841926378
Test error at (after) epoch 300: 0.014144988750139335
----------
Error at epoch 600 is 5.045678711706527
Train mean error at (after) epoch 600: 0.012614196779266318
Test error at (after) epoch 600: 0.010743411528070377
----------
Error at epoch 900 is 4.978884645926432
Train mean error at (after) epoch 900: 0.01244721161481608
Test error at (after) epoch 900: 0.010459062235967148
----------
Error at epoch 1200 is 4.970060556155823
Train mean error at (after) epoch 1200: 0.012425151390389556
Test error at (after) epoch 1200: 0.010412104833619339
----------
Error at epoch 1500 is 4.966073785295169
Train mean error at (after) epoch 1500: 0.012415184463237923
Test error at (after) epoch 1500: 0.010400512044207687
----------
Error at epoch 1800 is 4.962475061423731
Train mean error at (after) epoch 1800: 0.012406187653559329
Test error at (after) epoch 1800: 0.010396882474191706
----------
Error at epoch 2100 is 4.958850700778431
Train mean error at (after) epoch 2100: 0.012397126751946076
Test error at (after) epoch 2100: 0.01039549466890584
----------
Error at epoch 2400 is 4.95515873281057
Train mean error at (after) epoch 2400: 0.012387896832026426
Test error at (after) epoch 2400: 0.010394810950742676
----------
Error at epoch 2700 is 4.951392242491524
Train mean error at (after) epoch 2700: 0.01237848060622881
Test error at (after) epoch 2700: 0.010394372474285898
----------
Error at epoch 3000 is 4.94754756265012
Train mean error at (after) epoch 3000: 0.0123688689066253
Test error at (after) epoch 3000: 0.010394037917426355
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.9087567014920773
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.2273960376085803
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.889599425541466
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.37526305356400563
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.957243927131537
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.958200120403574
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.3870707679217687
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.6536223969691984
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.9532149723139035
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6441285208051494
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.9218819126698138
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.8346972643142596
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.8345448348542854
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.9661369713447261
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.860613238747016
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.6901224235245367
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.8611025794977686
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.5657272562944968
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.4111771389307585
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.6871283826018278
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.7902437577002841
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.7449640415931746
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.8901068619523911
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.8452425283271059
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.3687332860921749
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.8747244886906272
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.592647037353018
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.4843172088003012
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.9114692742955255
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.8758388037888007
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.868253295686948
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.63791872071098
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.6507734777310898
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.9534447990069864
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.9074269874101449
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.411421578518502
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.9538860618976013
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.9508050995579868
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.6992526013170915
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.9725256593358498
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.8947644115872071
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.9383234325335217
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.877270991572823
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.5157950279536353
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.941301769978732
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.860633610622751
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.31676789022637575
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.8954981228067473
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.7224963122116533
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.7179556695380303
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.9801535588400454
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.48981241130953423
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.7778732309741277
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.9807299083520589
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.9591262668874735
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.9058127292596987
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.9519125334556935
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.9689482495134624
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.7407935503074276
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.8503901695365699
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.3432912460805929
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.21457457003619199
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.3246377565049825
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.8452327450652525
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.9623592017068905
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.8897489336499601
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.8564454430428372
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.6972729738819623
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.9704322685613941
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.6198229691644451
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.8891241481441319
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.9401023011892842
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.8404041552332746
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.5834594422849149
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.8896107981844628
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.9491856666980031
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.06669106129881737
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.6499655502144236
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.7862624867658344
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.8810413326677067
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.9637880765308295
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.7819594246915519
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.34686038572461647
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.8324135531018947
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.6978894888261935
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.6968941792101777
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.8675271852297923
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.4221492684290434
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.9186371205576169
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.5487873963596523
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.23071562452037392
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.700730857494272
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.9485042762524933
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.2830278953742824
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.7978063863985196
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.5165465204158958
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.8517005443757953
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.7922291096371351
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.8618889102812946
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.3614459395810794
---------------------------------------------------------

Hidden units: 6
Epochs: 10000
Learning rate: 0.05

Errors during training:
Error at epoch 1 is 106.1155344845449
Train mean error at (after) epoch 1: 0.26528883621136223
Test error at (after) epoch 1: 0.3040173206280049
----------
Error at epoch 1000 is 4.936785795212559
Train mean error at (after) epoch 1000: 0.012341964488031399
Test error at (after) epoch 1000: 0.010454665097495947
----------
Error at epoch 2000 is 4.91021009277128
Train mean error at (after) epoch 2000: 0.0122755252319282
Test error at (after) epoch 2000: 0.010410084051170545
----------
Error at epoch 3000 is 4.883409430028284
Train mean error at (after) epoch 3000: 0.01220852357507071
Test error at (after) epoch 3000: 0.010405693815930494
----------
Error at epoch 4000 is 4.85389947430321
Train mean error at (after) epoch 4000: 0.012134748685758026
Test error at (after) epoch 4000: 0.010403022507032043
----------
Error at epoch 5000 is 4.821106994659645
Train mean error at (after) epoch 5000: 0.012052767486649112
Test error at (after) epoch 5000: 0.010401209138410288
----------
Error at epoch 6000 is 4.7844801504314365
Train mean error at (after) epoch 6000: 0.011961200376078592
Test error at (after) epoch 6000: 0.010400129902791749
----------
Error at epoch 7000 is 4.743510273218243
Train mean error at (after) epoch 7000: 0.011858775683045608
Test error at (after) epoch 7000: 0.01039967850780463
----------
Error at epoch 8000 is 4.697762629422504
Train mean error at (after) epoch 8000: 0.01174440657355626
Test error at (after) epoch 8000: 0.010399674011871436
----------
Error at epoch 9000 is 4.646903284438295
Train mean error at (after) epoch 9000: 0.011617258211095738
Test error at (after) epoch 9000: 0.01039976140733705
----------
Error at epoch 10000 is 4.590701124207178
Train mean error at (after) epoch 10000: 0.011476752810517944
Test error at (after) epoch 10000: 0.010399311645775145
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.8595909580081265
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.2414946352101954
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.8500573510691015
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.3841549859741796
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.9343287020627689
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.9039153375418368
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.4001355746205691
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.6587951647624155
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.9290391721478497
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6346331854531914
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.9018489049320911
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.8009437276439667
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.8178205539585113
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.9289742673380176
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.820747539524157
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.702332477224396
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.8441167285350605
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.5571892542328054
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.424309813001656
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.6962767895659269
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.7799830965202094
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.7192147855051128
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.8466851857607004
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.7945174715921318
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.37301936270763686
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.855650071432228
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.5826071781426955
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.4881291366815155
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.8683428596786128
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.8196452051908035
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.821943864970542
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.6358635011438118
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.654099527655129
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.8950110953470396
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.8907771275179567
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.4383818356452354
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.9263066964981508
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.8876179169074747
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.6931980568170423
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.9198661061535695
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.8764831043193246
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.9122589549374768
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.8310189610847308
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.5173897248041419
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.9072989782371687
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.8212195051412128
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.3171434795348012
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.8458783953936562
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.7174664110907951
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.7244594480721119
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.9255292586302675
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.5066932658355818
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.763024014765423
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.9518440842065677
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.8989123683343794
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.8899754083833281
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.9243396998753207
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.9405364667012585
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.716841308941
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.8340382946552157
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.3521486550411412
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.224406322419474
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.3367413277313057
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.8098631339633208
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.9385057762656789
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.8671835996110169
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.8155489917213056
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.6978711981480532
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.93920501014202
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.6180831241759577
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.8425207445584925
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.877072988474324
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.8292422614138698
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.6008594519884382
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.8574711092449679
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.8937276230855131
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.07149850140618776
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.6380286071715642
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.7673954326467636
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.8233539606232387
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.9110035271240186
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.7522325165352478
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.35428754367942317
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.7867743155257121
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.6752705561622175
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.700513671297258
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.8249955723775191
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.43000721507541495
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.8925692679282249
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.550483381495551
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.22671210847183185
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.709544120663444
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.8912489670072444
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.2910047897072175
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.7894859681370179
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.5211535854858789
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.8062846704803172
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.766158073551915
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.815881621031448
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.3679117216558632
---------------------------------------------------------

Hidden units: 6
Epochs: 100
Learning rate: 0.1

Errors during training:
Error at epoch 1 is 132.96323422264052
Train mean error at (after) epoch 1: 0.3324080855566013
Test error at (after) epoch 1: 0.37268164201205245
----------
Error at epoch 10 is 78.9829889891257
Train mean error at (after) epoch 10: 0.19745747247281425
Test error at (after) epoch 10: 0.2237832975447429
----------
Error at epoch 20 is 49.22369822885982
Train mean error at (after) epoch 20: 0.12305924557214955
Test error at (after) epoch 20: 0.1408792462746884
----------
Error at epoch 30 is 32.90656932005271
Train mean error at (after) epoch 30: 0.08226642330013177
Test error at (after) epoch 30: 0.09448758287776533
----------
Error at epoch 40 is 23.447154432387492
Train mean error at (after) epoch 40: 0.05861788608096873
Test error at (after) epoch 40: 0.0669497515917516
----------
Error at epoch 50 is 17.7003980906403
Train mean error at (after) epoch 50: 0.044250995226600746
Test error at (after) epoch 50: 0.04990023137037086
----------
Error at epoch 60 is 14.039490735169213
Train mean error at (after) epoch 60: 0.03509872683792303
Test error at (after) epoch 60: 0.03889908999332985
----------
Error at epoch 70 is 11.605053161068861
Train mean error at (after) epoch 70: 0.029012632902672152
Test error at (after) epoch 70: 0.031523029528949705
----------
Error at epoch 80 is 9.926627469396713
Train mean error at (after) epoch 80: 0.024816568673491784
Test error at (after) epoch 80: 0.026408760711942602
----------
Error at epoch 90 is 8.734673069371775
Train mean error at (after) epoch 90: 0.021836682673429437
Test error at (after) epoch 90: 0.022759924522638388
----------
Error at epoch 100 is 7.867452179884107
Train mean error at (after) epoch 100: 0.01966863044971027
Test error at (after) epoch 100: 0.02009283490886886
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.7812133356236819
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.0839227796873673
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.7602048207340903
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.28978241549302935
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.859947076512782
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.8653000300975824
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.3456656208241722
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.48139193387067886
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.848624337021753
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.4640499536613014
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.7971565714351961
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.682683797967556
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.663598234662807
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.8223998258007259
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.7189222505741089
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.5513941276971644
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.7038945631351136
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.44936627838664445
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.2982758017443309
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.547376701970521
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.6763666327059107
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.5920737851344323
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.7576026755999233
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.6780652140551335
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.27503754645923456
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.7182956235294877
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.4513822555209344
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.30879449270847475
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.7950002031112497
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.696611305642733
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.7196981382578507
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.44796969509361684
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.4770518774463012
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.8453921408829227
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.7593333570031552
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.3416362071316905
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.8486429819653504
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.8397659222397983
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.5333860474544311
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.8981001567850248
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.7528777067149915
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.8072976653603167
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.7311302267707823
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.39415984793171444
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.7793506800072837
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.701057148676703
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.21217384805723963
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.7615194501064142
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.5302528999510315
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.5595797094127446
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.9146091022665699
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.3649738540700304
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.6371982898751072
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.9094772326806326
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.860883484769306
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.7713063705313619
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.8426533363008536
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.8757969953470244
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.5751797274491866
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.6886022659599849
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.20966334590812205
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.1840733705962606
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.27131324802669
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.7113263015526913
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.8726693617979786
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.7178071477701816
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.6995515231963232
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.5733244228534871
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.8775711240057079
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.4952251819057911
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.7336715854698863
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.8186606382896651
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.7365656528427975
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.4411061707420938
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.7805844015833863
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.8435205443000626
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.09453092991932659
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.48832709517283734
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.6443541230308161
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.7065110415940501
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.8766905305629744
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.6278075731872683
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.29073675512310787
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.6803916074675777
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.49744220725138294
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.5218803911431544
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.7260843653571669
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.25576556116973176
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.7824469052661389
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.3840415322427059
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.11336823341356754
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.5234461386798491
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.8408227252078252
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.20199114808583793
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.6321089302275441
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.33303655493863404
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.6994542682996412
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.6473215602406195
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.7087720496717945
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.2711469019375288
---------------------------------------------------------

Hidden units: 6
Epochs: 1000
Learning rate: 0.1

Errors during training:
Error at epoch 1 is 100.57455322867173
Train mean error at (after) epoch 1: 0.2514363830716793
Test error at (after) epoch 1: 0.2887961038993635
----------
Error at epoch 100 is 8.166314836125277
Train mean error at (after) epoch 100: 0.020415787090313192
Test error at (after) epoch 100: 0.020883354189260784
----------
Error at epoch 200 is 5.366481414313167
Train mean error at (after) epoch 200: 0.013416203535782918
Test error at (after) epoch 200: 0.012102224048372927
----------
Error at epoch 300 is 5.039904472682301
Train mean error at (after) epoch 300: 0.012599761181705754
Test error at (after) epoch 300: 0.010893397994360786
----------
Error at epoch 400 is 4.980890553572402
Train mean error at (after) epoch 400: 0.012452226383931004
Test error at (after) epoch 400: 0.010615266340706616
----------
Error at epoch 500 is 4.966774772397481
Train mean error at (after) epoch 500: 0.012416936930993702
Test error at (after) epoch 500: 0.010530564698497391
----------
Error at epoch 600 is 4.9614630543729
Train mean error at (after) epoch 600: 0.01240365763593225
Test error at (after) epoch 600: 0.010499503628567039
----------
Error at epoch 700 is 4.957985414396825
Train mean error at (after) epoch 700: 0.012394963535992063
Test error at (after) epoch 700: 0.010486745520068704
----------
Error at epoch 800 is 4.954889993629281
Train mean error at (after) epoch 800: 0.012387224984073202
Test error at (after) epoch 800: 0.01048121267840819
----------
Error at epoch 900 is 4.951862937235666
Train mean error at (after) epoch 900: 0.012379657343089165
Test error at (after) epoch 900: 0.010478805026451049
----------
Error at epoch 1000 is 4.94883411918082
Train mean error at (after) epoch 1000: 0.01237208529795205
Test error at (after) epoch 1000: 0.010477823698349082
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.9157898386364359
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.24469638997033652
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.8816122790474235
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.37668918219720343
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.962374035091069
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.959712228292448
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.3901227786270846
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.6510484847426096
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.9517472238208908
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6525175869069689
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.9203261149244951
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.8396655017086715
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.8253521740674342
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.9509602672452598
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.8564835512026686
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.7027292184191606
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.8547235019553114
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.5267576594034928
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.3979968061941225
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.7318122071523862
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.8202486550671495
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.7429253002038542
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.8976898158769642
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.8300634872202379
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.37320699435612326
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.8674173696004236
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.5886863057362366
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.49237272245828395
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.9190689123806792
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.8516515531167731
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.857957955342614
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.6329566807779828
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.6595857266194329
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.9494859495194442
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.9151277743746049
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.4400363174336678
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.9486400021511752
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.9383958094427394
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.6917500726359921
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.9748159893352926
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.8998859254887975
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.9309097374991832
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.8583561864929663
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.5001372109017082
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.9240387183039784
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.8618037360898411
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.31932700393215335
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.8815259261671623
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.6954599377377293
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.7203976672624657
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.9764268145801334
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.4818767418890691
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.7863008349119016
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.9798480427061751
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.9535326077332904
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.907142826347114
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.9494042291386182
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.9688497848846407
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.7491699135578098
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.8274146011691532
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.34306234436881544
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.21243464952655405
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.3301128995091593
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.857766446291995
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.9590650977281749
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.8690824717011947
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.8290922680125193
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.6965678097883927
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.9627835891841049
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.6138961699765328
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.8759302895118971
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.9261565825488289
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.865098252927729
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.5713960116105856
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.913280822224419
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.9428827424414433
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.05932333978132409
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.6581873212930648
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.7716440933164698
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.8533635663700143
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.9681805554406225
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.7890857133344074
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.3529209183074674
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.8291967451356959
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.6709594893422165
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.6822677770049922
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.8621950536299815
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.4081184690065775
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.9101047606824221
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.5456345325645736
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.193297090520457
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.6920338413329666
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.9374142576751977
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.27428255951895336
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.7960274778677815
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.5256445356021797
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.8409092651987887
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.7939606040846826
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.8475342501227094
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.35322779468934734
---------------------------------------------------------

Hidden units: 6
Epochs: 3000
Learning rate: 0.1

Errors during training:
Error at epoch 1 is 111.99650367764761
Train mean error at (after) epoch 1: 0.27999125919411905
Test error at (after) epoch 1: 0.32933929548043295
----------
Error at epoch 300 is 5.120153168619084
Train mean error at (after) epoch 300: 0.01280038292154771
Test error at (after) epoch 300: 0.010932238174929327
----------
Error at epoch 600 is 5.023424216001845
Train mean error at (after) epoch 600: 0.012558560540004614
Test error at (after) epoch 600: 0.010490688335289449
----------
Error at epoch 900 is 5.018547478702422
Train mean error at (after) epoch 900: 0.012546368696756054
Test error at (after) epoch 900: 0.01047046194330819
----------
Error at epoch 1200 is 5.014448004815901
Train mean error at (after) epoch 1200: 0.012536120012039752
Test error at (after) epoch 1200: 0.010467669280750326
----------
Error at epoch 1500 is 5.010344223979871
Train mean error at (after) epoch 1500: 0.012525860559949677
Test error at (after) epoch 1500: 0.010466618803115512
----------
Error at epoch 1800 is 5.0062143078655135
Train mean error at (after) epoch 1800: 0.012515535769663784
Test error at (after) epoch 1800: 0.010465906969734116
----------
Error at epoch 2100 is 5.00204448996284
Train mean error at (after) epoch 2100: 0.0125051112249071
Test error at (after) epoch 2100: 0.010465380361560925
----------
Error at epoch 2400 is 4.997821729122822
Train mean error at (after) epoch 2400: 0.012494554322807055
Test error at (after) epoch 2400: 0.010465013061376198
----------
Error at epoch 2700 is 4.993533501529543
Train mean error at (after) epoch 2700: 0.012483833753823857
Test error at (after) epoch 2700: 0.01046479392303824
----------
Error at epoch 3000 is 4.989167655295003
Train mean error at (after) epoch 3000: 0.012472919138237509
Test error at (after) epoch 3000: 0.010464714868233683
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.9183720217004763
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.2431322455966456
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.8847087529238548
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.3786934206223844
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.9678954047627558
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.966616246409921
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.381480563598195
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.6551236446835841
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.9618823112009023
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6303788694189291
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.9208366003545755
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.829329716848295
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.8343664487852961
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.9666474028874514
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.8596337648678313
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.7012794456776422
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.86396292250137
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.5664403202847733
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.40662633550496363
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.7090295086392034
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.8205592571872384
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.7483219223202638
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.8905321181790256
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.8426790341192972
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.3636669564661244
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.8765435185395015
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.59073242271875
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.4677006855468755
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.9150717911730429
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.8656174668789355
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.8712391119243009
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.6216100916455257
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.6505373685576709
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.9602669581079123
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.9102772041507523
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.42927697993320924
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.9562716286141744
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.9548742526589449
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.6916550349712108
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.9788732135101047
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.9054746827837654
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.9430883875518667
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.8784328606052417
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.5182915567454477
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.939950623874638
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.850173582882212
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.31396624814232843
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.8947444633183756
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.7147402533822037
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.7208052590073869
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.9828918192842797
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.4907538481019362
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.7821093309594201
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.9862590780241279
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.9642343520936469
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.9031178520760724
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.956382212656016
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.9751738801108965
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.7355650615186569
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.8552535126583889
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.33189342980154624
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.20840734485754905
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.3212305636377072
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.863292543752931
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.9680944875498402
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.8926031856255096
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.8516460732208679
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.7095670257703776
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.9728417941383097
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.6156056380014898
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.8821075528585152
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.9438853728232676
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.8648381017299586
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.5839809220998269
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.914483337983566
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.9494821549800752
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.055458742687824865
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.6456750197222715
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.7885122663723085
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.8710480730075154
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.9714806896709479
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.7820416248856084
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.334642402009152
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.8363319856593633
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.7068637049039342
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.696917684324675
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.8670962102351913
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.4012856326886206
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.9228984098590489
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.5572260819544533
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.21915512711377536
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.6880643011694126
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.9493467047153697
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.2742214498201491
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.8004580828359041
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.5045834714441069
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.8547172493885733
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.7956609993582581
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.8618377885461912
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.3648056701754659
---------------------------------------------------------

Hidden units: 6
Epochs: 10000
Learning rate: 0.1

Errors during training:
Error at epoch 1 is 143.79304676004372
Train mean error at (after) epoch 1: 0.3594826169001093
Test error at (after) epoch 1: 0.40976163806003135
----------
Error at epoch 1000 is 4.995948860838589
Train mean error at (after) epoch 1000: 0.012489872152096473
Test error at (after) epoch 1000: 0.010510179340351611
----------
Error at epoch 2000 is 4.979135807680643
Train mean error at (after) epoch 2000: 0.012447839519201608
Test error at (after) epoch 2000: 0.010499380886762093
----------
Error at epoch 3000 is 4.961059119515771
Train mean error at (after) epoch 3000: 0.012402647798789428
Test error at (after) epoch 3000: 0.010492872628589585
----------
Error at epoch 4000 is 4.940872943791199
Train mean error at (after) epoch 4000: 0.012352182359477997
Test error at (after) epoch 4000: 0.010488899290789343
----------
Error at epoch 5000 is 4.917782455914311
Train mean error at (after) epoch 5000: 0.012294456139785777
Test error at (after) epoch 5000: 0.010487163692202072
----------
Error at epoch 6000 is 4.890979113012566
Train mean error at (after) epoch 6000: 0.012227447782531415
Test error at (after) epoch 6000: 0.010487587624484087
----------
Error at epoch 7000 is 4.859638258885508
Train mean error at (after) epoch 7000: 0.01214909564721377
Test error at (after) epoch 7000: 0.010490218598379786
----------
Error at epoch 8000 is 4.82297363216412
Train mean error at (after) epoch 8000: 0.0120574340804103
Test error at (after) epoch 8000: 0.010495082234589916
----------
Error at epoch 9000 is 4.780350491833501
Train mean error at (after) epoch 9000: 0.011950876229583754
Test error at (after) epoch 9000: 0.010501906459437514
----------
Error at epoch 10000 is 4.731434440321886
Train mean error at (after) epoch 10000: 0.011828586100804714
Test error at (after) epoch 10000: 0.010509661328010365
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.88103704785589
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.24814535991498957
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.8396980743350928
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.38437281392968525
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.952186531905077
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.9253197120360779
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.39394297470634293
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.6529764903290873
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.9448999992886438
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6322912139845045
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.9050790162750809
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.79847095047452
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.8247727605435585
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.9528791999366559
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.8189420361834784
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.7055041582113741
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.8534289695399299
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.5634509091326625
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.41842898719795407
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.70346447807975
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.7955515647201675
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.7265998532182484
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.854389019491925
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.8114226398548499
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.3661480571897819
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.8614591871230313
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.5806015742100437
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.484356484207108
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.8754695043387988
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.8448083107842234
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.8283084178471039
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.635514853384479
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.6459310868165586
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.9185295663305914
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.9055224585390712
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.4245911787761884
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.9378161318568541
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.917074153975807
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.6933822116302758
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.9396674572316881
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.8942949767873871
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.9335741767293184
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.8327249180683002
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.5235596481356622
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.927206590580365
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.8296268596791939
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.3161002270173543
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.8664492341176742
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.7082323539304048
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.7244398419365524
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.9428436401448216
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.5030866588532107
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.7605279219576953
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.9696943803793561
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.9250805151707511
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.8906046675980837
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.9410289407681941
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.9598473501064673
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.7188374908302653
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.8527384791647451
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.3498183988399037
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.2241499463472585
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.332684220568492
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.8296954036031533
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.949827591693684
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.8689897975680502
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.8004536958677132
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.6980954698237157
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.9539359094791083
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.6276028019444863
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.8610484852333389
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.9064797563805297
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.8396630445353702
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.5965836806105933
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.877851897750392
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.9151597108497003
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.06514849114863536
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.6354315464340772
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.7597856174405312
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.8532894166905098
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.9323012372184358
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.7551465189503153
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.3386398770654695
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.8034221595332657
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.6571482136727194
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.7047914537664342
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.8249241119625452
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.4152271857425384
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.9111475337764275
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.537585076161925
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.20654760018711157
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.7026103324621119
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.9162835362210643
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.2909193633659264
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.7944981205770496
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.5169769485352695
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.8160494078814224
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.7665719391830879
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.8160056022007406
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.35144860638444725
---------------------------------------------------------

Hidden units: 6
Epochs: 100
Learning rate: 0.3

Errors during training:
Error at epoch 1 is 81.48528447953277
Train mean error at (after) epoch 1: 0.2037132111988319
Test error at (after) epoch 1: 0.21145481496721216
----------
Error at epoch 10 is 33.08427440496161
Train mean error at (after) epoch 10: 0.08271068601240403
Test error at (after) epoch 10: 0.08767549707575949
----------
Error at epoch 20 is 14.639145888102268
Train mean error at (after) epoch 20: 0.03659786472025567
Test error at (after) epoch 20: 0.0389140817646511
----------
Error at epoch 30 is 9.060470582558487
Train mean error at (after) epoch 30: 0.022651176456396218
Test error at (after) epoch 30: 0.023046896996995154
----------
Error at epoch 40 is 6.977820544545272
Train mean error at (after) epoch 40: 0.01744455136136318
Test error at (after) epoch 40: 0.01684830937797743
----------
Error at epoch 50 is 6.047638291918496
Train mean error at (after) epoch 50: 0.01511909572979624
Test error at (after) epoch 50: 0.01400367641971879
----------
Error at epoch 60 is 5.58480419884421
Train mean error at (after) epoch 60: 0.013962010497110523
Test error at (after) epoch 60: 0.01254962637962178
----------
Error at epoch 70 is 5.338386950447275
Train mean error at (after) epoch 70: 0.013345967376118189
Test error at (after) epoch 70: 0.011748983802913303
----------
Error at epoch 80 is 5.200961383218583
Train mean error at (after) epoch 80: 0.013002403458046456
Test error at (after) epoch 80: 0.011283268373677642
----------
Error at epoch 90 is 5.121658702238788
Train mean error at (after) epoch 90: 0.01280414675559697
Test error at (after) epoch 90: 0.01100048989724857
----------
Error at epoch 100 is 5.074659303464412
Train mean error at (after) epoch 100: 0.01268664825866103
Test error at (after) epoch 100: 0.010822610394501317
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.9058147880061032
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.2151493588577153
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.8717762292114115
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.36153475084803616
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.95583006233874
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.9584618025082069
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.3700413637807509
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.6319967819647676
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.9463231573511699
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6266263362425252
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.917575072929315
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.8325796545361343
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.8196225195124002
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.9565870737009695
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.8461384039721485
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.667625815737314
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.8525071934439336
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.5010967526925388
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.36847443673301644
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.6921021116387477
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.78358358706622
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.7393335323973251
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.888647980083495
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.8328980068421233
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.35098962418588553
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.8633263654120416
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.5663708021655464
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.4686692451682201
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.9104652975547367
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.8643925781377806
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.8633423472764679
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.5927246146149727
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.6311841660751347
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.9501641743557944
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.8982865059630226
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.42541083488773235
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.949312987220392
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.9471672295941829
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.67216017178545
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.9750000197218186
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.8855095459258545
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.9239181802816162
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.8492576425319857
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.47373330448531364
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.9285791678315946
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.8477245212437041
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.28838238424614043
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.8815518814282833
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.6562955310069096
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.689997525684034
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.9801265199812732
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.4527891079533366
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.7595864462305297
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.9799710663652961
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.957890772799657
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.9019843941683545
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.9480039953476495
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.9669111790568811
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.7317535579762804
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.8123703105819025
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.32637184585780527
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.1969278361037105
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.3181004195180174
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.8357689741089057
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.9559465866542437
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.8675627968299837
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.8098339765154691
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.659989180628722
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.9669114216435177
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.6018490115929063
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.8595743386899396
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.9349868887786781
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.833940131264329
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.538024010064618
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.8919283760862289
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.9453938741242796
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.027005072958283152
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.6400276907992009
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.7434755660282462
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.866336612005571
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.9662404935518265
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.7723787930544219
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.32818503346627675
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.8224305801746643
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.6300478362143109
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.6562990298921748
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.8542237526632259
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.386738350065776
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.9090345549193519
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.5119197696420417
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.21521865000953783
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.6856678674582923
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.9414825415744259
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.24556046771666104
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.7877709436564312
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.49819767454053904
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.8320303459171708
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.7724166516671314
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.8429596038483588
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.34677764314023685
---------------------------------------------------------

Hidden units: 6
Epochs: 1000
Learning rate: 0.3

Errors during training:
Error at epoch 1 is 128.47245698158457
Train mean error at (after) epoch 1: 0.32118114245396145
Test error at (after) epoch 1: 0.3189041731390857
----------
Error at epoch 100 is 4.969171338429826
Train mean error at (after) epoch 100: 0.012422928346074565
Test error at (after) epoch 100: 0.010914787237771752
----------
Error at epoch 200 is 4.871392906174523
Train mean error at (after) epoch 200: 0.012178482265436308
Test error at (after) epoch 200: 0.010494422784064279
----------
Error at epoch 300 is 4.853340935242755
Train mean error at (after) epoch 300: 0.012133352338106886
Test error at (after) epoch 300: 0.010481307940374987
----------
Error at epoch 400 is 4.835393491853038
Train mean error at (after) epoch 400: 0.012088483729632594
Test error at (after) epoch 400: 0.010489706090889242
----------
Error at epoch 500 is 4.816712998060401
Train mean error at (after) epoch 500: 0.012041782495151003
Test error at (after) epoch 500: 0.010500514882632029
----------
Error at epoch 600 is 4.797193901026786
Train mean error at (after) epoch 600: 0.011992984752566964
Test error at (after) epoch 600: 0.01051156027340967
----------
Error at epoch 700 is 4.77675688154508
Train mean error at (after) epoch 700: 0.0119418922038627
Test error at (after) epoch 700: 0.010522322604978524
----------
Error at epoch 800 is 4.755343360606658
Train mean error at (after) epoch 800: 0.011888358401516646
Test error at (after) epoch 800: 0.010532460125067646
----------
Error at epoch 900 is 4.732917848472328
Train mean error at (after) epoch 900: 0.01183229462118082
Test error at (after) epoch 900: 0.010541652291928705
----------
Error at epoch 1000 is 4.709470736115156
Train mean error at (after) epoch 1000: 0.01177367684028789
Test error at (after) epoch 1000: 0.010549589590069533
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.8640779552700586
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.25050612341269385
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.8603694771008418
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.3821936844939763
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.9419132559159662
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.922342361017317
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.389075592210716
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.6626062348140643
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.9401939879465322
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6210068488726515
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.8967103818386787
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.7907250210289729
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.8240600478302842
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.9413374162799676
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.8326346449232616
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.7091846610695475
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.8437502966984864
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.5512937283373607
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.4261334778489352
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.6997899215988425
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.8017121120191755
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.7152854542924564
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.8477327599468736
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.8129154633385466
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.36705061858865323
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.8594522996391962
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.5929155753057874
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.4870426035527355
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.8760687619091074
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.8367209197796512
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.8303985393473254
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.6115534599977446
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.6374077049208823
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.9171517085173836
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.8823270325205771
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.4405502744423344
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.9303078324646394
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.8964673126151737
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.6982785338617057
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.9337626906949024
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.8830253867442809
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.9012575038056949
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.8548689153760706
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.5061576192485471
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.9191561666738264
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.7988269478827061
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.314962338090819
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.8243447604271881
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.7275810727564253
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.7303329834605534
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.9458579063231046
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.5052787902181346
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.7745192380378538
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.9609688905210756
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.9087256919628754
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.8805717328630747
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.9250907502828593
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.9422770087987036
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.7098568143038408
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.8228276271083004
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.35170352826093737
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.2109777340891117
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.334780256158557
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.8341820699332594
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.9478386222457592
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.8795319298475576
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.8374332109418205
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.7150034686014468
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.9464373742011604
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.6142509163968536
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.8138453906415105
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.8865403920469459
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.8469317462326281
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.6007132076904668
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.8779735646249194
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.8789149835214668
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.0936078737305115
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.6330827905777098
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.7862924217391755
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.8383531149486267
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.9209204968997665
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.7583415665746541
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.3615444421106079
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.8014135971933906
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.7023999797272629
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.6867768589901173
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.8373345424333021
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.42636733430772084
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.8905924917651314
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.5571141237021388
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.237241409619254
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.7092350016181636
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.8737794018970177
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.2874802416655272
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.7870603510648396
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.522017151262258
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.8289133812697871
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.7812160776588949
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.8328051148896256
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.37531388720797476
---------------------------------------------------------

Hidden units: 6
Epochs: 3000
Learning rate: 0.3

Errors during training:
Error at epoch 1 is 78.31526093341421
Train mean error at (after) epoch 1: 0.19578815233353553
Test error at (after) epoch 1: 0.2181374700839801
----------
Error at epoch 300 is 4.856106105593608
Train mean error at (after) epoch 300: 0.01214026526398402
Test error at (after) epoch 300: 0.01031575457944481
----------
Error at epoch 600 is 4.811622092132475
Train mean error at (after) epoch 600: 0.012029055230331187
Test error at (after) epoch 600: 0.01033022865454144
----------
Error at epoch 900 is 4.762979585748825
Train mean error at (after) epoch 900: 0.011907448964372062
Test error at (after) epoch 900: 0.010353463654756706
----------
Error at epoch 1200 is 4.709663891352186
Train mean error at (after) epoch 1200: 0.011774159728380465
Test error at (after) epoch 1200: 0.010382279680495482
----------
Error at epoch 1500 is 4.651541874669476
Train mean error at (after) epoch 1500: 0.011628854686673691
Test error at (after) epoch 1500: 0.010413707886290889
----------
Error at epoch 1800 is 4.588621597305516
Train mean error at (after) epoch 1800: 0.01147155399326379
Test error at (after) epoch 1800: 0.01044324915110154
----------
Error at epoch 2100 is 4.520546263413408
Train mean error at (after) epoch 2100: 0.01130136565853352
Test error at (after) epoch 2100: 0.010465618270613385
----------
Error at epoch 2400 is 4.445611540875218
Train mean error at (after) epoch 2400: 0.011114028852188046
Test error at (after) epoch 2400: 0.010476128719239556
----------
Error at epoch 2700 is 4.35925562076146
Train mean error at (after) epoch 2700: 0.010898139051903651
Test error at (after) epoch 2700: 0.01047196714083589
----------
Error at epoch 3000 is 4.252467716746745
Train mean error at (after) epoch 3000: 0.010631169291866862
Test error at (after) epoch 3000: 0.010452045109091337
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.8233118405998141
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.2782017749681521
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.8011746114286025
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.4053005424344544
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.8937387888952172
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.8496115078097235
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.41187829766959766
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.6671549801396887
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.8910326589479081
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6291334582165696
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.8573401830777438
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.76336651827352
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.8068418862668301
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.905721599937555
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.7850718236066687
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.7108329222938303
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.8240429290044533
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.5823972090313472
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.4394232046377833
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.7108111904451232
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.7753391343164742
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.7119791371037518
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.8032672018058532
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.7881495248817459
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.3854061916206362
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.8312094958531795
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.5922473883496682
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.5045868189290381
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.8191378658934071
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.8214733622064779
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.7931292236823465
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.6269848473431578
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.6655872294498243
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.8502852268863221
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.8567378546705693
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.4652174449105932
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.8804937744823276
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.8485438899143063
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.701910692920981
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.8478377121409572
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.8553251876133036
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.8738457840997241
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.8001825989524178
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.538049553903629
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.8882563624230287
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.7786018963697288
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.3328331908844117
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.8051424309434018
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.7207276096508684
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.7244461773239925
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.8471349489356315
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.5247531783981318
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.7427224522188175
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.8970449306131666
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.8470435167954498
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.8465817908850894
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.8814332552227743
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.8919165946533189
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.7019787942038404
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.8206385342788883
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.37044605950568155
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.23844724202736556
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.35281704151796717
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.7980675882291818
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.890955965622958
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.845039763065617
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.7835708419037705
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.6961630974405442
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.8908680878998975
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.6391210866668615
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.798973308077381
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.8448281448262513
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.8057671921149513
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.6131572146106011
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.8312520539105349
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.8308262907451277
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.0906495063407003
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.634567548713156
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.7463436123033135
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.8281480377179096
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.8471214906734458
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.7346490605228841
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.37066806196853164
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.7754308412244015
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.6865291358685806
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.699183154936831
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.7892915162253967
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.45124525308069324
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.8635941093975521
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.5655364942048525
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.25304754692216386
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.7183141600374724
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.8319475456179491
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.31147796899767066
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.7776823275769916
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.5357633272992743
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.7877119012651054
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.7474336028055572
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.7868349681278812
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.37875198948851607
---------------------------------------------------------

Hidden units: 6
Epochs: 10000
Learning rate: 0.3

Errors during training:
Error at epoch 1 is 108.30549790994571
Train mean error at (after) epoch 1: 0.2707637447748643
Test error at (after) epoch 1: 0.2946246974268535
----------
Error at epoch 1000 is 4.8299338748015135
Train mean error at (after) epoch 1000: 0.012074834687003783
Test error at (after) epoch 1000: 0.01033247194345745
----------
Error at epoch 2000 is 4.637911009337256
Train mean error at (after) epoch 2000: 0.01159477752334314
Test error at (after) epoch 2000: 0.010361494252032177
----------
Error at epoch 3000 is 4.32566852823093
Train mean error at (after) epoch 3000: 0.010814171320577326
Test error at (after) epoch 3000: 0.01038763120473315
----------
Error at epoch 4000 is 3.7196535919035596
Train mean error at (after) epoch 4000: 0.009299133979758898
Test error at (after) epoch 4000: 0.009935879355978137
----------
Error at epoch 5000 is 3.0563063471093077
Train mean error at (after) epoch 5000: 0.007640765867773269
Test error at (after) epoch 5000: 0.008800121913050643
----------
Error at epoch 6000 is 2.5551139680646746
Train mean error at (after) epoch 6000: 0.006387784920161687
Test error at (after) epoch 6000: 0.00777709132370166
----------
Error at epoch 7000 is 2.251134559726874
Train mean error at (after) epoch 7000: 0.005627836399317185
Test error at (after) epoch 7000: 0.007065584281076693
----------
Error at epoch 8000 is 2.091992920390957
Train mean error at (after) epoch 8000: 0.0052299823009773925
Test error at (after) epoch 8000: 0.006517260025825782
----------
Error at epoch 9000 is 1.9775662213585028
Train mean error at (after) epoch 9000: 0.004943915553396257
Test error at (after) epoch 9000: 0.006074476970143888
----------
Error at epoch 10000 is 1.8844689104921697
Train mean error at (after) epoch 10000: 0.004711172276230424
Test error at (after) epoch 10000: 0.005704928413114938
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.834145835975836
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.26396282844785807
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.8830658645641387
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.46411486274578445
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.7351611192277757
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.787585013391489
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.3922027046252516
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.6942161310488296
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.7785505451463431
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.719742576440323
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.8578335950048723
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.8321146842216565
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.8155961122702889
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.8014382173643277
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.859116713108792
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.7154267636265056
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.8301432643346836
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.6416681794859599
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.4260175218409046
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.6579211758205538
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.776869965182188
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.7737357996225126
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.8515729656285601
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.828940779675518
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.44338353242632517
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.8374319897680979
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.6506710157083186
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.5276182290448536
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.8697915544664401
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.8196042005683676
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.8379169089608403
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.6833873955487395
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.6859736370771756
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.8058637780925939
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.841414933982008
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.37490820035041156
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.8188669813018948
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.7678329980730634
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.7336008693344606
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.5742857085108664
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.8267915728244789
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.8792256009962276
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.8731035283029901
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.5544076728817176
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.8334122283509988
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.83374857552586
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.39006562192957983
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.8278815606214609
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.7695484247829386
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.742631688450133
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.46911737280678173
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.5472231275270475
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.7963682716803266
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.49009114746382565
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.7207406075476576
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.8587829885000315
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.8245303503285202
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.7390024202192255
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.7829101575473059
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.8512764253958667
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.38033029793154155
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.20541109185292294
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.39817580869629615
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.8312159304075364
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.7664528351196993
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.8515654944273509
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.8681669793943895
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.7005176051614328
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.7850984170664529
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.6203945667236321
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.8402927387879494
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.79545243696649
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.836189840814132
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.6411118083870321
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.8666168066597304
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.7760980601416833
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: -0.01105783994206483
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.7202624562378748
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.8039837492174986
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.8142570139860703
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.686949468279746
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.8058639885568264
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.39387685369313863
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.8256347126931731
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.7502219652240955
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.6900963652748936
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.8594467091921009
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.5063240246600427
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.86233569690846
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.6264558667492306
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.380715479699675
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.7167472863370002
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.7896945833620336
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.2755088144001088
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.7916226071322202
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.5946257784203121
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.8479389514424804
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.8120357562736796
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.8546859787103197
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.5034212764392393
---------------------------------------------------------

Hidden units: 6
Epochs: 100
Learning rate: 0.5

Errors during training:
Error at epoch 1 is 136.90321442093207
Train mean error at (after) epoch 1: 0.3422580360523302
Test error at (after) epoch 1: 0.2850420238342685
----------
Error at epoch 10 is 18.83389822668902
Train mean error at (after) epoch 10: 0.04708474556672255
Test error at (after) epoch 10: 0.045890606212989765
----------
Error at epoch 20 is 7.897033459351777
Train mean error at (after) epoch 20: 0.01974258364837944
Test error at (after) epoch 20: 0.018603680853874604
----------
Error at epoch 30 is 5.865600649699594
Train mean error at (after) epoch 30: 0.014664001624248985
Test error at (after) epoch 30: 0.013190154470333568
----------
Error at epoch 40 is 5.310837903406831
Train mean error at (after) epoch 40: 0.013277094758517079
Test error at (after) epoch 40: 0.011581849467319353
----------
Error at epoch 50 is 5.122524354527719
Train mean error at (after) epoch 50: 0.012806310886319297
Test error at (after) epoch 50: 0.010984097614277887
----------
Error at epoch 60 is 5.050636089734918
Train mean error at (after) epoch 60: 0.012626590224337295
Test error at (after) epoch 60: 0.010729899903589326
----------
Error at epoch 70 is 5.021117651506224
Train mean error at (after) epoch 70: 0.012552794128765562
Test error at (after) epoch 70: 0.010610992846042833
----------
Error at epoch 80 is 5.008262463735967
Train mean error at (after) epoch 80: 0.012520656159339918
Test error at (after) epoch 80: 0.010550972343141764
----------
Error at epoch 90 is 5.002273895740964
Train mean error at (after) epoch 90: 0.012505684739352409
Test error at (after) epoch 90: 0.010518658129814845
----------
Error at epoch 100 is 4.999198289284589
Train mean error at (after) epoch 100: 0.012497995723211473
Test error at (after) epoch 100: 0.010500275196091506
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.9204464027386167
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.21992793404901553
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.8843782730438553
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.3763173405827596
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.9655466310450244
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.9671267218329426
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.35611326136413246
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.6532578506173986
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.9595903923071201
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.635359539166759
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.9084897584912411
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.8232476594822226
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.832608566885104
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.9637490433541348
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.8609092672160099
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.6958489193194515
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.8586505631739071
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.5701797382840244
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.4093085544278144
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.6952245819579742
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.807945134524437
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.7442815783194289
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.8937770710531581
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.8430825036750433
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.37054585999902423
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.8702398869816065
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.5920380664810071
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.47598538476070024
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.9182684326291701
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.8651860087150517
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.8663880578839805
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.6190694570785263
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.6573737986802574
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.9601515434465708
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.910017964003343
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.4086326185824819
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.9522804941554218
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.9553833123422603
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.6936977783996771
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.9796113758746245
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.9008540590576827
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.941915415980686
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.881490905997259
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.5167907306632974
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.9377277025717156
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.8552456817779808
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.3154270966479527
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.8959948594925286
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.7122458343200078
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.7211176208732587
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.9833260412325906
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.4921033302037038
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.786483762987074
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.9848713687724903
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.965004630694683
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.8876551582269032
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.953853127324736
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.9733462395377857
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.7379291056944534
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.8547065751843249
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.33467493550793076
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.21164213360412834
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.3191722423211973
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.854186440695401
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.9665311651086421
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.8829806826078493
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.8486133106230256
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.7107130255277139
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.9699737177880671
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.6224666421542021
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.8910513728472664
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.9442372417896022
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.8635262189328536
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.5871084787306919
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.9100165767980242
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.9509392412701437
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.06634658227164125
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.6432861001437629
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.7942819425172399
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.8696608014017403
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.9726272663602984
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.7847339759054534
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.33574503809756834
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.8360783259013245
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.6835303212529056
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.6918261244754691
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.8676617276064447
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.41513251137023044
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.919994766122001
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.5351157304776124
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.2146352803281243
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.6996231199429616
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.9513213290507815
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.27903856617904066
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.7944366587149445
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.5082458121053034
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.8568082318292202
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.7993592392832549
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.8602050730480408
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.368602776954049
---------------------------------------------------------

Hidden units: 6
Epochs: 1000
Learning rate: 0.5

Errors during training:
Error at epoch 1 is 116.02476090432981
Train mean error at (after) epoch 1: 0.2900619022608245
Test error at (after) epoch 1: 0.2511557824763732
----------
Error at epoch 100 is 4.985441582567581
Train mean error at (after) epoch 100: 0.012463603956418951
Test error at (after) epoch 100: 0.010432483538759417
----------
Error at epoch 200 is 4.972005622676034
Train mean error at (after) epoch 200: 0.012430014056690085
Test error at (after) epoch 200: 0.010395944297427809
----------
Error at epoch 300 is 4.960121121279894
Train mean error at (after) epoch 300: 0.012400302803199734
Test error at (after) epoch 300: 0.010391574626447462
----------
Error at epoch 400 is 4.947571696009932
Train mean error at (after) epoch 400: 0.01236892924002483
Test error at (after) epoch 400: 0.010388292497889593
----------
Error at epoch 500 is 4.934210141279703
Train mean error at (after) epoch 500: 0.012335525353199256
Test error at (after) epoch 500: 0.010385583066425126
----------
Error at epoch 600 is 4.919891509856228
Train mean error at (after) epoch 600: 0.01229972877464057
Test error at (after) epoch 600: 0.01038345756559385
----------
Error at epoch 700 is 4.904472346230132
Train mean error at (after) epoch 700: 0.01226118086557533
Test error at (after) epoch 700: 0.010381962297638743
----------
Error at epoch 800 is 4.8878120608662945
Train mean error at (after) epoch 800: 0.012219530152165736
Test error at (after) epoch 800: 0.010381166889476616
----------
Error at epoch 900 is 4.869776023179189
Train mean error at (after) epoch 900: 0.012174440057947973
Test error at (after) epoch 900: 0.010381160459357629
----------
Error at epoch 1000 is 4.8502402581675135
Train mean error at (after) epoch 1000: 0.012125600645418783
Test error at (after) epoch 1000: 0.010382044725859418
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.9002717741530741
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.23817697466443885
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.8762747084326569
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.37991396464642646
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.9597078253506012
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.9452846417171789
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.37876170292900585
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.6522812669784883
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.9513274345781491
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6342363492322634
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.9201845604788502
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.8224169512161679
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.8238372180518982
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.9501259816648767
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.8453546675154094
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.6987349656676205
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.8562148582475032
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.5669747548956103
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.4146066845921111
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.7160519183213372
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.8057525086825589
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.7351158742262154
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.8779590677603416
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.8139012547673946
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.36409780489596383
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.8687282718224464
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.5809907522987892
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.4724488411813294
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.9014772075783862
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.8379035816463265
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.850113590178552
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.6341715608006225
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.65907155218705
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.9348750311788174
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.9118964783278777
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.43374518688323993
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.9486419091618481
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.9320268470891864
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.6833027250829621
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.9617817146855453
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.8949876849364136
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.9396371084548473
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.857539509686477
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.5220648079861928
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.9230819038110768
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.8493755499598231
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.3131771015537551
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.8855130412362491
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.7201113942367101
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.7229090039299612
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.964613212981435
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.4969920024238211
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.7796401204798107
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.9772915680637362
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.943419992484654
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.9058272110377256
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.9486211325801928
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.9678032527933488
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.7295792386059613
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.8519643765956015
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.3347112770863316
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.21394931660421473
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.32263060246101566
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.8365923628480081
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.9604004581745695
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.8834605420954604
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.84185059974998
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.7076647337998634
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.9634473470835302
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.6210757680562305
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.8808715113074025
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.9196473365469107
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.8623383074514169
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.5922422012302989
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.8962452383046946
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.9381310343101728
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.07481135215944232
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.6410017353710442
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.7834722571679156
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.8454884505148449
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.954792895025508
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.7695631572912623
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.3487452904713263
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.8107418035536884
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.6948789991883563
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.701484739266407
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.8508505709158692
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.4097232134551014
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.9141464865184347
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.5527453834688154
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.21207161895592633
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.6932551070214883
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.9379338242739068
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.28337221482596764
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.7951542722190582
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.5072034678884432
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.8290116282750611
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.7838601685768026
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.841672584598082
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.35814721408331235
---------------------------------------------------------

Hidden units: 6
Epochs: 3000
Learning rate: 0.5

Errors during training:
Error at epoch 1 is 116.29065168162073
Train mean error at (after) epoch 1: 0.29072662920405185
Test error at (after) epoch 1: 0.2761001061165881
----------
Error at epoch 300 is 4.933000557625656
Train mean error at (after) epoch 300: 0.01233250139406414
Test error at (after) epoch 300: 0.010543670716532822
----------
Error at epoch 600 is 4.863332987193106
Train mean error at (after) epoch 600: 0.012158332467982765
Test error at (after) epoch 600: 0.01053941035910273
----------
Error at epoch 900 is 4.776996048258795
Train mean error at (after) epoch 900: 0.011942490120646987
Test error at (after) epoch 900: 0.01052414226966715
----------
Error at epoch 1200 is 4.669706356299082
Train mean error at (after) epoch 1200: 0.011674265890747706
Test error at (after) epoch 1200: 0.010494370320473035
----------
Error at epoch 1500 is 4.546133848113152
Train mean error at (after) epoch 1500: 0.01136533462028288
Test error at (after) epoch 1500: 0.010449475768030176
----------
Error at epoch 1800 is 4.4120637118778685
Train mean error at (after) epoch 1800: 0.011030159279694671
Test error at (after) epoch 1800: 0.01038414803624679
----------
Error at epoch 2100 is 4.240667138883245
Train mean error at (after) epoch 2100: 0.010601667847208111
Test error at (after) epoch 2100: 0.010274875157936595
----------
Error at epoch 2400 is 3.9422627611779135
Train mean error at (after) epoch 2400: 0.009855656902944784
Test error at (after) epoch 2400: 0.010042853635289405
----------
Error at epoch 2700 is 3.49273041380479
Train mean error at (after) epoch 2700: 0.008731826034511975
Test error at (after) epoch 2700: 0.009541888192987487
----------
Error at epoch 3000 is 3.0938584465494503
Train mean error at (after) epoch 3000: 0.0077346461163736255
Test error at (after) epoch 3000: 0.008848380114538557
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.7890355024015867
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.33590510506103605
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.8518304390348506
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.42396622603924916
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.8161108595152466
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.749844676219152
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.4139989084895814
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.6744344782262657
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.8282870669817414
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6817870476831434
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.8708318889926012
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.8075834568540322
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.7765228373044036
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.8518963470398403
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.8105583280495364
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.7311911195778027
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.7784263369010906
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.5873240810588877
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.4652073925865459
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.7424429837181022
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.8132123178953692
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.7088894895015961
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.8160011402786544
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.7781872519154538
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.42604969609677795
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.8012680399881585
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.6253610771014667
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.5335004993607014
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.8271076246426559
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.7980929877265994
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.7776133312364994
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.7068050889147229
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.683846118403569
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.7714566824770088
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.8450623504130028
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.5130960222993315
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.8228231650167308
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.7223181024693259
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.7130896727108961
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.6834990439762397
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.8156414495680917
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.8008081498491717
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.8117796666302663
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.5399695057497171
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.8460373377613464
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.8217647878611489
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.3544189238970479
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.7732184488747321
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.7509132076543341
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.74168230016532
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.633806397809884
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.5568663510747367
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.7903885735190653
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.7102706462304211
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.7104664440826384
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.8800494636513613
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.8025482813109307
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.7755433453869178
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.7340437998211456
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.7517146181916591
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.3777364739910243
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.2553832970128114
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.38508923544884033
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.8143155474638222
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.8255134273181921
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.8235173815792511
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.8291956185286806
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.7462415293699467
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.7853852228683245
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.6359229754828403
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.8080196684435476
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.7430751482963146
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.8428677028534873
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.6448757676254697
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.8353262028058794
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.7813261709528619
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.11883334993375234
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.6682604566470264
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.7931848918661228
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.7954370644419884
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.731956416949565
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.7597133175940023
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.4280001147604845
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.7688972273018344
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.7158088861389419
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.6824679285304099
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.8073398325097383
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.47114610368063964
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.7868175795747702
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.5862628115184815
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.2425177543288272
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.7457027581810052
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.7579096525455993
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.32623486346780084
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.746205318888112
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.5846064252973231
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.7939027941084902
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.7805882366316933
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.7957984860216785
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.40466854691075305
---------------------------------------------------------

Hidden units: 6
Epochs: 10000
Learning rate: 0.5

Errors during training:
Error at epoch 1 is 121.22798490402852
Train mean error at (after) epoch 1: 0.30306996226007127
Test error at (after) epoch 1: 0.26562286978852256
----------
Error at epoch 1000 is 4.347233552716339
Train mean error at (after) epoch 1000: 0.010868083881790846
Test error at (after) epoch 1000: 0.010438977637999362
----------
Error at epoch 2000 is 3.4240558303515423
Train mean error at (after) epoch 2000: 0.008560139575878856
Test error at (after) epoch 2000: 0.009878682011169437
----------
Error at epoch 3000 is 2.611327951500333
Train mean error at (after) epoch 3000: 0.006528319878750832
Test error at (after) epoch 3000: 0.008234851053051795
----------
Error at epoch 4000 is 2.206357426908567
Train mean error at (after) epoch 4000: 0.005515893567271417
Test error at (after) epoch 4000: 0.007166711525238345
----------
Error at epoch 5000 is 1.9524877001732073
Train mean error at (after) epoch 5000: 0.004881219250433018
Test error at (after) epoch 5000: 0.00621826294382002
----------
Error at epoch 6000 is 1.7436518482414078
Train mean error at (after) epoch 6000: 0.00435912962060352
Test error at (after) epoch 6000: 0.005293195126836142
----------
Error at epoch 7000 is 2.012297672640103
Train mean error at (after) epoch 7000: 0.005030744181600258
Test error at (after) epoch 7000: 0.00523269309189428
----------
Error at epoch 8000 is 1.854172687925796
Train mean error at (after) epoch 8000: 0.00463543171981449
Test error at (after) epoch 8000: 0.004741402508447731
----------
Error at epoch 9000 is 1.8095806239270062
Train mean error at (after) epoch 9000: 0.004523951559817515
Test error at (after) epoch 9000: 0.004505818561968168
----------
Error at epoch 10000 is 1.7889854947448058
Train mean error at (after) epoch 10000: 0.004472463736862014
Test error at (after) epoch 10000: 0.004355669924905361
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.8177834344208539
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.24805594087043797
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.9172437920831624
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.47747333821533666
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.7317099500745821
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.804714525428203
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.39518994890494513
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.6431588743013099
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.8507789991667329
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.7174234532123869
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.8914918136053437
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.8560310477931729
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.7761378775648003
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.881986872970322
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.8696133743841041
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.6983239772435844
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.805819452817354
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.6408161834450461
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.4464984328253148
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.7723734440617298
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.8483656462718197
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.7619243410028083
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.8502134096280829
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.8551139275546451
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.3750669225132054
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.80066802358433
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.6686055368821612
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.6339475699089688
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.8748234732307157
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.9055164894638621
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.8152483011263072
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.6524253319659155
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.743772004995597
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.8687220618975665
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.8694637072912939
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.5078706811292342
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.7910771931709091
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.8078568924628463
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.7184155038709357
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.5127773327473588
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.818026938606126
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.9164363049009228
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.894210529232436
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.5663976854593624
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.8752830631520794
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.8694698077502391
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.29565255699125614
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.8920006774163896
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.7274514389730149
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.7119865267368924
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.505920606025343
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.46671801424786913
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.8286586454505223
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.26407494469735
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.7329180445963719
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.8943113195232043
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.810548914773939
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.7512303690716376
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.7774147412290713
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.8273769510788325
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.4772878268088211
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.294136118503041
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.44857736196464143
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.8852508482103539
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.8284793197486637
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.8050895810121549
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.8853421440968046
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.7350313618866382
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.6736016075953926
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.6808066706540337
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.8992991154249413
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.8295099637640327
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.8907174351207214
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.5612823202095742
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.9215765609334002
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.9209956730464218
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.1577915717734391
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.7168167827979731
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.8146026387284513
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.9135522729835469
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.6382092367701249
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.8023528554749599
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.36036144469442966
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.8306642831508255
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.7826047107753983
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.6508868201567407
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.8653914176799723
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.5277331007355667
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.8529214937314203
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.6676365433088581
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.22557391941675128
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.7360970946640454
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.9340226642727986
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.3240763689035348
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.7694235024913243
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.5603582801947727
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.8740382533880987
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.8330474742583831
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.856101828065969
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.38286409700478446
---------------------------------------------------------

Hidden units: 6
Epochs: 100
Learning rate: 1

Errors during training:
Error at epoch 1 is 127.6173807328913
Train mean error at (after) epoch 1: 0.31904345183222826
Test error at (after) epoch 1: 0.23677300323661538
----------
Error at epoch 10 is 10.050409902463725
Train mean error at (after) epoch 10: 0.025126024756159313
Test error at (after) epoch 10: 0.023398625485642848
----------
Error at epoch 20 is 5.594008806835841
Train mean error at (after) epoch 20: 0.013985022017089604
Test error at (after) epoch 20: 0.012601389036686212
----------
Error at epoch 30 is 5.138907924147589
Train mean error at (after) epoch 30: 0.012847269810368973
Test error at (after) epoch 30: 0.01121919177154503
----------
Error at epoch 40 is 5.055689819075597
Train mean error at (after) epoch 40: 0.012639224547688992
Test error at (after) epoch 40: 0.01090094605596053
----------
Error at epoch 50 is 5.032210679289827
Train mean error at (after) epoch 50: 0.012580526698224568
Test error at (after) epoch 50: 0.010796637722108393
----------
Error at epoch 60 is 5.020508919703132
Train mean error at (after) epoch 60: 0.012551272299257829
Test error at (after) epoch 60: 0.01075107003911121
----------
Error at epoch 70 is 5.01148896882826
Train mean error at (after) epoch 70: 0.01252872242207065
Test error at (after) epoch 70: 0.010725807913130245
----------
Error at epoch 80 is 5.003249179392269
Train mean error at (after) epoch 80: 0.012508122948480672
Test error at (after) epoch 80: 0.010708938446493992
----------
Error at epoch 90 is 4.995358025152661
Train mean error at (after) epoch 90: 0.012488395062881652
Test error at (after) epoch 90: 0.010696053322529738
----------
Error at epoch 100 is 4.987698808520211
Train mean error at (after) epoch 100: 0.012469247021300527
Test error at (after) epoch 100: 0.010685300075477798
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.9173659899815253
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.24441074148497155
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.8200796775380755
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.3767062504346696
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.9556121447011237
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.9598792598375361
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.3805889614327113
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.674797101358784
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.9503433136208078
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6402497855865524
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.88299795478806
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.8075790780735501
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.841789614798724
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.967887871769471
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.8311036762566069
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.7129098102214162
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.8642453097359621
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.5372593616423434
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.4142955526267079
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.7137645839594681
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.8259391214906783
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.7595297741738559
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.8732680248460946
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.8564409575570319
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.38299780468627204
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.8681846854022028
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.6018682137762593
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.46098393746910676
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.8899068330620699
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.8732027931158542
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.8687964683279772
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.6491272155156329
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.6802229697713844
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.9580488300011041
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.895905903991635
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.4474205803614816
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.9377667656868741
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.9540127332193352
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.7118627858969211
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.9684486617561264
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.905087338698833
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.9367930928090029
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.8594891454811585
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.5170694331160636
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.9447187320661805
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.845438103499973
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.3305970901636829
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.8965815330989166
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.6745397904837919
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.7103470853398424
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.9722596460720111
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.4968660394329222
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.7505468412098665
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.9773630491671446
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.9604965315289155
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.8592534139179012
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.9454305308081928
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.9648228021764986
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.7378899617662644
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.8549230402356415
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.33372242120452167
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.22028999444984265
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.328215075617824
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.8714968445320596
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.9448862351559653
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.8807294522953734
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.7846995513187169
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.7028506683391318
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.9604714764047293
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.6039950719636887
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.8876309758613441
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.9446299546320207
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.8362686938060164
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.5800930407577608
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.9095882426760327
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.9411256636875313
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: -0.011867146122778506
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.6499478435332096
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.7525445773199583
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.8701214735996349
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.9613744201853122
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.7774770453417585
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.29889313060502887
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.8460595500300708
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.6843124169733513
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.7067734188035554
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.843238318116732
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.42956673037868215
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.9198587299842743
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.5499823246710104
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.23406856747371327
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.7212933835542029
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.9439669486740678
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.29122396443666204
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.8044620921790223
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.4978354702875697
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.8572566784636767
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.7805922434528584
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.8459618100096169
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.3639850651490278
---------------------------------------------------------

Hidden units: 6
Epochs: 1000
Learning rate: 1

Errors during training:
Error at epoch 1 is 55.53027152938003
Train mean error at (after) epoch 1: 0.13882567882345007
Test error at (after) epoch 1: 0.10936864341028246
----------
Error at epoch 100 is 4.9489525617006285
Train mean error at (after) epoch 100: 0.012372381404251571
Test error at (after) epoch 100: 0.010412726045986104
----------
Error at epoch 200 is 4.9235257285550835
Train mean error at (after) epoch 200: 0.01230881432138771
Test error at (after) epoch 200: 0.010408033194148186
----------
Error at epoch 300 is 4.893184628343828
Train mean error at (after) epoch 300: 0.01223296157085957
Test error at (after) epoch 300: 0.010405311480577944
----------
Error at epoch 400 is 4.856497490835068
Train mean error at (after) epoch 400: 0.012141243727087669
Test error at (after) epoch 400: 0.010404270138895935
----------
Error at epoch 500 is 4.811664778423217
Train mean error at (after) epoch 500: 0.012029161946058043
Test error at (after) epoch 500: 0.010405099808436928
----------
Error at epoch 600 is 4.756522610912667
Train mean error at (after) epoch 600: 0.011891306527281667
Test error at (after) epoch 600: 0.010407972729010053
----------
Error at epoch 700 is 4.688685763685361
Train mean error at (after) epoch 700: 0.011721714409213402
Test error at (after) epoch 700: 0.010412855388883764
----------
Error at epoch 800 is 4.605878850984436
Train mean error at (after) epoch 800: 0.011514697127461091
Test error at (after) epoch 800: 0.010418961926076971
----------
Error at epoch 900 is 4.506302866715367
Train mean error at (after) epoch 900: 0.011265757166788418
Test error at (after) epoch 900: 0.01042364346968701
----------
Error at epoch 1000 is 4.38863701754843
Train mean error at (after) epoch 1000: 0.010971592543871075
Test error at (after) epoch 1000: 0.010421367253932745
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.8262431170912189
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.2480390910196412
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.838767685630813
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.3914992256892308
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.925918060537716
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.8793661631841694
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.4045597202417999
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.666317722507163
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.929570391787207
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6137964672439542
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.8936712655801812
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.7750628946117275
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.8275944789122898
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.9403157365389595
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.8130636279681389
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.7080608267132041
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.8453268626610044
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.5469025745849605
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.4303160913726153
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.678282243909585
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.77485638507278
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.711599916754634
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.818310496323819
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.8055506275652236
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.3641804970620266
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.8602822087242411
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.5931715146549056
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.48885473459934786
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.8428078491252029
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.8335905667634589
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.8185101676667503
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.6003819652158189
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.6220058086529378
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.8830478537302389
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.8732213608930928
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.4329551489815929
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.9222916342223247
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.865912189295689
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.7045923520339411
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.8782117666568378
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.874079506838093
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.8911090769810946
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.8378428509146385
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.5099186143182018
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.9215019517281485
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.7733649601789019
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.30914813561039123
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.8012294734372473
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.7324944259828149
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.7306401077851449
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.8979803670023229
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.5062601581094256
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.755785171461886
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.9395046459597756
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.8690936611010169
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.8789807947689561
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.9141753774645514
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.9244368081385905
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.6976856212581001
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.8198456502483183
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.3600893769367378
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.21708020693837568
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.3465074310069664
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.8090232692716889
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.9360077402855111
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.8822799164350825
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.8233861234176983
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.7024648859414069
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.9373076266587326
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.6190283857689601
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.7830246367235942
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.8599176161156106
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.8176005019618128
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.6041801416305749
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.8411653911991602
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.840360979519976
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.0933340248067744
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.6303470000793893
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.7723243578897013
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.8328153319709793
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.8683047725254841
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.7421084424195742
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.354111699811212
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.784972973595944
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.6936979887994539
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.6904122949488753
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.8180083214471657
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.4271820919181781
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.885656527597159
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.5595029515617057
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.27027734062274533
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.7183561620739801
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.8372145391213591
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.29225929603365697
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.7899230627515095
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.5243646434653764
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.8136314203418975
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.7638153647217082
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.8186789449703658
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.37485294119200624
---------------------------------------------------------

Hidden units: 6
Epochs: 3000
Learning rate: 1

Errors during training:
Error at epoch 1 is 83.00408115635996
Train mean error at (after) epoch 1: 0.2075102028908999
Test error at (after) epoch 1: 0.17582356606730787
----------
Error at epoch 300 is 5.0111665610434235
Train mean error at (after) epoch 300: 0.01252791640260856
Test error at (after) epoch 300: 0.010468531909752105
----------
Error at epoch 600 is 4.943125232719864
Train mean error at (after) epoch 600: 0.01235781308179966
Test error at (after) epoch 600: 0.01044631736250013
----------
Error at epoch 900 is 4.84731717453118
Train mean error at (after) epoch 900: 0.01211829293632795
Test error at (after) epoch 900: 0.01043810129364249
----------
Error at epoch 1200 is 4.695789683040787
Train mean error at (after) epoch 1200: 0.011739474207601968
Test error at (after) epoch 1200: 0.010450069046468115
----------
Error at epoch 1500 is 4.478448647459436
Train mean error at (after) epoch 1500: 0.011196121618648589
Test error at (after) epoch 1500: 0.010483059117291981
----------
Error at epoch 1800 is 4.162052733503572
Train mean error at (after) epoch 1800: 0.01040513183375893
Test error at (after) epoch 1800: 0.010459722180299669
----------
Error at epoch 2100 is 3.5542955235095164
Train mean error at (after) epoch 2100: 0.008885738808773792
Test error at (after) epoch 2100: 0.010170547659728992
----------
Error at epoch 2400 is 2.9323590470550727
Train mean error at (after) epoch 2400: 0.007330897617637682
Test error at (after) epoch 2400: 0.009113748670742624
----------
Error at epoch 2700 is 2.5284853184874905
Train mean error at (after) epoch 2700: 0.006321213296218726
Test error at (after) epoch 2700: 0.008147216153620256
----------
Error at epoch 3000 is 2.1410895306912496
Train mean error at (after) epoch 3000: 0.005352723826728124
Test error at (after) epoch 3000: 0.0072240925007816285
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.8152423850830521
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.3026595533397516
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.8682680886231161
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.4567208949597266
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.7954017537218747
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.7271647309497603
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.4540618036400673
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.650611283967391
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.817658064265429
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6682035724917096
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.8756378754138052
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.813048714737786
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.7828631396095591
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.9159920305551911
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.8367664953459855
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.7091352597510492
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.7838137848559203
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.645834997727411
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.44480353226166097
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.7368638674148753
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.8198659378810846
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.7457427665526247
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.8536638128423425
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.8210806412348532
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.41859817750264283
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.7970236363014513
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.6529916892196959
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.5062312445424387
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.8725521175862425
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.850859089770226
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.796450997933157
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.6531791009202822
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.6502926168861914
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.7527575930314522
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.8663983944557864
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.4567564270170264
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.8101412180635627
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.7288604832137359
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.7086204682994125
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.6434067023574288
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.8188526501770631
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.8012894708292546
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.8383013577284315
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.5896559047349845
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.8932403038268039
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.8349344879070266
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.3577804676171559
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.7945062942451115
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.7722271114744133
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.7718508983317175
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.5198784909851846
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.5896360747827607
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.8093319380651299
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.6213123008954939
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.6867449272995478
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.889721382710867
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.7942060149421362
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.7382943225671081
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.7506724548398127
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.7888937904938085
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.36292721100447006
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.27513701942691654
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.4122524109863922
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.8288703087979435
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.8273274027684223
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.7909384314253419
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.8172024859435124
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.7595832988033961
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.7429017092383419
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.7098676026615763
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.8257591081617373
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.7663366852044491
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.8760561774467439
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.6830434066795948
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.8430948745321154
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.7897927096079619
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.15140425612513367
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.6769802019070892
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.8023202488632837
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.8547741071202749
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.7310745424712883
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.7880513483800012
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.3871626959163009
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.807172491646359
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.6427315528728789
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.6972202959238305
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.834499457804863
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.3947344471238415
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.807113675638293
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.5471253040411408
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.30138205209808433
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.7369472169971841
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.7574296203762825
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.3207641791947056
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.7497900385033838
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.6565884343576424
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.8275433363555503
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.8073017117915846
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.8158587701378048
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.37127285615486816
---------------------------------------------------------

Hidden units: 6
Epochs: 10000
Learning rate: 1

Errors during training:
Error at epoch 1 is 143.19919371399234
Train mean error at (after) epoch 1: 0.35799798428498086
Test error at (after) epoch 1: 0.3123412591305478
----------
Error at epoch 1000 is 4.403307054350511
Train mean error at (after) epoch 1000: 0.011008267635876277
Test error at (after) epoch 1000: 0.010378297883082286
----------
Error at epoch 2000 is 2.497988134060326
Train mean error at (after) epoch 2000: 0.006244970335150815
Test error at (after) epoch 2000: 0.007744831703920779
----------
Error at epoch 3000 is 2.1221028292139392
Train mean error at (after) epoch 3000: 0.005305257073034848
Test error at (after) epoch 3000: 0.006591588568099582
----------
Error at epoch 4000 is 1.7477656254208154
Train mean error at (after) epoch 4000: 0.004369414063552038
Test error at (after) epoch 4000: 0.005343269944011227
----------
Error at epoch 5000 is 1.4297627408830182
Train mean error at (after) epoch 5000: 0.0035744068522075454
Test error at (after) epoch 5000: 0.004007054146436108
----------
Error at epoch 6000 is 1.2730367726563727
Train mean error at (after) epoch 6000: 0.0031825919316409317
Test error at (after) epoch 6000: 0.0033334390485371835
----------
Error at epoch 7000 is 1.203578696745236
Train mean error at (after) epoch 7000: 0.00300894674186309
Test error at (after) epoch 7000: 0.003085583829650905
----------
Error at epoch 8000 is 1.169813878732071
Train mean error at (after) epoch 8000: 0.0029245346968301777
Test error at (after) epoch 8000: 0.00296036583601391
----------
Error at epoch 9000 is 1.0139449443845239
Train mean error at (after) epoch 9000: 0.0025348623609613096
Test error at (after) epoch 9000: 0.0025054229328843086
----------
Error at epoch 10000 is 0.5098947046946021
Train mean error at (after) epoch 10000: 0.001274736761736505
Test error at (after) epoch 10000: 0.0012935941227350156
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.9352747557479548
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.12780555124784423
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.9219099284857188
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.35916437247778354
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.771819767445169
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.8284865657548679
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.399721164509958
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.670675581215491
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.8217953392944356
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6592331982774083
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.9046207483334583
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.8952420452349613
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.8742530094210028
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.8907211986653603
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.9277876709498589
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.7281826748316692
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.8949677013319629
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.5529714539519421
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.39577243505544973
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.7968734276566795
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.8916707881454374
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.8271732321630879
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.9396770969265513
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.9060197860564949
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.2600383545409117
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.9040909776777982
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.627629752406896
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.4346243306573753
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.9426935841507876
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.9429636470835868
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.9299215113317589
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.6406164240570439
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.7207811770787429
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.8897637239950392
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.9120166423506307
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.4264052929368862
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.8613905790377069
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.8974218568180071
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.7135689054119859
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.48451522015732035
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.9030544083603289
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.8805981834306255
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.9366013186795001
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.5349822466193531
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.9196076889437137
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.9124215801483881
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.2324684265019565
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.93933846460474
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.7278463769008977
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.7610311337198138
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.24068799650724135
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.42946060619638193
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.8656853650166774
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.30920991781635127
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.8421156614693485
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.8953611393168706
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.850693371669097
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.6836958516230395
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.8144509368181456
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.8861324045581566
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.310990929482396
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.1874113899959953
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.2669698621678854
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.9159390632378597
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.7852792080843582
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.9095331950254434
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.9125331944189535
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.8019265280577658
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.7269461726730104
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.6515348846695892
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.9352092481271082
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.9207629402530991
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.9374186763506351
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.5627964175105238
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.9345088737813165
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.8973832899673402
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.04777589996146941
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.6956074297244851
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.8793640730005886
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.9480911634223201
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.7247414541263771
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.8685283734437602
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.2091925232762682
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.8949540971943571
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.7821779215401318
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.7366680435090859
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.9323917757041519
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.3795059380848355
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.8996384578918616
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.5705255119457003
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.11878719054361102
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.7533198215007323
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.8927886720737662
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.2699874727928359
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.8500434707466699
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.38782050727102874
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.9138277461022533
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.8844684240528089
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.9294082441250022
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.27023665571825706
=========================================================

---------------------------------------------------------

Hidden units: 7
Epochs: 100
Learning rate: 0.05

Errors during training:
Error at epoch 1 is 72.05109893745903
Train mean error at (after) epoch 1: 0.1801277473436476
Test error at (after) epoch 1: 0.2094866824673142
----------
Error at epoch 10 is 53.810696377751896
Train mean error at (after) epoch 10: 0.13452674094437975
Test error at (after) epoch 10: 0.15541332160638216
----------
Error at epoch 20 is 40.66736432947635
Train mean error at (after) epoch 20: 0.10166841082369088
Test error at (after) epoch 20: 0.1167349866420305
----------
Error at epoch 30 is 31.91048282931162
Train mean error at (after) epoch 30: 0.07977620707327905
Test error at (after) epoch 30: 0.09109180935732855
----------
Error at epoch 40 is 25.834758501435736
Train mean error at (after) epoch 40: 0.06458689625358933
Test error at (after) epoch 40: 0.07331054976743216
----------
Error at epoch 50 is 21.478308365375515
Train mean error at (after) epoch 50: 0.05369577091343879
Test error at (after) epoch 50: 0.060531019285601874
----------
Error at epoch 60 is 18.26642091580888
Train mean error at (after) epoch 60: 0.045666052289522197
Test error at (after) epoch 60: 0.05107232110460164
----------
Error at epoch 70 is 15.84106447647096
Train mean error at (after) epoch 70: 0.0396026611911774
Test error at (after) epoch 70: 0.04389707658109462
----------
Error at epoch 80 is 13.971360973880751
Train mean error at (after) epoch 80: 0.034928402434701876
Test error at (after) epoch 80: 0.03833895701420655
----------
Error at epoch 90 is 12.503894910514694
Train mean error at (after) epoch 90: 0.03125973727628673
Test error at (after) epoch 90: 0.03395544461780077
----------
Error at epoch 100 is 11.333981459935318
Train mean error at (after) epoch 100: 0.028334953649838294
Test error at (after) epoch 100: 0.030444159187044892
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.731549478131574
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.05289940694406163
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.6762842475778915
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.22994270819569684
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.8275593215007416
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.8434128865671615
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.31720612471968956
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.41125798930038104
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.8175421018238795
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.3879061492898677
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.7023672189838862
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.5847408991217943
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.5972658132618596
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.8484359456345523
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.6395841394608771
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.4767825667626441
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.6233093478595106
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.3703215429460056
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.2661180534908587
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.44901517623129505
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.6075136261812669
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.5062653257652264
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.6815403589965642
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.6423728608768486
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.23012447589195079
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.6384738595819553
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.3921460198054934
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.26246273945603754
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.7249051085241971
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.6875529734231054
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.6471720161998245
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.3716115824611477
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.3983760318274606
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.8315556074308773
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.6887308198751624
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.2716103448538519
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.7918674522933699
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.8181792626668661
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.4791659525840392
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.8798001601175532
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.6960937303832526
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.7649377637934818
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.6769005740774683
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.3160204518361024
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.7837362079483013
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.6213699461741374
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.17682164074910797
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.6930397919680791
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.4642638520700822
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.47327654235017574
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.8942779934308474
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.30117857073850746
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.5490607174324742
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.8975955802429595
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.8386789780840997
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.6670164185677833
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.7954492393194272
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.8520088222522577
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.48963194714474495
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.6197787622088514
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.18134527219788416
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.17328170148952138
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.23282344000177002
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.6676029402141991
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.83127376395177
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.6568456915537635
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.6306766629528919
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.4986381156226997
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.8421519287520746
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.4177064556740816
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.6769948926944565
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.7941215550620321
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.6456750294103136
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.36956291463703966
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.7265928471157274
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.8007456757777746
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.05210089177109793
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.4069019835547609
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.5684624020791694
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.6961535120922993
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.8546347638185392
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.5462911417651398
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.22166542025837846
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.6247407824415643
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.4502193533920383
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.427002957136273
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.6493382008113732
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.21535638031635745
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.7252999562516573
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.32794440188982543
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.0760512332100388
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.47591952716686925
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.8036804529341547
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.19427195969320665
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.5405553510109259
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.2684613999580869
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.6517088696827771
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.5695966274271356
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.6410414480213315
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.20273212633862053
---------------------------------------------------------

Hidden units: 7
Epochs: 1000
Learning rate: 0.05

Errors during training:
Error at epoch 1 is 112.02614147678648
Train mean error at (after) epoch 1: 0.28006535369196617
Test error at (after) epoch 1: 0.3313452227657306
----------
Error at epoch 100 is 20.180537523903457
Train mean error at (after) epoch 100: 0.050451343809758645
Test error at (after) epoch 100: 0.059979746601628976
----------
Error at epoch 200 is 8.383958390367798
Train mean error at (after) epoch 200: 0.020959895975919497
Test error at (after) epoch 200: 0.022039790208733357
----------
Error at epoch 300 is 6.025485504713415
Train mean error at (after) epoch 300: 0.015063713761783537
Test error at (after) epoch 300: 0.014316541603078263
----------
Error at epoch 400 is 5.352482705177787
Train mean error at (after) epoch 400: 0.013381206762944466
Test error at (after) epoch 400: 0.012043769200807857
----------
Error at epoch 500 is 5.117682046175526
Train mean error at (after) epoch 500: 0.012794205115438814
Test error at (after) epoch 500: 0.011202419643317
----------
Error at epoch 600 is 5.026039691801934
Train mean error at (after) epoch 600: 0.012565099229504835
Test error at (after) epoch 600: 0.01084368666665794
----------
Error at epoch 700 is 4.987562850519646
Train mean error at (after) epoch 700: 0.012468907126299117
Test error at (after) epoch 700: 0.010674797430474591
----------
Error at epoch 800 is 4.970386450351292
Train mean error at (after) epoch 800: 0.01242596612587823
Test error at (after) epoch 800: 0.010588872174006581
----------
Error at epoch 900 is 4.962153906195426
Train mean error at (after) epoch 900: 0.012405384765488565
Test error at (after) epoch 900: 0.010542239554526833
----------
Error at epoch 1000 is 4.95778913489349
Train mean error at (after) epoch 1000: 0.012394472837233725
Test error at (after) epoch 1000: 0.010515508550663733
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.9179481210245792
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.2628948584581868
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.8774488974488943
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.36995893153710036
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.9632170962612512
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.9630848060343158
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.3727987002900193
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.6415432047978763
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.9545320469601186
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6332351790059133
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.9048089557001816
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.8217952741256143
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.8232281347603243
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.9626069192301758
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.8525317668660793
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.6931144606288089
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.8497499511333368
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.550335945788249
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.4101124434483464
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.7184454045613453
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.8103905112286284
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.7379778527719197
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.8908457469927465
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.8406388352503855
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.36673774052233177
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.8599387330255569
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.584154546170527
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.48076163872267746
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.915473393701705
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.8767351537548813
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.8556501376693307
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.6167171808604772
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.666960560414363
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.955421303168749
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.9100419588907345
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.4144370457092746
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.9453496821271379
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.9498962395086743
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.6910698275068637
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.976633648700968
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.8985709200323972
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.9363426716266922
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.8674339690238514
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.4998352033639976
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.9352211912079996
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.8523440766110834
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.3086551540537272
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.8867170702494404
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.6976565335600889
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.717594088503275
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.977925812696578
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.4921186610974201
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.7874663746933654
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.981672366040859
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.9599918849893598
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.8868932598407057
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.9488506902216828
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.9705122776980274
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.7344142954403513
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.8419318395726584
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.3341213412299597
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.21454046923416709
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.32765226254471336
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.855235938733146
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.9609929359748498
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.8661914851697876
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.833706464724505
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.7073971441088992
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.9625463077470514
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.624998428201709
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.8824807917175387
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.9391158135968338
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.8692353287917304
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.585387231582368
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.911189065962153
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.9457047800244709
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.043141143078996046
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.6403413355510165
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.7869790719232965
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.8840500832007947
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.9702945913435762
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.7796946829319168
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.355254165808592
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.8317309629005634
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.6628688251517448
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.6772178125201119
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.8584360002207704
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.41162469643683897
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.9129065314189762
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.5301254880829552
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.22185255872023388
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.6975998333247853
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.9445103155587004
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.28026227919268454
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.7862923371745791
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.5062419064395395
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.8467255725835999
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.7931854020410944
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.846760928753614
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.35799173550622954
---------------------------------------------------------

Hidden units: 7
Epochs: 3000
Learning rate: 0.05

Errors during training:
Error at epoch 1 is 90.26417079382931
Train mean error at (after) epoch 1: 0.22566042698457328
Test error at (after) epoch 1: 0.2678298041453931
----------
Error at epoch 300 is 5.888853013356659
Train mean error at (after) epoch 300: 0.014722132533391647
Test error at (after) epoch 300: 0.01375272430358407
----------
Error at epoch 600 is 4.9704635113453906
Train mean error at (after) epoch 600: 0.012426158778363476
Test error at (after) epoch 600: 0.010724444036275418
----------
Error at epoch 900 is 4.905067578632253
Train mean error at (after) epoch 900: 0.012262668946580632
Test error at (after) epoch 900: 0.010450766527038085
----------
Error at epoch 1200 is 4.893142470643858
Train mean error at (after) epoch 1200: 0.012232856176609646
Test error at (after) epoch 1200: 0.010403145315971474
----------
Error at epoch 1500 is 4.8858124543391375
Train mean error at (after) epoch 1500: 0.012214531135847844
Test error at (after) epoch 1500: 0.010391311201398296
----------
Error at epoch 1800 is 4.878763441363981
Train mean error at (after) epoch 1800: 0.012196908603409953
Test error at (after) epoch 1800: 0.010388006667737506
----------
Error at epoch 2100 is 4.871569463092164
Train mean error at (after) epoch 2100: 0.01217892365773041
Test error at (after) epoch 2100: 0.010387276569495708
----------
Error at epoch 2400 is 4.864179723048138
Train mean error at (after) epoch 2400: 0.012160449307620344
Test error at (after) epoch 2400: 0.010387459482285939
----------
Error at epoch 2700 is 4.856580350571132
Train mean error at (after) epoch 2700: 0.012141450876427831
Test error at (after) epoch 2700: 0.010388045711014156
----------
Error at epoch 3000 is 4.848761124560839
Train mean error at (after) epoch 3000: 0.012121902811402097
Test error at (after) epoch 3000: 0.010388877896977667
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.8927285911924695
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.22874212763879692
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.882286495790923
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.37388624752086524
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.9558847757823705
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.949143763113394
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.36380341778576675
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.6659590573709027
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.9520942292227619
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6344755427530934
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.9073170661271449
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.8183653623181513
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.8295516757531725
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.9498525415341719
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.8564616151312058
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.7041834811873596
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.8509767573683013
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.5392724751206762
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.4148181641640171
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.7255724486894544
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.8106043678362292
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.7329346313187554
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.8789128554908705
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.8285281392619045
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.3770171688801705
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.8679157658311716
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.596627252406966
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.4859603551126895
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.9069447702668687
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.8475858510723733
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.8570151074540274
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.6320535934606578
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.6525994228251596
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.9414175839580731
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.8967500890700758
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.43436625135748225
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.9433390271800477
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.9242163964875577
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.6958817129169701
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.9610755045452756
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.8880249748161207
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.9136873074995422
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.8766722683318898
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.5030200528410741
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.926099201634682
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.8356191144037403
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.3204170019354157
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.8602251090950098
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.7170853152945588
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.7321784217408316
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.9688080153355348
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.5059204227878589
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.7952725937852487
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.9736900801450774
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.9376997341826913
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.8899771865026155
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.9384934418284999
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.9566091145028481
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.7293620168606743
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.8190490030948406
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.33963796339333946
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.21384170303480693
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.3325452874406319
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.8416552466247877
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.9610635867363434
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.8880021958471789
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.8498277001330268
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.7240609530095736
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.9596049196793094
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.6125723666925688
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.8527273284913227
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.9125388691037185
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.876352406642208
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.5994411949889721
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.9012744439916319
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.9176217563605529
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.08789878845683391
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.6437177315669838
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.8005011858964884
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.8463498515797794
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.9512684199651716
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.7784259517825621
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.3616158697080901
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.8171749582952181
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.69887482912118
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.6828492381093181
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.8617806334431937
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.4213958043593682
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.8995014688093423
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.5498109720558445
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.22822068186643707
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.7168830892025096
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.9127710647238113
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.27900350061350043
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.7906793436925824
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.5137256104074364
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.847502861205043
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.8000517682270705
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.8557222810126032
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.36493568187701536
---------------------------------------------------------

Hidden units: 7
Epochs: 10000
Learning rate: 0.05

Errors during training:
Error at epoch 1 is 58.95404717197028
Train mean error at (after) epoch 1: 0.1473851179299257
Test error at (after) epoch 1: 0.17832058930673697
----------
Error at epoch 1000 is 4.997077620906225
Train mean error at (after) epoch 1000: 0.012492694052265562
Test error at (after) epoch 1000: 0.010559881979860554
----------
Error at epoch 2000 is 4.982987468186053
Train mean error at (after) epoch 2000: 0.012457468670465132
Test error at (after) epoch 2000: 0.010514897785854864
----------
Error at epoch 3000 is 4.971002804568069
Train mean error at (after) epoch 3000: 0.012427507011420173
Test error at (after) epoch 3000: 0.01051147310389583
----------
Error at epoch 4000 is 4.958200731060546
Train mean error at (after) epoch 4000: 0.012395501827651366
Test error at (after) epoch 4000: 0.010509881549926173
----------
Error at epoch 5000 is 4.944392815875909
Train mean error at (after) epoch 5000: 0.012360982039689772
Test error at (after) epoch 5000: 0.010509253589253819
----------
Error at epoch 6000 is 4.929381589959691
Train mean error at (after) epoch 6000: 0.012323453974899227
Test error at (after) epoch 6000: 0.010509484384989292
----------
Error at epoch 7000 is 4.912957857342497
Train mean error at (after) epoch 7000: 0.012282394643356242
Test error at (after) epoch 7000: 0.010510491407563303
----------
Error at epoch 8000 is 4.894901973323525
Train mean error at (after) epoch 8000: 0.012237254933308812
Test error at (after) epoch 8000: 0.010512188059807925
----------
Error at epoch 9000 is 4.874988868877513
Train mean error at (after) epoch 9000: 0.012187472172193783
Test error at (after) epoch 9000: 0.010514474065612128
----------
Error at epoch 10000 is 4.852998356513613
Train mean error at (after) epoch 10000: 0.012132495891284033
Test error at (after) epoch 10000: 0.01051722555781846
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.8958168044092851
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.24037503658914164
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.8759938488444915
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.37689207913558814
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.961458793997194
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.9489381982439858
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.3930443674998123
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.6562392638859352
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.955997670313619
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6289544089154475
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.9094653767573648
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.8066546811060273
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.830968859976177
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.9587063452790012
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.8483807241468335
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.7026040877693143
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.8531317387376777
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.5433822064928568
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.417911199479387
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.7148593375919005
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.8113983627406474
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.7232828567983266
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.8756384581068474
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.8263257690326178
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.37354992653426566
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.8675131391988046
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.5928154247888593
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.49071434008772924
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.9041114857496746
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.8521844978376407
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.8385057528383272
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.6172483339419804
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.6444555192409595
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.9409996459656362
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.9060800333573082
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.4269032768916313
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.9457986413988878
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.9245272418209018
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.7024899990116538
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.9624916827032598
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.8975335062927019
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.9266367782856457
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.8658631691250928
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.5060752910718309
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.9343709725093567
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.8284056277603463
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.3168056853592626
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.8558266135539995
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.7208669911328849
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.7308302377410145
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.9650204697311076
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.49312226711293305
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.79225881742043
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.9785205307676045
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.9384477979303542
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.8925215036733196
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.9452213131079764
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.9651180648416212
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.7246707079163164
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.8348033984896508
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.34779981485864403
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.2192425930197968
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.3358248358870114
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.8495838214123483
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.9634064814006876
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.8777310145133429
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.8383339631839625
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.717575585747576
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.9604967920939955
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.6127778020523125
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.8503695716617974
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.9130989679137667
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.8695637631047888
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.5917275830728803
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.9016976342107581
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.9168481187935925
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.08322039396236282
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.63884573030847
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.7947557214996234
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.8549476231798276
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.9539408445199842
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.7741076334608088
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.3562726048583811
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.8177631910924803
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.6622436182160505
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.6885905045852898
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.8525221074716665
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.40922734176517933
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.9083167948952349
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.5320626155580759
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.22717506237586602
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.7088200922028189
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.9133835012539715
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.28240363701720383
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.792936317415022
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.5181785113519167
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.8424891458313846
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.7950747040757549
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.8408070843922646
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.3601893018253482
---------------------------------------------------------

Hidden units: 7
Epochs: 100
Learning rate: 0.1

Errors during training:
Error at epoch 1 is 84.29795953686542
Train mean error at (after) epoch 1: 0.21074489884216355
Test error at (after) epoch 1: 0.24157509674062524
----------
Error at epoch 10 is 67.84212191395926
Train mean error at (after) epoch 10: 0.16960530478489816
Test error at (after) epoch 10: 0.19274469629275306
----------
Error at epoch 20 is 53.25048743518763
Train mean error at (after) epoch 20: 0.13312621858796908
Test error at (after) epoch 20: 0.14969769029699342
----------
Error at epoch 30 is 41.3959212503465
Train mean error at (after) epoch 30: 0.10348980312586624
Test error at (after) epoch 30: 0.11462309566985135
----------
Error at epoch 40 is 32.01511251876839
Train mean error at (after) epoch 40: 0.08003778129692098
Test error at (after) epoch 40: 0.08694349841942332
----------
Error at epoch 50 is 24.811835266268048
Train mean error at (after) epoch 50: 0.06202958816567012
Test error at (after) epoch 50: 0.06600462957661263
----------
Error at epoch 60 is 19.43610557310013
Train mean error at (after) epoch 60: 0.04859026393275032
Test error at (after) epoch 60: 0.05072207967069496
----------
Error at epoch 70 is 15.521001235648077
Train mean error at (after) epoch 70: 0.03880250308912019
Test error at (after) epoch 70: 0.0398297497424903
----------
Error at epoch 80 is 12.716051932724298
Train mean error at (after) epoch 80: 0.031790129831810746
Test error at (after) epoch 80: 0.03214777606050203
----------
Error at epoch 90 is 10.719929835492817
Train mean error at (after) epoch 90: 0.026799824588732042
Test error at (after) epoch 90: 0.02672514670086182
----------
Error at epoch 100 is 9.296656258397126
Train mean error at (after) epoch 100: 0.023241640645992816
Test error at (after) epoch 100: 0.022862327831386503
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.7876424560746609
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.10016852622183516
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.748028814415872
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.19893613381232422
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.8931426153860208
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.9007683848669369
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.3342442106197395
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.47468035938754516
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.8869532254385112
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.4204562929896158
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.7582569558379672
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.641505820999106
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.6596787604537349
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.8744247829604681
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.7256136983498274
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.556042970489743
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.6810203661298154
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.30743721736903074
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.3823544440634858
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.5300587554084296
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.6835410980745017
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.546744835909807
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.7578309891608852
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.6855689249031462
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.2737705493201841
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.7093103349588841
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.470059467866856
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.33616687663781647
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.80846442770905
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.6893234870003514
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.7122927478417611
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.36193650158152835
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.4056938076021595
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.8840569673890792
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.7559297867502269
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.27126882723175927
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.85677606641484
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.8573729195855694
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.5374300844074098
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.9327614603921834
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.7555861283553679
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.8073956762615767
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.7675649985566521
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.27157987065445444
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.820309252619883
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.6664287804790021
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.23935746729890603
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.7282899826200984
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.5651784498124526
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.5803903099591446
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.942723354255024
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.4168723889956783
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.6633314893215311
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.9460423011876348
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.8860067650174851
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.7166062887567245
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.8573221020267092
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.9059373506376551
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.545071819631443
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.6255677529819393
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.24501384585899788
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.23814929596343035
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.2447771302071107
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.7226586813911734
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.903239882081378
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.7308443931922448
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.707874126233368
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.6224383662714277
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.897402016825656
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.3905778855712587
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.7053899159351629
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.8310138088834566
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.7658486265229564
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.49469933086105494
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.8012064408043535
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.8478527579006696
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: -0.07214880787289284
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.4591888283291461
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.6864023927213246
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.6837366703011768
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.9104114806816191
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.6258075435862754
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.16951043419601294
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.6774390564197915
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.5509753425461594
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.4236792724372609
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.7326520861750112
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.20980972540693815
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.7751966140145051
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.4069341307592711
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.02960282411548606
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.5084122209895289
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.8446521885583
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.2994276411016428
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.5931161126094743
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.3288513990180906
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.7319370366197752
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.6709082933773315
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.7211968356505574
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.1612714221443877
---------------------------------------------------------

Hidden units: 7
Epochs: 1000
Learning rate: 0.1

Errors during training:
Error at epoch 1 is 119.58009284178551
Train mean error at (after) epoch 1: 0.2989502321044638
Test error at (after) epoch 1: 0.35124067356649796
----------
Error at epoch 100 is 9.615689571284728
Train mean error at (after) epoch 100: 0.02403922392821182
Test error at (after) epoch 100: 0.02528494211471558
----------
Error at epoch 200 is 5.597466650955148
Train mean error at (after) epoch 200: 0.013993666627387871
Test error at (after) epoch 200: 0.012594050191662121
----------
Error at epoch 300 is 5.1530135647118716
Train mean error at (after) epoch 300: 0.01288253391177968
Test error at (after) epoch 300: 0.011089815368399083
----------
Error at epoch 400 is 5.073577384500239
Train mean error at (after) epoch 400: 0.012683943461250598
Test error at (after) epoch 400: 0.01077239293041905
----------
Error at epoch 500 is 5.05481711957011
Train mean error at (after) epoch 500: 0.012637042798925276
Test error at (after) epoch 500: 0.010680083653628526
----------
Error at epoch 600 is 5.048140896813177
Train mean error at (after) epoch 600: 0.012620352242032942
Test error at (after) epoch 600: 0.010645127146268146
----------
Error at epoch 700 is 5.044088575215258
Train mean error at (after) epoch 700: 0.012610221438038145
Test error at (after) epoch 700: 0.010628338581176408
----------
Error at epoch 800 is 5.040650799228626
Train mean error at (after) epoch 800: 0.012601626998071564
Test error at (after) epoch 800: 0.01061841999843323
----------
Error at epoch 900 is 5.037381459589916
Train mean error at (after) epoch 900: 0.01259345364897479
Test error at (after) epoch 900: 0.010611477858327927
----------
Error at epoch 1000 is 5.034177370349948
Train mean error at (after) epoch 1000: 0.01258544342587487
Test error at (after) epoch 1000: 0.010605967676049028
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.9133518421085931
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.17818970703271794
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.8815919488449654
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.3819872107281681
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.9671291351453877
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.9680396371556236
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.309258209355964
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.6792289904297409
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.9644277115310782
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6208589952870853
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.899066218451865
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.8096212183137037
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.8507809414048488
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.9652517647899201
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.869554681570135
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.7058428365097071
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.8724272987181501
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.5469990398259976
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.4233613864474863
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.7233119869491287
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.8158809390014813
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.7595129224258294
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.8907624809597078
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.8537131480477121
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.37802143889469686
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.8842495533628933
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.608818645371203
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.4749639710063052
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.91998607821359
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.8721803347709775
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.8812891519519078
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.5980328559236903
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.6284047512119362
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.9622042712186983
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.8957982273906583
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.4351764870737288
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.9559253323738133
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.9553751106555485
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.6971152680778872
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.9779981741362014
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.9026979007012444
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.925850003984594
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.894261272124677
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.5181971960433306
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.9426435130337878
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.8225123133320611
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.32762637607977213
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.8784565420537233
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.7204613682260967
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.7442373452031957
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.9849995630340826
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.5166652945341162
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.8069454726969771
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.9856237678045864
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.9634456115448101
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.8681525227301699
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.953679790035059
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.9701535633689116
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.7356617073512931
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.8347784960337294
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.338727139672156
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.19710342259670668
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.3242519857308718
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.8521267750057658
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.9714839538235401
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.9005669247524731
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.8498212320027299
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.7325568154052235
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.9743160866269889
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.6402982074565969
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.850834815471428
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.9451600426660094
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.8874299898693271
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.611213482210342
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.9141840452776558
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.9319588782808442
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.05717197136990774
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.6492361779721484
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.8134486942840745
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.8744160285095601
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.9687169794742055
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.7949794312001891
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.34996701886950393
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.8434786952273714
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.6849723578178474
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.6860782994528613
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.8768240168659582
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.39480888343558523
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.9210785203696201
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.5377007976599952
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.2055752490921231
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.7173075143860426
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.9320461213446507
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.2778245676750513
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.8097815623236219
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.5086983643365216
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.8677083698444781
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.8164029221475858
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.8735673746751422
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.3616185792228295
---------------------------------------------------------

Hidden units: 7
Epochs: 3000
Learning rate: 0.1

Errors during training:
Error at epoch 1 is 76.73406443246768
Train mean error at (after) epoch 1: 0.1918351610811692
Test error at (after) epoch 1: 0.2158633400272548
----------
Error at epoch 300 is 5.104212130502068
Train mean error at (after) epoch 300: 0.012760530326255171
Test error at (after) epoch 300: 0.010778615546069214
----------
Error at epoch 600 is 5.041198150262807
Train mean error at (after) epoch 600: 0.012602995375657018
Test error at (after) epoch 600: 0.010499116991137005
----------
Error at epoch 900 is 5.037882803009507
Train mean error at (after) epoch 900: 0.012594707007523766
Test error at (after) epoch 900: 0.010485593895863237
----------
Error at epoch 1200 is 5.035080101433065
Train mean error at (after) epoch 1200: 0.012587700253582664
Test error at (after) epoch 1200: 0.0104829173767166
----------
Error at epoch 1500 is 5.032263910496599
Train mean error at (after) epoch 1500: 0.0125806597762415
Test error at (after) epoch 1500: 0.010481292040103674
----------
Error at epoch 1800 is 5.029421040596276
Train mean error at (after) epoch 1800: 0.012573552601490689
Test error at (after) epoch 1800: 0.010479851085988803
----------
Error at epoch 2100 is 5.026543416146415
Train mean error at (after) epoch 2100: 0.012566358540366038
Test error at (after) epoch 2100: 0.01047850173519864
----------
Error at epoch 2400 is 5.023623117735366
Train mean error at (after) epoch 2400: 0.012559057794338415
Test error at (after) epoch 2400: 0.010477229464990528
----------
Error at epoch 2700 is 5.020652282658084
Train mean error at (after) epoch 2700: 0.012551630706645209
Test error at (after) epoch 2700: 0.010476028338140706
----------
Error at epoch 3000 is 5.017623040943033
Train mean error at (after) epoch 3000: 0.012544057602357583
Test error at (after) epoch 3000: 0.01047489387071992
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.9251126467157599
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.2393561639971944
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.8965591748637399
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.37141877764692177
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.9731005824153329
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.9715590864356385
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.3887769824411832
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.6521730398678628
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.9665682255318687
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6479175651887463
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.9302030734165585
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.8445347729076489
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.8342155792514276
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.9644385057263667
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.8709486517106377
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.7055499929191902
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.8643443306025829
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.5469760344619261
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.4069956738599689
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.712426863771475
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.8256877944293205
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.747632583348937
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.9050120129808606
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.8392713579417976
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.3666717971193029
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.8798702049877754
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.5953089562710228
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.47205604062692685
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.9288351489599042
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.8577126630881476
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.8726514585342907
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.6423719567286974
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.6617890127749065
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.9630730344702794
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.9215549378587071
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.42478666452920316
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.9620417745795679
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.954088239676147
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.6947130862735037
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.9844205033252676
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.9072439918083013
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.9467546579220323
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.8853382462020565
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.5109554343478645
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.9379910654173922
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.8715038239380947
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.31749308233660356
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.9029523819293147
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.7162593086301453
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.7271328186523206
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.987397608330248
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.48946280387978935
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.7924372484354437
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.9891874177827239
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.966791269539046
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.9142518977963058
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.9611457237184201
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.9792347571994118
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.7488265014753605
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.8470910840980791
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.33413885044898006
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.2099220209859119
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.3210470433159833
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.8658062848526535
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.9744616236915081
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.8913257301865078
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.8557007741471818
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.7145549393282338
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.9763267051352663
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.6140081959469663
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.8985336734981617
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.941836893109985
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.874624868698648
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.5842949201295916
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.9220325935198294
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.9592023591599597
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.08121504026727783
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.655441204814758
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.794842310374085
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.8611148606135496
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.9780814318847959
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.7932360023095971
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.3391765052841078
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.8362904730316185
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.6906463318901656
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.695586663623923
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.8773559199719048
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.41460257079939733
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.923168896536519
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.5509104027618741
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.22649987590205828
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.687675003507332
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.9572089823033542
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.28076147013478225
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.8009140041367271
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.5112133746447467
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.8595603362681684
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.8063429793402683
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.8673678574139788
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.3515629618716159
---------------------------------------------------------

Hidden units: 7
Epochs: 10000
Learning rate: 0.1

Errors during training:
Error at epoch 1 is 109.71100111182808
Train mean error at (after) epoch 1: 0.2742775027795702
Test error at (after) epoch 1: 0.3274725158143073
----------
Error at epoch 1000 is 5.03021548393521
Train mean error at (after) epoch 1000: 0.012575538709838026
Test error at (after) epoch 1000: 0.010504971046021484
----------
Error at epoch 2000 is 5.007232296962947
Train mean error at (after) epoch 2000: 0.012518080742407367
Test error at (after) epoch 2000: 0.01048238799155
----------
Error at epoch 3000 is 4.982721934213072
Train mean error at (after) epoch 3000: 0.01245680483553268
Test error at (after) epoch 3000: 0.010464532447276704
----------
Error at epoch 4000 is 4.955013516158232
Train mean error at (after) epoch 4000: 0.01238753379039558
Test error at (after) epoch 4000: 0.010449339382813696
----------
Error at epoch 5000 is 4.922314804234719
Train mean error at (after) epoch 5000: 0.012305787010586797
Test error at (after) epoch 5000: 0.010436308836244712
----------
Error at epoch 6000 is 4.882527289457572
Train mean error at (after) epoch 6000: 0.01220631822364393
Test error at (after) epoch 6000: 0.010425441950950241
----------
Error at epoch 7000 is 4.833182222502545
Train mean error at (after) epoch 7000: 0.012082955556256363
Test error at (after) epoch 7000: 0.010417219706940276
----------
Error at epoch 8000 is 4.771609155622341
Train mean error at (after) epoch 8000: 0.01192902288905585
Test error at (after) epoch 8000: 0.010412512766586078
----------
Error at epoch 9000 is 4.695532121208596
Train mean error at (after) epoch 9000: 0.01173883030302149
Test error at (after) epoch 9000: 0.010412053526384009
----------
Error at epoch 10000 is 4.60414918887554
Train mean error at (after) epoch 10000: 0.01151037297218885
Test error at (after) epoch 10000: 0.01041496362387634
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.8552677169869382
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.23974240704582883
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.8594037497384178
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.38546204263077477
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.9430115416120582
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.9083033341689161
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.40284486411197895
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.6643783465148916
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.940286019476823
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6303978744261162
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.9142221424794554
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.8032342456685294
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.8294641507333196
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.9414568973919297
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.8294828941458681
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.7044820218856389
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.8543273509926671
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.5398601266467097
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.41928669578972294
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.6974251784329429
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.782547101299487
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.7209656201613102
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.8495463040012157
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.8016449655372893
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.3696901835114689
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.8688757922589105
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.5874615086002498
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.49414894036165835
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.8740479099220625
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.8242485349321325
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.8305697685294998
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.6257013428458437
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.6297106934404293
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.9015570578994087
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.8941252804455772
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.42569066001063094
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.9386925094267395
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.8882626205052112
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.6999871834187578
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.9215883864491529
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.8812093049801054
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.9113679157183769
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.8434590108261961
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.514212826153011
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.9206203930181968
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.8139155743080146
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.31303096355244836
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.8377298202011313
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.7211603537649643
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.730455583623332
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.9350085292194218
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.5015474329144666
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.7705868833879435
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.9601436212669011
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.8991625572703936
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.9014178683842333
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.9324018070042664
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.9464947829074456
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.7159642906907174
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.8244281941593179
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.35543645270923807
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.22095160079837692
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.3389361164299224
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.8124283445755319
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.9503360995089954
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.8843569510672418
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.8251544926209864
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.7048379287601988
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.9523853229103164
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.6192000159934322
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.8258908218019207
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.8780048409035751
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.8390204546648187
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.5980868971217496
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.8612510132267711
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.8865283805385539
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.09791114571406279
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.6389698668121342
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.7748005112683715
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.8252326254328005
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.9109076450409357
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.7563272561125686
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.35216058824835617
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.7896574521572401
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.6708416192620235
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.6960889699086767
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.8340360094605992
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.42046095496447855
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.8983844081724681
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.5449167325543331
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.2310926245394623
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.713956706983528
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.881936912569043
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.28491642972492226
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.7975316919131497
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.5214858124887418
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.8163209217059014
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.7737752870632265
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.8268475572170024
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.3575707870666132
---------------------------------------------------------

Hidden units: 7
Epochs: 100
Learning rate: 0.3

Errors during training:
Error at epoch 1 is 120.37629668406149
Train mean error at (after) epoch 1: 0.3009407417101537
Test error at (after) epoch 1: 0.30466130074018344
----------
Error at epoch 10 is 43.03057127918626
Train mean error at (after) epoch 10: 0.10757642819796566
Test error at (after) epoch 10: 0.11260663285613035
----------
Error at epoch 20 is 17.55274740529975
Train mean error at (after) epoch 20: 0.04388186851324938
Test error at (after) epoch 20: 0.045566978953666536
----------
Error at epoch 30 is 10.173882975042154
Train mean error at (after) epoch 30: 0.025434707437605387
Test error at (after) epoch 30: 0.02537276379909094
----------
Error at epoch 40 is 7.481277862347641
Train mean error at (after) epoch 40: 0.0187031946558691
Test error at (after) epoch 40: 0.01779487439922397
----------
Error at epoch 50 is 6.310444569896322
Train mean error at (after) epoch 50: 0.015776111424740804
Test error at (after) epoch 50: 0.014425709184055667
----------
Error at epoch 60 is 5.74236444985635
Train mean error at (after) epoch 60: 0.014355911124640875
Test error at (after) epoch 60: 0.01275175412547447
----------
Error at epoch 70 is 5.445974621927384
Train mean error at (after) epoch 70: 0.01361493655481846
Test error at (after) epoch 70: 0.011853639603584433
----------
Error at epoch 80 is 5.283256526477621
Train mean error at (after) epoch 80: 0.013208141316194053
Test error at (after) epoch 80: 0.011343779115755062
----------
Error at epoch 90 is 5.190526804002888
Train mean error at (after) epoch 90: 0.012976317010007218
Test error at (after) epoch 90: 0.011041364647703307
----------
Error at epoch 100 is 5.136147281717764
Train mean error at (after) epoch 100: 0.01284036820429441
Test error at (after) epoch 100: 0.010855471548064684
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.8999025850334941
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.21741145778116452
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.889033231681652
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.36021928161162564
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.9567314722393594
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.9630007468482127
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.3918891233790761
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.608960855631005
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.9548767017557716
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6243997836279725
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.9232844054273593
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.8364068178542199
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.8192246157424433
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.9630487565100937
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.8583066337989599
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.6750165422717203
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.853068602480442
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.5147127817853432
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.3965045372755213
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.6331133508531732
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.7827773675151678
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.7384520344158236
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.8887169934706888
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.8338724012417715
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.3375994121314198
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.8660764327336086
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.5767782116295547
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.448279664864081
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.913242209987882
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.860485306367412
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.8624811302303987
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.6142225455273153
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.5951075319959301
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.9577077161202473
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.8872436172842386
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.3821994865678107
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.9551584186062041
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.9527948342740393
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.6780607552069967
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.9776533543731069
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.8844425527274271
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.9217504094022241
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.8701062222937427
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.4867449796556174
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.9333582502522024
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.8497045211362015
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.2875087475239286
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.889316083919716
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.6906860025415579
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.6987466467594201
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.9854343603844639
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.46447336038133924
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.7644067684974639
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.9835814941764376
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.9620865451801516
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.9076378275149858
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.9509366449926999
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.9675132189679424
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.7290664990472943
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.8158032706701829
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.31762220723229045
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.17890516398036208
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.3101388459183579
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.8456578522134219
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.9652939132880309
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.8619290485887868
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.8408496264499723
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.6839594941021024
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.9719725198049692
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.6089031843084871
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.8636482868674051
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.9409990673793814
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.8269294965621095
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.5608609311640359
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.886441941685739
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.9484640586772526
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.0472792244452412
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.6393220315081337
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.7761748350034426
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.8689691801176159
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.9662773655647616
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.7740233167353467
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.3385843129501605
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.8274576856747285
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.6210235180144494
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.6654069048879282
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.8654320123180202
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.3943152822268646
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.9124846072505243
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.5112889836554033
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.23970676866356963
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.6202335879162927
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.9457347079453778
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.2691210339347176
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.7869796754463835
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.48829338453968
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.8462660290130415
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.784897323586428
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.8528963506327202
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.32921095270252215
---------------------------------------------------------

Hidden units: 7
Epochs: 1000
Learning rate: 0.3

Errors during training:
Error at epoch 1 is 126.19544600417872
Train mean error at (after) epoch 1: 0.3154886150104468
Test error at (after) epoch 1: 0.3361617229551447
----------
Error at epoch 100 is 5.151399701037478
Train mean error at (after) epoch 100: 0.012878499252593696
Test error at (after) epoch 100: 0.011002863991227104
----------
Error at epoch 200 is 5.028531526616437
Train mean error at (after) epoch 200: 0.012571328816541091
Test error at (after) epoch 200: 0.010500615580173251
----------
Error at epoch 300 is 5.018067740136022
Train mean error at (after) epoch 300: 0.012545169350340056
Test error at (after) epoch 300: 0.01047068894437965
----------
Error at epoch 400 is 5.008730685544106
Train mean error at (after) epoch 400: 0.012521826713860264
Test error at (after) epoch 400: 0.010460099092768727
----------
Error at epoch 500 is 4.999512710589246
Train mean error at (after) epoch 500: 0.012498781776473115
Test error at (after) epoch 500: 0.01045211755612148
----------
Error at epoch 600 is 4.990326038844083
Train mean error at (after) epoch 600: 0.012475815097110208
Test error at (after) epoch 600: 0.01044516489519002
----------
Error at epoch 700 is 4.981099703935918
Train mean error at (after) epoch 700: 0.012452749259839795
Test error at (after) epoch 700: 0.010438990867476215
----------
Error at epoch 800 is 4.971769333202589
Train mean error at (after) epoch 800: 0.012429423333006473
Test error at (after) epoch 800: 0.010433494946048212
----------
Error at epoch 900 is 4.962275599739592
Train mean error at (after) epoch 900: 0.01240568899934898
Test error at (after) epoch 900: 0.010428605812063112
----------
Error at epoch 1000 is 4.952563052917307
Train mean error at (after) epoch 1000: 0.012381407632293267
Test error at (after) epoch 1000: 0.010424266986081822
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.9099512080900148
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.23222730136935218
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.8669859366596129
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.37736926292026
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.9606317362689988
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.9591003841392849
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.3861224038290048
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.6639885659830713
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.9557231532255182
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6426839684707213
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.9170926334161261
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.8298477983336684
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.8365596844451092
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.9636952669696535
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.8512985364358167
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.7056721894710783
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.8643398530564818
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.5532801905088419
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.4009265373914611
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.711427816844627
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.8219675009667864
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.749919635546824
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.8854584246662794
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.8411759663530722
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.37275209528187464
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.8761998999636985
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.5944306480497225
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.46606832154651895
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.9067414609761089
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.8566143140446114
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.8698696576047346
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.6557295857872237
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.6462433313427242
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.9539259825567217
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.9054238034552778
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.43276634079354553
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.9524883437702842
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.9488583312105354
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.6980599796502587
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.971660337367653
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.8997049538106884
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.9384826029520285
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.8703912445040909
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.522249659634534
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.9385682611320875
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.8575685857148194
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.32315569668106675
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.8981771639301238
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.6967704498128402
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.7176609111712141
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.9784088966006956
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.49307131714207986
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.7707959856082862
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.9811013586158104
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.9581217588597739
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.8999369451078415
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.9522985155237701
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.9692312744150652
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.7394971078125125
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.8491156321898834
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.33270921741673376
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.21884064661226307
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.32386333933647277
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.8588853116818322
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.960803492331185
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.8912848238546675
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.8274948476973821
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.7084279047040768
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.9697333473874457
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.5975507745132097
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.8890787878890751
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.9374969102617033
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.8573797964297052
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.5799860260413148
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.9075493273702468
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.9474530891280722
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.05334817864869218
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.6508528275793872
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.771344144522514
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.8557709216003012
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.963150994583311
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.7801717610628794
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.3220127227481484
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.8327435894542135
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.7036213120498317
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.7059870620348097
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.8602260879739863
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.4090735504535386
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.9198260658764448
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.558972215826499
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.1974642413606481
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.7023746498824137
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.9476775783576047
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.27426133221974586
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.802540817612311
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.5056917180027594
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.8524550640957768
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.7894264304758243
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.8571634984242925
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.3545398040330123
---------------------------------------------------------

Hidden units: 7
Epochs: 3000
Learning rate: 0.3

Errors during training:
Error at epoch 1 is 145.95309721718223
Train mean error at (after) epoch 1: 0.3648827430429556
Test error at (after) epoch 1: 0.37778340629018126
----------
Error at epoch 300 is 5.00767770032748
Train mean error at (after) epoch 300: 0.0125191942508187
Test error at (after) epoch 300: 0.010529235947194921
----------
Error at epoch 600 is 4.986939589773535
Train mean error at (after) epoch 600: 0.012467348974433839
Test error at (after) epoch 600: 0.010523268547141229
----------
Error at epoch 900 is 4.9648124255813615
Train mean error at (after) epoch 900: 0.012412031063953404
Test error at (after) epoch 900: 0.010521511001806021
----------
Error at epoch 1200 is 4.940493762128542
Train mean error at (after) epoch 1200: 0.012351234405321354
Test error at (after) epoch 1200: 0.010521447331111277
----------
Error at epoch 1500 is 4.913172369932084
Train mean error at (after) epoch 1500: 0.012282930924830212
Test error at (after) epoch 1500: 0.010522776927645933
----------
Error at epoch 1800 is 4.881964354737522
Train mean error at (after) epoch 1800: 0.012204910886843804
Test error at (after) epoch 1800: 0.010525341467838147
----------
Error at epoch 2100 is 4.845885100056097
Train mean error at (after) epoch 2100: 0.012114712750140241
Test error at (after) epoch 2100: 0.010529011152723802
----------
Error at epoch 2400 is 4.803860310333827
Train mean error at (after) epoch 2400: 0.012009650775834569
Test error at (after) epoch 2400: 0.010533576297856683
----------
Error at epoch 2700 is 4.754781737760169
Train mean error at (after) epoch 2700: 0.011886954344400423
Test error at (after) epoch 2700: 0.010538608292156795
----------
Error at epoch 3000 is 4.697563566581307
Train mean error at (after) epoch 3000: 0.011743908916453267
Test error at (after) epoch 3000: 0.010543237646619867
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.8807198937222956
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.2534089040543321
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.8468562453016221
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.3853511263765244
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.9546945368476885
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.9245071073681952
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.3867771168916592
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.6560489779576387
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.9461946490551265
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6273322219532539
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.9057614897213997
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.7961835494797495
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.8234937770744528
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.9395076936638451
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.8236388189530511
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.7109895823937394
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.8511062263924578
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.5557794110515399
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.4209186738165914
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.7127314390435993
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.808971127830455
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.7179259475023055
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.8565019733536133
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.7949746193933026
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.36501182290841877
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.8619324638818063
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.5846553957198302
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.4812963520838525
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.8811522839218253
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.8141173027299567
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.818929960570387
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.6171749812571142
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.644471228264751
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.9117119782525255
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.9034103603076401
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.43425892343011807
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.9365642776381302
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.901386973663925
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.6926321905351511
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.9408125026959346
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.8953561667458375
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.9273022374261783
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.8339174691294309
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.5140121202465034
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.9158578122225918
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.8193868405285818
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.3172404775137865
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.8500106082875468
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.7149595959074007
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.7293733594292803
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.9353899439991654
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.501875389993491
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.7707606159043467
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.9687056415874218
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.9161261989302378
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.8910656507699677
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.9390216770725144
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.9589638375863938
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.7176133222189377
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.8440623386775156
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.34817686358851935
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.21141439557353886
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.33074174008063467
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.8337844270331279
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.9518931849626114
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.8693426649287429
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.807893200375852
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.708789810261377
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.948963952630985
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.6124966693767389
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.844213009981413
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.8898092803651358
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.855389382521364
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.597273967410783
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.8886033817901867
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.9059068442508237
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.07727471571795388
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.6364012484119645
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.7685390042025815
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.8227815361376322
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.9344591162833815
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.7591515122032244
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.35017742245875955
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.7979345876120927
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.6679413533914045
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.6988317272188506
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.8280203353392407
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.41751814363543427
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.9060781300323102
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.5490112107536002
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.21161530177780222
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.6909833315333478
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.9039944304046842
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.28868243467264626
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.7944107494074228
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.5136717241433595
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.8136293353784797
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.774557879413537
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.815236729187823
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.3519982779048951
---------------------------------------------------------

Hidden units: 7
Epochs: 10000
Learning rate: 0.3

Errors during training:
Error at epoch 1 is 139.33945202872647
Train mean error at (after) epoch 1: 0.34834863007181616
Test error at (after) epoch 1: 0.36697604383156424
----------
Error at epoch 1000 is 4.853945722801108
Train mean error at (after) epoch 1000: 0.01213486430700277
Test error at (after) epoch 1000: 0.010348951820741142
----------
Error at epoch 2000 is 4.709455099170602
Train mean error at (after) epoch 2000: 0.011773637747926504
Test error at (after) epoch 2000: 0.010378090536564643
----------
Error at epoch 3000 is 4.519061678111066
Train mean error at (after) epoch 3000: 0.011297654195277665
Test error at (after) epoch 3000: 0.010446566199038871
----------
Error at epoch 4000 is 4.252586402867801
Train mean error at (after) epoch 4000: 0.010631466007169504
Test error at (after) epoch 4000: 0.01047258722388277
----------
Error at epoch 5000 is 3.693471030097631
Train mean error at (after) epoch 5000: 0.009233677575244077
Test error at (after) epoch 5000: 0.0103628413808676
----------
Error at epoch 6000 is 3.007688155892308
Train mean error at (after) epoch 6000: 0.007519220389730769
Test error at (after) epoch 6000: 0.009294927856871069
----------
Error at epoch 7000 is 2.597229237268397
Train mean error at (after) epoch 7000: 0.006493073093170992
Test error at (after) epoch 7000: 0.008126881095420641
----------
Error at epoch 8000 is 2.309974034658232
Train mean error at (after) epoch 8000: 0.00577493508664558
Test error at (after) epoch 8000: 0.007170216868925324
----------
Error at epoch 9000 is 2.0933475119102054
Train mean error at (after) epoch 9000: 0.005233368779775514
Test error at (after) epoch 9000: 0.006431750866610037
----------
Error at epoch 10000 is 1.9205332411686546
Train mean error at (after) epoch 10000: 0.004801333102921637
Test error at (after) epoch 10000: 0.005920022732006003
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.8453018867322072
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.23690301979669387
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.869197743167191
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.45227381298924674
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.7738822141108416
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.7563618156639446
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.45408315137149574
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.6681159926897217
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.7723241636324746
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6902254338949628
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.8392240565326997
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.8285654762767731
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.8117828462626684
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.8859158752640283
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.8497251771950054
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.7156685678500039
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.8204929846402117
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.6213672477503396
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.4740500786052212
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.6502719848251232
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.8121067679964382
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.7728304013937178
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.8497395616139605
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.8301897884220686
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.41087389112388006
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.833530720259418
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.662965773027164
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.48503678055865285
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.8620408653576264
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.8353793179706485
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.849678593540003
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.7006743657599114
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.6080233821838659
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.7643639066314614
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.8575109374229314
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.39036947769864644
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.8139098148744726
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.7352219205018197
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.7247979826981336
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.6412774432276306
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.8147197679340804
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.8320647937493609
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.8648692954265265
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.5898445226046591
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.8854506761083719
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.8367844769783562
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.3592771318492998
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.8121898412553195
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.7608678853653558
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.7438537554860157
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.44951521874465034
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.5572274085012716
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.7983864890119271
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.5175197716070511
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.6988070569829292
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.8398234722975052
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.7963043179781484
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.7309420942133507
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.766680048381056
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.818285510280308
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.3709265265818625
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.21400160332860974
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.374785166383849
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.8291570321312629
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.7514163780677422
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.868085379270233
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.8704044980277905
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.7505032426019844
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.8058977729477964
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.6508616247513787
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.8512686392694481
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.7726663782745544
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.8523603185523975
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.6448996555943309
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.8685885878726973
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.7811394278039868
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.06994503080522305
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.7055245855908568
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.8183482420261217
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.8267614517598808
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.7746436779805753
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.7974684017114676
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.3679116264621797
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.8153106374890089
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.7703314777452832
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.7411836457384564
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.8514666824041149
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.39482318330938065
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.8280945840038647
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.6362687764361513
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.2873983466743191
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.6994386930396378
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.763053649476904
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.3092483821703696
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.7818085188656437
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.6026069605087838
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.8424732684902824
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.8117542810904814
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.8564773288002152
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.46416909421807057
---------------------------------------------------------

Hidden units: 7
Epochs: 100
Learning rate: 0.5

Errors during training:
Error at epoch 1 is 104.3963894443871
Train mean error at (after) epoch 1: 0.26099097361096774
Test error at (after) epoch 1: 0.2640854630569322
----------
Error at epoch 10 is 23.19246830789894
Train mean error at (after) epoch 10: 0.057981170769747355
Test error at (after) epoch 10: 0.05926793781887936
----------
Error at epoch 20 is 8.945320819831577
Train mean error at (after) epoch 20: 0.022363302049578943
Test error at (after) epoch 20: 0.021877871287522166
----------
Error at epoch 30 is 6.1879699092304605
Train mean error at (after) epoch 30: 0.015469924773076151
Test error at (after) epoch 30: 0.01432265466824124
----------
Error at epoch 40 is 5.399547387585665
Train mean error at (after) epoch 40: 0.013498868468964163
Test error at (after) epoch 40: 0.012044040608285289
----------
Error at epoch 50 is 5.122725770217097
Train mean error at (after) epoch 50: 0.012806814425542743
Test error at (after) epoch 50: 0.011189181046370076
----------
Error at epoch 60 is 5.012857394518797
Train mean error at (after) epoch 60: 0.012532143486296991
Test error at (after) epoch 60: 0.010821563182983114
----------
Error at epoch 70 is 4.965070219342799
Train mean error at (after) epoch 70: 0.012412675548356997
Test error at (after) epoch 70: 0.010646730041472567
----------
Error at epoch 80 is 4.9422640998136655
Train mean error at (after) epoch 80: 0.012355660249534163
Test error at (after) epoch 80: 0.01055621532367619
----------
Error at epoch 90 is 4.930027154298176
Train mean error at (after) epoch 90: 0.012325067885745439
Test error at (after) epoch 90: 0.01050556290451681
----------
Error at epoch 100 is 4.922414765630643
Train mean error at (after) epoch 100: 0.012306036914076607
Test error at (after) epoch 100: 0.010475051548887261
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.9102661220079139
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.2261326742842144
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.8849429582227081
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.37981169473767745
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.9586307599240981
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.9546473581307934
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.37971726149528495
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.6560781582135626
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.9518259530510356
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6425843958160867
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.9133508811061839
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.8313928696066785
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.8187926230200285
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.9301823995296705
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.8608795090762057
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.7081098572149932
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.8487097462531682
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.5437155897775026
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.4067013520948663
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.7172693835518514
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.8249227990532878
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.7389753704719474
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.8909441390539266
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.8076457708387895
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.37613677229196363
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.8664180105380765
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.5960046902949488
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.45471992773895703
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.9152020480147579
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.7908010675923052
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.8587919866030591
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.6432307681398834
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.6706028417109107
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.9424487614979478
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.9078209921627287
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.43554184982802124
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.9454979884673517
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.9274460300775489
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.6847759739076383
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.9693564590806572
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.8919453010347487
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.9312011610743915
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.8780954100841063
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.5174888695695299
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.9040165022926642
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.8583903917638848
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.3250860752635615
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.8871590832344192
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.714527166720657
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.7253909679766172
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.9723174952929405
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.49323446866135645
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.788253799818696
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.9748159780048257
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.9460765317933858
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.8964141543882947
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.943705367746085
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.9633938858709221
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.7418486880343914
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.8352259134721741
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.3181592004370624
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.2213853069997905
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.3213739280288536
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.8500684202166868
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.9610983983033806
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.8817056697708336
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.8518314581364849
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.7230608960861665
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.959134970267741
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.579495140716134
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.8879275109374116
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.9124850517840759
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.8749844829693738
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.5893246814450305
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.9126079736634393
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.9416281298550235
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.07091500615520309
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.651461155183202
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.7969913485549559
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.7843857200570508
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.9626599679551028
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.7852342430669788
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.3280838893238059
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.8161312552645388
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.7076163517861126
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.6995585731732443
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.8667614596468534
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.4120589392920193
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.9030948882122934
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.5585103376478077
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.2097934296625774
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.6685708827393358
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.939119086781628
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.28161763013791513
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.790946222817039
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.4960126935753068
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.8467540387924316
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.8016433508735418
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.8582599234348488
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.3715822512181066
---------------------------------------------------------

Hidden units: 7
Epochs: 1000
Learning rate: 0.5

Errors during training:
Error at epoch 1 is 133.57849337851496
Train mean error at (after) epoch 1: 0.33394623344628743
Test error at (after) epoch 1: 0.3214165785609874
----------
Error at epoch 100 is 5.0083062612436775
Train mean error at (after) epoch 100: 0.012520765653109193
Test error at (after) epoch 100: 0.010510987845872117
----------
Error at epoch 200 is 4.9963950260791306
Train mean error at (after) epoch 200: 0.012490987565197826
Test error at (after) epoch 200: 0.01046483293337273
----------
Error at epoch 300 is 4.987971250053553
Train mean error at (after) epoch 300: 0.012469928125133882
Test error at (after) epoch 300: 0.01045792389484357
----------
Error at epoch 400 is 4.979436216085427
Train mean error at (after) epoch 400: 0.012448590540213567
Test error at (after) epoch 400: 0.010452811923158162
----------
Error at epoch 500 is 4.970687859669159
Train mean error at (after) epoch 500: 0.012426719649172897
Test error at (after) epoch 500: 0.010448739076044149
----------
Error at epoch 600 is 4.961635816437429
Train mean error at (after) epoch 600: 0.012404089541093573
Test error at (after) epoch 600: 0.01044557913334883
----------
Error at epoch 700 is 4.95219574753994
Train mean error at (after) epoch 700: 0.01238048936884985
Test error at (after) epoch 700: 0.010443250564715765
----------
Error at epoch 800 is 4.94228599645031
Train mean error at (after) epoch 800: 0.012355714991125775
Test error at (after) epoch 800: 0.010441696145241462
----------
Error at epoch 900 is 4.93182498964731
Train mean error at (after) epoch 900: 0.012329562474118275
Test error at (after) epoch 900: 0.010440876823354817
----------
Error at epoch 1000 is 4.920729126028451
Train mean error at (after) epoch 1000: 0.012301822815071129
Test error at (after) epoch 1000: 0.01044076733169429
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.9020191250947494
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.23695109497464326
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.8845657091701755
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.377791368680191
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.9631520898849122
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.955955881317756
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.3569864334000186
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.6601411462486915
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.9583367039517086
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6256204401145623
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.9171174855826288
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.8186659350920943
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.8343525767294835
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.9616402089175545
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.8574349693465906
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.6994948665028987
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.8606465424454309
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.5585432285338516
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.41611622670137155
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.7194567929941172
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.8101720816633098
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.7388963665221171
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.8835880721712167
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.8359430215784172
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.3674179400148004
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.8744145973331903
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.5924532061521125
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.4817936375275538
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.9111591937637352
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.8646619783107885
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.8617810140598392
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.6073053979467807
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.6476362604049789
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.9485921204103018
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.9070060367508517
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.4311599590811665
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.952996466834374
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.9404271573279217
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.692099122256428
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.970277574908271
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.8964629811189706
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.9322646769570733
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.8766766499167814
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.5106321561729925
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.9367771535906957
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.837569753526399
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.31220047284529245
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.8762618423037448
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.7180750711515376
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.72991145667883
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.9764714252923639
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.5010651926817646
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.7937469266831348
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.9818106215121656
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.9507575385531293
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.8988294436901856
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.950409537826443
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.968724123044916
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.7284976950072609
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.8417091615744998
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.34071123975061496
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.21330968052574845
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.32846962235073374
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.845872012991351
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.9672911046699896
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.8915819224705698
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.8499293620253218
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.720779895477463
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.9692064810176789
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.6305383675970977
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.8634570604925674
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.9290536382226341
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.8752354853404469
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.5964182935658224
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.9037106459459497
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.9351771795683368
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.08474591786311085
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.6409241365187037
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.79941354693574
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.8689071972865168
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.9611466287209138
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.7783613934247631
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.35289328825234817
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.8237851196490181
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.6903838420658512
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.6902788591134139
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.863190117519938
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.4051166813485568
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.9147206724352687
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.5446409340948091
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.22604920612007084
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.7117638114401098
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.9334567362569044
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.2793201847932308
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.7978619964194067
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.511974753317804
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.848728775280328
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.7984481336734434
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.8563478284618913
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.3641621981297949
---------------------------------------------------------

Hidden units: 7
Epochs: 3000
Learning rate: 0.5

Errors during training:
Error at epoch 1 is 59.56896827932496
Train mean error at (after) epoch 1: 0.1489224206983124
Test error at (after) epoch 1: 0.1481119324720394
----------
Error at epoch 300 is 4.93562662820812
Train mean error at (after) epoch 300: 0.0123390665705203
Test error at (after) epoch 300: 0.010446385011643229
----------
Error at epoch 600 is 4.8882797225210854
Train mean error at (after) epoch 600: 0.012220699306302714
Test error at (after) epoch 600: 0.010456719647610078
----------
Error at epoch 900 is 4.8245864539895456
Train mean error at (after) epoch 900: 0.012061466134973864
Test error at (after) epoch 900: 0.010473149889046936
----------
Error at epoch 1200 is 4.737778509907876
Train mean error at (after) epoch 1200: 0.011844446274769691
Test error at (after) epoch 1200: 0.010491626599874782
----------
Error at epoch 1500 is 4.623124625119616
Train mean error at (after) epoch 1500: 0.011557811562799041
Test error at (after) epoch 1500: 0.010500844680882202
----------
Error at epoch 1800 is 4.484062186003385
Train mean error at (after) epoch 1800: 0.011210155465008462
Test error at (after) epoch 1800: 0.010482274600951408
----------
Error at epoch 2100 is 4.328230245485897
Train mean error at (after) epoch 2100: 0.010820575613714743
Test error at (after) epoch 2100: 0.01042343705015885
----------
Error at epoch 2400 is 4.147060870167933
Train mean error at (after) epoch 2400: 0.010367652175419833
Test error at (after) epoch 2400: 0.010330853739482337
----------
Error at epoch 2700 is 3.908188504303238
Train mean error at (after) epoch 2700: 0.009770471260758095
Test error at (after) epoch 2700: 0.010204904816707104
----------
Error at epoch 3000 is 3.591348314074822
Train mean error at (after) epoch 3000: 0.008978370785187055
Test error at (after) epoch 3000: 0.009968804587776879
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.7760853626725498
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.2678072185619066
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.8578148285064597
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.4153718151953057
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.8547962121836205
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.7840251918356627
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.4435530372748067
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.6751381819311789
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.8642333720913977
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6461490942916756
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.8625732711304377
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.7900835915451281
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.7935791009988331
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.8244113553002387
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.8232251293998837
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.7196717299995742
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.8089234000164334
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.554799032286579
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.455269770739613
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.7259898159867224
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.784947612825113
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.7173436356225666
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.809943307629016
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.7707446724851154
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.3921766359501622
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.8271431437542494
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.6234998480508291
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.5295570849479163
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.8322185391588175
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.7734184813654079
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.8047637980978999
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.6333520503724033
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.6520467625661793
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.7871965519328374
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.8359733499505725
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.47619219408645846
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.8595203313978315
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.7537534299526879
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.6934565373997031
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.745915100003348
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.8224282240896862
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.8082428512279216
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.8357512532273187
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.5373765122245029
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.8342876628720769
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.7690314892047366
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.3359308188461716
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.7599634380481507
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.7467427174663605
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.7464970983492422
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.7594476139933763
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.5438071013273656
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.7899805706344538
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.8067330856269996
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.7493755357835788
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.8571472412065374
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.8370858348785075
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.817632676477506
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.7180573250705817
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.7690992855818414
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.3851031217067849
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.2404480783103332
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.3690911715662742
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.7862615634986844
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.8791320708725614
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.8502588599796191
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.8500044712025601
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.7359734705717357
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.8497666991191712
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.6377352263823615
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.7435801153670594
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.761415939134462
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.8394260946848167
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.6349004297992337
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.8212581061588473
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.7537805809036692
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.1453239917042077
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.661003938572826
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.8021179034337813
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.7658989532702949
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.758808661301549
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.7580620530613352
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.4068879378878121
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.7597394222930729
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.7383544744538008
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.6982780879557885
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.8226095797139962
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.4526583458995767
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.8180716703958879
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.6031357255361492
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.2979853535758173
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.7153642912029795
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.7396537262143766
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.3121578835185278
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.7719222029154936
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.5621466897105396
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.8004554277095194
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.7851019683004314
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.8193360286580018
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.40371306428023135
---------------------------------------------------------

Hidden units: 7
Epochs: 10000
Learning rate: 0.5

Errors during training:
Error at epoch 1 is 86.445603538793
Train mean error at (after) epoch 1: 0.21611400884698248
Test error at (after) epoch 1: 0.23192004831570084
----------
Error at epoch 1000 is 4.870395582800159
Train mean error at (after) epoch 1000: 0.012175988957000396
Test error at (after) epoch 1000: 0.010441549696763164
----------
Error at epoch 2000 is 4.610560681254876
Train mean error at (after) epoch 2000: 0.01152640170313719
Test error at (after) epoch 2000: 0.010466590400659462
----------
Error at epoch 3000 is 3.980267317437117
Train mean error at (after) epoch 3000: 0.009950668293592792
Test error at (after) epoch 3000: 0.010156839910101278
----------
Error at epoch 4000 is 2.751365944718444
Train mean error at (after) epoch 4000: 0.00687841486179611
Test error at (after) epoch 4000: 0.008058212565455728
----------
Error at epoch 5000 is 1.942189002304765
Train mean error at (after) epoch 5000: 0.004855472505761913
Test error at (after) epoch 5000: 0.005920370014809804
----------
Error at epoch 6000 is 0.9261600240424297
Train mean error at (after) epoch 6000: 0.002315400060106074
Test error at (after) epoch 6000: 0.002914070277670887
----------
Error at epoch 7000 is 0.4753074899447644
Train mean error at (after) epoch 7000: 0.001188268724861911
Test error at (after) epoch 7000: 0.001479686486917002
----------
Error at epoch 8000 is 0.3718838813142702
Train mean error at (after) epoch 8000: 0.0009297097032856755
Test error at (after) epoch 8000: 0.001120546235424005
----------
Error at epoch 9000 is 0.6882225819722987
Train mean error at (after) epoch 9000: 0.0017205564549307468
Test error at (after) epoch 9000: 0.0015590911841853173
----------
Error at epoch 10000 is 0.6637502185353182
Train mean error at (after) epoch 10000: 0.0016593755463382956
Test error at (after) epoch 10000: 0.0015193587624523833
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.8929838933170247
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.29313749346428747
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.9309722295349271
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.23425384740813984
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.798527163271877
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.7771190017361673
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.33209760462687293
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.6844581646748058
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.8537717723680651
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6445756636446602
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.9436476016791119
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.8927049676849064
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.8880698091178972
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.91282613758006
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.8969889414558901
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.7502619242923756
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.9087798538422165
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.5081343998054841
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.29022184443550336
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.7422136389250303
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.8839218626619092
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.761202897277851
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.9087723483345155
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.8922144761603555
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.3332638995807834
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.9130923924616459
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.5152180140181198
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.3966731502103119
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.9121899690557738
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.9330872148557295
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.8892248531510278
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.7063402026072547
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.6645047588311598
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.8559082882960873
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.9353317454433336
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.28581978697018107
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.877075643480074
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.838224354975566
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.7495060822760876
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.4487340812997222
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.9202404431816175
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.9206516073987968
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.9099724552592022
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.4335240792875171
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.94063270271794
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.9183417180185175
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.27976761714868426
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.9109933373219746
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.7971593422594214
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.774940529052874
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.26886028733736667
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.47382100734503807
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.8420976260948703
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.2795108135376079
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.7664081558225307
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.9524136621238405
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.87745167644174
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.7312763844464681
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.7638921001212572
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.9157354741523345
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.19749427598426858
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.11845052050139855
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.20558884686011428
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.9145187857266908
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.7954588856786559
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.9188354186656994
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.9117548671304756
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.7512438961789611
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.7559502846145268
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.615878634022724
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.9252832591993839
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.8777776798673015
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.919782214768588
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.6054726664654972
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.9199305152370266
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.8669856601686722
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: -0.044649425117659784
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.6165942327644761
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.8537537300102817
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.9376276969759048
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.6577920942291913
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.8099445103575357
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.3528600619328918
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.8688347062503929
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.7139921809263968
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.7824564413605388
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.8980473810568885
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.31792983570895855
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.9230894841949651
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.4663704353664758
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.2063553473642034
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.7844508952082424
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.8607759297034451
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.16420384943451577
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.8628913669950092
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.5285565113217443
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.8938382965025222
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.8373758759068789
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.890656038088353
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.3169362077684776
---------------------------------------------------------

Hidden units: 7
Epochs: 100
Learning rate: 1

Errors during training:
Error at epoch 1 is 107.94410208495314
Train mean error at (after) epoch 1: 0.2698602552123829
Test error at (after) epoch 1: 0.2079038357548253
----------
Error at epoch 10 is 9.433064036035546
Train mean error at (after) epoch 10: 0.023582660090088865
Test error at (after) epoch 10: 0.02129173618080157
----------
Error at epoch 20 is 5.5559731535731025
Train mean error at (after) epoch 20: 0.013889932883932756
Test error at (after) epoch 20: 0.01220087246526767
----------
Error at epoch 30 is 5.186029961534304
Train mean error at (after) epoch 30: 0.01296507490383576
Test error at (after) epoch 30: 0.011079475236785971
----------
Error at epoch 40 is 5.124168733757682
Train mean error at (after) epoch 40: 0.012810421834394205
Test error at (after) epoch 40: 0.010826634762123463
----------
Error at epoch 50 is 5.1093163448395185
Train mean error at (after) epoch 50: 0.012773290862098797
Test error at (after) epoch 50: 0.010743279484499239
----------
Error at epoch 60 is 5.10319952882035
Train mean error at (after) epoch 60: 0.012757998822050875
Test error at (after) epoch 60: 0.010705416077339264
----------
Error at epoch 70 is 5.098958307868288
Train mean error at (after) epoch 70: 0.01274739576967072
Test error at (after) epoch 70: 0.010683055572638284
----------
Error at epoch 80 is 5.095248564315529
Train mean error at (after) epoch 80: 0.012738121410788823
Test error at (after) epoch 80: 0.010667074769227465
----------
Error at epoch 90 is 5.091788075611118
Train mean error at (after) epoch 90: 0.012729470189027793
Test error at (after) epoch 90: 0.010654162729460024
----------
Error at epoch 100 is 5.088507977160158
Train mean error at (after) epoch 100: 0.012721269942900395
Test error at (after) epoch 100: 0.01064295927982309
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.9246705576697379
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.21536347344057835
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.9083650361902719
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.383831504892916
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.9720535629455667
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.9740686729213164
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.37265763607628316
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.6367976201599206
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.9679737460101974
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6547201698676741
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.9361307415287742
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.8559889728732606
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.8334087736674174
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.9642985161037918
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.8799617052424668
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.7142657024464789
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.8696460513926568
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.5800344247438297
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.41992292108944307
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.6396294473169172
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.8243606754253814
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.7573305267519119
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.9092480678327435
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.8382835588077988
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.3531608279688264
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.8825514175796791
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.5982681023618313
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.4656667568171379
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.9319539742801534
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.8490066610451963
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.8758488930695836
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.6543915187303743
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.5516435330817696
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.9672150761307259
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.9129180071545171
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.38149662727947586
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.9652596100529429
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.9623794854635881
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.6882734593620685
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.9858548807535713
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.9102733851052949
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.9470554502323258
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.8902271313896425
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.531613255529739
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.9353133590964168
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.8736083496418161
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.30551719528820503
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.9141707330789679
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.7175229209563881
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.7382975644112427
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.9896988351306776
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.5118668937266547
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.8027529888092756
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.9901733854761967
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.9723664979211648
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.9214703198119554
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.9643639677345058
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.9799014621890791
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.758471955939081
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.8601894913749972
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.34639888604405117
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.19937842217623747
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.3056205659873196
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.8706856016754352
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.9758938388311257
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.8809539788912685
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.864796199417052
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.7309521743332362
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.978421852913967
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.6076927571977303
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.8929937039522174
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.9509652515532073
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.8687362665819109
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.605481212343031
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.916440145739651
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.9633779307412873
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.0626656663382845
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.6671970592278907
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.8117564417624604
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.8573729138183158
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.9785302378582535
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.802066742180238
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.3348630539548377
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.8451014456449788
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.6741133927363555
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.7132440105110703
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.8855298242905468
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.3533502954580531
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.9309570505692315
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.5388084895933358
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.10292722459309013
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.6630867427557121
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.9624816220854024
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.26763141855141676
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.8075335362258912
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.5211453978054815
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.863767639701545
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.8160731258813891
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.8711399722344946
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.36912225676786886
---------------------------------------------------------

Hidden units: 7
Epochs: 1000
Learning rate: 1

Errors during training:
Error at epoch 1 is 77.46267406727635
Train mean error at (after) epoch 1: 0.19365668516819087
Test error at (after) epoch 1: 0.1265133695352667
----------
Error at epoch 100 is 4.980787675171044
Train mean error at (after) epoch 100: 0.01245196918792761
Test error at (after) epoch 100: 0.010482655100100486
----------
Error at epoch 200 is 4.95787281446278
Train mean error at (after) epoch 200: 0.01239468203615695
Test error at (after) epoch 200: 0.01047510572103543
----------
Error at epoch 300 is 4.932822687852288
Train mean error at (after) epoch 300: 0.012332056719630719
Test error at (after) epoch 300: 0.01047049884245767
----------
Error at epoch 400 is 4.904628636590297
Train mean error at (after) epoch 400: 0.012261571591475742
Test error at (after) epoch 400: 0.010467743568970587
----------
Error at epoch 500 is 4.872361585530972
Train mean error at (after) epoch 500: 0.01218090396382743
Test error at (after) epoch 500: 0.010466439685853993
----------
Error at epoch 600 is 4.835188095405721
Train mean error at (after) epoch 600: 0.012087970238514302
Test error at (after) epoch 600: 0.010466185019945362
----------
Error at epoch 700 is 4.79249228522134
Train mean error at (after) epoch 700: 0.01198123071305335
Test error at (after) epoch 700: 0.01046639061651631
----------
Error at epoch 800 is 4.744078567103629
Train mean error at (after) epoch 800: 0.011860196417759072
Test error at (after) epoch 800: 0.010466000706707453
----------
Error at epoch 900 is 4.690349961147403
Train mean error at (after) epoch 900: 0.011725874902868506
Test error at (after) epoch 900: 0.010463089255031543
----------
Error at epoch 1000 is 4.632232518475538
Train mean error at (after) epoch 1000: 0.011580581296188846
Test error at (after) epoch 1000: 0.010454433112372047
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.8670766094992065
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.2476404574876975
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.8453143170517609
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.3863401593717762
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.946448248098921
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.9110888454015973
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.3817128869746978
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.6616122879548461
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.939514321151313
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6240256241424397
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.907178404711813
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.7927268026661244
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.8264700217163352
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.9451416722309924
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.818219761323124
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.700294253589557
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.8528003374703621
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.5589113601491957
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.41423304195987487
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.7104493450830579
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.7831972546723044
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.7180580167041454
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.845966104612067
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.8018467238233979
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.3652358728212044
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.8641792762680671
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.5796929755172379
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.48977780083435485
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.8686207924904439
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.8323804273759828
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.8233832507464917
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.6106917654620128
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.6534093817942644
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.9034129418266378
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.8998565338869104
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.4419230328018074
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.9353737900664318
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.8990652800808768
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.6922003639592669
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.9253566166324508
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.8887149712938994
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.9229404928802402
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.8298493485792797
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.5118408727446837
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.9217826811666437
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.8110632923189842
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.3118412272515975
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.8423511172115373
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.7204462346730303
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.7252426710060188
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.9278656085277346
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.4985325677776696
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.7614705559191565
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.9624984300851324
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.9082617702626165
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.8932663983777618
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.9350258646585681
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.9524987648912162
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.7119516371567477
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.8433523222724166
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.35296044000438814
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.21741416856371878
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.3371911805044
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.815059916750472
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.9468577210599144
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.8791181201973444
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.8136113618203921
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.6909146301323733
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.949597786311488
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.618555883335911
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.8348504013132813
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.8887706455367002
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.8353664773367409
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.5932332485535037
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.8660882129238806
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.8945005391443752
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.07869095056100778
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.6329288895692151
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.7609836352325
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.8385129028295976
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.9181427929694987
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.751108806957834
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.3512314323748367
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.7930293465879953
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.6835865463628229
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.698627801731709
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.8231729358911195
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.42282795267307144
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.904256833519787
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.5530883083039947
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.22220156787804762
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.7116306303044355
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.8932621591908565
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.2819014421677229
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.7952670974981203
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.5178405542849772
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.8076870513080993
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.7640004327508373
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.8158062417247138
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.3632688047036605
---------------------------------------------------------

Hidden units: 7
Epochs: 3000
Learning rate: 1

Errors during training:
Error at epoch 1 is 120.01033769605569
Train mean error at (after) epoch 1: 0.30002584424013923
Test error at (after) epoch 1: 0.24780791342072309
----------
Error at epoch 300 is 5.007347061733163
Train mean error at (after) epoch 300: 0.012518367654332906
Test error at (after) epoch 300: 0.01047300493297768
----------
Error at epoch 600 is 4.9562158594661705
Train mean error at (after) epoch 600: 0.012390539648665426
Test error at (after) epoch 600: 0.010475356625017602
----------
Error at epoch 900 is 4.884985462294198
Train mean error at (after) epoch 900: 0.012212463655735495
Test error at (after) epoch 900: 0.010496307215439118
----------
Error at epoch 1200 is 4.774169234912705
Train mean error at (after) epoch 1200: 0.011935423087281762
Test error at (after) epoch 1200: 0.010537786400652173
----------
Error at epoch 1500 is 4.606038694160366
Train mean error at (after) epoch 1500: 0.011515096735400916
Test error at (after) epoch 1500: 0.01058458510184513
----------
Error at epoch 1800 is 4.369458810144048
Train mean error at (after) epoch 1800: 0.010923647025360118
Test error at (after) epoch 1800: 0.01054138585585024
----------
Error at epoch 2100 is 3.964844718602092
Train mean error at (after) epoch 2100: 0.00991211179650523
Test error at (after) epoch 2100: 0.01017123486618456
----------
Error at epoch 2400 is 3.3074280508078058
Train mean error at (after) epoch 2400: 0.008268570127019514
Test error at (after) epoch 2400: 0.009211464571336873
----------
Error at epoch 2700 is 2.7202246289868897
Train mean error at (after) epoch 2700: 0.006800561572467224
Test error at (after) epoch 2700: 0.008095646157601284
----------
Error at epoch 3000 is 7.801447891564345
Train mean error at (after) epoch 3000: 0.019503619728910862
Test error at (after) epoch 3000: 0.01732632167050434
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.906563634860414
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.06335238760862844
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.9364586366123934
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.7060732711757416
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.799569393914496
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.8749404281452249
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.708925173930284
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.5132675588285757
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.7958151031373218
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.8551264306572677
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.8591098980641084
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.9205181374428137
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.7080558617029382
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.829050032447165
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.9255907581794148
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.5893947845491789
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.7387937797711702
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.8045490826051198
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.7029271667749593
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.8869845433911289
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.93050370217643
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.8817698133991901
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.9222394372792395
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.9154647105071705
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.14416480928463235
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.7530306365624228
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.8283457322196087
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.7551987300590111
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.9255902941626877
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.9184005954679025
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.9161735888169359
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.8547199180768722
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.8672626295020097
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.9033551831926446
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.862480146510809
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.7450648842098474
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.8065278818619208
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.8608100664958782
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.5998470908620863
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.77178605417428
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.7809653388955441
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.8590794067504914
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.9361651395186288
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.7858614542908324
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.8256678513939232
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.9220903094465681
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.035694626195622976
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.9032680773706571
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.6231954442885388
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.6197041497158271
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.7391402246279173
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.31259794569045246
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.9090240780826865
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.6828103907659496
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.8426620786408726
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.8686324330104185
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.8141903553479215
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.8104720824745453
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.8875787981646805
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.7730048952383043
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.6504141359467397
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.5267479300768543
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.6425912708865407
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.934270290846366
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.7908680703480763
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.761739077043592
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.9333000657121192
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.896077671639219
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.7554226467041962
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.8281286415007707
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.9155038027982357
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.8802827130184583
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.9380376782950047
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.4502073412216128
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.9356656537826307
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.8890555769195877
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.44946304054578273
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.8548959507285886
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.9166727904264074
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.9138438541775371
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.8303251954074544
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.901539910768106
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.2104102249324424
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.9100473536730961
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.8847743544957456
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.6311252849746336
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.9256886824454789
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.7321821714108996
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.7928184328837797
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.8143804971256499
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.10244157801806707
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.6539626440669953
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.8783584908382718
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.5963202274531333
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.6842755025255316
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.42294566159298774
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.9285785224921044
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.9124508895047522
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.9251332099310082
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.18255746389854732
---------------------------------------------------------

Hidden units: 7
Epochs: 10000
Learning rate: 1

Errors during training:
Error at epoch 1 is 79.51623299788368
Train mean error at (after) epoch 1: 0.19879058249470918
Test error at (after) epoch 1: 0.1596634888449536
----------
Error at epoch 1000 is 4.910995851837076
Train mean error at (after) epoch 1000: 0.012277489629592691
Test error at (after) epoch 1000: 0.010461037734051534
----------
Error at epoch 2000 is 4.088800564049592
Train mean error at (after) epoch 2000: 0.01022200141012398
Test error at (after) epoch 2000: 0.010331433528706033
----------
Error at epoch 3000 is 2.0672412146211614
Train mean error at (after) epoch 3000: 0.005168103036552903
Test error at (after) epoch 3000: 0.006811053342511538
----------
Error at epoch 4000 is 1.6988997672934794
Train mean error at (after) epoch 4000: 0.004247249418233698
Test error at (after) epoch 4000: 0.0043424981297604335
----------
Error at epoch 5000 is 1.1022610389398895
Train mean error at (after) epoch 5000: 0.002755652597349724
Test error at (after) epoch 5000: 0.0026631231567436024
----------
Error at epoch 6000 is 0.4635789207600645
Train mean error at (after) epoch 6000: 0.0011589473019001614
Test error at (after) epoch 6000: 0.0011286407893038523
----------
Error at epoch 7000 is 0.27075480947247815
Train mean error at (after) epoch 7000: 0.0006768870236811954
Test error at (after) epoch 7000: 0.0006537210034519955
----------
Error at epoch 8000 is 0.204641111036531
Train mean error at (after) epoch 8000: 0.0005116027775913275
Test error at (after) epoch 8000: 0.0005094824548224165
----------
Error at epoch 9000 is 0.1643165177287432
Train mean error at (after) epoch 9000: 0.000410791294321858
Test error at (after) epoch 9000: 0.00042761234221194483
----------
Error at epoch 10000 is 0.13716150142823802
Train mean error at (after) epoch 10000: 0.00034290375357059506
Test error at (after) epoch 10000: 0.0003700840329410965
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.9398328118926472
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.21877030146922624
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.9381387424533872
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.3119643117749842
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.8635171668753849
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.8314488287028793
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.31845817510395413
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.6621730326006342
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.9115606981581033
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6280333822785488
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.948587374869443
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.8936343437691927
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.8897931543250119
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.8893300729259404
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.9162616713056897
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.7183297075765659
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.917710432633025
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.5237392593100574
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.3497584805096428
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.7447922220794516
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.8736044540128132
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.7751522038388002
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.9361043147952198
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.8970749132814995
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.33560734846380263
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.9285949184563745
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.553892373210619
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.42096566997379364
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.9417177471226588
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.9280793682030374
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.9218963598252544
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.6390900808961893
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.6673047656544204
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.8950347633114965
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.9512325917230139
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.34987015116597436
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.9192345746599353
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.9060370283951836
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.7113318795932543
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.41812814875931237
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.9446384145922333
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.9411837566799939
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.9297818681986556
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.46763555449938826
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.9519650373035058
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.9212304833308619
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.28818569804641475
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.9380402245120271
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.7519233812870113
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.7493619227309708
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.20715420362961573
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.46493031742380725
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.8406027699670582
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.13348225065782815
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.8498355830760771
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.9472984620863619
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.920779980382593
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.727088692207631
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.7659765327273889
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.9102782776506476
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.268663200444931
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.14734188668157167
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.26053199244764214
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.9122645891852974
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.8503627855312523
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.9413037580280547
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.9163274147205731
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.7362755327948289
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.7909595438214422
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.6161988837015726
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.9395454181867924
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.9310873744029591
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.9271013172481786
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.5779447470648246
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.9402852146619793
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.8936473700456737
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.04196134490695799
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.6321295090106211
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.8485316222230759
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.9324853337999143
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.6953660591496744
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.8244725421377782
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.3264248019068703
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.8838383458743982
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.7158859220220023
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.7168137333861445
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.9209800778716317
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.35327382406185304
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.9487743081503076
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.5106361565835494
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.19025042284973595
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.7229409817095539
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.8943746465585545
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.21655912080811937
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.8491895701242862
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.47432271101449575
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.9066775283978127
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.8462153212944281
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.9153976351800912
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.31611796588414576
=========================================================

---------------------------------------------------------

Hidden units: 10
Epochs: 100
Learning rate: 0.05

Errors during training:
Error at epoch 1 is 111.13874885648686
Train mean error at (after) epoch 1: 0.2778468721412171
Test error at (after) epoch 1: 0.31699036663749086
----------
Error at epoch 10 is 89.87100731406647
Train mean error at (after) epoch 10: 0.2246775182851662
Test error at (after) epoch 10: 0.2592808937221463
----------
Error at epoch 20 is 73.59427802748615
Train mean error at (after) epoch 20: 0.1839856950687154
Test error at (after) epoch 20: 0.21475611314795595
----------
Error at epoch 30 is 61.60397204887069
Train mean error at (after) epoch 30: 0.15400993012217673
Test error at (after) epoch 30: 0.18148900160887732
----------
Error at epoch 40 is 52.17533742764672
Train mean error at (after) epoch 40: 0.1304383435691168
Test error at (after) epoch 40: 0.1548679881348827
----------
Error at epoch 50 is 44.498120676367435
Train mean error at (after) epoch 50: 0.11124530169091859
Test error at (after) epoch 50: 0.13277913204428418
----------
Error at epoch 60 is 38.15390507001062
Train mean error at (after) epoch 60: 0.09538476267502656
Test error at (after) epoch 60: 0.11417798319000376
----------
Error at epoch 70 is 32.888451633260416
Train mean error at (after) epoch 70: 0.08222112908315105
Test error at (after) epoch 70: 0.0984601610967046
----------
Error at epoch 80 is 28.5181546101136
Train mean error at (after) epoch 80: 0.071295386525284
Test error at (after) epoch 80: 0.08519858280643142
----------
Error at epoch 90 is 24.894300567581837
Train mean error at (after) epoch 90: 0.06223575141895459
Test error at (after) epoch 90: 0.07404180254619812
----------
Error at epoch 100 is 21.890679224522923
Train mean error at (after) epoch 100: 0.05472669806130731
Test error at (after) epoch 100: 0.06467991966796859
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.6759041347599106
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.029449588986073597
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.45766559829384806
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.2955526502108799
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.7546544123611653
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.7716536124424771
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.13120560293928035
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.24019957426259955
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.6913436301765103
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.36386189107711026
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.5862275772774909
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.48791035464394766
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.45135708182289436
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.6698182321058412
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.46961581214035947
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.29995861279334934
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.5256459509609251
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.44401975796324744
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: -0.004495645949589443
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.38550265191614874
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.4314069590554895
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.44777815661671966
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.5913445274696921
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.4742090673553555
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.07975016441142521
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.5095875832188338
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.23326784756682378
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.2113801854022134
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.6133881176566104
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.4816134131741715
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.5241821366911414
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.3724534717484762
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.4339900965444737
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.7271524118285969
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.6218484340822921
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.2848778839888924
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.6987573000167698
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.7290763489935143
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.28648220077506514
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.8399554986614787
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.6092461248655193
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.6958268905268495
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.4468976005355154
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.3985929942203747
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.5867056695952616
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.547017292152818
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.022717305248874164
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.6281470611671539
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.1494983737026546
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.27398165428557025
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.8470611910915613
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.06037708069754921
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.33188853198445845
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.8571981144222921
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.7706177780654662
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.5455968301282463
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.7253168220363071
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.8017992809750605
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.4317969840331073
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.5804225485332514
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.11848472235552136
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: -0.018850939518481078
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.13357666073402658
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.5108735562583433
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.7097272098866895
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.45932966068542314
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.32957332386791727
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.21085378021578216
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.7605331459253917
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.40523930896356036
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.5952819100729586
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.6972016017112539
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.40429832367531193
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.08645623452657028
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.6034015951206396
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.7224017337411038
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.30963574528873467
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.3429330319053823
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.25530785150788865
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.5088953381067085
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.8091238124835707
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.4375004250734292
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.241807243555997
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.51353463168617
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.17933807824250264
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.4372146056349209
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.488779380410848
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.2812032667795733
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.6474476510446673
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.15182053551294744
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.2147408711818779
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.22422032885889315
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.7209749163124408
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: -0.05245469837427142
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.45912982148712544
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.20649000361615585
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.4620097639481543
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.3800337764896491
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.4629993617269189
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.2899837260975632
---------------------------------------------------------

Hidden units: 10
Epochs: 1000
Learning rate: 0.05

Errors during training:
Error at epoch 1 is 134.60903090999977
Train mean error at (after) epoch 1: 0.33652257727499946
Test error at (after) epoch 1: 0.39062358248067974
----------
Error at epoch 100 is 18.61375648832891
Train mean error at (after) epoch 100: 0.04653439122082228
Test error at (after) epoch 100: 0.05196653641412623
----------
Error at epoch 200 is 8.348919599400066
Train mean error at (after) epoch 200: 0.020872298998500165
Test error at (after) epoch 200: 0.020852649766772053
----------
Error at epoch 300 is 6.2020335508711
Train mean error at (after) epoch 300: 0.01550508387717775
Test error at (after) epoch 300: 0.014215442627163448
----------
Error at epoch 400 is 5.5474985235934335
Train mean error at (after) epoch 400: 0.013868746308983583
Test error at (after) epoch 400: 0.012156801992827905
----------
Error at epoch 500 is 5.308072944903988
Train mean error at (after) epoch 500: 0.01327018236225997
Test error at (after) epoch 500: 0.011379345484038952
----------
Error at epoch 600 is 5.210759382809724
Train mean error at (after) epoch 600: 0.01302689845702431
Test error at (after) epoch 600: 0.01104719052580186
----------
Error at epoch 700 is 5.1682356555935876
Train mean error at (after) epoch 700: 0.012920589138983968
Test error at (after) epoch 700: 0.01089198294863053
----------
Error at epoch 800 is 5.1484401489625
Train mean error at (after) epoch 800: 0.01287110037240625
Test error at (after) epoch 800: 0.010813821689050485
----------
Error at epoch 900 is 5.1385330039234
Train mean error at (after) epoch 900: 0.0128463325098085
Test error at (after) epoch 900: 0.010771610068434025
----------
Error at epoch 1000 is 5.133073265816459
Train mean error at (after) epoch 1000: 0.012832683164541147
Test error at (after) epoch 1000: 0.01074717190395453
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.931059600596409
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.22018239252178703
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.9036182834204042
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.37312361713448755
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.9742453007496833
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.9760368499904207
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.2987380288965476
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.6583616051116737
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.9687343839600477
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6253984316156295
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.9130872208505982
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.8220337689993857
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.8484360712069182
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.9718655737251233
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.8800361721550796
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.6896726853895181
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.8697473984966461
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.5751564466528821
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.4227516340538989
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.6773053973995562
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.7674323543065141
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.7486295740695984
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.9097170443479206
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.8574928781379301
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.3831771756578106
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.8829353845297461
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.6066038563150163
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.4797459439596419
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.9354226696639599
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.8813971089102719
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.8761993360513112
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.5866035304883992
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.6522083314610374
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.9688091113804258
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.9205836176241953
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.3856671277512411
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.965295182136139
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.9664407914799554
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.7054476578183349
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.9881547328308395
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.9120277718257965
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.9491540800083209
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.8965864471707564
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.5015907845097701
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.947971506314915
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.8510455168440546
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.3142590460672198
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.8953444479410904
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.7255303785362489
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.7416879950695962
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.9917253125147989
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.5079501466360083
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.8067322526345533
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.9921934007036219
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.9752170074173871
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.884577437377029
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.9659686529281412
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.9824558990380315
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.7448796665093518
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.8616628716293456
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.33732614453766313
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.21433424039389318
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.33594121633399976
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.8375930289370633
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.9788238767748229
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.8907651159066492
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.8638021706809393
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.7030146810448875
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.9803782534734042
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.6244718574240167
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.8855577945782699
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.9562733089670462
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.8542344950540705
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.6042365498179039
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.89880545782165
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.9563856927153288
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.040961341301891996
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.6454100215129548
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.812365235102168
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.8874484164692823
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.9816172742971422
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.8026726561451009
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.3592429646771548
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.8510959082155123
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.6690463748498044
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.6774749661332522
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.8857457555773883
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.4001580861017016
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.932353261618008
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.5147387304526359
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.21080031414766268
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.7155601306388351
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.9554140907618957
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.28034967384935344
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.802075191469035
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.5098741897385516
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.8678590325238054
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.817221388390082
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.8750849421777985
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.3837487395115038
---------------------------------------------------------

Hidden units: 10
Epochs: 3000
Learning rate: 0.05

Errors during training:
Error at epoch 1 is 123.71701495407173
Train mean error at (after) epoch 1: 0.3092925373851793
Test error at (after) epoch 1: 0.3508757261667828
----------
Error at epoch 300 is 6.255162763957776
Train mean error at (after) epoch 300: 0.015637906909894438
Test error at (after) epoch 300: 0.014388386493441173
----------
Error at epoch 600 is 5.182561903183578
Train mean error at (after) epoch 600: 0.012956404757958945
Test error at (after) epoch 600: 0.01097671264264472
----------
Error at epoch 900 is 5.10595943459531
Train mean error at (after) epoch 900: 0.012764898586488277
Test error at (after) epoch 900: 0.010690015958695231
----------
Error at epoch 1200 is 5.094866256035381
Train mean error at (after) epoch 1200: 0.012737165640088453
Test error at (after) epoch 1200: 0.010640966650081289
----------
Error at epoch 1500 is 5.090087308296033
Train mean error at (after) epoch 1500: 0.012725218270740081
Test error at (after) epoch 1500: 0.010625173727681651
----------
Error at epoch 1800 is 5.086085940198702
Train mean error at (after) epoch 1800: 0.012715214850496754
Test error at (after) epoch 1800: 0.010616548197924203
----------
Error at epoch 2100 is 5.082276996854283
Train mean error at (after) epoch 2100: 0.012705692492135707
Test error at (after) epoch 2100: 0.010610096911166957
----------
Error at epoch 2400 is 5.0785872348834165
Train mean error at (after) epoch 2400: 0.012696468087208541
Test error at (after) epoch 2400: 0.010604515957778332
----------
Error at epoch 2700 is 5.074998703556652
Train mean error at (after) epoch 2700: 0.01268749675889163
Test error at (after) epoch 2700: 0.010599396375049822
----------
Error at epoch 3000 is 5.0715001094616925
Train mean error at (after) epoch 3000: 0.012678750273654232
Test error at (after) epoch 3000: 0.010594593803298651
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.9246014726564892
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.24341702747128607
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.8908537404701917
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.375891719261033
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.9728994937615448
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.9733994812968435
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.3532447878080843
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.676049346250012
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.9676766605264959
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6454485864358138
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.9295098573069763
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.8474266017381651
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.8484152543972918
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.9615711491803982
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.8748263324161284
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.7171877107054386
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.8751950690479793
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.5369994677325829
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.39757627851019645
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.7311619318343113
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.8313338225823597
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.7611697823312192
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.9072913355659118
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.8465851024187563
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.3848436039557959
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.8899195841887916
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.6108123627826172
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.4896996602006565
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.9304661219769035
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.843193023592474
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.8875739049044696
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.6178906679513525
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.6679697030845524
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.9655843589126742
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.917919151946927
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.43824656438911447
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.9641685700270165
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.95523807504248
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.7058432557353336
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.9849785312499905
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.9090442339532449
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.9387719684723446
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.8924528282183837
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.5004515664252567
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.9380617429894449
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.8624525929511807
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.32860328826036495
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.8927765287724286
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.6939231825714497
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.7339859994949401
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.9892779821786664
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.4954539227259256
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.7940886048839412
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.989630083384603
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.9683632527187929
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.9122696052763225
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.9620603051332332
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.9783292006205904
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.7524218152013792
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.8339711227946276
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.33883451724886443
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.2256932253827768
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.3259360836550525
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.8652948779735017
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.9741457831730425
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.9020744548003433
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.8424602141361127
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.7243730993858181
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.9789908163961785
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.6127418616324954
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.8759710134588319
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.9425978659275596
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.878995446663024
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.5856353527602597
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.9239758278032298
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.952725199669478
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.10635086101183354
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.6621277212037078
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.7909184542872713
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.8365571802801559
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.9778866111423086
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.8015249751720672
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.3271647232674119
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.843500402540964
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.6866858831630518
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.6825456186323303
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.8829080321540469
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.4150433635157494
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.9246926289260491
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.5527191878970993
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.23703610396211622
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.6994496487163867
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.948454748123579
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.28177104331872166
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.8135078151551866
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.5183462445178871
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.8709988129688954
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.8133157202786903
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.8772138750585969
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.36325714367526346
---------------------------------------------------------

Hidden units: 10
Epochs: 10000
Learning rate: 0.05

Errors during training:
Error at epoch 1 is 124.69904763428538
Train mean error at (after) epoch 1: 0.31174761908571347
Test error at (after) epoch 1: 0.35720174686056916
----------
Error at epoch 1000 is 5.058221039293676
Train mean error at (after) epoch 1000: 0.01264555259823419
Test error at (after) epoch 1000: 0.010569583351876893
----------
Error at epoch 2000 is 5.05350835851086
Train mean error at (after) epoch 2000: 0.01263377089627715
Test error at (after) epoch 2000: 0.010536440945266094
----------
Error at epoch 3000 is 5.050493092578154
Train mean error at (after) epoch 3000: 0.012626232731445386
Test error at (after) epoch 3000: 0.010534806843141816
----------
Error at epoch 4000 is 5.047349242092908
Train mean error at (after) epoch 4000: 0.01261837310523227
Test error at (after) epoch 4000: 0.010533743962058023
----------
Error at epoch 5000 is 5.044061116992257
Train mean error at (after) epoch 5000: 0.012610152792480643
Test error at (after) epoch 5000: 0.010532748309221478
----------
Error at epoch 6000 is 5.040612377139951
Train mean error at (after) epoch 6000: 0.012601530942849876
Test error at (after) epoch 6000: 0.010531805553909028
----------
Error at epoch 7000 is 5.036985177609809
Train mean error at (after) epoch 7000: 0.012592462944024522
Test error at (after) epoch 7000: 0.010530911244581396
----------
Error at epoch 8000 is 5.0331599178258175
Train mean error at (after) epoch 8000: 0.012582899794564544
Test error at (after) epoch 8000: 0.010530061491988983
----------
Error at epoch 9000 is 5.029114955385357
Train mean error at (after) epoch 9000: 0.012572787388463394
Test error at (after) epoch 9000: 0.010529252730287854
----------
Error at epoch 10000 is 5.024826277274222
Train mean error at (after) epoch 10000: 0.012562065693185555
Test error at (after) epoch 10000: 0.010528481658325683
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.9233011407765004
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.251621767643621
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.8825931108626147
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.37736183163378967
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.9714454493601109
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.9704168007829274
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.3922398256342589
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.6482487460360521
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.9645863349108943
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.646687679591878
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.924199445600842
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.8382432781503115
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.8350175343118678
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.9711672581676766
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.859292777127337
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.7024467889761302
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.8666673822952103
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.5488802714605581
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.40460618670290244
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.711483649438818
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.8196204468475335
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.7521762766887848
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.9003393797968278
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.8462898781824915
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.36340777872372104
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.8755570829373938
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.5867652009710422
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.4852011279246864
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.9230717182421456
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.8774559764567904
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.8685973292441556
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.6439246493750076
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.6441485310488945
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.9634609294632711
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.9200270225754628
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.4035658937476412
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.9591173294125798
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.9601294164168754
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.6957405671737472
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.9835262082664067
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.9069171852253817
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.948474026049549
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.8716675086465834
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.5163818334132175
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.9447422349269904
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.8710483073398266
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.30983642312689275
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.9076935242817313
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.6977054085738186
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.7234175383193155
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.9858844354486301
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.4945886954900053
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.790227445255507
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.9893441068341937
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.9692678985282873
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.9083651462280832
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.9614734590586412
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.9796140803152164
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.745619744408711
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.8516916489084019
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.3393531541046182
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.20625280261113768
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.3248713004423328
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.8633926743733991
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.970643263264672
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.8796609823598086
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.8322149771205836
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.7130876476367366
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.9750084684071382
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.6294797883171686
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.8986843210694807
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.9491505944135381
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.8746775334764738
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.5870707576408589
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.9164722143548975
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.960873383938763
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.04723195645095335
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.650689186669718
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.7859261160513208
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.8839789982494015
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.9768989029736778
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.7867348148236399
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.34019848093741334
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.8387752225714611
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.6669808215825043
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.6996698609721864
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.8660524122295229
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.4100980004307565
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.9275937346619724
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.5376738599962579
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.19877489177153798
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.6931715641310876
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.9602428913852656
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.27143343294507577
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.8028411024427183
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.5116124840049411
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.8535176107836381
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.7975580022988049
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.8540348341424743
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.3485255329829646
---------------------------------------------------------

Hidden units: 10
Epochs: 100
Learning rate: 0.1

Errors during training:
Error at epoch 1 is 105.86935317667913
Train mean error at (after) epoch 1: 0.26467338294169784
Test error at (after) epoch 1: 0.2981037300571985
----------
Error at epoch 10 is 61.34542201853565
Train mean error at (after) epoch 10: 0.15336355504633914
Test error at (after) epoch 10: 0.17615036903286085
----------
Error at epoch 20 is 37.83398235729877
Train mean error at (after) epoch 20: 0.09458495589324693
Test error at (after) epoch 20: 0.1098754604359316
----------
Error at epoch 30 is 25.725084740887564
Train mean error at (after) epoch 30: 0.06431271185221892
Test error at (after) epoch 30: 0.07436716788835081
----------
Error at epoch 40 is 18.86381823085545
Train mean error at (after) epoch 40: 0.047159545577138626
Test error at (after) epoch 40: 0.0536421076345971
----------
Error at epoch 50 is 14.685400767552228
Train mean error at (after) epoch 50: 0.03671350191888057
Test error at (after) epoch 50: 0.04080486831364203
----------
Error at epoch 60 is 11.997012392532667
Train mean error at (after) epoch 60: 0.02999253098133167
Test error at (after) epoch 60: 0.03247626788051861
----------
Error at epoch 70 is 10.191355424531414
Train mean error at (after) epoch 70: 0.025478388561328537
Test error at (after) epoch 70: 0.026861320725735854
----------
Error at epoch 80 is 8.93609020617905
Train mean error at (after) epoch 80: 0.022340225515447627
Test error at (after) epoch 80: 0.022950766059888692
----------
Error at epoch 90 is 8.038557430829902
Train mean error at (after) epoch 90: 0.020096393577074757
Test error at (after) epoch 90: 0.020150770749542017
----------
Error at epoch 100 is 7.381690523749921
Train mean error at (after) epoch 100: 0.0184542263093748
Test error at (after) epoch 100: 0.01809801315820123
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.8520793199084238
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.09276350540538965
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.7672224665041636
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.2894612849759565
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.9266650327605382
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.9317409495271621
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.32944368038965255
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.48774086901242864
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.9076203217887329
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.4971013034535221
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.8152500916199851
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.6956944997034366
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.6999836462143143
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.9167072750002926
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.7404560262234926
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.5610194824002812
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.7360882346974302
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.4505483138036289
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.28483253153191784
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.5894546459544137
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.6937459972939298
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.6043743432675089
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.8029256580978282
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.7269223004138444
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.25305481135916275
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.7507778149730016
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.4531426617080675
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.36491868725497184
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.8394754281110771
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.7544380472999695
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.7518208177187703
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.46183563453767107
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.5652657877210593
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.9155602538502405
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.830302761066807
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.35238931102547166
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.8950205920930521
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.9021552342382075
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.5512872972622835
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.9611224046558856
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.8145305773201027
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.8787801659446243
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.76058253214244
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.3872526224840003
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.8637694017027295
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.7421883011600969
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.19378976670062636
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.7945966130242187
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.5195888833473472
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.5686736192733189
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.9666413701844632
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.3572499540989916
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.648630704476354
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.9705977535310851
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.9256956249326949
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.7801013712359376
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.901278511347235
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.9453638100229589
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.604334755655778
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.7371795827668974
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.24359198446034708
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.14131123212470934
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.2460288417124691
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.755972562093492
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.9207153152345381
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.7610778000656476
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.6971476275250912
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.5625362582980935
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.9316395553480296
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.4721682376885014
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.7936388128009636
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.8805077389390646
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.7477062664290604
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.42968130520639625
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.8300851451925516
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.8967292034660251
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.0530676617197948
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.5026427770990974
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.6389623064533168
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.7589215766267431
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.9469079788964117
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.6558081031544932
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.26300760672229323
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.7245369546454191
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.5039923357303687
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.535189033802072
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.75094467748889
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.33738888987428767
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.8350405329905367
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.37696638057884163
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.1993571226114944
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.5349486702259947
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.8942007673342538
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.1786039122198638
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.652826676164496
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.3687029833066601
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.7388621682629047
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.6637489367973352
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.7362506443068211
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.29998675014178694
---------------------------------------------------------

Hidden units: 10
Epochs: 1000
Learning rate: 0.1

Errors during training:
Error at epoch 1 is 146.0266763811424
Train mean error at (after) epoch 1: 0.36506669095285604
Test error at (after) epoch 1: 0.4158671191595913
----------
Error at epoch 100 is 9.716034967518421
Train mean error at (after) epoch 100: 0.024290087418796055
Test error at (after) epoch 100: 0.02479833930003689
----------
Error at epoch 200 is 5.605494488158617
Train mean error at (after) epoch 200: 0.014013736220396542
Test error at (after) epoch 200: 0.012450086711384551
----------
Error at epoch 300 is 5.171969511713774
Train mean error at (after) epoch 300: 0.012929923779284435
Test error at (after) epoch 300: 0.011011482654707314
----------
Error at epoch 400 is 5.098360893238276
Train mean error at (after) epoch 400: 0.01274590223309569
Test error at (after) epoch 400: 0.01071682267476154
----------
Error at epoch 500 is 5.082521214973295
Train mean error at (after) epoch 500: 0.012706303037433237
Test error at (after) epoch 500: 0.010634682948132794
----------
Error at epoch 600 is 5.077780845687142
Train mean error at (after) epoch 600: 0.012694452114217856
Test error at (after) epoch 600: 0.010605471005692708
----------
Error at epoch 700 is 5.075351199238156
Train mean error at (after) epoch 700: 0.01268837799809539
Test error at (after) epoch 700: 0.010592642236186578
----------
Error at epoch 800 is 5.073431140876569
Train mean error at (after) epoch 800: 0.012683577852191423
Test error at (after) epoch 800: 0.010585840384319317
----------
Error at epoch 900 is 5.071636651649132
Train mean error at (after) epoch 900: 0.01267909162912283
Test error at (after) epoch 900: 0.010581551511686344
----------
Error at epoch 1000 is 5.069883620728685
Train mean error at (after) epoch 1000: 0.012674709051821713
Test error at (after) epoch 1000: 0.010578405994679884
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.9295787902960114
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.23637070279093417
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.9003421256520384
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.37913203441470855
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.9718389978502334
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.9730797655416126
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.40261659403217676
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.6443510083508701
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.9649082764908969
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.65437482297461
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.9334773773570062
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.8546849089971461
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.833605303176995
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.9567870161585146
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.8751865596001132
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.7089306369364435
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.8685756549737575
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.5538381820906931
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.4138464112839015
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.6856650049255203
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.821405609041197
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.7567440390130006
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.9095011825117582
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.8328290770909063
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.36954421641917984
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.8818502561311788
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.6017024646043858
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.4656780017577237
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.9301910088841523
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.829697617393547
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.8738923250494791
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.6447779159045499
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.6448593439582426
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.9642317306713829
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.920413242599393
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.4256096710987287
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.9628031913547644
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.9582088795078464
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.6973840632797054
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.9858813047917181
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.9106970920590242
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.9504472359821575
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.886083562943881
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.5208262792202885
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.9289215330525012
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.8776168951421025
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.3192940877006
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.913491763686733
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.7203670326180998
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.7285622268556995
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.9878937460658136
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.48825153621031214
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.7897313887409814
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.9896417436042619
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.9711332473761813
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.9189726376102146
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.9637635838525248
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.9805250312000917
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.7590356152924513
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.8570713889829401
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.33515736598889395
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.22289736674662847
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.31676617973890936
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.867940550748333
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.9721763797065652
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.8809121824064131
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.8587797140452264
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.7114376972860171
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.9759072964523156
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.6020377173678916
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.9018827368000721
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.9451948036177361
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.8581177156596109
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.585916037130618
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.9182104959365576
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.964777367793691
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.0659538697524301
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.6665936965808777
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.7973030257481646
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.8315896619257498
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.9796207453710288
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.8005154077731564
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.32689232811967023
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.8411747708883107
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.6732413823124691
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.7086330037893492
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.8814935807658494
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.39367983693490444
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.9286724228976705
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.5452453996033549
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.20206761249840685
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.6562899035316395
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.9636044134023328
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.2912273510209107
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.8084340555581009
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.5148328279956164
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.8614815892056836
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.8093546872162257
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.86884597552301
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.36646987323015134
---------------------------------------------------------

Hidden units: 10
Epochs: 3000
Learning rate: 0.1

Errors during training:
Error at epoch 1 is 147.38720215957923
Train mean error at (after) epoch 1: 0.3684680053989481
Test error at (after) epoch 1: 0.4130687346796351
----------
Error at epoch 300 is 5.075571320043069
Train mean error at (after) epoch 300: 0.012688928300107673
Test error at (after) epoch 300: 0.01078437346201272
----------
Error at epoch 600 is 4.997918636559827
Train mean error at (after) epoch 600: 0.012494796591399569
Test error at (after) epoch 600: 0.010435096222898281
----------
Error at epoch 900 is 4.989966461867436
Train mean error at (after) epoch 900: 0.01247491615466859
Test error at (after) epoch 900: 0.010417866240574891
----------
Error at epoch 1200 is 4.982287230826667
Train mean error at (after) epoch 1200: 0.012455718077066667
Test error at (after) epoch 1200: 0.010414646045978557
----------
Error at epoch 1500 is 4.974303062634239
Train mean error at (after) epoch 1500: 0.012435757656585597
Test error at (after) epoch 1500: 0.010412860637196463
----------
Error at epoch 1800 is 4.965970219224973
Train mean error at (after) epoch 1800: 0.012414925548062433
Test error at (after) epoch 1800: 0.010411411168593152
----------
Error at epoch 2100 is 4.957247301795759
Train mean error at (after) epoch 2100: 0.012393118254489396
Test error at (after) epoch 2100: 0.010410184233745304
----------
Error at epoch 2400 is 4.948090202674377
Train mean error at (after) epoch 2400: 0.012370225506685944
Test error at (after) epoch 2400: 0.010409162808136188
----------
Error at epoch 2700 is 4.938451675957386
Train mean error at (after) epoch 2700: 0.012346129189893465
Test error at (after) epoch 2700: 0.010408340483492862
----------
Error at epoch 3000 is 4.928280924555931
Train mean error at (after) epoch 3000: 0.012320702311389828
Test error at (after) epoch 3000: 0.01040771287048585
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.9001118075704956
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.2266627444867253
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.8950434330162248
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.3761826249433404
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.9608517298042203
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.9535510566619662
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.36904093369821594
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.6536025934925488
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.9541767635719419
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6331861518942338
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.9239954942516784
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.8319419949447789
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.826394331247118
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.9461542457714357
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.8616970673767531
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.7026363277186808
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.8579790202089925
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.5518002332868106
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.4163169535308147
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.7110932058845086
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.8142753045210063
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.7406158703701513
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.8865071047561158
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.8210568821306362
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.3609027639557482
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.8731858653467638
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.5887305047016758
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.47723420853496235
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.9134868408345079
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.8427697715974836
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.8628817343231602
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.6295053243954348
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.6342795586997355
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.9425807888568732
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.9031840996560128
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.4260267093463677
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.9528083197515659
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.9353519951318425
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.6814307975484767
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.9699911790981656
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.8933048533631606
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.9273408706822736
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.8731184751324146
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.5093081066583464
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.9199857413452741
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.8450791655480637
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.31502954825122387
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.8785314681629931
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.7224972505453691
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.7293186807548928
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.9764387496197976
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.5027912149516758
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.7952128943489165
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.9796427102751173
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.9480539280976655
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.908281430282815
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.9484217681985196
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.9663893472566835
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.7326779559610657
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.8347450241035059
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.33590803900224897
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.1954147194969059
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.3234174609476659
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.8440660111916599
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.9658358420789426
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.887873941461305
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.8605660558573867
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.7204747622988941
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.9673432737657144
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.6259517080266621
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.8634170831993802
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.9229278373992831
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.8767495692510042
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.5975504579160278
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.9039986808567193
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.9359777014296327
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.08092269598208883
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.6463450597131258
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.8008307571628382
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.8506496138909787
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.96040304328317
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.7795149806832029
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.36446546603434066
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.8181292510839111
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.7018309859278862
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.6892484033518915
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.8667728132104405
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.4077763949050023
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.9108156743243018
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.5586589627962041
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.21889477153990328
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.6786679148761836
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.9327402957053555
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.2761402250749137
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.7971306142216267
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.5085347759788488
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.8401567540329942
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.7984158512369761
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.8573988768761368
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.35844330010735864
---------------------------------------------------------

Hidden units: 10
Epochs: 10000
Learning rate: 0.1

Errors during training:
Error at epoch 1 is 122.37731361056291
Train mean error at (after) epoch 1: 0.30594328402640725
Test error at (after) epoch 1: 0.3437757915488244
----------
Error at epoch 1000 is 5.069232650363626
Train mean error at (after) epoch 1000: 0.012673081625909063
Test error at (after) epoch 1000: 0.01050529879474244
----------
Error at epoch 2000 is 5.061543489450362
Train mean error at (after) epoch 2000: 0.012653858723625906
Test error at (after) epoch 2000: 0.01050086436023587
----------
Error at epoch 3000 is 5.053894207453174
Train mean error at (after) epoch 3000: 0.012634735518632936
Test error at (after) epoch 3000: 0.010497741229847292
----------
Error at epoch 4000 is 5.0460157315086205
Train mean error at (after) epoch 4000: 0.012615039328771551
Test error at (after) epoch 4000: 0.010495097886117678
----------
Error at epoch 5000 is 5.037667215399538
Train mean error at (after) epoch 5000: 0.012594168038498846
Test error at (after) epoch 5000: 0.010492807750317254
----------
Error at epoch 6000 is 5.028608522442572
Train mean error at (after) epoch 6000: 0.01257152130610643
Test error at (after) epoch 6000: 0.010490782295348595
----------
Error at epoch 7000 is 5.018579302118405
Train mean error at (after) epoch 7000: 0.012546448255296012
Test error at (after) epoch 7000: 0.01048895814583093
----------
Error at epoch 8000 is 5.0072787958663385
Train mean error at (after) epoch 8000: 0.012518196989665846
Test error at (after) epoch 8000: 0.010487289611629544
----------
Error at epoch 9000 is 4.994343270613494
Train mean error at (after) epoch 9000: 0.012485858176533735
Test error at (after) epoch 9000: 0.010485744457118744
----------
Error at epoch 10000 is 4.979318262020972
Train mean error at (after) epoch 10000: 0.01244829565505243
Test error at (after) epoch 10000: 0.01048430199932634
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.9079302187857968
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.2257137427920443
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.8911218853761957
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.37505639304968885
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.9654920224114102
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.9590883967974976
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.3897298281085513
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.6551619242019739
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.9594052756930475
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6503838123473208
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.9305248243886055
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.8421434399824105
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.8349016695211298
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.964778565860923
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.8612692471885522
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.6990953383847288
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.8651854702802445
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.5570215684792077
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.4096054593936691
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.6886877947710991
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.798576276845435
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.745094256934203
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.8942535613265318
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.8339163752738452
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.36600066514349944
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.8786222392268099
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.5891742948923195
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.48395646658195035
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.9164111053471511
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.8601014184505302
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.8670343555746052
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.648868828235049
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.6417162197662817
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.95095170340345
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.917638789182558
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.4064917494320383
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.9592869827972641
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.9472308862087923
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.6948905096879354
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.9760810874696646
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.8994543916812788
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.9435304432895839
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.872269303692182
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.5130230706591569
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.9390533106803568
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.8676379393933646
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.3121625785616917
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.8972418312805058
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.7108713642188458
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.7250161793976436
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.9816585677979482
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.49566582266871656
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.7842233860131881
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.9857553094795003
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.9582335855047769
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.9163151734238164
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.9578092438558773
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.9750728898066144
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.7439980039827719
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.849323639444165
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.3442973654724433
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.21105714673944084
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.32362500879444833
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.8426680202554382
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.9688779745041936
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.8889542368084862
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.8482083191868521
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.7047832566389942
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.9741049121563164
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.6130366733211164
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.8913888807485306
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.9348909454033515
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.8551005436034654
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.5890343688972054
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.8955895871097902
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.9526702577638236
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.06812288617405537
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.65396074249132
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.78675274567008
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.8639229728093162
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.9674423899967288
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.7827258589082166
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.342493540752452
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.8246039871475642
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.6822001536507742
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.6996410984681926
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.8674433210177726
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.41690920764580897
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.9219711795063545
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.5484350478699576
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.21439837122965916
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.7029982589912275
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.9506473898120354
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.2759308052874322
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.8022201140948124
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.518049650210407
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.8456309031967384
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.7935597211675185
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.8579377327936875
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.3589288371172211
---------------------------------------------------------

Hidden units: 10
Epochs: 100
Learning rate: 0.3

Errors during training:
Error at epoch 1 is 105.9054665518157
Train mean error at (after) epoch 1: 0.26476366637953924
Test error at (after) epoch 1: 0.2679771924051003
----------
Error at epoch 10 is 32.66988394283678
Train mean error at (after) epoch 10: 0.08167470985709196
Test error at (after) epoch 10: 0.08693992080089796
----------
Error at epoch 20 is 14.699560516010399
Train mean error at (after) epoch 20: 0.036748901290026
Test error at (after) epoch 20: 0.03763457111912008
----------
Error at epoch 30 is 9.0132550297598
Train mean error at (after) epoch 30: 0.022533137574399502
Test error at (after) epoch 30: 0.022138773003890888
----------
Error at epoch 40 is 6.90593746782397
Train mean error at (after) epoch 40: 0.017264843669559927
Test error at (after) epoch 40: 0.016260189926940737
----------
Error at epoch 50 is 5.999891169743021
Train mean error at (after) epoch 50: 0.014999727924357553
Test error at (after) epoch 50: 0.013635859412123091
----------
Error at epoch 60 is 5.56514489934476
Train mean error at (after) epoch 60: 0.013912862248361899
Test error at (after) epoch 60: 0.012323608687195276
----------
Error at epoch 70 is 5.340561078334478
Train mean error at (after) epoch 70: 0.013351402695836194
Test error at (after) epoch 70: 0.01161424259408489
----------
Error at epoch 80 is 5.21855181102878
Train mean error at (after) epoch 80: 0.01304637952757195
Test error at (after) epoch 80: 0.011208328304973737
----------
Error at epoch 90 is 5.149847541831023
Train mean error at (after) epoch 90: 0.012874618854577557
Test error at (after) epoch 90: 0.010965527703573806
----------
Error at epoch 100 is 5.110108766990487
Train mean error at (after) epoch 100: 0.012775271917476218
Test error at (after) epoch 100: 0.010814900045769483
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.91237615992745
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.19540375487622236
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.8839824279388365
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.3663311501017446
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.9629767429647437
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.9669745727148739
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.37091782451045996
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.6141655101918874
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.9572224753490154
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6220522497954522
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.9108130009119992
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.8216163913740173
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.8129320900483321
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.9617442135488257
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.8540334573450247
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.6768495887746981
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.8478437753315994
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.5525889421824102
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.39371199910263505
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.6542933768933977
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.7934690888251188
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.7317471543188933
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.889643556000108
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.8263363049565976
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.33621520036132824
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.8587477542529486
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.5692542473144487
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.46392223977593305
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.9153357794884713
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.8527436066906766
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.8542503420537235
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.607369772279015
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.5954277668833107
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.9597506144890403
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.8981999609910033
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.3710702425681039
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.9518829251305323
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.9568228826999335
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.6661816672800245
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.9807904143425846
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.8931419902317547
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.9357603658915535
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.8668198117409966
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.5060463040248173
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.9292703573771401
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.848372403565569
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.29186360225972485
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.8943511509708196
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.6926209774262225
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.7034746150304415
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.9848970488246536
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.47360813380701705
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.7765237310888689
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.9861711398408602
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.9663238761158274
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.890698112287337
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.9532986624941211
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.9731167632968558
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.7274499621725392
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.8413590532977925
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.3296255760223467
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.18713081480014815
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.29738835475899406
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.8484167011381156
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.9656675559784178
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.8611456722115122
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.840382534652072
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.6924786265222692
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.9694721066830309
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.6029463781107475
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.8774551688751638
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.9448861827371705
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.849013745349011
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.5665376165043748
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.8992925054759795
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.9522385805409276
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.061465172125369914
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.6324431818194172
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.7811388846536519
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.8647202581850346
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.9720763004034771
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.773509944872498
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.3320373135676293
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.8263135034833816
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.6614663773881363
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.6777556286256953
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.8603237953155629
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.38150129730258275
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.9168937459676113
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.518503037238727
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.17571250187910772
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.6407521846980295
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.9521149646270605
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.2597635519498698
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.7808368249032913
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.4931577896805905
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.8410693177907309
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.7866314956844833
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.8466586555976826
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.342923140235878
---------------------------------------------------------

Hidden units: 10
Epochs: 1000
Learning rate: 0.3

Errors during training:
Error at epoch 1 is 85.05412775984227
Train mean error at (after) epoch 1: 0.21263531939960567
Test error at (after) epoch 1: 0.2189539546357192
----------
Error at epoch 100 is 5.111003731581277
Train mean error at (after) epoch 100: 0.012777509328953192
Test error at (after) epoch 100: 0.010820804485861018
----------
Error at epoch 200 is 5.0494474853614495
Train mean error at (after) epoch 200: 0.012623618713403624
Test error at (after) epoch 200: 0.010552653820408722
----------
Error at epoch 300 is 5.044939594312851
Train mean error at (after) epoch 300: 0.012612348985782127
Test error at (after) epoch 300: 0.01053804124914643
----------
Error at epoch 400 is 5.040930579044649
Train mean error at (after) epoch 400: 0.012602326447611622
Test error at (after) epoch 400: 0.010534566597622953
----------
Error at epoch 500 is 5.036904494273046
Train mean error at (after) epoch 500: 0.012592261235682616
Test error at (after) epoch 500: 0.010532298536261545
----------
Error at epoch 600 is 5.032841041965941
Train mean error at (after) epoch 600: 0.012582102604914854
Test error at (after) epoch 600: 0.010530324277667025
----------
Error at epoch 700 is 5.028725254492787
Train mean error at (after) epoch 700: 0.012571813136231968
Test error at (after) epoch 700: 0.010528534596174017
----------
Error at epoch 800 is 5.024542480224921
Train mean error at (after) epoch 800: 0.012561356200562302
Test error at (after) epoch 800: 0.010526903698147502
----------
Error at epoch 900 is 5.020278153038119
Train mean error at (after) epoch 900: 0.012550695382595298
Test error at (after) epoch 900: 0.010525415943660996
----------
Error at epoch 1000 is 5.0159176112463655
Train mean error at (after) epoch 1000: 0.012539794028115914
Test error at (after) epoch 1000: 0.010524058070274359
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.9217527214670296
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.21288483527489827
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.8836405007313564
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.3793301150210116
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.9681983218209066
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.9678677431060775
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.35383074723443175
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.6608056980466968
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.9615602692194695
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.642333894272054
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.9210782142338559
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.8315337415106798
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.8428434483831846
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.9689993746991863
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.8628116300045923
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.6973627291326624
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.871258813343297
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.5653680171006331
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.4178357574476178
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.6905723584172097
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.8047155639285108
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.7543108075540423
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.8977864315728948
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.8496483727380516
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.3743398041358734
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.881270903741388
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.5974401293237553
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.48405538258042075
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.9198965488742978
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.8769550576262426
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.8722377299726602
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.6230887842646847
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.6411546207251873
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.9611514377773771
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.9172500299997672
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.4121733540238977
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.9595627575679143
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.9607430872027897
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.6977842315861501
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.9812321648817202
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.9064721278434316
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.9482077909131456
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.8788248710467023
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.5141672880446547
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.9437138898874196
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.8602427280053747
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.32080444659666896
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.9000226854111916
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.7132438281234614
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.7284530023020054
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.9847398170552683
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.5002332234747856
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.7883576975347839
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.9878080350566202
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.9688577060546985
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.9019242832837956
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.9610862777904757
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.9783216951469649
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.7452597405688137
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.8599715543798727
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.3427404481224608
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.2180707895915691
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.3266520733315497
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.8522465443456715
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.968961667490503
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.8889628006427452
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.8409437258499035
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.7130521918597567
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.9754395253023096
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.6330080386197946
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.8894919231695356
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.9502945204766792
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.861452906327264
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.5953375058754728
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.905751504527012
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.9548606885155742
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.05098035858072879
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.6525338056089142
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.7927756770598826
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.8835066248369327
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.9742370871260294
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.7897192578735125
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.34210109803562777
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.8416375033584907
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.6657185494333495
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.6967839282007512
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.8699300130212958
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.4066111273923932
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.9297558656076937
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.5310451067247056
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.21207652341226751
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.703091368442656
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.9546139550637293
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.2873941722529762
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.8082914433217946
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.5189354538960482
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.8569183579255039
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.8007061069685931
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.8616152542779889
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.36645371391829534
---------------------------------------------------------

Hidden units: 10
Epochs: 3000
Learning rate: 0.3

Errors during training:
Error at epoch 1 is 170.65929284683023
Train mean error at (after) epoch 1: 0.4266482321170756
Test error at (after) epoch 1: 0.4045174487085199
----------
Error at epoch 300 is 5.003247141859306
Train mean error at (after) epoch 300: 0.012508117854648265
Test error at (after) epoch 300: 0.010404176494348003
----------
Error at epoch 600 is 4.984526471655087
Train mean error at (after) epoch 600: 0.012461316179137719
Test error at (after) epoch 600: 0.010394380753050854
----------
Error at epoch 900 is 4.963634422902116
Train mean error at (after) epoch 900: 0.01240908605725529
Test error at (after) epoch 900: 0.010387603830940785
----------
Error at epoch 1200 is 4.939817005684577
Train mean error at (after) epoch 1200: 0.012349542514211442
Test error at (after) epoch 1200: 0.010382628246515126
----------
Error at epoch 1500 is 4.912191029542835
Train mean error at (after) epoch 1500: 0.012280477573857087
Test error at (after) epoch 1500: 0.010379574875285371
----------
Error at epoch 1800 is 4.879700584375942
Train mean error at (after) epoch 1800: 0.012199251460939855
Test error at (after) epoch 1800: 0.010378666943212805
----------
Error at epoch 2100 is 4.84109616933684
Train mean error at (after) epoch 2100: 0.0121027404233421
Test error at (after) epoch 2100: 0.010380135987644812
----------
Error at epoch 2400 is 4.794949230960938
Train mean error at (after) epoch 2400: 0.011987373077402346
Test error at (after) epoch 2400: 0.010384018305389743
----------
Error at epoch 2700 is 4.7397126844808755
Train mean error at (after) epoch 2700: 0.011849281711202189
Test error at (after) epoch 2700: 0.010389737636761532
----------
Error at epoch 3000 is 4.673777819520946
Train mean error at (after) epoch 3000: 0.011684444548802363
Test error at (after) epoch 3000: 0.010395350746910965
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.8561838682974247
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.2256810651923753
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.8639999774121349
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.3847875223412875
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.9387324601536486
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.91012642989416
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.39832162144688193
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.6560537497906399
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.937843882163582
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6324664092155521
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.9124256773132354
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.8083161654412157
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.8263105075381069
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.9458714371853736
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.8319760729481209
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.7007745971860732
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.8523682716814619
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.5549184539715937
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.42384033482463174
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.6754421916011185
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.7739228312804144
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.7239663599491261
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.8507540982089054
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.807730660324472
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.36674468428640117
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.8656221887884967
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.5867548815601633
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.4837112876408611
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.8731847265312535
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.8343128706970508
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.8357595832802044
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.6343378224214151
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.6297856518734585
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.9066559373452653
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.8919034881469178
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.42232774452057625
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.9390011981178302
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.9016136942164791
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.6963197240762462
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.9245518993388966
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.8804913500344712
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.9151694897566861
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.8469071334395418
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.5174717616193888
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.9227283531038143
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.8214587429564493
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.3115528012794351
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.8504988784181282
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.7226588298338648
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.7257125865539301
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.9443262905562335
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.500452266937512
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.7643048226982136
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.9598931148135986
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.9092426468106765
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.8989499431656388
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.9332055275392069
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.9462221723840191
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.7174086322995872
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.8354372580198474
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.350964628117655
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.21891711538446026
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.33528156570524104
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.8112416625002231
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.9485942969419355
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.8781076159757402
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.8333063626966081
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.6980812600610412
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.9546933642421725
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.6164071301987915
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.8373953919977336
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.8908161230709747
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.8239157549894656
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.5973098323155871
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.8520569434871438
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.8997633421851058
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.08606343169646555
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.6399611822460163
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.7761693518991428
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.8371709927937099
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.9116379590281015
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.7556093941218179
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.35180609707780913
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.7938843307772594
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.6754430114985817
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.7015578554857025
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.8371042891904207
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.42077841300059393
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.9010013002751807
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.5476887239526483
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.23835636481947736
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.7030993001721029
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.8970149057355241
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.2894732097953237
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.7945771772096913
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.5200704873639705
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.8184634729581114
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.7713627922592802
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.8311869583732732
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.36583955334257595
---------------------------------------------------------

Hidden units: 10
Epochs: 10000
Learning rate: 0.3

Errors during training:
Error at epoch 1 is 149.90118641668013
Train mean error at (after) epoch 1: 0.37475296604170033
Test error at (after) epoch 1: 0.34441208906372284
----------
Error at epoch 1000 is 4.977296813585818
Train mean error at (after) epoch 1000: 0.012443242033964545
Test error at (after) epoch 1000: 0.010505319709928424
----------
Error at epoch 2000 is 4.901479316948369
Train mean error at (after) epoch 2000: 0.012253698292370923
Test error at (after) epoch 2000: 0.01049202218876019
----------
Error at epoch 3000 is 4.757934057216852
Train mean error at (after) epoch 3000: 0.011894835143042131
Test error at (after) epoch 3000: 0.01047171397236373
----------
Error at epoch 4000 is 4.44468993316862
Train mean error at (after) epoch 4000: 0.01111172483292155
Test error at (after) epoch 4000: 0.010389882806076656
----------
Error at epoch 5000 is 3.578978384128101
Train mean error at (after) epoch 5000: 0.008947445960320252
Test error at (after) epoch 5000: 0.009730642560622248
----------
Error at epoch 6000 is 2.679367313494483
Train mean error at (after) epoch 6000: 0.0066984182837362075
Test error at (after) epoch 6000: 0.00812558537252862
----------
Error at epoch 7000 is 2.124180016507904
Train mean error at (after) epoch 7000: 0.00531045004126976
Test error at (after) epoch 7000: 0.006694446631339893
----------
Error at epoch 8000 is 1.5055199142396851
Train mean error at (after) epoch 8000: 0.003763799785599213
Test error at (after) epoch 8000: 0.004960552140653629
----------
Error at epoch 9000 is 0.9221334989810133
Train mean error at (after) epoch 9000: 0.002305333747452533
Test error at (after) epoch 9000: 0.003090369508382698
----------
Error at epoch 10000 is 0.5697661594581149
Train mean error at (after) epoch 10000: 0.0014244153986452874
Test error at (after) epoch 10000: 0.0018738602800409043
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.8847212629720786
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.3029693053214912
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.9295072712668585
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.33799479112501707
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.8051053896279593
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.7763413672647477
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.4351053557734912
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.6515066939059222
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.8280229048813421
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6563567513450136
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.9297769575189265
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.8847348606496298
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.8281721731566989
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.9106467235447152
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.882119175047951
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.6833774384627062
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.8465688800156863
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.5519983638680066
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.3492912147206438
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.7518988453781262
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.8749883007955357
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.7586895298576605
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.8976233715696457
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.887695395781246
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.323243568541568
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.860193666975554
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.5671966132219992
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.45420342685934445
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.9043554607595036
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.9326941278716824
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.8837739802338854
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.6779528519055211
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.6889361888909795
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.8457866849612461
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.9152552304651493
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.43523152020719597
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.8563529000069541
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.8182690053417118
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.7057377682385935
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.5122234898384062
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.8703525690343682
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.8887368816493687
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.8917887113419606
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.4894727345471995
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.9225683410431882
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.9020463650092599
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.23822858993643725
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.8862245154683241
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.7316155488789159
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.699173461243116
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.35894737815042027
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.4221921239323363
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.8157719690649877
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.3583163214956405
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.7567406491218265
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.938872928664297
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.8414209463475342
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.7421451871622222
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.7571707258904433
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.8512925912408168
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.296586833284962
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.20339107884526061
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.3157590193045914
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.8996928217437683
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.7927768708066072
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.8879879065156756
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.9062553817643585
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.7380663092551727
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.7610651774373822
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.6604019790308394
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.9082415890572666
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.8575688437177573
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.8995644247148542
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.529854381983897
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.9127894493267852
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.8691175361138698
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.051962070151113454
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.6441914093008074
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.8203148863949443
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.9313000217041747
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.7097575548115153
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.7957117990096396
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.3360870601974717
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.8522185553442648
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.7531317614843549
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.7154345972607996
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.884044689071441
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.38240559577883115
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.8644594559564096
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.5475549057152321
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.2648038827087704
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.7988398159914037
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.8525940756797061
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.22071297333034184
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.7928010933468534
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.5217114167535956
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.8771760570060372
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.8148407810574702
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.8807719065717551
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.3362695992098364
---------------------------------------------------------

Hidden units: 10
Epochs: 100
Learning rate: 0.5

Errors during training:
Error at epoch 1 is 130.78769383055695
Train mean error at (after) epoch 1: 0.3269692345763924
Test error at (after) epoch 1: 0.2705276802324543
----------
Error at epoch 10 is 16.685608640694625
Train mean error at (after) epoch 10: 0.04171402160173656
Test error at (after) epoch 10: 0.040601409154706364
----------
Error at epoch 20 is 7.59014139748209
Train mean error at (after) epoch 20: 0.018975353493705226
Test error at (after) epoch 20: 0.017942314314551063
----------
Error at epoch 30 is 5.834267594350807
Train mean error at (after) epoch 30: 0.014585668985877018
Test error at (after) epoch 30: 0.013174935936440453
----------
Error at epoch 40 is 5.319423199101559
Train mean error at (after) epoch 40: 0.013298557997753898
Test error at (after) epoch 40: 0.011667689231412141
----------
Error at epoch 50 is 5.135473417218145
Train mean error at (after) epoch 50: 0.012838683543045362
Test error at (after) epoch 50: 0.011084497740232875
----------
Error at epoch 60 is 5.062091359466632
Train mean error at (after) epoch 60: 0.01265522839866658
Test error at (after) epoch 60: 0.010829034585230966
----------
Error at epoch 70 is 5.0304851696794675
Train mean error at (after) epoch 70: 0.012576212924198669
Test error at (after) epoch 70: 0.010706530586377114
----------
Error at epoch 80 is 5.015846183921976
Train mean error at (after) epoch 80: 0.012539615459804941
Test error at (after) epoch 80: 0.010643247795197562
----------
Error at epoch 90 is 5.008413621484992
Train mean error at (after) epoch 90: 0.012521034053712481
Test error at (after) epoch 90: 0.010608351103625888
----------
Error at epoch 100 is 5.004129984090557
Train mean error at (after) epoch 100: 0.012510324960226393
Test error at (after) epoch 100: 0.010587946329502013
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.9050743437681215
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.2531521971397762
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.8815450509599384
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.3792005288060041
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.9589780213382295
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.9601387480524753
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.34259281495069693
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.6607072763185954
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.9534080490310711
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6352428397547126
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.9171009472226846
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.8375583471504984
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.836642385710332
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.9564601879007059
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.8599950674328224
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.6969178969983275
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.8640646141784448
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.554707807556529
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.4044784918771142
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.7208370477137482
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.8020363734482101
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.7550993695928583
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.892692903876426
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.8419845938238522
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.38320809667931904
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.8741844635384588
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.5971432620925162
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.4881128243527493
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.9165106710977592
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.8645213390197201
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.8719694705170171
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.6018479587755843
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.6433202148486912
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.9522274730316511
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.8976857479816195
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.4448971239026188
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.9508465474101143
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.9465783191821842
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.6957143767661691
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.9746932741895764
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.8903657160183741
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.9193582582562576
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.8701450445177663
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.506137221425257
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.9316596367365538
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.8457724722926088
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.31492471146339035
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.8812528612929407
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.6848494430287688
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.7261468254325618
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.9808711947901582
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.5027581343684131
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.7905732712925408
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.9814630867454741
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.9563888890564913
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.9020743226109609
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.9485907787579894
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.965162049940085
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.7420402694106324
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.8253447372233013
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.34421598023143646
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.23306406359189757
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.332471728783873
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.8388183756900699
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.9620235151986389
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.8773392123973061
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.8261509059704362
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.7125684707331256
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.9678551258057224
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.6395799260944158
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.854065699583252
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.9354039673378333
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.8671432035441643
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.5903495851718517
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.9001382386253377
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.9375838946452112
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.08627774750133997
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.655386372969241
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.7828571464899012
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.866500956534791
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.9645540309588541
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.7881355874862873
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.3486526586728024
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.8310798857861863
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.6435416738873861
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.6758683964914295
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.8667158071384764
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.3844213188042642
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.9127782199791448
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.5302786721297372
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.22053765099821596
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.714520876946233
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.9333647497717316
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.27595412194876073
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.8034958584548675
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.5200732764661781
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.8505612990463871
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.7989767773253548
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.8566255787636958
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.3675258879128545
---------------------------------------------------------

Hidden units: 10
Epochs: 1000
Learning rate: 0.5

Errors during training:
Error at epoch 1 is 97.5980243761774
Train mean error at (after) epoch 1: 0.24399506094044351
Test error at (after) epoch 1: 0.21814508248344677
----------
Error at epoch 100 is 5.002313463060622
Train mean error at (after) epoch 100: 0.012505783657651554
Test error at (after) epoch 100: 0.01052614010218967
----------
Error at epoch 200 is 4.986019473254849
Train mean error at (after) epoch 200: 0.012465048683137123
Test error at (after) epoch 200: 0.010488200203309362
----------
Error at epoch 300 is 4.971684448469643
Train mean error at (after) epoch 300: 0.012429211121174108
Test error at (after) epoch 300: 0.010481010243927892
----------
Error at epoch 400 is 4.956800296426294
Train mean error at (after) epoch 400: 0.012392000741065733
Test error at (after) epoch 400: 0.010475101579338848
----------
Error at epoch 500 is 4.941123131549599
Train mean error at (after) epoch 500: 0.012352807828873998
Test error at (after) epoch 500: 0.010469816146536052
----------
Error at epoch 600 is 4.924412985715325
Train mean error at (after) epoch 600: 0.012311032464288312
Test error at (after) epoch 600: 0.01046501619408352
----------
Error at epoch 700 is 4.906423491794875
Train mean error at (after) epoch 700: 0.012266058729487187
Test error at (after) epoch 700: 0.010460603352095305
----------
Error at epoch 800 is 4.8868938391383105
Train mean error at (after) epoch 800: 0.012217234597845777
Test error at (after) epoch 800: 0.010456499909036304
----------
Error at epoch 900 is 4.865541362847925
Train mean error at (after) epoch 900: 0.012163853407119814
Test error at (after) epoch 900: 0.010452639801885343
----------
Error at epoch 1000 is 4.8420538304075045
Train mean error at (after) epoch 1000: 0.01210513457601876
Test error at (after) epoch 1000: 0.010448958354157241
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.8949005753312993
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.24003072558845961
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.8647332414873504
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.3761772372187187
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.9569170432757828
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.9435900785904017
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.3918249969172103
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.659194137313542
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.950370011855001
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6410134986072074
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.9135460297116396
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.8192453908268122
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.829504316573435
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.9509758731082949
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.8425105333764442
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.7031916819690279
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.8569209941006423
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.5450130296018663
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.41449530393394524
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.705982490550215
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.7976823782811877
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.7347934392474965
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.8748863510242738
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.8193700817396943
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.3700553672386662
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.8697564782671431
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.5904964785073392
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.4799273066707302
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.8972267388227195
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.8372492111419543
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.8502611618870192
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.6454614122628559
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.6588660217601875
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.9345764851617205
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.9092049106313576
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.4219125053606362
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.9454937183498862
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.9267871570161792
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.696805888567982
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.9595201344557741
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.8934127738056583
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.933281335543102
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.8591947692478445
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.5110073046161213
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.9266764929274934
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.8476836344354876
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.31786278982931343
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.8778634097189794
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.7132374873531836
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.7251921071113175
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.9623799187665291
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.49949532786191414
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.77216542106652
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.9755747806272292
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.9395703146541486
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.8983729546365622
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.9457408769533996
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.9644563050889154
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.7316700906081847
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.8407250537254277
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.33945276819818865
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.22290757988185492
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.3283037757820313
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.8353249710408864
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.957318580453387
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.8841015423510428
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.8306390069412066
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.7043356708591791
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.9607758580753888
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.6055109489764634
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.8752813092292555
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.9142539266741307
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.8495045195947194
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.5925115308187624
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.8892471220428647
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.931618863959661
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.06440030012974961
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.6448462868311059
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.7762530782437013
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.839090495518791
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.951694007060141
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.7712182068775683
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.34744135987186775
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.8128433833404768
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.69487704902142
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.6993931742718678
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.8490594142319255
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.42833513447117827
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.910982704534737
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.5546705234476746
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.22261562317754602
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.6995416368498361
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.9302083530808225
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.29147318599022864
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.7970208896145358
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.512677833549259
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.8353163823064544
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.783786063125688
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.8426696535585689
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.3575516360520991
---------------------------------------------------------

Hidden units: 10
Epochs: 3000
Learning rate: 0.5

Errors during training:
Error at epoch 1 is 108.78892184169709
Train mean error at (after) epoch 1: 0.2719723046042427
Test error at (after) epoch 1: 0.20612206771186764
----------
Error at epoch 300 is 4.6651612303411305
Train mean error at (after) epoch 300: 0.011662903075852826
Test error at (after) epoch 300: 0.010311607417375019
----------
Error at epoch 600 is 4.442420060291714
Train mean error at (after) epoch 600: 0.011106050150729286
Test error at (after) epoch 600: 0.010389758533163264
----------
Error at epoch 900 is 4.10423863015164
Train mean error at (after) epoch 900: 0.010260596575379099
Test error at (after) epoch 900: 0.01046599936223466
----------
Error at epoch 1200 is 3.5847697816347446
Train mean error at (after) epoch 1200: 0.008961924454086861
Test error at (after) epoch 1200: 0.010191710781272394
----------
Error at epoch 1500 is 3.087170968871224
Train mean error at (after) epoch 1500: 0.00771792742217806
Test error at (after) epoch 1500: 0.009365905823077936
----------
Error at epoch 1800 is 2.766026453616384
Train mean error at (after) epoch 1800: 0.00691506613404096
Test error at (after) epoch 1800: 0.008513840061980043
----------
Error at epoch 2100 is 2.5217528079044937
Train mean error at (after) epoch 2100: 0.006304382019761234
Test error at (after) epoch 2100: 0.007793663526531171
----------
Error at epoch 2400 is 2.3060065780312216
Train mean error at (after) epoch 2400: 0.005765016445078054
Test error at (after) epoch 2400: 0.007133102719556727
----------
Error at epoch 2700 is 2.1202043196511875
Train mean error at (after) epoch 2700: 0.005300510799127969
Test error at (after) epoch 2700: 0.006568129287919571
----------
Error at epoch 3000 is 1.9722639994618059
Train mean error at (after) epoch 3000: 0.0049306599986545145
Test error at (after) epoch 3000: 0.006164876105000704
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.835609873378649
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.38651400266562497
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.8639014478122339
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.42164056189907695
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.7862907677869355
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.736425436153088
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.45328120827025337
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.6807222774487381
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.8087152850799357
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6852758117216108
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.8454258494824033
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.8184126845208501
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.8097079730591729
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.8257384907009558
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.834182423584113
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.7455450929120395
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.8065877671714653
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.5216583729992809
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.4601863238138574
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.78251654112691
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.830112447573417
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.7503349009510016
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.8246912051100473
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.8206966825487907
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.4344555700412585
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.818083017739809
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.6521592519964164
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.5356113071725527
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.8315319692610961
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.8387243604470447
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.8192937109626597
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.6830915433235253
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.7099802467085679
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.7761701506662709
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.8545981611957704
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.49991988783910213
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.7954870582801754
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.7502006689494878
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.7482207513388445
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.5610351600599712
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.8444868687023328
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.8618722876840892
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.8418715230573935
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.525428984827093
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.8573448048336879
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.8245351014169238
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.34563984029791217
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.8128313878361586
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.7055381716549208
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.7496759499078317
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.5341336077541009
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.5537573692861311
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.8034365488129072
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.4953168328413956
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.7217782204883945
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.8530295048554831
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.7861787898248116
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.7481454691937208
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.7537229559827914
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.818185779280983
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.381201303728985
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.22068653773333172
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.415694441932421
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.8392843760747584
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.797892013545605
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.8288399347864079
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.8251420929631492
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.7597626936246553
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.7363878767960631
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.6648305654009811
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.8513016702739802
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.7770450263164271
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.8557203788530752
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.6361953034939967
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.8545393866284715
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.8015529291238734
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: -0.009831689416537635
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.6946625180552372
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.7990171194776612
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.8334050535454612
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.7063787955304971
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.7867498832359887
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.44751586963112744
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.8086251603574747
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.641167414467761
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.6976833700215627
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.8345044283166746
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.4711197715742445
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.8199155904008336
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.5910343153727711
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.28920769101487787
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.7452979954135434
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.8130704144895357
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.30595457038808166
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.7787711684660131
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.5742975673559423
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.8302245024755933
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.8049030151645309
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.8285422304911202
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.385083909270457
---------------------------------------------------------

Hidden units: 10
Epochs: 10000
Learning rate: 0.5

Errors during training:
Error at epoch 1 is 96.9496768172196
Train mean error at (after) epoch 1: 0.242374192043049
Test error at (after) epoch 1: 0.21864347016724697
----------
Error at epoch 1000 is 4.84222376788138
Train mean error at (after) epoch 1000: 0.012105559419703451
Test error at (after) epoch 1000: 0.010466601828603284
----------
Error at epoch 2000 is 4.300305460620564
Train mean error at (after) epoch 2000: 0.01075076365155141
Test error at (after) epoch 2000: 0.010452483968822987
----------
Error at epoch 3000 is 2.7355301351893933
Train mean error at (after) epoch 3000: 0.006838825337973483
Test error at (after) epoch 3000: 0.007906751836670712
----------
Error at epoch 4000 is 2.0199270454882434
Train mean error at (after) epoch 4000: 0.005049817613720609
Test error at (after) epoch 4000: 0.005948543107088073
----------
Error at epoch 5000 is 1.735134812802251
Train mean error at (after) epoch 5000: 0.004337837032005628
Test error at (after) epoch 5000: 0.005026762617937842
----------
Error at epoch 6000 is 1.5767929065529989
Train mean error at (after) epoch 6000: 0.003941982266382497
Test error at (after) epoch 6000: 0.004501171961920168
----------
Error at epoch 7000 is 1.4846133932088514
Train mean error at (after) epoch 7000: 0.0037115334830221287
Test error at (after) epoch 7000: 0.004181918933592831
----------
Error at epoch 8000 is 2.264359813516445
Train mean error at (after) epoch 8000: 0.0056608995337911125
Test error at (after) epoch 8000: 0.005388660818507824
----------
Error at epoch 9000 is 1.7410149087985487
Train mean error at (after) epoch 9000: 0.004352537271996372
Test error at (after) epoch 9000: 0.004511076437675253
----------
Error at epoch 10000 is 1.7156824342702583
Train mean error at (after) epoch 10000: 0.004289206085675646
Test error at (after) epoch 10000: 0.004409797884288129
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.797763314087546
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.402725170224334
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.8840709206625404
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.33932684489928333
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.767265281519832
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.7243476023671088
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.33014420891618174
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.7366232967581464
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.8634262538314843
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.629270353754331
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.8846258991124193
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.805334157972634
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.8332229922090566
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.8899122218439024
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.8504184095497941
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.7562611382524818
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.8402839085935027
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.5336009087009906
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.3664129116755503
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.7265945737564233
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.8210148456011411
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.7190911599821979
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.813076976332817
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.8380819635312724
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.4797255109667143
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.8456405563917037
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.6140018436925837
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.498188154832431
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.8385268695410042
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.8942826823396783
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.818633416976368
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.579233160273492
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.670011943753231
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.8251775249334504
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.9022790849795742
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.4128597049323386
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.8121537433948167
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.7916337150932061
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.7608367212990035
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.41308551074743455
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.8483719281377958
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.9273044026129801
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.8627013515791461
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.4790509546652292
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.9004906560218063
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.8318457108578917
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.42771139162312066
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.8707004610100632
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.7398177258816326
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.7793575893147788
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.4390214141561963
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.5666224292051509
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.8046101755387657
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.3311481778259745
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.7220116251627908
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.8950962581418287
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.8341659719890869
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.8116110254684329
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.7169176602759744
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.8527435179059072
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.34653485150471014
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.14317797724544867
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.30925427379863396
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.8551809283887852
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.8594556691623888
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.8658839707861051
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.8341653129384743
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.6880345204864448
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.7106511775913943
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.6324204917449541
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.8725628357398801
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.8089365820942255
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.8623878731948255
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.6324056945072396
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.8728971764553897
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.9090915113557593
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.038447295208453615
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.6497933288789319
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.761497265896879
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.8950619377635493
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.6149078590602117
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.7703776681728651
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.4627415203087459
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.8012584163699328
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.6866805626657352
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.7082219556298949
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.8497451273141574
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.4042613045702627
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.8678309317029831
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.6031040447613446
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.3502059203533505
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.7898266542430432
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.9266418605968815
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.2149611499033781
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.8142812005139995
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.6583901408261027
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.8455417105557461
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.807126281516059
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.8476753492296364
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.4352424303030116
---------------------------------------------------------

Hidden units: 10
Epochs: 100
Learning rate: 1

Errors during training:
Error at epoch 1 is 134.44749148786406
Train mean error at (after) epoch 1: 0.33611872871966014
Test error at (after) epoch 1: 0.23267463918227096
----------
Error at epoch 10 is 9.559546664540058
Train mean error at (after) epoch 10: 0.023898866661350146
Test error at (after) epoch 10: 0.02166914819945111
----------
Error at epoch 20 is 5.571004253226563
Train mean error at (after) epoch 20: 0.013927510633066407
Test error at (after) epoch 20: 0.012072114073987046
----------
Error at epoch 30 is 5.177408948938827
Train mean error at (after) epoch 30: 0.012943522372347067
Test error at (after) epoch 30: 0.010947429763431342
----------
Error at epoch 40 is 5.112314386630231
Train mean error at (after) epoch 40: 0.01278078596657558
Test error at (after) epoch 40: 0.010715494895950433
----------
Error at epoch 50 is 5.098363704283343
Train mean error at (after) epoch 50: 0.012745909260708357
Test error at (after) epoch 50: 0.010649933365769273
----------
Error at epoch 60 is 5.094024190375652
Train mean error at (after) epoch 60: 0.012735060475939131
Test error at (after) epoch 60: 0.010626051702443453
----------
Error at epoch 70 is 5.091672646888797
Train mean error at (after) epoch 70: 0.012729181617221991
Test error at (after) epoch 70: 0.010615199235623278
----------
Error at epoch 80 is 5.089783624521199
Train mean error at (after) epoch 80: 0.012724459061302998
Test error at (after) epoch 80: 0.01060919356968599
----------
Error at epoch 90 is 5.088037643803129
Train mean error at (after) epoch 90: 0.012720094109507822
Test error at (after) epoch 90: 0.010605232044165415
----------
Error at epoch 100 is 5.086364104633719
Train mean error at (after) epoch 100: 0.012715910261584298
Test error at (after) epoch 100: 0.010602215148555303
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.9338170829078304
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.2504216718735188
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.8911826986449768
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.37772179969865227
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.9715901952777225
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.9733478548782432
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.35274479955262417
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.658261238319386
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.959911823275009
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6521083855379076
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.9322972309767548
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.8515368777504906
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.8440810772981636
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.9689749567682082
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.8673386774382348
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.6873696376031557
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.876089440492736
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.5401330124729582
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.41527436632944226
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.7092311050997137
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.7917426039404996
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.7647573382441629
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.9118763967071638
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.8555909508465603
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.38009138721193886
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.8840625184277957
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.5909801567411109
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.4718360917037247
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.9302347111775586
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.8874184619935885
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.8823005482509264
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.6289049046759532
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.6716716532989235
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.9645919454238624
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.9293773993001535
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.4213709950753842
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.9643603176354678
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.9668060698319766
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.6984104935484708
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.9880583623491759
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.9100482733485019
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.9555215520136695
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.8723144568942585
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.4940616133608928
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.9436896300108426
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.8815215255214318
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.3100384654720554
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.9146159700808443
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.6962317889173265
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.7199614773400402
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.9894517120819231
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.49434769870626516
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.7886806141531875
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.9907697090784625
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.9757792651247624
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.9162282804344462
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.9669996113812162
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.9837205294946595
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.758506889410941
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.8574370420144601
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.3260900615936698
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.21487476357779542
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.34414817347517435
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.84690505938505
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.9688106591650985
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.8854465863705844
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.841095177025348
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.697817670466207
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.9787989158419766
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.6259815600410935
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.9061158263338744
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.9562818034663837
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.858544693460822
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.5847450490898075
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.9058886764237087
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.9694660463980599
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: -0.018048043594360713
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.6608493632256893
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.7845930173271416
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.8923531897153603
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.9828793700616012
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.7967981489860194
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.35853456763237906
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.8477245277455383
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.6579585649520578
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.6912123021176276
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.8749121695987231
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.40948537061417467
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.934560709631498
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.5289361268277588
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.22783587760788523
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.7161331414196275
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.9678136724179057
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.28035195798219464
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.8134070635823548
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.51005707735876
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.852112728191852
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.7977762505742231
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.8637083824156924
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.3710108831808696
---------------------------------------------------------

Hidden units: 10
Epochs: 1000
Learning rate: 1

Errors during training:
Error at epoch 1 is 110.5728609969703
Train mean error at (after) epoch 1: 0.27643215249242575
Test error at (after) epoch 1: 0.10840275053131046
----------
Error at epoch 100 is 5.011623981288813
Train mean error at (after) epoch 100: 0.012529059953222033
Test error at (after) epoch 100: 0.010435807680237752
----------
Error at epoch 200 is 4.996732564845671
Train mean error at (after) epoch 200: 0.012491831412114178
Test error at (after) epoch 200: 0.010433469439547967
----------
Error at epoch 300 is 4.979643463239668
Train mean error at (after) epoch 300: 0.012449108658099171
Test error at (after) epoch 300: 0.010431672582161829
----------
Error at epoch 400 is 4.959510627197821
Train mean error at (after) epoch 400: 0.012398776567994551
Test error at (after) epoch 400: 0.010430044459382393
----------
Error at epoch 500 is 4.935145332829455
Train mean error at (after) epoch 500: 0.012337863332073637
Test error at (after) epoch 500: 0.01042840031013468
----------
Error at epoch 600 is 4.904807952061001
Train mean error at (after) epoch 600: 0.012262019880152502
Test error at (after) epoch 600: 0.010426461854342815
----------
Error at epoch 700 is 4.8658588345122205
Train mean error at (after) epoch 700: 0.012164647086280551
Test error at (after) epoch 700: 0.010423726361989117
----------
Error at epoch 800 is 4.814161110187977
Train mean error at (after) epoch 800: 0.012035402775469944
Test error at (after) epoch 800: 0.010419155716656936
----------
Error at epoch 900 is 4.743064822383428
Train mean error at (after) epoch 900: 0.01185766205595857
Test error at (after) epoch 900: 0.01041035405292786
----------
Error at epoch 1000 is 4.641776278650759
Train mean error at (after) epoch 1000: 0.011604440696626896
Test error at (after) epoch 1000: 0.010391220495532164
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.8514480261846158
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.24178057104400474
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.852012317055595
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.3870473311031854
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.9342338475479802
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.9058749281785872
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.39556618712825814
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.6585956129249844
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.9325253140815556
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6206220698191129
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.9028798068673638
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.7955289078866679
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.8231533634989978
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.9433529998263377
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.8223143397919849
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.6982617709394023
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.8472881475197017
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.5607659491042135
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.4224207694912836
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.6862760071336965
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.7812630341525827
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.7197390999570883
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.8401915238645722
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.8072244790232432
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.3672341359582433
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.8599936376590709
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.5836352851190256
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.4801247570865861
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.8645525254757047
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.8356058310945575
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.8300025779076292
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.625766438935442
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.6167163525717595
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.902294440261176
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.8814954825744222
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.42612875441601616
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.9306746222079164
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.8975845180171492
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.695092610624088
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.9193109276470983
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.8749248081285019
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.9090313656072574
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.8402919626691091
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.5182135510177353
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.9202858236367365
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.8079770845671002
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.31227489663521424
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.8430066418810832
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.718928850003658
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.7205370342995985
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.9337338674062773
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.5018470329984437
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.762915438025986
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.9546702779070511
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.9040988902374412
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.8889920046077661
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.925844205932465
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.9408164888760205
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.7073233420745413
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.8321675245765582
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.34703325774681065
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.21593411579133437
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.33801024805478513
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.8129666656190647
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.9417070201326495
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.8784701242254539
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.8259987193227346
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.7028896250110803
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.9473392140451892
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.6118766649475296
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.8282452304797736
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.8873976344582575
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.835020795848562
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.5959698902407089
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.8568456584075268
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.892024262569589
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.0820494727836561
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.6316994562532819
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.7731831644512155
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.838635303533628
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.9077362326927787
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.7478020876946153
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.3554606212660186
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.7916911755297787
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.6916158930478139
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.698528137126942
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.827682911460871
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.41008838510721635
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.8954101933451871
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.5550218432394026
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.22966501784269303
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.7053262380062519
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.8911810861157541
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.2836304594613588
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.7899370085843747
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.5111396100559918
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.8141417060240249
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.7664860716966223
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.8243458363986513
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.3658884363134435
---------------------------------------------------------

Hidden units: 10
Epochs: 3000
Learning rate: 1

Errors during training:
Error at epoch 1 is 144.10112049547843
Train mean error at (after) epoch 1: 0.3602528012386961
Test error at (after) epoch 1: 0.18491985330691224
----------
Error at epoch 300 is 5.042900357461972
Train mean error at (after) epoch 300: 0.012607250893654932
Test error at (after) epoch 300: 0.010504633290021118
----------
Error at epoch 600 is 4.996713910348635
Train mean error at (after) epoch 600: 0.012491784775871588
Test error at (after) epoch 600: 0.010473871346449292
----------
Error at epoch 900 is 4.93053925070939
Train mean error at (after) epoch 900: 0.012326348126773475
Test error at (after) epoch 900: 0.010446244838440737
----------
Error at epoch 1200 is 4.804436544988662
Train mean error at (after) epoch 1200: 0.012011091362471655
Test error at (after) epoch 1200: 0.010406008638372394
----------
Error at epoch 1500 is 4.484180592699934
Train mean error at (after) epoch 1500: 0.011210451481749834
Test error at (after) epoch 1500: 0.01028678838461074
----------
Error at epoch 1800 is 3.463956840328852
Train mean error at (after) epoch 1800: 0.008659892100822129
Test error at (after) epoch 1800: 0.009324949944684458
----------
Error at epoch 2100 is 2.559673195743361
Train mean error at (after) epoch 2100: 0.006399182989358403
Test error at (after) epoch 2100: 0.00768805543058011
----------
Error at epoch 2400 is 2.166279790280386
Train mean error at (after) epoch 2400: 0.005415699475700964
Test error at (after) epoch 2400: 0.00668626856182223
----------
Error at epoch 2700 is 5.484250130564243
Train mean error at (after) epoch 2700: 0.013710625326410607
Test error at (after) epoch 2700: 0.011701261685499837
----------
Error at epoch 3000 is 2.6171427654225528
Train mean error at (after) epoch 3000: 0.006542856913556382
Test error at (after) epoch 3000: 0.007488819137739564
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.8029240736562594
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.4210000283565941
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.8389934801037993
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.3599134366361487
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.8056404600747015
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.7289392167306208
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.33503613655909487
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.7499093556163383
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.8313775061126135
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6685676294047372
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.8940908772640479
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.8088379571211838
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.8417188229104315
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.8397742851397529
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.8163669386699186
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.7818744098903793
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.8485840897046756
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.5263937591612144
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.35813335650428213
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.6877833284976288
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.7714616936604508
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.7267105201978432
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.8278373066850327
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.8092851057251053
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.5490880247058396
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.8552333883761413
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.6077422219407353
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.49765327351098665
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.8316383850032568
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.818461525793814
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.7979179899635732
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.6378097991628467
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.6405910571554128
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.7766895286809135
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.8702690191346494
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.34090484378343583
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.8374053252476208
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.7175311831427608
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.7935586228278598
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.5052127984503506
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.8647262741261207
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.8495970310715307
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.8187436454432654
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.4750592124048868
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.8616765653342827
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.8256803450378901
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.4810473370071816
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.7985073174772466
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.7801952202266774
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.8030073452862858
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.41815053952017894
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.6518426081499401
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.7749074586801633
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.5408419487159847
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.6789924037451993
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.8986949428387646
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.8264998281438886
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.7433813988692073
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.7448037021620713
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.8335844272782647
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.31069297108421845
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.15470910386078537
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.3350350787456031
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.8147552722181157
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.788062312428216
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.8535617710516329
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.7937615359954384
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.711978937320562
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.7733713367009373
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.6012348222543844
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.8100111132128819
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.7536204858094646
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.8181071374895794
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.7199737458639093
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.8342178166656119
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.7738851004492519
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: -0.034490318656750237
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.6644790716411288
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.7649939180621699
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.808377705543296
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.6312167498849621
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.7737157582939401
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.5053144765847863
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.7995021302351251
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.6278086568119581
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.7676287813867554
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.8167108812626934
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.42090599074015117
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.8507632797898572
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.5251814851064518
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.3887398530158718
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.791789164675309
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.7574988484639927
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.19183996113170562
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.8271236913051223
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.6693766643075357
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.8169350033323057
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.7812163877981559
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.8037088655723825
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.5241529086932197
---------------------------------------------------------

Hidden units: 10
Epochs: 10000
Learning rate: 1

Errors during training:
Error at epoch 1 is 82.41006768248862
Train mean error at (after) epoch 1: 0.20602516920622155
Test error at (after) epoch 1: 0.1326099082817113
----------
Error at epoch 1000 is 4.647729421096074
Train mean error at (after) epoch 1000: 0.011619323552740184
Test error at (after) epoch 1000: 0.010566296151262655
----------
Error at epoch 2000 is 2.303025185024082
Train mean error at (after) epoch 2000: 0.005757562962560205
Test error at (after) epoch 2000: 0.00693554422617346
----------
Error at epoch 3000 is 1.692112472145101
Train mean error at (after) epoch 3000: 0.004230281180362752
Test error at (after) epoch 3000: 0.004302523981635433
----------
Error at epoch 4000 is 1.162205766071772
Train mean error at (after) epoch 4000: 0.00290551441517943
Test error at (after) epoch 4000: 0.002691057790839735
----------
Error at epoch 5000 is 1.061256496840527
Train mean error at (after) epoch 5000: 0.002653141242101317
Test error at (after) epoch 5000: 0.0024598288942609624
----------
Error at epoch 6000 is 1.0218355610875083
Train mean error at (after) epoch 6000: 0.002554588902718771
Test error at (after) epoch 6000: 0.002387938572215936
----------
Error at epoch 7000 is 0.9995026795977051
Train mean error at (after) epoch 7000: 0.0024987566989942626
Test error at (after) epoch 7000: 0.0023503088062808287
----------
Error at epoch 8000 is 0.9851890946330917
Train mean error at (after) epoch 8000: 0.002462972736582729
Test error at (after) epoch 8000: 0.0023266482808259616
----------
Error at epoch 9000 is 0.9749179989719663
Train mean error at (after) epoch 9000: 0.0024372949974299156
Test error at (after) epoch 9000: 0.0023104157263052205
----------
Error at epoch 10000 is 0.9669229674521709
Train mean error at (after) epoch 10000: 0.0024173074186304272
Test error at (after) epoch 10000: 0.0022987503830188463
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.8931960453710555
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.29730282475686304
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.9362806809819021
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.1952206124062489
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.807015392766876
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.7463581314522135
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.3122641784462703
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.7112327722963191
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.8408159486825649
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6388288443980902
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.9462596175770739
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.8974250670366021
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.87730796518572
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.9373486142089397
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.8965552823683969
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.7571543012165576
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.8954701312112125
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.5326529667191698
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.2466341167653547
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.7800871145975573
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.8943442058857924
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.7414390706884907
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.8981335377991164
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.8900350027146661
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.34052059867412504
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.9056222943543285
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.4677722726838607
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.3929755412101375
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.8991914449971263
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.9450190972222172
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.890296802522196
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.7117050637409097
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.7336811191330642
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.839652391411337
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.9317743240863202
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.3336179106808341
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.8712683811971114
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.8216012411449755
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.7537893913292578
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.4428243723711419
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.9169890505496783
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.9232408587592408
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.9079090804014904
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.39981634937711646
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.9465836073626078
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.9217403204785353
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.28755778509375035
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.9058560093167256
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.8326354070449188
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.7676483891841791
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.36558353930291343
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.47741614624786655
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.838435238183031
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.3384436181140466
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.7319781097346617
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.954388114017131
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.8527263379464011
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.7456853188585186
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.7521623886251071
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.9291756544401027
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.18304321074013247
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.09860168306171034
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.18104548872031956
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.9200808075553781
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.7936832336780427
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.9383265484221652
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.9291665628591629
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.7233560287897848
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.7785651570178014
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.6004412708668518
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.9283124157758822
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.8671711025879855
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.9167554021883925
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.615971652463599
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.9309341333724456
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.869086565821687
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: -0.03740561770307999
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.5972958086453
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.8573592223454235
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.9503020632920267
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.6571549320656248
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.7918094234332628
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.3632285131632866
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.8568366208699039
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.7757656989906205
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.790318597273538
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.8959969580322513
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.2978365516318067
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.9082906520825039
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.490182090880939
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.26191711144662694
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.819092078339828
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.8637192485172626
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.11607362884090676
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.8519514790055847
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.5393872799254783
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.8801997968051588
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.8235205062791409
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.8952524502922703
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.36471966528807825
=========================================================

---------------------------------------------------------

Hidden units: 12
Epochs: 100
Learning rate: 0.05

Errors during training:
Error at epoch 1 is 93.1533899217773
Train mean error at (after) epoch 1: 0.23288347480444327
Test error at (after) epoch 1: 0.2773979636003495
----------
Error at epoch 10 is 76.99895377108764
Train mean error at (after) epoch 10: 0.1924973844277191
Test error at (after) epoch 10: 0.2289115921488084
----------
Error at epoch 20 is 63.91920200821905
Train mean error at (after) epoch 20: 0.15979800502054764
Test error at (after) epoch 20: 0.18934546810672562
----------
Error at epoch 30 is 53.85521962115263
Train mean error at (after) epoch 30: 0.13463804905288157
Test error at (after) epoch 30: 0.1587158742351452
----------
Error at epoch 40 is 45.769674260050245
Train mean error at (after) epoch 40: 0.11442418565012562
Test error at (after) epoch 40: 0.13397024041091182
----------
Error at epoch 50 is 39.13481646482436
Train mean error at (after) epoch 50: 0.0978370411620609
Test error at (after) epoch 50: 0.11357403557847015
----------
Error at epoch 60 is 33.64075600788933
Train mean error at (after) epoch 60: 0.08410189001972332
Test error at (after) epoch 60: 0.09665193325606111
----------
Error at epoch 70 is 29.07689971525461
Train mean error at (after) epoch 70: 0.07269224928813652
Test error at (after) epoch 70: 0.0826135985539996
----------
Error at epoch 80 is 25.283352991485746
Train mean error at (after) epoch 80: 0.06320838247871437
Test error at (after) epoch 80: 0.07099651909954051
----------
Error at epoch 90 is 22.130549843137715
Train mean error at (after) epoch 90: 0.055326374607844286
Test error at (after) epoch 90: 0.061406773221151185
----------
Error at epoch 100 is 19.510323533171505
Train mean error at (after) epoch 100: 0.048775808832928765
Test error at (after) epoch 100: 0.05350095218913761
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.6355282654225828
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: 0.08547412361143238
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.5695042689356081
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.10513078644367786
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.7878521733400888
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.8075513221108118
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.3797210999976472
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.3873435089181632
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.7848826666204705
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.21140188404360558
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.5471470186898943
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.4335944865307981
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.5286939069114582
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.7676982876527785
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.5712987367775119
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.47368265751025085
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.5145200972776071
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.16742044706891965
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.33775643686715023
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.3909311794514007
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.6123563834895226
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.3940695992648293
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.5802191231554263
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.5848098975726158
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.2660097598726777
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.5491471098749182
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.39387846330969106
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.1770881309873999
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.6517024481662635
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.5846625338965663
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.5722155319364242
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.09843193371180213
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.2007612703106963
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.789470850451976
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.5334994327458422
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.23699401762770306
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.711349925638377
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.7303084976010724
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.46235488342355213
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.8476962026610014
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.6160173445960809
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.5972977390177475
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.6505100509741191
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.1055011484859981
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.7093720394146951
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.41196849421615317
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.20727797116517568
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.49492885790142743
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.425917127742238
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.447942419451843
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.8664203442896224
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.3410625654986011
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.5178461874570905
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.87371797728121
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.770859864144355
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.4842241170331268
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.7090211550266822
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.7876918166158606
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.35656739997351955
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.40164022291270174
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.1337703177687526
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.3123623171742053
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.2563840228998616
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.6404593356117807
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.7896428239080198
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.5965145725652472
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.5489238251349585
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.5375932040624611
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.7839230230199503
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.2853741585148323
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.4206606821158805
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.6986298911945554
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.6505626743427633
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.4026888638107706
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.7087814871374234
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.6560120002141426
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: -0.09225440754018985
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.29820592673801577
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.5627417831957628
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.5633640532751608
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.8061070598660456
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.4729497068313059
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.13149351129154202
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.5568167630291235
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.43107487827883256
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.17617436994601351
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.5818169114269602
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.009077446954944002
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.6021362746043497
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.29122482585616044
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: 0.1328870883221975
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.4723213125247033
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.6463030928459595
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.3147016060377149
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.42084271038301935
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.15730044866360202
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.6286192896590316
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.5415158461938504
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.5870702508966236
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.05896505216228069
---------------------------------------------------------

Hidden units: 12
Epochs: 1000
Learning rate: 0.05

Errors during training:
Error at epoch 1 is 121.67305948814433
Train mean error at (after) epoch 1: 0.3041826487203608
Test error at (after) epoch 1: 0.33096818132203987
----------
Error at epoch 100 is 13.676893150181282
Train mean error at (after) epoch 100: 0.034192232875453206
Test error at (after) epoch 100: 0.03719422462011547
----------
Error at epoch 200 is 7.281657824407509
Train mean error at (after) epoch 200: 0.018204144561018775
Test error at (after) epoch 200: 0.01754003132325728
----------
Error at epoch 300 is 5.834451767749433
Train mean error at (after) epoch 300: 0.014586129419373584
Test error at (after) epoch 300: 0.0130483154011101
----------
Error at epoch 400 is 5.37810907808978
Train mean error at (after) epoch 400: 0.01344527269522445
Test error at (after) epoch 400: 0.01160766944574583
----------
Error at epoch 500 is 5.209681040088427
Train mean error at (after) epoch 500: 0.013024202600221066
Test error at (after) epoch 500: 0.011055468838821872
----------
Error at epoch 600 is 5.141707226976099
Train mean error at (after) epoch 600: 0.012854268067440246
Test error at (after) epoch 600: 0.010818778437436487
----------
Error at epoch 700 is 5.1126415842006105
Train mean error at (after) epoch 700: 0.012781603960501526
Test error at (after) epoch 700: 0.010708735003971353
----------
Error at epoch 800 is 5.099637881801232
Train mean error at (after) epoch 800: 0.012749094704503078
Test error at (after) epoch 800: 0.010654010687322892
----------
Error at epoch 900 is 5.093539418560175
Train mean error at (after) epoch 900: 0.012733848546400438
Test error at (after) epoch 900: 0.010625079885051757
----------
Error at epoch 1000 is 5.090489810478058
Train mean error at (after) epoch 1000: 0.012726224526195144
Test error at (after) epoch 1000: 0.010608866879326327
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.9265092190672899
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.1727812214136209
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.9031677470235417
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.3645891528524647
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.9726606082206342
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.9741629061041762
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.36635538415812013
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.6625208299445984
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.9658645297107235
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6458995030654561
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.930291445251147
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.8429850482783463
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.8433749673284726
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.9671244652456987
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.879883294658575
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.6833852659119231
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.8712046467531418
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.5420877599429254
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.40911539692600724
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.7029501600200466
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.7838721289507684
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.7525157817558831
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.9126160210706232
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.8476362904600466
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.37357300193703147
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.8874345630450388
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.5996975865159081
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.4931369365729189
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.9356261065324568
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.8705811768234225
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.8823479717910395
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.6206984401942935
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.6638306040097233
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.9655840121859331
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.9258600466869392
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.41103556531519675
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.9674451151271698
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.9607532093219563
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.6943400316314339
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.9881900399394764
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.9034146109652836
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.9479063774650971
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.8931726024913811
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.5065234882934508
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.9425434212954915
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.8707633605980211
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.3261404022609394
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.9039645896969571
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.7225407947882695
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.7295192410929584
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.9919576693825339
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.4856611063917461
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.7968160722852705
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.9915743436375906
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.9720691011978229
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.9093973338488617
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.9653823280291286
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.9819526802067546
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.7529610057541525
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.8445003006776062
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.3462776984189623
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.2151696626224941
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.31669035186566147
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.8422426665809958
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.9771732973216047
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.8998106489265795
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.8604899390777575
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.6929211830493383
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.9814581272285889
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.6229067861711054
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.8966858390345412
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.9488434210806832
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.8538731224416074
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.5816144149818615
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.9026410811153452
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.9623324981253002
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.074481200859223
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.657255914879818
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.797061909298574
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.8742306033235724
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.9816989497110296
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.8005097004923665
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.34462697725512687
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.8388248688524053
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.6842050549406573
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.6898271769281972
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.8864290536103914
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.41851644005157845
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.9273741135851389
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.5373422838475455
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.2289754791530955
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.7049177047302667
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.9599715693595453
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.286410839390895
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.806213171545691
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.5253309503867534
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.8625856893601989
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.8101363148716044
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.8777584607190158
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.3481062175073867
---------------------------------------------------------

Hidden units: 12
Epochs: 3000
Learning rate: 0.05

Errors during training:
Error at epoch 1 is 84.0102968051392
Train mean error at (after) epoch 1: 0.21002574201284802
Test error at (after) epoch 1: 0.23827070336132725
----------
Error at epoch 300 is 6.071226649467451
Train mean error at (after) epoch 300: 0.015178066623668628
Test error at (after) epoch 300: 0.01379914541148754
----------
Error at epoch 600 is 5.187991889151556
Train mean error at (after) epoch 600: 0.01296997972287889
Test error at (after) epoch 600: 0.010958870878976885
----------
Error at epoch 900 is 5.128039577863099
Train mean error at (after) epoch 900: 0.012820098944657748
Test error at (after) epoch 900: 0.01071424260758085
----------
Error at epoch 1200 is 5.1210864917636245
Train mean error at (after) epoch 1200: 0.012802716229409062
Test error at (after) epoch 1200: 0.010672187885550683
----------
Error at epoch 1500 is 5.119013678446397
Train mean error at (after) epoch 1500: 0.01279753419611599
Test error at (after) epoch 1500: 0.010659496559650738
----------
Error at epoch 1800 is 5.117482156992539
Train mean error at (after) epoch 1800: 0.012793705392481347
Test error at (after) epoch 1800: 0.010653266908219742
----------
Error at epoch 2100 is 5.116056383302551
Train mean error at (after) epoch 2100: 0.012790140958256377
Test error at (after) epoch 2100: 0.01064893115292079
----------
Error at epoch 2400 is 5.114688308103145
Train mean error at (after) epoch 2400: 0.012786720770257862
Test error at (after) epoch 2400: 0.010645282648310179
----------
Error at epoch 2700 is 5.1133697956353865
Train mean error at (after) epoch 2700: 0.012783424489088466
Test error at (after) epoch 2700: 0.010641952689185386
----------
Error at epoch 3000 is 5.112097069444201
Train mean error at (after) epoch 3000: 0.012780242673610503
Test error at (after) epoch 3000: 0.010638818889626492
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.9377495667278409
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.2289471973295961
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.8867179534885602
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.3736972112057538
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.9811002871256373
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.9821618191395823
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.34875845072813827
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.666114636733804
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.9753031218510653
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6508410653720016
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.9298563505513475
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.8500010748539553
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.850313144745015
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.973163613362348
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.8774698342637406
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.7131981312646852
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.8807041150664707
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.5540373238155847
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.407352385562635
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.7183427492804211
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.833271484450492
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.7665830334632999
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.9167353401117768
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.8553653081673248
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.37775703097909075
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.8914350486377476
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.6071657654965968
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.4859880298996181
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.9391480175782558
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.8648083868906015
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.8887458748166897
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.6251854649905791
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.6340425109008142
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.9752206450342346
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.9282887140860042
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.413190455059958
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.9694486426104566
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.9693718230135626
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.701456668054216
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.9918841475976169
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.9189160586512042
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.9546870967579683
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.8926703515443145
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.5086446981410976
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.9486566726978639
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.8748410488562312
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.3243992931647165
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.9137419765871195
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.6840456708429413
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.7396507314607956
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.9936077087914486
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.5067464913487203
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.8046413491298479
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.9948934768767622
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.9794614626114535
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.9104716046957596
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.971351395577013
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.986810449705069
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.7608201170098507
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.854733664257894
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.34610248945692207
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.22785145551776553
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.31813399511319473
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.872580379168093
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.9801793154501962
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.8933226784552679
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.8287440947741975
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.7313462746044926
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.9836323562816986
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.6131680599490366
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.8973394265810257
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.9582126512277209
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.890832458903549
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.5957822803518675
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.9324365033901669
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.968177052883914
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.08549426652777037
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.6670076596619416
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.7968574528257715
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.8647611562367233
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.9867122038407325
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.8082333459191384
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.326174765322342
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.8530680949420404
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.6622818725997447
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.6968082216708563
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.8854251587067022
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.38419010557859257
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.9375251014077366
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.5397334248882056
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.17184065590945596
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.7044287102942594
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.9666192404074192
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.2802221261880057
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.8172343143765802
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.5209489706504736
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.8745387031172251
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.8191769742757702
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.8752296467422374
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.3552422176422922
---------------------------------------------------------

Hidden units: 12
Epochs: 10000
Learning rate: 0.05

Errors during training:
Error at epoch 1 is 164.6649719403726
Train mean error at (after) epoch 1: 0.4116624298509315
Test error at (after) epoch 1: 0.46569373070121406
----------
Error at epoch 1000 is 5.060396599795409
Train mean error at (after) epoch 1000: 0.012650991499488522
Test error at (after) epoch 1000: 0.010604618981972555
----------
Error at epoch 2000 is 5.052539311357737
Train mean error at (after) epoch 2000: 0.012631348278394343
Test error at (after) epoch 2000: 0.010568959621077486
----------
Error at epoch 3000 is 5.046800388354606
Train mean error at (after) epoch 3000: 0.012617000970886517
Test error at (after) epoch 3000: 0.01056469566915303
----------
Error at epoch 4000 is 5.040915535956063
Train mean error at (after) epoch 4000: 0.012602288839890157
Test error at (after) epoch 4000: 0.010561432390767829
----------
Error at epoch 5000 is 5.034824905911945
Train mean error at (after) epoch 5000: 0.012587062264779863
Test error at (after) epoch 5000: 0.010558617520463255
----------
Error at epoch 6000 is 5.028468654730951
Train mean error at (after) epoch 6000: 0.012571171636827378
Test error at (after) epoch 6000: 0.010556196873332204
----------
Error at epoch 7000 is 5.02178421032865
Train mean error at (after) epoch 7000: 0.012554460525821624
Test error at (after) epoch 7000: 0.010554135091716751
----------
Error at epoch 8000 is 5.014704385332052
Train mean error at (after) epoch 8000: 0.012536760963330128
Test error at (after) epoch 8000: 0.01055240421922363
----------
Error at epoch 9000 is 5.007155380687392
Train mean error at (after) epoch 9000: 0.01251788845171848
Test error at (after) epoch 9000: 0.010550982183413455
----------
Error at epoch 10000 is 4.999054565214777
Train mean error at (after) epoch 10000: 0.012497636413036943
Test error at (after) epoch 10000: 0.010549851716539872
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.923275626866841
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.2520873332270927
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.8922091916256728
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.3765089193921715
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.9700700329381169
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.9663532525689571
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.3777068074459138
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.6538627708325682
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.961728180515319
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6405196987715294
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.9207682338684483
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.8296976564495518
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.8326259501389691
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.960906689507687
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.8631129133241153
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.6985201136240214
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.8595120960932641
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.5614264097497478
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.41090902590292266
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.7137699665302367
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.8098470116601197
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.737288741399909
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.8986349198604672
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.8332222612559423
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.37555798219984465
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.8737770212283523
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.5922215846979707
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.48170307298874593
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.9227382981765467
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.8496385503000186
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.858891538027156
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.6194944848801425
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.676815588626697
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.9568647364564635
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.9225609733079861
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.4179456574909452
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.9566028611580778
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.9486827312680721
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.6980615474346081
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.98067096805249
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.907128407580492
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.9473762570447369
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.8767607089972574
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.5066399129813844
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.9347653490370386
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.8604006176418402
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.3185474735788705
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.8899069314780701
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.7198672568938737
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.7257252672841327
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.982440010363123
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.48845120904484857
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.7924260909669176
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.9872214995536548
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.9624688051619071
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.9033866350480148
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.9582063048010115
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.9778268770026796
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.7422753640943014
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.8545706109140164
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.3356706345874427
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.2236009233227044
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.32864105065943244
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.8543447282702695
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.9697914106297048
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.8839229418804102
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.8532694279332292
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.7080522355571753
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.9714632209427723
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.6047881093253333
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.8919766991221862
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.9361154141215461
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.8670594725052577
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.5852343975132009
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.9122652820792955
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.9509813945174829
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.06842091081014916
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.6474672032062848
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.7944884693869056
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.8528580060990608
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.9746066683016534
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.787656165184573
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.351754590518496
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.8319755819089857
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.6853910920652253
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.6901202935411044
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.8685195225311173
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.4172125541574017
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.9214132542216397
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.5426141377630161
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.21861419500452928
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.6949727315558264
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.9489861696233919
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.28447798793923174
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.7967727920048631
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.5112886418988741
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.8511055636638544
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.8005926954649435
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.856846427191669
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.3691159490103379
---------------------------------------------------------

Hidden units: 12
Epochs: 100
Learning rate: 0.1

Errors during training:
Error at epoch 1 is 121.34305581700445
Train mean error at (after) epoch 1: 0.30335763954251116
Test error at (after) epoch 1: 0.33174132408962287
----------
Error at epoch 10 is 57.797069421988915
Train mean error at (after) epoch 10: 0.14449267355497228
Test error at (after) epoch 10: 0.15990174581026664
----------
Error at epoch 20 is 32.767940089447265
Train mean error at (after) epoch 20: 0.08191985022361817
Test error at (after) epoch 20: 0.09066046942192407
----------
Error at epoch 30 is 21.83882761839469
Train mean error at (after) epoch 30: 0.05459706904598672
Test error at (after) epoch 30: 0.059631610088073675
----------
Error at epoch 40 is 16.071350045176864
Train mean error at (after) epoch 40: 0.04017837511294216
Test error at (after) epoch 40: 0.04304666306197157
----------
Error at epoch 50 is 12.672826386282647
Train mean error at (after) epoch 50: 0.03168206596570662
Test error at (after) epoch 50: 0.03321386926013061
----------
Error at epoch 60 is 10.521551252698382
Train mean error at (after) epoch 60: 0.026303878131745954
Test error at (after) epoch 60: 0.026962410120642755
----------
Error at epoch 70 is 9.08845088910543
Train mean error at (after) epoch 70: 0.022721127222763572
Test error at (after) epoch 70: 0.022779326476656897
----------
Error at epoch 80 is 8.096236363793968
Train mean error at (after) epoch 80: 0.02024059090948492
Test error at (after) epoch 80: 0.019868625355778328
----------
Error at epoch 90 is 7.38821229850699
Train mean error at (after) epoch 90: 0.018470530746267474
Test error at (after) epoch 90: 0.01777998429639697
----------
Error at epoch 100 is 6.870584432637536
Train mean error at (after) epoch 100: 0.01717646108159384
Test error at (after) epoch 100: 0.016243655116139073
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.8471604311445532
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.08737408722305612
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.7767649027833288
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.28347278961495814
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.9313958590636154
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.9333686641384912
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.30016388377770314
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.5277092152802173
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.9185730595798508
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.5121011846106165
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.8245188607682089
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.7169970350722041
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.72000525424205
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.9049067022410492
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.763675991473741
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.5877690072493511
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.7550155713262754
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.4340707705269934
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.3284686065389809
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.5998984435763142
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.7271034787815839
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.627805446525276
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.816775124334834
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.7343629009647303
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.2915073985277912
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.7702642974772809
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.4870591612229196
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.37192636003757323
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.8549369022266586
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.7484123064558544
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.7710165777182206
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.5004804628007721
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.5068101950648307
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.9157476530616913
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.8324139963617619
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.34443862185612906
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.9017855679382025
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.9018805129972265
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.5691885286580641
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.9608551117497243
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.8134906852218294
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.8747796856300702
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.7905400617803575
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.39809115517960963
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.8596336561103362
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.7624529391931448
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.24164938320707124
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.8162590381953556
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.5546036831978974
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.607678951525188
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.9653764324037882
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.3988248918577304
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.6869653089862933
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.9691343926606293
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.924506791601148
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.7914606135743261
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.9055673659383694
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.9438275809824248
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.6210971104080466
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.7251044345011564
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.2576918097383967
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.19815647287274227
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.258574220025092
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.7640890152190873
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.931295697377859
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.7773337412651077
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.7086507281407176
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.6174207516076957
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.9336422846263979
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.501378014243906
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.8006674516782377
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.8800065012655169
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.8002931881969801
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.4787233009258968
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.8500598734512272
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.9072025214172614
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.06380028729719996
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.5249498607180325
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.6846047746151784
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.7499962369763065
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.9462715801800653
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.6775218570508054
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.2506485365756112
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.7292398649511989
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.5287797013228769
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.5543639706830152
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.7729314558046151
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.2865835208437288
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.840335816935857
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.40545853997700676
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.10459993160618304
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.5787698052164769
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.9050208579942561
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.23361405639075492
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.6751062529514067
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.3859760668166425
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.7631477948862433
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.6987965559020458
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.7591085845410382
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.2557329388771803
---------------------------------------------------------

Hidden units: 12
Epochs: 1000
Learning rate: 0.1

Errors during training:
Error at epoch 1 is 112.90081088602061
Train mean error at (after) epoch 1: 0.2822520272150515
Test error at (after) epoch 1: 0.31505806147969434
----------
Error at epoch 100 is 8.408848315432653
Train mean error at (after) epoch 100: 0.021022120788581632
Test error at (after) epoch 100: 0.021176401498324796
----------
Error at epoch 200 is 5.48452375464742
Train mean error at (after) epoch 200: 0.013711309386618551
Test error at (after) epoch 200: 0.012075536505382584
----------
Error at epoch 300 is 5.151854672932957
Train mean error at (after) epoch 300: 0.012879636682332392
Test error at (after) epoch 300: 0.010944686854483665
----------
Error at epoch 400 is 5.094104907130216
Train mean error at (after) epoch 400: 0.01273526226782554
Test error at (after) epoch 400: 0.010708643613132151
----------
Error at epoch 500 is 5.081863890389472
Train mean error at (after) epoch 500: 0.012704659725973679
Test error at (after) epoch 500: 0.010642942974564064
----------
Error at epoch 600 is 5.078494290878706
Train mean error at (after) epoch 600: 0.012696235727196765
Test error at (after) epoch 600: 0.010620085459271369
----------
Error at epoch 700 is 5.076984618426319
Train mean error at (after) epoch 700: 0.012692461546065799
Test error at (after) epoch 700: 0.010610515309264133
----------
Error at epoch 800 is 5.075883992492108
Train mean error at (after) epoch 800: 0.012689709981230271
Test error at (after) epoch 800: 0.010605814172373931
----------
Error at epoch 900 is 5.074881076762715
Train mean error at (after) epoch 900: 0.012687202691906787
Test error at (after) epoch 900: 0.010603123084511206
----------
Error at epoch 1000 is 5.0739075930737485
Train mean error at (after) epoch 1000: 0.01268476898268437
Test error at (after) epoch 1000: 0.01060132923951792
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.9334698532695758
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.23037653982789297
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.8970425468615338
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.3702045990388782
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.9807072220456736
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.9796092568245083
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.35767389446658615
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.6603548913200131
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.9756520339891733
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6468882739275393
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.9205048078458304
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.8356623744972289
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.8401103020540389
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.9647764180674613
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.87883318194003
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.7203929259462862
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.8641333819894387
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.5441772373189824
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.40583399662714575
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.7049865087348226
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.8348004462562527
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.74558184985838
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.9138157508723254
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.8460792900608423
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.37797369068801917
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.8804936640364858
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.6056820525717809
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.4784790845118051
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.9402435534021218
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.8531520562585769
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.8726663876931737
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.6382356936179499
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.6455044292927722
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.9711491356144204
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.9281111997706609
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.4008887772384437
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.9643813803858151
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.9554143867414733
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.7051076874420736
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.9898636224897157
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.9164267146699036
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.9484355251670646
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.8970124213543967
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.5090551822804517
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.9405199479949242
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.8708113569426604
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.3181959303343313
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.9004241351957468
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.7044679251439813
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.7458245402131887
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.9910881956620055
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.5049340267864787
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.8118651378491771
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.9931487297373526
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.9710261057298072
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.8993972760513189
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.9653637154571607
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.9834386014114216
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.7519516614358835
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.844250288841822
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.337616358219615
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.2109456003264155
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.32553712533118473
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.875675117038462
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.9817210335954962
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.8883104096026507
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.8474542472728078
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.7327032399482315
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.9778945972867619
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.6030696400095193
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.9001058063157849
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.9425961980556676
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.8923704341569696
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.599280115312812
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.9342803623511025
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.9603670834869913
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.07390894186194943
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.6536856166641423
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.8096091655720262
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.8491375440607001
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.9843469100589723
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.8049620667204681
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.3293219457470361
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.8454801745547695
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.6755204348443697
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.6939281905772783
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.8845316438363917
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.4077848654035219
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.924400690578908
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.5330453575282534
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.182036981622277
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.7119377255959766
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.9577645584956269
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.2670605358901174
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.7997629652144871
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.5177198483138716
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.8744036166131073
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.8236299094070517
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.8716122246853681
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.36459308989530415
---------------------------------------------------------

Hidden units: 12
Epochs: 3000
Learning rate: 0.1

Errors during training:
Error at epoch 1 is 150.90919827730772
Train mean error at (after) epoch 1: 0.37727299569326933
Test error at (after) epoch 1: 0.4351818705685326
----------
Error at epoch 300 is 5.165462551815673
Train mean error at (after) epoch 300: 0.012913656379539182
Test error at (after) epoch 300: 0.011046831161572233
----------
Error at epoch 600 is 5.092251495785543
Train mean error at (after) epoch 600: 0.012730628739463859
Test error at (after) epoch 600: 0.010677659415140782
----------
Error at epoch 900 is 5.0869408395762665
Train mean error at (after) epoch 900: 0.012717352098940666
Test error at (after) epoch 900: 0.010649515274555717
----------
Error at epoch 1200 is 5.082450649968277
Train mean error at (after) epoch 1200: 0.012706126624920693
Test error at (after) epoch 1200: 0.01063826010988229
----------
Error at epoch 1500 is 5.078138795487211
Train mean error at (after) epoch 1500: 0.012695346988718027
Test error at (after) epoch 1500: 0.010629207036602074
----------
Error at epoch 1800 is 5.0739699128805835
Train mean error at (after) epoch 1800: 0.012684924782201458
Test error at (after) epoch 1800: 0.010620940067569782
----------
Error at epoch 2100 is 5.0699182765723405
Train mean error at (after) epoch 2100: 0.012674795691430851
Test error at (after) epoch 2100: 0.01061325576482741
----------
Error at epoch 2400 is 5.0659610689206955
Train mean error at (after) epoch 2400: 0.012664902672301739
Test error at (after) epoch 2400: 0.010606081536312949
----------
Error at epoch 2700 is 5.062077819602804
Train mean error at (after) epoch 2700: 0.01265519454900701
Test error at (after) epoch 2700: 0.010599364756065644
----------
Error at epoch 3000 is 5.058249986492821
Train mean error at (after) epoch 3000: 0.012645624966232052
Test error at (after) epoch 3000: 0.010593060406961024
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.9295362994989126
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.19314983328919907
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.8744900734301945
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.37625143351785795
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.9732141001294894
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.9735342655680628
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.3891355336996031
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.6590193211429114
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.9641025377958009
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6537061823225551
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.9189306631673223
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.8383995499225042
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.8417244282943501
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.9701604440743263
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.8611205844331231
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.7005864424479015
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.8734084639639587
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.523184281942661
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.4028888313884764
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.720325166100648
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.8218941577881147
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.7627720922412985
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.906743222162626
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.8538940208562615
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.3747770967948051
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.8790156045453332
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.5924322967202578
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.48870657937543227
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.9279647034761153
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.8832447222289734
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.8749921226374133
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.6496443416848209
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.6383587001055893
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.9659193512435394
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.9253252701255882
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.4071671860426951
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.9595136890788296
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.9637408487091855
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.6971164345811087
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.9862306347044617
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.9100158373601971
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.9509974425061665
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.8700375555459204
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.5157171623926144
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.9448853518063687
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.8747353340819284
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.31920001063757264
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.9113766157708885
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.6801822720225196
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.7259604270940553
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.9870784074310048
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.492220747237503
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.7948086041901177
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.9900505538683542
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.9728743725477709
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.899775983420894
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.9640695196248686
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.9816672709321824
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.7545935904121042
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.8492174016838624
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.34336617917851237
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.20626588821959496
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.33047932422351683
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.8646439408488953
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.9693476406614617
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.8754583027117816
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.8145287825994639
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.7094076132302221
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.9753163261358033
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.6301343193704162
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.900786980060448
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.9530066752746358
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.8793978580796784
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.581743917621118
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.9211247664230707
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.9636243240885114
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.01807005331461699
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.659500805037138
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.7810037606948584
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.8859286660563483
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.9806644075618267
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.7953863354871882
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.32565323795558365
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.8453430388070768
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.6394878715653427
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.7064928223412417
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.8684703607314535
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.40286760935920096
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.931464934884467
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.5256788202023418
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.18746214199550137
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.7117840656462449
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.9626913213967301
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.2658953510787226
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.8118204709939488
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.5208820558227595
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.8567601813196332
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.8019227190771583
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.8556179013388812
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.3428143728954205
---------------------------------------------------------

Hidden units: 12
Epochs: 10000
Learning rate: 0.1

Errors during training:
Error at epoch 1 is 111.89471857996304
Train mean error at (after) epoch 1: 0.2797367964499076
Test error at (after) epoch 1: 0.3296857681964648
----------
Error at epoch 1000 is 5.053239195830491
Train mean error at (after) epoch 1000: 0.012633097989576228
Test error at (after) epoch 1000: 0.010598424516944366
----------
Error at epoch 2000 is 5.032254480487495
Train mean error at (after) epoch 2000: 0.012580636201218737
Test error at (after) epoch 2000: 0.010562167833171616
----------
Error at epoch 3000 is 5.011776086762134
Train mean error at (after) epoch 3000: 0.012529440216905335
Test error at (after) epoch 3000: 0.010535930598134059
----------
Error at epoch 4000 is 4.990384287750557
Train mean error at (after) epoch 4000: 0.012475960719376393
Test error at (after) epoch 4000: 0.010515437916845276
----------
Error at epoch 5000 is 4.96687985247999
Train mean error at (after) epoch 5000: 0.012417199631199976
Test error at (after) epoch 5000: 0.010498805387031185
----------
Error at epoch 6000 is 4.940066988372375
Train mean error at (after) epoch 6000: 0.012350167470930937
Test error at (after) epoch 6000: 0.010484908815409446
----------
Error at epoch 7000 is 4.908613345295186
Train mean error at (after) epoch 7000: 0.012271533363237965
Test error at (after) epoch 7000: 0.010473149890426794
----------
Error at epoch 8000 is 4.870958354919861
Train mean error at (after) epoch 8000: 0.012177395887299653
Test error at (after) epoch 8000: 0.010463401069534837
----------
Error at epoch 9000 is 4.825291864252191
Train mean error at (after) epoch 9000: 0.012063229660630477
Test error at (after) epoch 9000: 0.010456086094854416
----------
Error at epoch 10000 is 4.769674898525657
Train mean error at (after) epoch 10000: 0.011924187246314142
Test error at (after) epoch 10000: 0.010452356159513829
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.8796623917702496
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.2504452915504777
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.8633035127840439
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.37984313541739523
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.9555999318382171
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.934769203592016
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.39787271946205494
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.6573097522812285
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.9516963745483462
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6335548702766156
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.9147421647592108
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.8103265183733951
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.8303029675285647
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.9535929859870592
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.8375769963074121
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.7099274593323358
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.8554463539595408
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.5394163173947392
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.4171906499837484
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.6911535537009822
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.8048818669976766
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.7246892972771065
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.8648723587259559
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.815345448460362
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.36438865492205924
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.8690059680803387
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.589259702241036
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.4899409429756984
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.8902306026029395
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.8399696395832756
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.8367233625987849
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.6298700338726464
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.6126961625684613
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.9271644143445985
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.9002040916260614
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.4135353903344627
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.9438779590596728
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.9136731479345545
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.7000706761477138
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.9487968753328866
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.8920107099585953
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.9223031773334943
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.8525983239962227
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.5072092461296713
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.9299817965474544
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.8290425484889897
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.30961873082695507
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.8557870170749899
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.7121289201747957
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.7311030070182769
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.951410541369774
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.5026337867621176
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.7801552321187963
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.9734114982409473
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.9263620260350723
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.9013400695523477
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.9420936257082195
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.9600736052073572
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.7228603104053474
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.8292378251774504
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.3528630678198295
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.20946290234153386
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.3324552080121059
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.8385660236087783
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.9582177713436081
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.8808687357916521
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.8247889129355833
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.716652555321397
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.9581216371542705
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.6125769142809655
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.8458224856315141
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.9021670589454718
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.8570028345934951
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.5972918811007654
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.8869968193539088
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.9131257456348536
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.08827617934351785
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.6410760431123621
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.782299110896181
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.842942051902147
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.9395823921397102
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.7660860035704069
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.3511120396547453
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.8069136622706096
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.6675011772178302
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.6928878251789299
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.8423902895488533
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.4077261303158987
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.9064847376116573
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.541895723215051
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.2126646726369506
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.7059780151256798
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.9099644370982968
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.2781184761399144
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.7961258091310738
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.5184908755187058
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.8307436173912466
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.7845132578404337
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.8324065128884593
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.3555638698393623
---------------------------------------------------------

Hidden units: 12
Epochs: 100
Learning rate: 0.3

Errors during training:
Error at epoch 1 is 75.95708034873961
Train mean error at (after) epoch 1: 0.18989270087184904
Test error at (after) epoch 1: 0.20142134630234845
----------
Error at epoch 10 is 28.629013572139858
Train mean error at (after) epoch 10: 0.07157253393034964
Test error at (after) epoch 10: 0.07860216287221312
----------
Error at epoch 20 is 13.80884784324227
Train mean error at (after) epoch 20: 0.034522119608105674
Test error at (after) epoch 20: 0.03613236818099734
----------
Error at epoch 30 is 8.920784005865347
Train mean error at (after) epoch 30: 0.022301960014663367
Test error at (after) epoch 30: 0.021915920561246898
----------
Error at epoch 40 is 6.9819898376347975
Train mean error at (after) epoch 40: 0.017454974594086993
Test error at (after) epoch 40: 0.016273930170037306
----------
Error at epoch 50 is 6.097756317570192
Train mean error at (after) epoch 50: 0.01524439079392548
Test error at (after) epoch 50: 0.013696653607122826
----------
Error at epoch 60 is 5.654828716574013
Train mean error at (after) epoch 60: 0.014137071791435031
Test error at (after) epoch 60: 0.012397771270068952
----------
Error at epoch 70 is 5.418276508598067
Train mean error at (after) epoch 70: 0.013545691271495169
Test error at (after) epoch 70: 0.011696331831357525
----------
Error at epoch 80 is 5.286071989065839
Train mean error at (after) epoch 80: 0.013215179972664597
Test error at (after) epoch 80: 0.011297893538661676
----------
Error at epoch 90 is 5.20967271755825
Train mean error at (after) epoch 90: 0.013024181793895624
Test error at (after) epoch 90: 0.011062639264313178
----------
Error at epoch 100 is 5.164374748201708
Train mean error at (after) epoch 100: 0.01291093687050427
Test error at (after) epoch 100: 0.01091935112108203
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.915808180523074
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.22930518874980704
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.8911618815877996
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.3557798503079696
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.9690555993667954
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.9687833001868755
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.3757154423389224
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.6290599993892634
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.9609950111150507
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6244253733842058
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.9223002093865592
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.8328618029244774
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.8181969403902185
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.9438639201876257
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.8687431729621402
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.6749162651063825
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.8517846110796016
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.5219904062152263
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.39890267069748603
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.6844096198413667
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.7877726046994703
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.7343455788052236
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.9020747282818202
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.817668829696851
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.34527836567757203
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.8715941341237832
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.5836001301210235
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.44979911338734724
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.9283866420890424
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.8335058381545413
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.8663999613071133
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.5815060659385571
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.6730634147635639
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.9555955012064632
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.9133282381122663
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.3848799661401673
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.9603273074925969
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.9434191223373342
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.6664589574530622
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.9854255526578104
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.8898766527491424
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.9328878049132686
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.8803488575573776
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.47387378516942336
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.9147624702575037
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.8503133521991237
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.3015875636276259
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.879005020319158
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.6907512620659889
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.7135386738059675
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.9889416976867956
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.4741393196933626
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.7830433443539875
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.9889766838134765
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.9615901122788788
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.9013110142843512
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.9569942889796629
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.9766348267064185
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.7361143776748337
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.8148160066935458
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.31337565702469755
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.1817469306593731
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.3118350649614249
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.8327278646898931
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.9739994518918137
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.8766026293710281
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.8428146366215628
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.6998464088918727
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.9745619346491022
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.6018323043806882
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.8740526996208627
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.9286977745754662
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.8556003973890316
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.5709191237248311
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.9016911979168969
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.9491832770118978
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.08976097376994198
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.6434508756452598
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.7887723132831248
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.8397666219323742
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.9777140071831669
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.7864245527355861
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.34882749694157933
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.8189018530320732
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.6562762615086496
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.6534763499394451
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.8753519485287106
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.4288279159767902
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.9093982928890958
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.53475835697329
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.28135559476301997
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.6357425566069611
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.9430532743936925
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.27114664734318367
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.7866839363666109
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.4887845549889084
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.8467302972760784
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.7996727662673087
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.8627251699861922
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.3407524566022213
---------------------------------------------------------

Hidden units: 12
Epochs: 1000
Learning rate: 0.3

Errors during training:
Error at epoch 1 is 94.26106102882812
Train mean error at (after) epoch 1: 0.2356526525720703
Test error at (after) epoch 1: 0.2279854583107196
----------
Error at epoch 100 is 5.140415145470224
Train mean error at (after) epoch 100: 0.01285103786367556
Test error at (after) epoch 100: 0.010877671406549508
----------
Error at epoch 200 is 5.076985611122069
Train mean error at (after) epoch 200: 0.012692464027805172
Test error at (after) epoch 200: 0.010599184524023274
----------
Error at epoch 300 is 5.072668539019786
Train mean error at (after) epoch 300: 0.012681671347549465
Test error at (after) epoch 300: 0.010581903228969878
----------
Error at epoch 400 is 5.068895164989624
Train mean error at (after) epoch 400: 0.012672237912474061
Test error at (after) epoch 400: 0.010575944630722343
----------
Error at epoch 500 is 5.065128957982578
Train mean error at (after) epoch 500: 0.012662822394956445
Test error at (after) epoch 500: 0.010571312868737215
----------
Error at epoch 600 is 5.06134831611538
Train mean error at (after) epoch 600: 0.01265337079028845
Test error at (after) epoch 600: 0.010567089225823065
----------
Error at epoch 700 is 5.057537485987576
Train mean error at (after) epoch 700: 0.01264384371496894
Test error at (after) epoch 700: 0.010563154611583352
----------
Error at epoch 800 is 5.053681168576632
Train mean error at (after) epoch 800: 0.01263420292144158
Test error at (after) epoch 800: 0.010559473815140772
----------
Error at epoch 900 is 5.04976424858663
Train mean error at (after) epoch 900: 0.012624410621466575
Test error at (after) epoch 900: 0.010556023056407142
----------
Error at epoch 1000 is 5.045771594338097
Train mean error at (after) epoch 1000: 0.012614428985845243
Test error at (after) epoch 1000: 0.010552782180523967
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.922233782179769
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.23391295547612284
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.9045961977274861
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.37788560571640223
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.9723448786533634
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.9702227782490139
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.36197067644463
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.6628656600150559
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.9652218853596625
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6393136212088396
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.9305602520705623
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.842840933368426
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.8365516934896283
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.9531925913080447
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.8771839856834476
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.7002482358725252
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.8670125212616846
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.5717814840548506
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.4058252637111854
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.7161190070753299
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.8116054421341999
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.7491689155779383
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.9070491144958756
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.8328649398071559
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.3737605077067776
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.8837226016330598
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.5975077018775169
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.4872060441945709
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.9322555391654225
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.841056244422223
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.8769316189262059
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.604421385242172
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.6440950425885852
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.9594165877600082
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.9191089007291195
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.4144948523707988
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.9637700248516066
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.9509561510680923
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.6901805389900513
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.9844873120759563
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.9054393213902294
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.9426096161623799
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.8877578096766962
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.5126772019364304
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.9284407682222223
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.8578544124328439
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.320116548097419
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.8938332371676648
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.7141152547946712
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.7357735862434923
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.9884416824428205
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.4998233189334493
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.8066638007906505
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.9893484145568396
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.9652251859930134
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.9119476686315875
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.9613633292701733
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.9785608484430629
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.749267645009613
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.8489840465730192
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.3452724233575488
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.2193647424348691
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.3204564946577259
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.8512781271589012
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.9755144152199633
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.8967217374334501
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.8622025087896192
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.7168370566038769
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.9774191522378923
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.6068655926324736
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.8803726181740488
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.9378177354400576
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.8812497291517682
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.5920836104167153
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.915469776341534
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.9534193620723503
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.09437773379372393
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.6577803254257776
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.803684487176319
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.8429857462043021
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.9771327998915698
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.7982077841002159
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.34515816398180327
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.8332117051880557
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.6991076528114722
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.6904289023113801
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.8827815051270672
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.3912989467238115
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.922749667440784
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.5543773886338313
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.18745960529963115
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.7000283152971111
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.9504589770603757
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.2685724764170781
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.8045765561715678
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.5195296150594695
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.8568539173220997
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.8124155633662948
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.872359831718349
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.37276405056677747
---------------------------------------------------------

Hidden units: 12
Epochs: 3000
Learning rate: 0.3

Errors during training:
Error at epoch 1 is 146.13625883738615
Train mean error at (after) epoch 1: 0.36534064709346536
Test error at (after) epoch 1: 0.35923568846981935
----------
Error at epoch 300 is 4.993509802275109
Train mean error at (after) epoch 300: 0.012483774505687772
Test error at (after) epoch 300: 0.010497389877575982
----------
Error at epoch 600 is 4.973172745294763
Train mean error at (after) epoch 600: 0.012432931863236907
Test error at (after) epoch 600: 0.01049172745586506
----------
Error at epoch 900 is 4.950165268269599
Train mean error at (after) epoch 900: 0.012375413170673998
Test error at (after) epoch 900: 0.010487291365487195
----------
Error at epoch 1200 is 4.923613720320874
Train mean error at (after) epoch 1200: 0.012309034300802183
Test error at (after) epoch 1200: 0.010482917405278831
----------
Error at epoch 1500 is 4.892559190061192
Train mean error at (after) epoch 1500: 0.01223139797515298
Test error at (after) epoch 1500: 0.010478742564144463
----------
Error at epoch 1800 is 4.855944157097666
Train mean error at (after) epoch 1800: 0.012139860392744164
Test error at (after) epoch 1800: 0.010474953752930784
----------
Error at epoch 2100 is 4.812635184278018
Train mean error at (after) epoch 2100: 0.012031587960695044
Test error at (after) epoch 2100: 0.010471727998976022
----------
Error at epoch 2400 is 4.76144831547286
Train mean error at (after) epoch 2400: 0.01190362078868215
Test error at (after) epoch 2400: 0.010469024683543875
----------
Error at epoch 2700 is 4.701056899589877
Train mean error at (after) epoch 2700: 0.011752642248974692
Test error at (after) epoch 2700: 0.010466074416389939
----------
Error at epoch 3000 is 4.629463274067037
Train mean error at (after) epoch 3000: 0.011573658185167592
Test error at (after) epoch 3000: 0.010460343555873568
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.8770160625608849
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.24943265259219333
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.8445908450903219
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.38316922783221496
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.9516033368736322
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.9170922726287383
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.40093485785091054
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.6550233295974478
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.9435857391151099
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.634105444694473
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.907764934492581
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.7961476626649934
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.8245856765937734
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.9443589149087013
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.8184624952040617
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.7016603308243196
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.8511725714883281
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.5615195031155882
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.41751290050482165
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.7005619731173489
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.784545263273464
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.7139939219827373
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.8531170678871571
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.7971474386114644
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.3693979780065901
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.8622849302808753
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.579042542827138
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.48748792350325604
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.8751289261042271
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.8240434485225906
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.8146665363912381
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.6311426107699942
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.6616470430870737
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.9065464483487784
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.9088103389688389
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.42297325063770796
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.9362049642259083
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.8998376698957542
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.6973925588840915
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.9322209802865277
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.8918743972787251
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.9322318981021495
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.8294629092745849
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.5149650742592646
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.9211178108155678
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.8279181820735719
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.3132471936739903
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.8546631367905557
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.7215076814752527
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.7279751643300246
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.9245463081504516
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.5010554614963526
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.7641260502153048
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.9660780122270198
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.9121734840031411
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.8946694998975718
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.939046334401898
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.9581959518863052
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.7178670033257292
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.8493551789939636
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.34930402910960223
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.22904616112491472
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.3360131298781708
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.8194039325134749
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.950235903800172
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.8711183974981256
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.8078475033513621
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.6953222622242179
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.9483290492343684
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.6081466300473951
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.8585221428230396
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.8886945982502548
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.838786897037927
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.5980844327708348
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.8722230316943512
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.9061397957361876
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.07213590174371128
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.6338230650464409
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.764152384840288
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.8303685830432667
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.9277307806141264
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.753922094263927
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.3491116225926157
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.7932717574363217
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.6619241104321598
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.7013704921040085
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.8225772739115228
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.43032407373682624
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.9071310322188022
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.5386662180409609
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.21813413758468145
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.706647128246094
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.9058939334002738
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.2905892688218274
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.7933923555443504
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.5162815573660593
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.8093865088398509
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.7669207347737891
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.8101964743757555
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.3600908634209662
---------------------------------------------------------

Hidden units: 12
Epochs: 10000
Learning rate: 0.3

Errors during training:
Error at epoch 1 is 115.51486368548397
Train mean error at (after) epoch 1: 0.28878715921370995
Test error at (after) epoch 1: 0.28605872620837347
----------
Error at epoch 1000 is 5.007495852996244
Train mean error at (after) epoch 1000: 0.01251873963249061
Test error at (after) epoch 1000: 0.010521223889117227
----------
Error at epoch 2000 is 4.957097329139052
Train mean error at (after) epoch 2000: 0.01239274332284763
Test error at (after) epoch 2000: 0.010534869833594543
----------
Error at epoch 3000 is 4.8781168056948205
Train mean error at (after) epoch 3000: 0.01219529201423705
Test error at (after) epoch 3000: 0.010561126042111006
----------
Error at epoch 4000 is 4.718766387312795
Train mean error at (after) epoch 4000: 0.011796915968281987
Test error at (after) epoch 4000: 0.010611383743510935
----------
Error at epoch 5000 is 4.338788223773641
Train mean error at (after) epoch 5000: 0.0108469705594341
Test error at (after) epoch 5000: 0.010728020335813803
----------
Error at epoch 6000 is 3.610900417662547
Train mean error at (after) epoch 6000: 0.009027251044156368
Test error at (after) epoch 6000: 0.010367136709111845
----------
Error at epoch 7000 is 2.7831423153579498
Train mean error at (after) epoch 7000: 0.006957855788394874
Test error at (after) epoch 7000: 0.008487528151952107
----------
Error at epoch 8000 is 2.270637717379982
Train mean error at (after) epoch 8000: 0.0056765942934499545
Test error at (after) epoch 8000: 0.0070688836596181255
----------
Error at epoch 9000 is 1.9669659764964567
Train mean error at (after) epoch 9000: 0.004917414941241142
Test error at (after) epoch 9000: 0.006126137480844469
----------
Error at epoch 10000 is 1.7712968569582206
Train mean error at (after) epoch 10000: 0.004428242142395552
Test error at (after) epoch 10000: 0.0054086132589856685
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.8272751642402641
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.38772018579765555
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.8563663110961571
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.42890226871994286
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.7794225012023989
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.7583639833828713
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.49508691985953146
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.6891904067238168
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.8052056437351076
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6832425965623197
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.8768377017415875
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.8268904900619621
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.8042814107045192
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.8027129529002122
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.8274204844843279
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.742108358376527
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.820579071346052
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.5561398760345441
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.45159611737190586
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.7762027074601832
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.8743599969370245
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.7520484118659905
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.8169556010592922
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.8236572692171151
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.41004349830132425
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.8285722735728389
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.63009878750342
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.5188655953599758
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.8226911855968131
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.8360316738890902
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.8303260192416038
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.6745761734080779
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.7123749417986017
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.812751735501909
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.8613921675251551
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.49997710773754406
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.8112096993565249
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.7479974983288074
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.7225359357651248
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.5138200551532582
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.8439762272381232
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.8714771013213415
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.8455846105099063
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.5326459017112013
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.8409041429185895
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.8232006934001806
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.34974818744552333
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.8160208262962193
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.7194572825327082
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.7322781633621916
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.4859776687834349
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.5274633022108393
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.7879892026980294
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.44132001392348436
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.7128319954391493
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.8867445629937958
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.8075527556730822
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.7572326390469017
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.7469181344124556
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.8252167348891455
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.36196415486785166
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.21325194083079244
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.36982289337398255
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.8813807677467113
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.762690982802139
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.8466592654646421
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.841939192566499
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.7645340599275492
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.7521355143217079
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.6599362295324043
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.8342340398455826
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.7774611312896609
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.8787490001815594
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.6117661544056971
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.89657815953697
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.802000592522537
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.032714916346063445
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.6869903033432359
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.7926192496075878
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.8279655192548084
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.6709676445621233
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.775721799725056
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.4289084519908694
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.8125697024032089
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.7150744908248661
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.7015455727258466
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.8301427592140029
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.4778534599161589
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.8353974516066703
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.613311629807915
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.3069673542486057
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.7217994804359408
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.8085613519449465
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.31191829036018776
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.7918508968303699
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.5886130459791536
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.8375601655194078
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.795605956583864
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.8329276710099874
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.41475032255607547
---------------------------------------------------------

Hidden units: 12
Epochs: 100
Learning rate: 0.5

Errors during training:
Error at epoch 1 is 103.51945958295485
Train mean error at (after) epoch 1: 0.25879864895738713
Test error at (after) epoch 1: 0.25164518213206755
----------
Error at epoch 10 is 21.7306511263867
Train mean error at (after) epoch 10: 0.05432662781596675
Test error at (after) epoch 10: 0.05462001122386596
----------
Error at epoch 20 is 8.86239953737026
Train mean error at (after) epoch 20: 0.022155998843425652
Test error at (after) epoch 20: 0.02105439681246157
----------
Error at epoch 30 is 6.308190923925977
Train mean error at (after) epoch 30: 0.015770477309814943
Test error at (after) epoch 30: 0.014124885239806696
----------
Error at epoch 40 is 5.558483615163426
Train mean error at (after) epoch 40: 0.013896209037908565
Test error at (after) epoch 40: 0.012016179429488466
----------
Error at epoch 50 is 5.290929344966656
Train mean error at (after) epoch 50: 0.013227323362416641
Test error at (after) epoch 50: 0.011227387706855078
----------
Error at epoch 60 is 5.184426315093965
Train mean error at (after) epoch 60: 0.012961065787734913
Test error at (after) epoch 60: 0.010892933010942806
----------
Error at epoch 70 is 5.139007176705047
Train mean error at (after) epoch 70: 0.012847517941762619
Test error at (after) epoch 70: 0.01073806837101845
----------
Error at epoch 80 is 5.118619788519781
Train mean error at (after) epoch 80: 0.012796549471299452
Test error at (after) epoch 80: 0.010661126435821185
----------
Error at epoch 90 is 5.109007986163234
Train mean error at (after) epoch 90: 0.012772519965408085
Test error at (after) epoch 90: 0.010620442157615356
----------
Error at epoch 100 is 5.10418744694683
Train mean error at (after) epoch 100: 0.012760468617367076
Test error at (after) epoch 100: 0.010597635601618758
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.9289767955670534
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.24684589785031497
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.891259796995384
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.3745872379339862
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.9721419694372203
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.9749950023970276
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.3461661151189257
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.658690913939067
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.9660316146055647
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6468879921607806
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.9359618996758212
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.8546669927628929
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.8431313287200689
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.9612189040465002
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.8748803171964185
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.706920331135168
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.8765510591650091
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.5512797857680638
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.4078179553100136
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.6853043780830841
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.8189381730244085
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.7623594960065999
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.9086946742373184
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.8406818675520311
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.36434852604104845
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.8917428390992729
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.6018574024145308
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.4461726212185865
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.9282049605334864
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.8411605691891395
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.8899970065193318
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.6208028123479208
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.6392242178774085
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.967276688680463
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.9166078108411139
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.43058476000676443
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.9676578646276616
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.9611590967371267
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.6900694511955744
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.9875482942214365
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.9101461853461789
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.9469670920410237
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.8879281235848278
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.5005866090962108
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.934916758236355
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.8686872766520436
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.3155399921700854
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.9069399976933539
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.7011952341313632
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.7241020044719324
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.9914792038048619
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.49532561762922545
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.7789930098818136
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.991306888832384
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.9733674124368308
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.918504862810599
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.9661228522874515
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.9816330148364815
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.7572829595655793
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.8478097973670369
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.32418331784478815
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.20246288593261866
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.31583538474999795
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.8617597320183515
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.972672376521989
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.9019461489184606
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.850247000592316
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.712791723382306
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.981955929185107
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.6007699450991262
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.8892631029696962
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.9487239357171112
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.852245964018082
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.5834664457764761
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.9150755528231882
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.9630645796739784
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.05975076875924536
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.6667359227629359
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.7852424406121127
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.8424175281038822
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.9807934097828555
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.8010115715847271
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.33224772044773176
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.8442529343901368
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.6972046805346087
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.6895055623971248
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.8840045660394579
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.39437184060190617
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.930475497887571
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.559583865153742
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.2034600264090408
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.671865455974338
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.9602111981156652
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.2759167221341695
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.8139006139015434
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.5013655601338144
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.8640991481901641
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.8059853902397033
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.8783976880172248
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.36823416343701265
---------------------------------------------------------

Hidden units: 12
Epochs: 1000
Learning rate: 0.5

Errors during training:
Error at epoch 1 is 82.69031066950586
Train mean error at (after) epoch 1: 0.20672577667376466
Test error at (after) epoch 1: 0.18811711422755958
----------
Error at epoch 100 is 5.1028464581663
Train mean error at (after) epoch 100: 0.01275711614541575
Test error at (after) epoch 100: 0.010571487158116651
----------
Error at epoch 200 is 5.097624825812907
Train mean error at (after) epoch 200: 0.012744062064532267
Test error at (after) epoch 200: 0.010543353260294687
----------
Error at epoch 300 is 5.094656552620714
Train mean error at (after) epoch 300: 0.012736641381551785
Test error at (after) epoch 300: 0.010540012063785204
----------
Error at epoch 400 is 5.0918010144333605
Train mean error at (after) epoch 400: 0.012729502536083402
Test error at (after) epoch 400: 0.010537374641267937
----------
Error at epoch 500 is 5.0890323359976435
Train mean error at (after) epoch 500: 0.012722580839994108
Test error at (after) epoch 500: 0.010535017655442824
----------
Error at epoch 600 is 5.0863294185242545
Train mean error at (after) epoch 600: 0.012715823546310637
Test error at (after) epoch 600: 0.010532895268092876
----------
Error at epoch 700 is 5.083674220142106
Train mean error at (after) epoch 700: 0.012709185550355264
Test error at (after) epoch 700: 0.01053097609123404
----------
Error at epoch 800 is 5.081051054234384
Train mean error at (after) epoch 800: 0.01270262763558596
Test error at (after) epoch 800: 0.01052923444552182
----------
Error at epoch 900 is 5.078446048007408
Train mean error at (after) epoch 900: 0.01269611512001852
Test error at (after) epoch 900: 0.010527649102133956
----------
Error at epoch 1000 is 5.075846718857366
Train mean error at (after) epoch 1000: 0.012689616797143415
Test error at (after) epoch 1000: 0.010526202420739863
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.9306149770849534
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.22677630372937496
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.9058984029033118
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.37842714163024777
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.9744826214543852
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.974984085505508
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.35674236946666454
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.6542324060708039
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.9674802289607684
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6395185434331493
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.9334342094549357
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.8438254581238466
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.8390287339450772
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.9673290152781184
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.8765894676278626
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.6965491603713533
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.8713043862068858
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.5765368108829896
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.41574037404631126
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.6971308659909241
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.8117346805820215
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.7542958146374968
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.9077616458974406
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.8433028321839896
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.3669497550645838
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.8856813743849609
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.5948616070828848
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.46062630386019
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.9314146987222095
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.861679637410422
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.880776436981618
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.6253078640738067
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.6484235571367221
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.9667762551822623
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.9239645202026231
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.4192555904803722
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.9674616708345319
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.9648862647103633
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.6887000972725703
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.988180631505752
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.9102993392591064
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.9558808354356377
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.8915906567145512
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.5182656879395953
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.9398927828146174
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.8689809180487912
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.3160384544153062
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.9113721154204731
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.7305826134027246
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.7291224647097216
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.9916881606054124
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.4980715033963276
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.7951054853382191
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.9922952440484023
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.974824667700498
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.9148278811059103
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.9669842532660526
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.9838791633454288
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.7484777569723666
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.8673458456995187
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.32643781777623576
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.20887292778707192
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.32039318655874377
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.856109153943285
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.9774009154832607
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.8990239398038663
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.8726646083604912
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.7155400850308482
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.9816875000243469
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.6175523162698702
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.9029367537346252
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.9533340090923339
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.870153245341936
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.5940327568345026
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.914892398235261
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.9654287038398722
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.057861458873209884
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.6535055528361143
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.8052671893437453
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.8685239953006612
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.981976814867884
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.794885899677466
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.3493434776698892
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.8417199583396955
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.7073997647871549
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.7008716002814012
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.8832460981648868
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.39834631719576546
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.9328360722385187
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.5529068355480935
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.20843108923430492
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.6854322540828182
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.9652059653379814
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.28139643898837285
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.8064821342005215
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.5064417133035636
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.8603284931967451
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.8079084760190122
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.8751099198926787
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.37029995210670585
---------------------------------------------------------

Hidden units: 12
Epochs: 3000
Learning rate: 0.5

Errors during training:
Error at epoch 1 is 101.99703537822852
Train mean error at (after) epoch 1: 0.25499258844557127
Test error at (after) epoch 1: 0.23335529107534062
----------
Error at epoch 300 is 5.0324412619763255
Train mean error at (after) epoch 300: 0.012581103154940813
Test error at (after) epoch 300: 0.01058013948944487
----------
Error at epoch 600 is 4.996383663416723
Train mean error at (after) epoch 600: 0.012490959158541808
Test error at (after) epoch 600: 0.010567019417446491
----------
Error at epoch 900 is 4.952802958853031
Train mean error at (after) epoch 900: 0.012382007397132577
Test error at (after) epoch 900: 0.010561818778915886
----------
Error at epoch 1200 is 4.894157311466644
Train mean error at (after) epoch 1200: 0.012235393278666611
Test error at (after) epoch 1200: 0.010563784420375815
----------
Error at epoch 1500 is 4.808784634743701
Train mean error at (after) epoch 1500: 0.012021961586859253
Test error at (after) epoch 1500: 0.01057468386079413
----------
Error at epoch 1800 is 4.678737232905185
Train mean error at (after) epoch 1800: 0.011696843082262962
Test error at (after) epoch 1800: 0.010598860371263365
----------
Error at epoch 2100 is 4.482283193336452
Train mean error at (after) epoch 2100: 0.011205707983341131
Test error at (after) epoch 2100: 0.010633642225136472
----------
Error at epoch 2400 is 4.198154190743827
Train mean error at (after) epoch 2400: 0.010495385476859567
Test error at (after) epoch 2400: 0.010613233225249635
----------
Error at epoch 2700 is 3.7875753835060415
Train mean error at (after) epoch 2700: 0.009468938458765104
Test error at (after) epoch 2700: 0.01030103147880167
----------
Error at epoch 3000 is 3.2965388255813415
Train mean error at (after) epoch 3000: 0.008241347063953354
Test error at (after) epoch 3000: 0.009463192708766976
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.7883336367495561
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.2942641260276168
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.8152224098146652
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.4157408663893058
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.8420798799483518
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.7832050218557755
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.4321609465458417
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.6862153204580054
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.8611391038546966
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6396839234886234
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.8139048575055603
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.751673750017189
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.7991042126125029
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.8485081642981502
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.7988943877182464
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.7326099512072743
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.7995111651230601
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.5733147121505269
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.47072491202220934
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.7536613658685422
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.8230829086740118
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.7091438898392065
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.7851043113534638
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.7919858893813236
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.41396395495917143
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.8115114108543516
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.6277811654088049
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.5327608151272137
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.8063566623353213
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.8067115148798109
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.7810547203072616
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.6421614299828339
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.6804683051856965
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.8042429775505863
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.8183730012250605
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.5109108768498715
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.820494498153809
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.7526529157030486
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.7206318608613357
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.6932943654505679
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.8362717973487254
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.8037353064161782
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.8270408620685541
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.5428376165081416
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.8583945098950516
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.7475157652890836
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.35607231248166005
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.7472173303068196
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.7370386687147815
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.7371652991394947
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.6785776958610268
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.5394651036469145
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.7831328442559637
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.7460372678048288
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.7372397666663214
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.80809724042056
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.8100508658171245
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.7806850896860624
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.7063538279188609
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.7889546427033147
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.3923575395118132
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.24060859645183683
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.3749062789805588
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.828876327249093
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.8501922982701626
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.8355467678308754
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.8176410722972877
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.7478611386270239
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.8029330159602583
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.6380446159822175
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.7487101243673572
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.768504966723761
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.8503617317465403
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.6291149420766315
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.8534448082079183
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.7185129465109134
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.09405256217996963
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.6496204210773568
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.7954991745914303
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.8005897351751186
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.7288643231347081
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.7499969855205879
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.39844202196165707
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.7783155693236856
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.7203045149335863
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.7023121988340251
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.7987597366612089
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.4660703519223965
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.8122965928447134
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.591137717414326
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.2892445500878345
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.7454770205410229
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.7169905195191203
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.3221813267811637
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.7647628223459929
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.5505138780032902
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.8107236030301015
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.7811047646852982
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.7988922399017824
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.412090859766676
---------------------------------------------------------

Hidden units: 12
Epochs: 10000
Learning rate: 0.5

Errors during training:
Error at epoch 1 is 111.25116206691095
Train mean error at (after) epoch 1: 0.27812790516727737
Test error at (after) epoch 1: 0.1977598882188478
----------
Error at epoch 1000 is 4.86847140438258
Train mean error at (after) epoch 1000: 0.01217117851095645
Test error at (after) epoch 1000: 0.01050955444958148
----------
Error at epoch 2000 is 4.237640430518334
Train mean error at (after) epoch 2000: 0.010594101076295834
Test error at (after) epoch 2000: 0.010385076901690122
----------
Error at epoch 3000 is 2.644582263263985
Train mean error at (after) epoch 3000: 0.006611455658159963
Test error at (after) epoch 3000: 0.0078283936036443
----------
Error at epoch 4000 is 1.84047309009236
Train mean error at (after) epoch 4000: 0.0046011827252309
Test error at (after) epoch 4000: 0.005702976631132864
----------
Error at epoch 5000 is 0.7872497792607905
Train mean error at (after) epoch 5000: 0.0019681244481519764
Test error at (after) epoch 5000: 0.00253054684670174
----------
Error at epoch 6000 is 0.3738157931806342
Train mean error at (after) epoch 6000: 0.0009345394829515855
Test error at (after) epoch 6000: 0.001110875732244336
----------
Error at epoch 7000 is 0.3055487972999758
Train mean error at (after) epoch 7000: 0.0007638719932499395
Test error at (after) epoch 7000: 0.0008525702745460252
----------
Error at epoch 8000 is 0.2867714754756432
Train mean error at (after) epoch 8000: 0.0007169286886891079
Test error at (after) epoch 8000: 0.0007879464534280151
----------
Error at epoch 9000 is 0.27628170571854455
Train mean error at (after) epoch 9000: 0.0006907042642963614
Test error at (after) epoch 9000: 0.0007573509639409462
----------
Error at epoch 10000 is 0.26853072747619466
Train mean error at (after) epoch 10000: 0.0006713268186904867
Test error at (after) epoch 10000: 0.0007361007045432475
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.9167440954683108
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.2221669744232857
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.9359328719080988
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.3054370238161533
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.8177636817049108
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.8163130497280463
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.36263925315427126
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.6425187897768614
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.8671217752801802
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6701242459225262
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.9395383419548435
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.89891603113317
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.8745568396939972
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.9053457481697605
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.9065184510890393
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.7176590901115562
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.8999350261479576
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.5554235341901071
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.3364207102251291
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.7786038855199864
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.8880980025621857
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.7849436282969698
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.919588599990664
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.9006094207525794
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.2774432017678759
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.9078322293653942
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.5538601757781583
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.4464036339438308
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.9224902446931991
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.9399646286256138
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.9062903387263574
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.7060256516664014
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.7071586189600281
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.8831352721118851
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.934099830687285
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.3677449342628613
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.8830271619277978
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.8826692100718568
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.7079418733452387
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.4657853333070563
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.9215855265219166
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.9186602675603153
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.9166298252830994
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.4870797906178448
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.9391461234632668
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.9205824560718898
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.22163538418913586
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.9235005343044985
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.7664225487039776
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.7447443076508372
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.25276009320942294
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.41705203593689333
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.8509098211552448
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.18276654599126746
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.8221056443646374
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.945667408555323
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.8816117023045085
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.7230795167920017
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.7854538366758368
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.9070459237130495
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.2657657778596941
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.16858600864181428
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.26495623323865913
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.9178912232174984
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.8098309051749609
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.922358995418977
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.9201441578712042
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.7566355127954724
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.7607993870847289
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.648468111677721
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.9307611677797473
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.9105319201709602
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.9226058399229886
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.5521902653124626
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.9305066701505216
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.8825992522685806
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.043320477383966
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.6531763243287265
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.8570116118316532
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.9446312797572247
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.7002727353535015
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.8284889367607666
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.2901833331861545
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.8820850448888885
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.7527824557923948
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.7476303437053268
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.9086544167770103
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.3669165346689294
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.9225305817743474
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.5274055790428099
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.1501237802603559
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.7534229245582178
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.8812586033460024
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.20957151596986295
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.842180271213327
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.4677466092941791
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.9000091851492541
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.8483329107969255
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.9032111733072402
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.27000961971100623
---------------------------------------------------------

Hidden units: 12
Epochs: 100
Learning rate: 1

Errors during training:
Error at epoch 1 is 143.5856002021095
Train mean error at (after) epoch 1: 0.3589640005052738
Test error at (after) epoch 1: 0.11878719033291299
----------
Error at epoch 10 is 6.602927111055951
Train mean error at (after) epoch 10: 0.016507317777639877
Test error at (after) epoch 10: 0.014852408807509406
----------
Error at epoch 20 is 5.172764097449026
Train mean error at (after) epoch 20: 0.012931910243622564
Test error at (after) epoch 20: 0.011172557798446838
----------
Error at epoch 30 is 5.012891456687718
Train mean error at (after) epoch 30: 0.012532228641719293
Test error at (after) epoch 30: 0.010642470351681395
----------
Error at epoch 40 is 4.985828285304427
Train mean error at (after) epoch 40: 0.012464570713261068
Test error at (after) epoch 40: 0.0105206045239326
----------
Error at epoch 50 is 4.97903654481934
Train mean error at (after) epoch 50: 0.012447591362048349
Test error at (after) epoch 50: 0.010483974510838004
----------
Error at epoch 60 is 4.975750124877055
Train mean error at (after) epoch 60: 0.012439375312192637
Test error at (after) epoch 60: 0.010471162412073616
----------
Error at epoch 70 is 4.973077689831569
Train mean error at (after) epoch 70: 0.012432694224578923
Test error at (after) epoch 70: 0.010466526666305495
----------
Error at epoch 80 is 4.970490043169345
Train mean error at (after) epoch 80: 0.012426225107923364
Test error at (after) epoch 80: 0.010465088319315943
----------
Error at epoch 90 is 4.967887202885418
Train mean error at (after) epoch 90: 0.012419718007213545
Test error at (after) epoch 90: 0.010464997315870765
----------
Error at epoch 100 is 4.965249218560306
Train mean error at (after) epoch 100: 0.012413123046400765
Test error at (after) epoch 100: 0.01046550184768854
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.9126614412929438
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.23887537790058078
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.8900010487688399
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.37692554177444054
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.9620147180259312
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.960760412193242
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.38081533158924413
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.6484165956367385
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.9552344298921669
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6386763524773919
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.9166130560335983
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.830070387287342
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.822639594256721
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.9502162466539558
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.8603379876145688
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.7032970687557297
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.8524242410353976
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.5694994133521593
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.41289096522800156
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.7090216994870511
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.821652251845836
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.7385536547577191
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.8906149261493087
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.8261082591615652
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.3676229561387565
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.8669150877648082
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.5903260228896311
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.4788680931457279
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.915713785189347
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.843847644999026
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.858396782631181
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.6307982371281762
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.650698703643527
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.9514960528703604
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.9058449595281275
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.42566918389753533
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.9496872573459978
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.9435406822939927
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.6872857797070943
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.9749851892724459
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.8972375751589595
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.9338027581994066
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.8744379987994142
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.5178403487620269
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.9223828540095232
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.8529204137983262
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.3202579166531149
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.8876732031237302
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.719827949289405
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.725056256425735
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.9794365018015648
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.49642095647367984
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.7915042925557904
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.9814132933113338
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.9562476815790345
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.9003744578567114
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.9488702877100554
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.9686748136309132
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.7375962478543912
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.8450931274917336
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.3384542914502776
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.21415739689442886
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.31977441573431886
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.8575336102589131
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.9637884428257547
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.8780270610834205
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.8538460477980131
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.7173311962140927
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.9654873561885409
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.6171593919475731
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.8799236967943612
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.9310336458935299
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.871285110569898
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.5915849813465792
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.9121814208794808
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.9439017927657576
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.08691465172785576
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.6472976267201416
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.7966826339333402
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.8506187355652685
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.9669487522722763
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.7827925032251274
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.3496812244389238
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.825922700206767
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.6931496299270963
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.6923468847340474
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.865696899349342
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.4068209558007012
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.911817925326142
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.550204025181629
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.19959215036237204
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.6791352815445295
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.9425681815070517
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.28177257626786933
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.7914300044928936
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.5124485891492824
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.8470448717715933
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.7991781678009496
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.8551044101948497
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.36341032581057475
---------------------------------------------------------

Hidden units: 12
Epochs: 1000
Learning rate: 1

Errors during training:
Error at epoch 1 is 75.84756267509655
Train mean error at (after) epoch 1: 0.1896189066877414
Test error at (after) epoch 1: 0.11585223662144113
----------
Error at epoch 100 is 5.066407476507364
Train mean error at (after) epoch 100: 0.01266601869126841
Test error at (after) epoch 100: 0.010572304944011584
----------
Error at epoch 200 is 5.055620706377777
Train mean error at (after) epoch 200: 0.012639051765944442
Test error at (after) epoch 200: 0.010568058893598395
----------
Error at epoch 300 is 5.044753889572574
Train mean error at (after) epoch 300: 0.012611884723931434
Test error at (after) epoch 300: 0.010565784122840823
----------
Error at epoch 400 is 5.033442148336589
Train mean error at (after) epoch 400: 0.012583605370841473
Test error at (after) epoch 400: 0.010564814350628329
----------
Error at epoch 500 is 5.02133261940513
Train mean error at (after) epoch 500: 0.012553331548512825
Test error at (after) epoch 500: 0.010564979123619578
----------
Error at epoch 600 is 5.008045392993343
Train mean error at (after) epoch 600: 0.012520113482483356
Test error at (after) epoch 600: 0.010566176169752344
----------
Error at epoch 700 is 4.9931362781710975
Train mean error at (after) epoch 700: 0.012482840695427743
Test error at (after) epoch 700: 0.010568348196785912
----------
Error at epoch 800 is 4.976053378815493
Train mean error at (after) epoch 800: 0.012440133447038733
Test error at (after) epoch 800: 0.010571468260414274
----------
Error at epoch 900 is 4.956079967065186
Train mean error at (after) epoch 900: 0.012390199917662966
Test error at (after) epoch 900: 0.010575529507784778
----------
Error at epoch 1000 is 4.932254034975029
Train mean error at (after) epoch 1000: 0.01233063508743757
Test error at (after) epoch 1000: 0.010580535924501356
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.8987397426408217
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.23607129768863672
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.8760952305472615
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.37983503131522595
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.9652875352474248
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.954734872324731
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.37787869687256365
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.6585621479021001
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.9607495786530338
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6302608498094975
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.9203715063781331
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.816805214047727
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.8369350130027393
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.9606047637378357
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.8514929302894874
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.7042569520432727
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.8631925831676992
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.5490047840631602
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.42245528115682346
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.6955506813813827
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.8041898752295695
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.7354761345784054
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.8783443427297991
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.8299477182284716
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.37029067552701495
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.8769805966934343
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.595075973553198
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.4770059298940071
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.9053099235322576
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.850106739254645
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.8531657100722078
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.6300699621372335
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.6292636022921637
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.9469040765069885
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.90843902444683
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.42198227125612003
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.9546125136404978
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.9351887562191429
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.7000747638871418
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.9688676660591717
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.90067627546162
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.9349817755661148
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.8717981015147146
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.512339435131753
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.9363872686798039
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.8369743885165406
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.31368682408586057
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.8734104325998346
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.7223005875798371
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.7327867569145354
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.9745477014565704
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.5014010115048203
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.7857164452602884
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.9840380121240968
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.9478974363248195
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.9039538344239333
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.9529435538239583
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.9709673052207808
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.7280227047363809
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.8445565553679656
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.34047592023174267
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.2232357585212896
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.3349730438020671
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.8453207134042897
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.9688996206097675
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.8892563951398311
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.840352705338962
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.7178472202054106
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.9698768031963788
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.6147007243735719
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.8602605151560897
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.9231176049173139
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.861643843022095
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.5994193854196509
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.8981213339501886
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.9301382705152054
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.06497724442424249
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.64205387412263
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.7944979790921348
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.8522471246526552
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.9590003982587803
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.7753369107874715
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.34786944464370795
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.8218864832254004
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.6706740129028625
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.6982119046610965
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.8574348535252322
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.4012018037506809
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.9176466899568653
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.5349848729498747
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.22486513795274057
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.7027037690587958
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.9282399714040492
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.28871574161567365
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.8017232193472283
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.5118582298160461
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.8466033194559258
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.7944347484898822
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.8493988386359723
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.36605334306489673
---------------------------------------------------------

Hidden units: 12
Epochs: 3000
Learning rate: 1

Errors during training:
Error at epoch 1 is 106.33348408726418
Train mean error at (after) epoch 1: 0.26583371021816044
Test error at (after) epoch 1: 0.1883145216253339
----------
Error at epoch 300 is 5.094480171709415
Train mean error at (after) epoch 300: 0.012736200429273536
Test error at (after) epoch 300: 0.01056472722920911
----------
Error at epoch 600 is 5.067887667600589
Train mean error at (after) epoch 600: 0.012669719169001472
Test error at (after) epoch 600: 0.010532970003344355
----------
Error at epoch 900 is 5.04251294733062
Train mean error at (after) epoch 900: 0.01260628236832655
Test error at (after) epoch 900: 0.010517377407337831
----------
Error at epoch 1200 is 5.011110273276127
Train mean error at (after) epoch 1200: 0.012527775683190316
Test error at (after) epoch 1200: 0.010510077471725948
----------
Error at epoch 1500 is 4.964404346482478
Train mean error at (after) epoch 1500: 0.012411010866206195
Test error at (after) epoch 1500: 0.010509517446544308
----------
Error at epoch 1800 is 4.880962571256693
Train mean error at (after) epoch 1800: 0.012202406428141733
Test error at (after) epoch 1800: 0.010517127952784384
----------
Error at epoch 2100 is 4.685999458680102
Train mean error at (after) epoch 2100: 0.011714998646700255
Test error at (after) epoch 2100: 0.010530038277207913
----------
Error at epoch 2400 is 3.989282389167817
Train mean error at (after) epoch 2400: 0.009973205972919542
Test error at (after) epoch 2400: 0.010291364925736396
----------
Error at epoch 2700 is 2.8604934537285995
Train mean error at (after) epoch 2700: 0.007151233634321499
Test error at (after) epoch 2700: 0.008553659124396835
----------
Error at epoch 3000 is 2.386458982654531
Train mean error at (after) epoch 3000: 0.0059661474566363275
Test error at (after) epoch 3000: 0.007321246603174783
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.8161465128754831
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.3640163908315079
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.879861268090298
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.42666298017477455
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.7870850778305161
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.7374510597678173
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.4616319865897186
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.6819607129970255
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.7988521402480023
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6723435231033986
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.8597624022724321
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.8073089331505313
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.7863325854250908
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.8349529557573754
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.8353404718085804
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.6960385523303743
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.7892646117524479
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.6190163578225428
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.478055928653544
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.7666425606824793
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.81091431629886
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.7166314554938716
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.8292482742467105
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.8062352456088907
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.4293668762636703
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.8036347007863786
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.646552095527719
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.5598860067034157
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.8414128220374095
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.8315779770920422
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.7904877036297834
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.627600507936962
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.7349802212972703
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.772645356685814
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.8556154101974758
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.509020638771722
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.7998117462238625
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.7295926972765958
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.7189274794140063
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.6040823607704222
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.8265091473166355
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.8380642080278922
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.8371287566936318
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.5341152861827907
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.8462174310954297
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.8073396246161026
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.3560411235139552
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.7738814178577332
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.7618062380966496
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.7230806001085556
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.5331515583097058
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.5178676467739314
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.8144071282928792
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.5802516423037207
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.7036795350895172
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.8690399655254949
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.791540632368119
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.7458356649054801
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.7452733468709347
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.8319715040578155
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.40771366188662295
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.259207285999328
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.40254087068218886
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.8284472361287081
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.7926868093716226
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.8235572890452552
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.8685386668790682
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.7537670144421811
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.7288886269212014
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.6319488049046771
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.8119505884012764
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.759222837083045
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.8486829422451301
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.6080641342539549
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.8395584525291229
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.7626255953429928
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.08541955638485425
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.6800769526060232
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.8178550308165105
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.8272176282890455
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.6995134987436511
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.7820779839832849
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.4544692858583916
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.7953000753608338
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.7454828081543696
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.7261128727824553
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.8313191289204778
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.4789895660549806
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.8082940495682027
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.6132435298346255
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.3219932566596866
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.76730597954441
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.7493365186376417
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.3136834625743683
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.7625089874618384
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.585793822478703
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.8172815904552181
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.8035038996424865
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.8205707469486242
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.46172411715580847
---------------------------------------------------------

Hidden units: 12
Epochs: 10000
Learning rate: 1

Errors during training:
Error at epoch 1 is 111.52821836116767
Train mean error at (after) epoch 1: 0.27882054590291916
Test error at (after) epoch 1: 0.19461935909756495
----------
Error at epoch 1000 is 4.972450203679287
Train mean error at (after) epoch 1000: 0.012431125509198218
Test error at (after) epoch 1000: 0.01047563376924386
----------
Error at epoch 2000 is 3.954911786245501
Train mean error at (after) epoch 2000: 0.009887279465613753
Test error at (after) epoch 2000: 0.01032958962422168
----------
Error at epoch 3000 is 4.8944286854097445
Train mean error at (after) epoch 3000: 0.01223607171352436
Test error at (after) epoch 3000: 0.01046907477117282
----------
Error at epoch 4000 is 2.230819979348588
Train mean error at (after) epoch 4000: 0.00557704994837147
Test error at (after) epoch 4000: 0.005917747347075444
----------
Error at epoch 5000 is 1.9116570765450973
Train mean error at (after) epoch 5000: 0.004779142691362743
Test error at (after) epoch 5000: 0.005403674895503336
----------
Error at epoch 6000 is 1.751710837834151
Train mean error at (after) epoch 6000: 0.004379277094585378
Test error at (after) epoch 6000: 0.005001029012962558
----------
Error at epoch 7000 is 1.6564992159609238
Train mean error at (after) epoch 7000: 0.004141248039902309
Test error at (after) epoch 7000: 0.004802858333108424
----------
Error at epoch 8000 is 1.5878936535629808
Train mean error at (after) epoch 8000: 0.003969734133907452
Test error at (after) epoch 8000: 0.004733603558760679
----------
Error at epoch 9000 is 1.535718373926057
Train mean error at (after) epoch 9000: 0.0038392959348151423
Test error at (after) epoch 9000: 0.004731304954383177
----------
Error at epoch 10000 is 1.4929652222919922
Train mean error at (after) epoch 10000: 0.0037324130557299805
Test error at (after) epoch 10000: 0.004744081223569655
----------


Outputs after training:

Input: [ 0.00660997 -0.54448479  0.89367809 -0.09221331] | Target: 0.999428490712769 | Output: 0.8865617117481861
Input: [0.31617864 0.58889469 0.9945387  0.93720711] | Target: -0.21372302707239993 | Output: -0.09148642104834115
Input: [ 0.69824715 -0.98030089 -0.49301403 -0.19496983] | Target: 0.981948953239795 | Output: 0.9292858588926216
Input: [-0.3859859   0.13742734  0.40268378 -0.46595129] | Target: 0.3384054312976108 | Output: 0.494665907212261
Input: [-0.58966642  0.7136049  -0.91289105 -0.07022932] | Target: -0.8391179384949584 | Output: -0.7540075529144804
Input: [ 0.62696977 -0.48384468  0.8627885  -0.19573419] | Target: 0.8261586504161109 | Output: 0.7733370194059359
Input: [0.9144665  0.84213768 0.69782673 0.41050166] | Target: 0.3519502831040755 | Output: 0.35241313940145574
Input: [-0.55252241 -0.25838646  0.26691363  0.66288357] | Target: -0.6366188485834259 | Output: -0.6147584406261213
Input: [-0.93324605  0.40764987 -0.67107608 -0.01858922] | Target: -0.9120312302297787 | Output: -0.7900019403759236
Input: [-0.42894996 -0.7052665   0.12197336 -0.27849849] | Target: 0.6262925213069901 | Output: 0.6920620513359634
Input: [-0.21012942  0.90493496  0.29893614  0.74460415] | Target: -0.9999493589600158 | Output: -0.907534836894434
Input: [-0.03716353 -0.75846362 -0.19173357 -0.59341891] | Target: 0.9013971316688032 | Output: 0.8536200282757987
Input: [-0.49508362 -0.13051281 -0.17946757  0.53459543] | Target: -0.8813130647051963 | Output: -0.7908769131767528
Input: [-0.99519937 -0.63650249 -0.97930906  0.78785362] | Target: -0.8498671243461939 | Output: -0.9587948230361024
Input: [ 0.57440751 -0.61505728 -0.14231851 -0.16896294] | Target: 0.9377552032907924 | Output: 0.8933633936614256
Input: [-0.62904586  0.0372796  -0.56895421 -0.47137346] | Target: -0.6917475466506349 | Output: -0.7359859777480272
Input: [-0.20406443  0.09789336 -0.19058329  0.69571326] | Target: -0.9277187622474865 | Output: -0.7870420150792762
Input: [-0.68065684  0.24271926  0.95841098 -0.53556552] | Target: 0.5401374256824362 | Output: 0.5298201255927132
Input: [ 0.78752242 -0.35799036 -0.35559585  0.41010491] | Target: 0.37074590033198085 | Output: 0.49773651523645684
Input: [ 0.04403245 -0.89152895  0.81756306  0.92823666] | Target: 0.7344716445333623 | Output: 0.8191807307453732
Input: [ 0.71706562 -0.19301911  0.86902531  0.71012342] | Target: 0.8767135034291788 | Output: 0.8951970900191496
Input: [-0.01516604 -0.05155823  0.14841033 -0.68373986] | Target: 0.7633882150108057 | Output: 0.7891201924831304
Input: [ 0.1467271  -0.78479717  0.2589917  -0.19106922] | Target: 0.9821529123087117 | Output: 0.8670803903970074
Input: [ 0.60407498  0.43830891  0.44125359 -0.52616978] | Target: 0.9057683967886992 | Output: 0.8921859511790514
Input: [-0.57837151 -0.45063429  0.10496752  0.3088502 ] | Target: -0.32557509606921753 | Output: -0.35834796880603303
Input: [-0.42554974  0.24546433  0.03003659  0.60165763] | Target: -0.9466365869717444 | Output: -0.8112346121337013
Input: [ 0.51484675 -0.04173777  0.00065847 -0.03284945] | Target: 0.5564378357605992 | Output: 0.7092296244347089
Input: [-0.12890365 -0.96962965  0.018042    0.40005599] | Target: 0.4427936399422434 | Output: 0.5388805194077048
Input: [ 0.40711526 -0.86148254  0.24786026 -0.03434404] | Target: 0.9998001222625834 | Output: 0.884520262699893
Input: [ 0.58264081  0.89610121  0.71816792 -0.87374158] | Target: 0.9575700400529655 | Output: 0.9176143021208911
Input: [ 0.41477449 -0.15086028 -0.09503076 -0.77678407] | Target: 0.948157786187183 | Output: 0.8606474690817323
Input: [-0.89488914 -0.78382926  0.11080321 -0.68544011] | Target: 0.632815064067291 | Output: 0.598479160626157
Input: [-0.63121862 -0.86029212  0.99776487  0.50566379] | Target: 0.6602672683310649 | Output: 0.7271115489615728
Input: [ 0.7691391  -0.10434706  0.82969471 -0.30076784] | Target: 0.9076470963149226 | Output: 0.8797075329986039
Input: [ 0.23115621  0.98161178 -0.64346799  0.09312939] | Target: -0.9964955711491944 | Output: -0.8863655257142535
Input: [-0.05645137 -0.30427556  0.97920374  0.82755947] | Target: 0.3889287053933207 | Output: 0.4986037048903272
Input: [-0.531566    0.63900064 -0.12190507  0.62397362] | Target: -0.9408557621688576 | Output: -0.8352227582490368
Input: [ 0.18429747 -0.02332226  0.87473081 -0.85265052] | Target: 0.9344073393154225 | Output: 0.8294823881933082
Input: [-0.71226403 -0.40536674 -0.32260343  0.11964769] | Target: -0.6810154155676115 | Output: -0.7218164504658221
Input: [ 0.45108957 -0.96476035  0.86576781 -0.40400648] | Target: 0.44033202690906553 | Output: 0.5493329565082075
Input: [-0.31881117  0.21793322 -0.84623259  0.00104113] | Target: -0.9826076004691221 | Output: -0.8517166741782551
Input: [ 0.43653392  0.72223075 -0.9685153   0.50437982] | Target: -0.9824181620647181 | Output: -0.9112982073366233
Input: [ 0.96557643 -0.31442401 -0.1123161  -0.12024945] | Target: 0.9602604228931649 | Output: 0.8740932831580198
Input: [-0.67450326  0.02653584  0.49349825 -0.71658436] | Target: 0.48734225045797874 | Output: 0.6213373659692376
Input: [-0.91636376 -0.55025922 -0.6790396   0.65581922] | Target: -0.9915402270163858 | Output: -0.9332774869807869
Input: [-0.5279109  -0.95201125  0.29323887 -0.52109691] | Target: 0.9452749035120543 | Output: 0.8156464223251743
Input: [-0.52201273 -0.12934378  0.41601463  0.30369295] | Target: -0.27668937160514306 | Output: -0.2599653959063125
Input: [-0.53994172 -0.5754326   0.53146679 -0.85939434] | Target: 0.989586046278749 | Output: 0.8666448553158808
Input: [-0.90557368  0.49039011  0.65381434  0.0603147 ] | Target: -0.7190706988121329 | Output: -0.6828752209039021
Input: [-0.56889372  0.45290396 -0.11589906 -0.33271312] | Target: -0.7208192897646896 | Output: -0.7397735077795984
Input: [ 0.96461696 -0.75897773  0.37264166 -0.82528295] | Target: 0.21830121943264208 | Output: 0.6362162674806298
Input: [-0.66230958  0.38122597 -0.02960296 -0.60450056] | Target: -0.4516715102644878 | Output: -0.5293712341341922
Input: [ 0.58702196 -0.78194813  0.04188266  0.43026604] | Target: 0.8308240301088078 | Output: 0.8498648556961184
Input: [-0.7190177   0.78581626 -0.98766355  0.47715056] | Target: -0.1710985872210444 | Output: -0.30867301843875833
Input: [ 0.21478363 -0.35384001  0.88017538 -0.67054894] | Target: 0.8532806680933988 | Output: 0.7544625999973329
Input: [-0.06456025  0.98674669  0.37184925  0.7697051 ] | Target: -0.9926117566524079 | Output: -0.8844006957295725
Input: [-0.21636942  0.60077566 -0.58246448  0.50839142] | Target: -0.9436831927190366 | Output: -0.7712927570693718
Input: [-0.15009614  0.84939375 -0.95346899  0.42762889] | Target: -0.6896494652678075 | Output: -0.7716631986381144
Input: [-0.13700234 -0.5564368   0.16448242 -0.26945288] | Target: 0.7535001163643024 | Output: 0.7906949159067007
Input: [ 0.50666931  0.16590429 -0.97880258  0.52406463] | Target: -0.9176405704605746 | Output: -0.8252243809956364
Input: [-0.01323816 -0.75336123 -0.13500443  0.30164259] | Target: 0.2988392175133625 | Output: 0.42266863795925547
Input: [ 0.9131922   0.54727247 -0.29002664 -0.11219756] | Target: 0.1869835632254722 | Output: 0.37664281984460557
Input: [ 0.40387258  0.59450974  0.17478928 -0.30832855] | Target: 0.2883284245865509 | Output: 0.4459674687149971
Input: [0.72225885 0.08717091 0.89666771 0.3277316 ] | Target: 0.9334896819421183 | Output: 0.9074354196071025
Input: [-0.99220134  0.78055939 -0.29866722  0.10684261] | Target: -0.8210923359398624 | Output: -0.8069057436042896
Input: [-0.82886882  0.09955343  0.43392452  0.83787379] | Target: -0.9717111974729203 | Output: -0.8217552207690093
Input: [ 0.97522866 -0.74090266 -0.73902786 -0.22935505] | Target: 0.9343599218694405 | Output: 0.8865268136793897
Input: [ 0.87570798 -0.38604674  0.16871943  0.62444629] | Target: 0.7215426827060627 | Output: 0.8312282940329621
Input: [-0.72140854  0.49135285 -0.19357847  0.87508415] | Target: -0.7579525861970133 | Output: -0.7473428195969971
Input: [-0.17274775  0.58386075  0.45722399 -0.9620896 ] | Target: 0.6152516047094471 | Output: 0.7268772210848762
Input: [-0.83837434 -0.94199894  0.74013399 -0.55994202] | Target: 0.9860719626880099 | Output: 0.8846382701856339
Input: [ 0.2031672   0.09234882  0.84748505 -0.81578744] | Target: 0.979406735358642 | Output: 0.8634773818345605
Input: [ 0.79055912 -0.86886814  0.51025923  0.87599745] | Target: 0.9618508336860752 | Output: 0.9073823321477604
Input: [-0.78839892  0.40732026  0.07404007 -0.5319612 ] | Target: -0.5561266036027359 | Output: -0.5975373903648034
Input: [ 0.65410487 -0.45601499  0.98307426  0.57580081] | Target: 0.9985743980177817 | Output: 0.9226785908667707
Input: [-0.45249896 -0.95375513  0.6399166  -0.83542812] | Target: 0.9187850886922511 | Output: 0.8693926837131796
Input: [-0.85386671  0.65590415  0.7649907  -0.80853512] | Target: 0.06371177667807901 | Output: 0.13494716057084574
Input: [-0.04392718 -0.43704501 -0.02396306 -0.31251981] | Target: 0.6300942460566235 | Output: 0.7399894689724795
Input: [ 0.94844202 -0.60401773 -0.20999102  0.34841243] | Target: 0.838244747433343 | Output: 0.8406264008541128
Input: [ 0.41019482  0.93997133  0.88862088 -0.95535357] | Target: 0.9672588724801208 | Output: 0.9083127214739244
Input: [ 0.23003298 -0.95112198  0.93735951 -0.26785471] | Target: 0.6854513954474696 | Output: 0.7398562182070834
Input: [ 0.24956745 -0.4603291   0.16787455 -0.07355775] | Target: 0.8141877558437529 | Output: 0.829933781866614
Input: [ 0.10821503 -0.78525108 -0.72469633  0.48538042] | Target: -0.31134746023481047 | Output: -0.31681672671540295
Input: [ 0.36841824  0.09908049  0.55290107 -0.27261688] | Target: 0.8888621437388369 | Output: 0.8685077036953013
Input: [ 0.88847421 -0.14428498 -0.95899514 -0.71451047] | Target: 0.7091377454218996 | Output: 0.6889757882873881
Input: [ 0.64936647  0.33802342 -0.40970558  0.66755337] | Target: -0.6931974180808799 | Output: -0.7134339978327192
Input: [ 0.56992174 -0.54739206 -0.12070126 -0.24559196] | Target: 0.9464977119719347 | Output: 0.8920482991208157
Input: [-0.77393128 -0.84364625  0.54200912  0.22263667] | Target: 0.37934420901797483 | Output: 0.4366826145584821
Input: [-0.03133868  0.2117887  -0.64420455  0.63017108] | Target: -0.998580246910916 | Output: -0.8281006658544547
Input: [ 0.45327632 -0.21121094 -0.71936995 -0.6050824 ] | Target: 0.5228574791619045 | Output: 0.659410527356073
Input: [ 0.87045129  0.79125711 -0.86069802 -0.59125462] | Target: -0.18910362206463052 | Output: -0.10624031517401339
Input: [-0.84107424 -0.82515829  0.06995435  0.83884449] | Target: -0.7066880021875999 | Output: -0.6937821411027717
Input: [-0.56383762 -0.84751693  0.76903608 -0.91820486] | Target: 0.9210127276943072 | Output: 0.8853292943246812
Input: [ 0.90317089 -0.00169976 -0.4596024   0.19719605] | Target: 0.2455356299614211 | Output: 0.3618874990010458
Input: [-0.08880742  0.11556957 -0.13853735  0.63538877] | Target: -0.8295509686265642 | Output: -0.7656593056706088
Input: [ 0.09527284  0.76392875  0.06865066 -0.11367786] | Target: -0.46738225546764745 | Output: -0.5332446216635827
Input: [ 0.80068362 -0.00700431  0.26219679 -0.09820054] | Target: 0.9200018679151167 | Output: 0.8828578970202678
Input: [ 0.61026847 -0.47993779  0.08763839  0.1845124 ] | Target: 0.8378497002732573 | Output: 0.8539909063987122
Input: [ 0.68839177 -0.31738248 -0.22479797 -0.42647027] | Target: 0.9347115382483204 | Output: 0.8763389978468534
Input: [ 4.84367488e-01  1.92520116e-02 -7.88128483e-01  2.80809538e-04] | Target: -0.3176914560245584 | Output: -0.2874743658961237
=========================================================


==================== GLOBAL SUMMARY ====================

HU=7 | LR=1 | Epochs=10000 | Test Error=0.0003700840329410965
HU=5 | LR=1 | Epochs=10000 | Test Error=0.0005568766827848885
HU=12 | LR=0.5 | Epochs=10000 | Test Error=0.0007361007045432475
HU=6 | LR=1 | Epochs=10000 | Test Error=0.0012935941227350156
HU=7 | LR=0.5 | Epochs=10000 | Test Error=0.0015193587624523833
HU=5 | LR=0.5 | Epochs=10000 | Test Error=0.001572011605271576
HU=10 | LR=0.3 | Epochs=10000 | Test Error=0.0018738602800409043
HU=10 | LR=1 | Epochs=10000 | Test Error=0.0022987503830188463
HU=5 | LR=1 | Epochs=3000 | Test Error=0.004244386903406982
HU=6 | LR=0.5 | Epochs=10000 | Test Error=0.004355669924905361
HU=10 | LR=0.5 | Epochs=10000 | Test Error=0.004409797884288129
HU=12 | LR=1 | Epochs=10000 | Test Error=0.004744081223569655
HU=12 | LR=0.3 | Epochs=10000 | Test Error=0.0054086132589856685
HU=6 | LR=0.3 | Epochs=10000 | Test Error=0.005704928413114938
HU=7 | LR=0.3 | Epochs=10000 | Test Error=0.005920022732006003
HU=10 | LR=0.5 | Epochs=3000 | Test Error=0.006164876105000704
HU=5 | LR=0.3 | Epochs=10000 | Test Error=0.0066690300581081115
HU=6 | LR=1 | Epochs=3000 | Test Error=0.0072240925007816285
HU=12 | LR=1 | Epochs=3000 | Test Error=0.007321246603174783
HU=10 | LR=1 | Epochs=3000 | Test Error=0.007488819137739564
HU=6 | LR=0.5 | Epochs=3000 | Test Error=0.008848380114538557
HU=5 | LR=0.5 | Epochs=3000 | Test Error=0.009249667144398266
HU=12 | LR=0.5 | Epochs=3000 | Test Error=0.009463192708766976
HU=7 | LR=0.5 | Epochs=3000 | Test Error=0.009968804587776879
HU=5 | LR=0.5 | Epochs=1000 | Test Error=0.010354634524410523
HU=5 | LR=0.1 | Epochs=3000 | Test Error=0.010357616993901055
HU=5 | LR=0.05 | Epochs=10000 | Test Error=0.010365738462178775
HU=6 | LR=0.5 | Epochs=1000 | Test Error=0.010382044725859418
HU=7 | LR=0.05 | Epochs=3000 | Test Error=0.010388877896977667
HU=10 | LR=1 | Epochs=1000 | Test Error=0.010391220495532164
HU=6 | LR=0.05 | Epochs=3000 | Test Error=0.010394037917426355
HU=10 | LR=0.3 | Epochs=3000 | Test Error=0.010395350746910965
HU=6 | LR=0.05 | Epochs=10000 | Test Error=0.010399311645775145
HU=10 | LR=0.1 | Epochs=3000 | Test Error=0.01040771287048585
HU=7 | LR=0.1 | Epochs=10000 | Test Error=0.01041496362387634
HU=5 | LR=0.1 | Epochs=10000 | Test Error=0.010415658022906851
HU=5 | LR=1 | Epochs=100 | Test Error=0.010420172742208656
HU=6 | LR=1 | Epochs=1000 | Test Error=0.010421367253932745
HU=7 | LR=0.3 | Epochs=1000 | Test Error=0.010424266986081822
HU=7 | LR=0.5 | Epochs=1000 | Test Error=0.01044076733169429
HU=10 | LR=0.5 | Epochs=1000 | Test Error=0.010448958354157241
HU=6 | LR=0.3 | Epochs=3000 | Test Error=0.010452045109091337
HU=12 | LR=0.1 | Epochs=10000 | Test Error=0.010452356159513829
HU=7 | LR=1 | Epochs=1000 | Test Error=0.010454433112372047
HU=12 | LR=0.3 | Epochs=3000 | Test Error=0.010460343555873568
HU=6 | LR=0.1 | Epochs=3000 | Test Error=0.010464714868233683
HU=12 | LR=1 | Epochs=100 | Test Error=0.01046550184768854
HU=5 | LR=0.05 | Epochs=3000 | Test Error=0.010467890839258072
HU=7 | LR=0.1 | Epochs=3000 | Test Error=0.01047489387071992
HU=7 | LR=0.5 | Epochs=100 | Test Error=0.010475051548887261
HU=6 | LR=0.1 | Epochs=1000 | Test Error=0.010477823698349082
HU=10 | LR=0.1 | Epochs=10000 | Test Error=0.01048430199932634
HU=6 | LR=0.5 | Epochs=100 | Test Error=0.010500275196091506
HU=5 | LR=0.5 | Epochs=100 | Test Error=0.010500686371914154
HU=6 | LR=0.1 | Epochs=10000 | Test Error=0.010509661328010365
HU=7 | LR=0.05 | Epochs=1000 | Test Error=0.010515508550663733
HU=7 | LR=0.05 | Epochs=10000 | Test Error=0.01051722555781846
HU=5 | LR=1 | Epochs=1000 | Test Error=0.010520485066247816
HU=10 | LR=0.3 | Epochs=1000 | Test Error=0.010524058070274359
HU=5 | LR=0.3 | Epochs=1000 | Test Error=0.01052418406693477
HU=12 | LR=0.5 | Epochs=1000 | Test Error=0.010526202420739863
HU=10 | LR=0.05 | Epochs=10000 | Test Error=0.010528481658325683
HU=7 | LR=0.3 | Epochs=3000 | Test Error=0.010543237646619867
HU=5 | LR=0.3 | Epochs=3000 | Test Error=0.010544084599837888
HU=6 | LR=0.3 | Epochs=1000 | Test Error=0.010549589590069533
HU=12 | LR=0.05 | Epochs=10000 | Test Error=0.010549851716539872
HU=5 | LR=0.05 | Epochs=1000 | Test Error=0.01055241650833558
HU=12 | LR=0.3 | Epochs=1000 | Test Error=0.010552782180523967
HU=6 | LR=0.05 | Epochs=1000 | Test Error=0.010561917445585635
HU=10 | LR=0.1 | Epochs=1000 | Test Error=0.010578405994679884
HU=12 | LR=1 | Epochs=1000 | Test Error=0.010580535924501356
HU=10 | LR=0.5 | Epochs=100 | Test Error=0.010587946329502013
HU=12 | LR=0.1 | Epochs=3000 | Test Error=0.010593060406961024
HU=10 | LR=0.05 | Epochs=3000 | Test Error=0.010594593803298651
HU=12 | LR=0.5 | Epochs=100 | Test Error=0.010597635601618758
HU=12 | LR=0.1 | Epochs=1000 | Test Error=0.01060132923951792
HU=10 | LR=1 | Epochs=100 | Test Error=0.010602215148555303
HU=7 | LR=0.1 | Epochs=1000 | Test Error=0.010605967676049028
HU=12 | LR=0.05 | Epochs=1000 | Test Error=0.010608866879326327
HU=5 | LR=0.1 | Epochs=1000 | Test Error=0.010613534522339091
HU=5 | LR=0.3 | Epochs=100 | Test Error=0.010637968989591528
HU=12 | LR=0.05 | Epochs=3000 | Test Error=0.010638818889626492
HU=7 | LR=1 | Epochs=100 | Test Error=0.01064295927982309
HU=6 | LR=1 | Epochs=100 | Test Error=0.010685300075477798
HU=10 | LR=0.05 | Epochs=1000 | Test Error=0.01074717190395453
HU=10 | LR=0.3 | Epochs=100 | Test Error=0.010814900045769483
HU=6 | LR=0.3 | Epochs=100 | Test Error=0.010822610394501317
HU=7 | LR=0.3 | Epochs=100 | Test Error=0.010855471548064684
HU=12 | LR=0.3 | Epochs=100 | Test Error=0.01091935112108203
HU=12 | LR=0.1 | Epochs=100 | Test Error=0.016243655116139073
HU=7 | LR=1 | Epochs=3000 | Test Error=0.01732632167050434
HU=10 | LR=0.1 | Epochs=100 | Test Error=0.01809801315820123
HU=6 | LR=0.1 | Epochs=100 | Test Error=0.02009283490886886
HU=7 | LR=0.1 | Epochs=100 | Test Error=0.022862327831386503
HU=7 | LR=0.05 | Epochs=100 | Test Error=0.030444159187044892
HU=5 | LR=0.1 | Epochs=100 | Test Error=0.034385747711082354
HU=6 | LR=0.05 | Epochs=100 | Test Error=0.04386594776221403
HU=12 | LR=0.05 | Epochs=100 | Test Error=0.05350095218913761
HU=10 | LR=0.05 | Epochs=100 | Test Error=0.06467991966796859
HU=5 | LR=0.05 | Epochs=100 | Test Error=0.12992100945084264
