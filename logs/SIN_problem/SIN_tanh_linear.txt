Global summary at the end of the file
---------------------------------------------------------

Hidden units: 5
Epochs: 100
Learning rate: 0.05

Errors during training:
Error at epoch 1 is 93.70889801705923
Train mean error at (after) epoch 1: 0.23427224504264807
Test error at (after) epoch 1: 0.19710267110937363
----------
Error at epoch 10 is 81.94247839265732
Train mean error at (after) epoch 10: 0.2048561959816433
Test error at (after) epoch 10: 0.1728754412201872
----------
Error at epoch 20 is 71.13710809083979
Train mean error at (after) epoch 20: 0.17784277022709946
Test error at (after) epoch 20: 0.15042234157342102
----------
Error at epoch 30 is 61.751353271994255
Train mean error at (after) epoch 30: 0.15437838317998565
Test error at (after) epoch 30: 0.1309335365834697
----------
Error at epoch 40 is 53.389721744560156
Train mean error at (after) epoch 40: 0.1334743043614004
Test error at (after) epoch 40: 0.1137900047607718
----------
Error at epoch 50 is 45.96917298317456
Train mean error at (after) epoch 50: 0.1149229324579364
Test error at (after) epoch 50: 0.09893741938467635
----------
Error at epoch 60 is 39.53302021283619
Train mean error at (after) epoch 60: 0.09883255053209047
Test error at (after) epoch 60: 0.0864948547762362
----------
Error at epoch 70 is 34.13426724298943
Train mean error at (after) epoch 70: 0.08533566810747358
Test error at (after) epoch 70: 0.0765221889037186
----------
Error at epoch 80 is 29.772831334903888
Train mean error at (after) epoch 80: 0.07443207833725972
Test error at (after) epoch 80: 0.06891608016840936
----------
Error at epoch 90 is 26.378413089751803
Train mean error at (after) epoch 90: 0.0659460327243795
Test error at (after) epoch 90: 0.06340820469733359
----------
Error at epoch 100 is 23.824849876487562
Train mean error at (after) epoch 100: 0.0595621246912189
Test error at (after) epoch 100: 0.05962438623863352
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.3229958732711261
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.43601637405185145
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.4172979673241258
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.35237117768085036
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.4191239370724156
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.8702171748070994
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.47580388447614913
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.5748567134168793
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: -0.01700480594743626
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.1805542653006545
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.5814748996031018
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: -0.005201796519908479
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.10472936843799338
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.76172005957627
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.39793556478923375
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.3577535806040688
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.21708432515380172
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.7705451521363055
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: -0.003202469594725879
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.7432469086351793
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.8421923594957271
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.02135580095878292
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.34387778965527627
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.6748310563472447
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.3088453920714436
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.5122473987895705
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 0.9909660324650454
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.8773871806991044
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.4554539312247405
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.49490512454724245
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.3013606787497555
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -0.928022759752484
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.8498309306032202
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.4898192179251902
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: -0.07152833158278168
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.5487169839377088
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.06831583505267262
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.8871204294327635
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.6568011755461114
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.3085918813495934
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.07948792860859383
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 1.134399582364692
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 1.1996580673637842
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.1720167989221747
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.5864853686153714
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.3013795058334554
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -1.037802484158251
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.03934406663531399
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.13091942400634463
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.24433447713583828
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.1400838837497882
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.5122309800554059
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.3487596769642703
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.2309071076982918
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.006031119094024106
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: 0.008229457416249194
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.3827461965712011
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.28277017171954033
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.4839923331603303
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.08995772996922986
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.6608106651763352
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.38043859263796215
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.49861006427291177
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.14090250984683347
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.0006142479224818494
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.2326662057804782
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.5159303696548151
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.14552615548449252
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.500914166379775
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 1.0131626345037286
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.1340526364961125
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.16619704087341514
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.30383968149150326
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.2936695054554369
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: 0.03595654727053641
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.36429927936618656
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.37044875107695685
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 0.940051092604527
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.5214479929499427
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.3127133775423627
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.37183785747572484
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.6517679938034451
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.6013671051596453
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.07156612433592056
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.191223734936882
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.027207982968006663
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.6518012231269693
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.22621455495570766
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.6716890370184797
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.17586069037507931
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.12696639229550075
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.26604461746962343
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.1727259925547096
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.40477283339170234
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -1.248800953937016
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.0721564665958275
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.24573329376629358
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.49451590175095994
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.22994064348722498
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -1.0511708411074694
---------------------------------------------------------

Hidden units: 5
Epochs: 1000
Learning rate: 0.05

Errors during training:
Error at epoch 1 is 111.84132935384967
Train mean error at (after) epoch 1: 0.2796033233846242
Test error at (after) epoch 1: 0.26715420825239056
----------
Error at epoch 100 is 16.851475392819147
Train mean error at (after) epoch 100: 0.042128688482047864
Test error at (after) epoch 100: 0.04346759151773445
----------
Error at epoch 200 is 9.252263455626117
Train mean error at (after) epoch 200: 0.023130658639065292
Test error at (after) epoch 200: 0.029135774903086768
----------
Error at epoch 300 is 8.152206640408503
Train mean error at (after) epoch 300: 0.02038051660102126
Test error at (after) epoch 300: 0.02629937776338736
----------
Error at epoch 400 is 7.3258410608554305
Train mean error at (after) epoch 400: 0.018314602652138575
Test error at (after) epoch 400: 0.02365541099349683
----------
Error at epoch 500 is 6.628822351137262
Train mean error at (after) epoch 500: 0.016572055877843155
Test error at (after) epoch 500: 0.02135240105664657
----------
Error at epoch 600 is 6.035253084306726
Train mean error at (after) epoch 600: 0.015088132710766816
Test error at (after) epoch 600: 0.01936917696669888
----------
Error at epoch 700 is 5.524040575028322
Train mean error at (after) epoch 700: 0.013810101437570806
Test error at (after) epoch 700: 0.01764656206737144
----------
Error at epoch 800 is 5.07834928302687
Train mean error at (after) epoch 800: 0.012695873207567175
Test error at (after) epoch 800: 0.016132871897220874
----------
Error at epoch 900 is 4.685527996290338
Train mean error at (after) epoch 900: 0.011713819990725844
Test error at (after) epoch 900: 0.014788911151239195
----------
Error at epoch 1000 is 4.336508155569447
Train mean error at (after) epoch 1000: 0.010841270388923619
Test error at (after) epoch 1000: 0.013586694328888487
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.5390474979377239
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.6935748879137762
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.7289544182784117
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.3899022964023814
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.7518479733198554
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -1.0232764095692002
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.6808988684933301
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.8525939481223621
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.0715834949241013
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.45044385841021006
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.7983285558759206
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.09110719121095211
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.4872829656709719
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.9157782763431663
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.7383130655934981
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.6003246429002481
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.48326909695526304
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.9872769272273397
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.1303024045134353
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.8935839807352272
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.919762049355085
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.3128310139778765
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.5774243784154385
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.8962487732280664
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.4530876225646926
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.777128753434853
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 0.9790856358828762
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 1.0027786384845563
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.7118138527699047
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.7464413280899401
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.4986904756330562
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -0.9788474943326597
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.9832902277490325
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.8658208046411451
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.32435562666740586
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.8816871337335462
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.37458935816095346
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.9728244817014653
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.8809010208029939
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.4787817661482953
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.4299022763278414
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 0.9621844522245343
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 0.960748354915377
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.2647474046291992
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.928823627254737
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.6351689700663412
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -0.9219949983686431
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.13417077890330179
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.5348488868779822
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.6242240399062722
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.3861411060947786
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.8283077588420205
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.5583736356376496
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.5430343182845369
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.08366144662282875
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.07262665213279507
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.7496630858172466
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.5418603313552839
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.886914860191988
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.052402337803576664
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.9140467127842855
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.5089320792395412
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.6637132418205248
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.21741917110454897
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.12992313334502775
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.2252992119185268
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.7657705364747155
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.08485340340382441
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.7442697834130851
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 1.002798339551294
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.024492888360581788
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.13085004862138766
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.5117353836844416
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.7336551187124236
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.3306745052611588
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.4748839328133526
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.7464292937969648
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 0.9499090059102484
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.7436635529936035
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.6585362272088683
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.5880145864009433
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.908513430995943
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.851647597124954
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.26931174954851034
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.5934249854472918
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.1789625689689711
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.857785094034445
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.4794820963478747
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.8910450125306006
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.574093961182341
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.2429444859402486
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.5830303804067671
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.22764844489114183
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.5900530488571312
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -0.9679367102835754
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.27589204370956893
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.2206671930940032
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.8315151980948937
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.3092472842909437
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -0.9506984876363923
---------------------------------------------------------

Hidden units: 5
Epochs: 3000
Learning rate: 0.05

Errors during training:
Error at epoch 1 is 102.4481895943335
Train mean error at (after) epoch 1: 0.25612047398583376
Test error at (after) epoch 1: 0.26791336307919505
----------
Error at epoch 300 is 12.589037630755978
Train mean error at (after) epoch 300: 0.031472594076889945
Test error at (after) epoch 300: 0.03982502792928988
----------
Error at epoch 600 is 9.460747400143406
Train mean error at (after) epoch 600: 0.023651868500358515
Test error at (after) epoch 600: 0.030148976440651575
----------
Error at epoch 900 is 7.2292080087374275
Train mean error at (after) epoch 900: 0.018073020021843567
Test error at (after) epoch 900: 0.023065422400396562
----------
Error at epoch 1200 is 5.840590134786414
Train mean error at (after) epoch 1200: 0.014601475336966034
Test error at (after) epoch 1200: 0.01857155888047703
----------
Error at epoch 1500 is 5.0024882885123905
Train mean error at (after) epoch 1500: 0.012506220721280976
Test error at (after) epoch 1500: 0.015772363882961056
----------
Error at epoch 1800 is 4.465511798556127
Train mean error at (after) epoch 1800: 0.011163779496390318
Test error at (after) epoch 1800: 0.013904327435656134
----------
Error at epoch 2100 is 4.077042515573116
Train mean error at (after) epoch 2100: 0.01019260628893279
Test error at (after) epoch 2100: 0.012498794001838532
----------
Error at epoch 2400 is 3.756095625988355
Train mean error at (after) epoch 2400: 0.009390239064970888
Test error at (after) epoch 2400: 0.011308341219186127
----------
Error at epoch 2700 is 3.4677938626281097
Train mean error at (after) epoch 2700: 0.008669484656570274
Test error at (after) epoch 2700: 0.010230554264665065
----------
Error at epoch 3000 is 3.205763881810917
Train mean error at (after) epoch 3000: 0.008014409704527293
Test error at (after) epoch 3000: 0.009252782382801274
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.5957876254596375
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.763459514347468
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.8047048133147643
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.4546845774068559
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.8109836834624554
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.8728088816238103
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.7078405820407593
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.8458685965448114
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.09767012162656934
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.49238340442223294
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.7893993462559823
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.0576164887779617
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.5532862324992334
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.9073740324462889
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.7899780557787496
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.6561366211379991
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.5503552262779872
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.8821288991623494
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.09946938696233909
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.9177044630403575
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.9027935721015704
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.31056857470941684
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.6414280836622482
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.9154084562151651
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.5125177643938146
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.788727333904979
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 0.8678624379585083
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.8838742970220156
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.757951912884476
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.7900697946878127
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.5556119085478994
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -0.8866570712533315
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.8906107938256609
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.8655977947148242
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.34724437279246556
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.8305432459802764
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.4163313314324081
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.8871755010537656
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.8697106516406392
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.5423237374632555
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.49672010865601673
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 0.8605787380576955
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 0.8339221732036648
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.29594192278826137
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.8660343731555985
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.7147880168697959
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -0.8808982233936536
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.1410530586426957
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.6033847590039491
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.7296935014336343
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.4263778728944307
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.8819980327916375
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.6114228609417789
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.6101299535564201
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.11534695422437151
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.1028270262071361
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.7800480110924028
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.605141396035348
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.8318017801925803
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.05520324175816055
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.8689827529406371
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.5469095254322888
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.6972166810729418
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.3004946574676687
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.13094816475389884
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.26139003923691223
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.807161644273441
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.10292563301691006
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.7775337311665823
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 0.8815752774992884
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.10218347649097068
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.15938566803054888
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.5716432841420874
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.8205804814092744
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.33596337379094937
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.5262161376743775
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.7531681841767043
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 0.8791579067114892
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.7616673730272607
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.7241939180577478
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.6534814347336539
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.900358316426318
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.8654558575372562
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.3188541265074762
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.6642759535374108
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.18656215194799883
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.8387750593135136
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.5451998847664645
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.8500187733719754
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.664628301936132
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.28344211924908264
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.663631070087043
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.28295105496941525
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.6405427788606941
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -0.8431630885750663
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.3319262600699538
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.27561659307412295
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.848898220603042
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.3885359915024134
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -0.8715081376158
---------------------------------------------------------

Hidden units: 5
Epochs: 10000
Learning rate: 0.05

Errors during training:
Error at epoch 1 is 143.05193726463693
Train mean error at (after) epoch 1: 0.35762984316159235
Test error at (after) epoch 1: 0.33737644666982564
----------
Error at epoch 1000 is 7.608423194551167
Train mean error at (after) epoch 1000: 0.019021057986377918
Test error at (after) epoch 1000: 0.024357622934697967
----------
Error at epoch 2000 is 3.8550035577292947
Train mean error at (after) epoch 2000: 0.009637508894323236
Test error at (after) epoch 2000: 0.011802128387023826
----------
Error at epoch 3000 is 2.8127730051985256
Train mean error at (after) epoch 3000: 0.007031932512996314
Test error at (after) epoch 3000: 0.007912247503375505
----------
Error at epoch 4000 is 2.454498531696458
Train mean error at (after) epoch 4000: 0.006136246329241145
Test error at (after) epoch 4000: 0.006522427983339926
----------
Error at epoch 5000 is 2.254195694307357
Train mean error at (after) epoch 5000: 0.005635489235768393
Test error at (after) epoch 5000: 0.005842645473373811
----------
Error at epoch 6000 is 2.0881312643005203
Train mean error at (after) epoch 6000: 0.005220328160751301
Test error at (after) epoch 6000: 0.005348265117855202
----------
Error at epoch 7000 is 1.9372494214364702
Train mean error at (after) epoch 7000: 0.004843123553591175
Test error at (after) epoch 7000: 0.004922558756148981
----------
Error at epoch 8000 is 1.799692536092891
Train mean error at (after) epoch 8000: 0.004499231340232227
Test error at (after) epoch 8000: 0.004541176216786979
----------
Error at epoch 9000 is 1.6758771467935958
Train mean error at (after) epoch 9000: 0.00418969286698399
Test error at (after) epoch 9000: 0.004200130858973324
----------
Error at epoch 10000 is 1.5661233766760965
Train mean error at (after) epoch 10000: 0.003915308441690241
Test error at (after) epoch 10000: 0.0038991485942079553
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.6346670598303568
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.7695160433549867
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.837261855121878
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.48676020983694307
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.8267751224939415
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.8251802375030873
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.7524869374502452
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.8926034890145527
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.09069594894024738
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.5292320455345884
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.8383228016461538
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.062472338409368534
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.5680531792196757
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.8580394514243904
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.8271103546427926
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.6880461848937749
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.571796299260138
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.911431054177418
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.11308569759014192
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.830881486505054
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.7866177895739265
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.3529172595085709
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.6713557006332165
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.8411357164294935
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.5351746783086148
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.8401785224932978
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 0.7252610011773384
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.8741823405713189
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.7858766527989833
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.8160425776131088
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.5888364192457072
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -0.8015742076050361
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.899816096602159
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.898564090695092
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.3526829821201603
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.9049453099611
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.4358385027112896
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.825735388595552
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.8803259095384699
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.5625228265803786
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.5165189700336449
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 0.6365593173215041
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 0.5555645515145411
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.3202180516108703
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.9312510698781391
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.7281747339600195
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -0.6621674075685562
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.13950860179482696
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.6171390860136545
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.7578929471962339
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.4356808337648415
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.8638730073665392
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.6618063254065705
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.642986483614612
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.0993114981342777
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.09102069333793711
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.8448971960701854
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.6345845374528297
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.9234800913746865
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.0672672260220161
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.9133633173169473
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.5610420867005701
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.7505519019079084
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.3070351947563111
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.1559758026665026
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.2704368028171162
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.8331086803128376
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.11574436331626584
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.8238305139645541
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 0.7847957469963942
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.10150566280017742
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.17239022298110704
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.5906612336737487
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.8388781292838611
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.3787612061457734
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.5395023202327718
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.8382963658116016
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 0.7351393541784668
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.8275938545184427
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.7445472446298578
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.6755628502231035
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.9267078616639359
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.8876595834287848
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.3475481141414867
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.7097603616452097
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.2059714928960587
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.8964665860708021
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.5605358157659661
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.8988157425361143
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.6786604979890036
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.30053821151869037
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.6939822462914931
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.30470366457922804
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.6880644886534422
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -0.5801067822489026
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.352131484658269
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.2782046692501272
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.893615973219259
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.38642694840824293
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -0.673587863950482
---------------------------------------------------------

Hidden units: 5
Epochs: 100
Learning rate: 0.1

Errors during training:
Error at epoch 1 is 82.03015806486295
Train mean error at (after) epoch 1: 0.20507539516215736
Test error at (after) epoch 1: 0.19690609437532136
----------
Error at epoch 10 is 71.28352758344928
Train mean error at (after) epoch 10: 0.1782088189586232
Test error at (after) epoch 10: 0.171916488908216
----------
Error at epoch 20 is 59.227754422964225
Train mean error at (after) epoch 20: 0.14806938605741057
Test error at (after) epoch 20: 0.14343782234192132
----------
Error at epoch 30 is 47.012659807093726
Train mean error at (after) epoch 30: 0.11753164951773432
Test error at (after) epoch 30: 0.11466614494401182
----------
Error at epoch 40 is 35.837262909670486
Train mean error at (after) epoch 40: 0.08959315727417622
Test error at (after) epoch 40: 0.08878359781252865
----------
Error at epoch 50 is 26.97342578764574
Train mean error at (after) epoch 50: 0.06743356446911436
Test error at (after) epoch 50: 0.06880754162784065
----------
Error at epoch 60 is 20.888930170488017
Train mean error at (after) epoch 60: 0.052222325426220045
Test error at (after) epoch 60: 0.05559023128327139
----------
Error at epoch 70 is 17.188352908610778
Train mean error at (after) epoch 70: 0.04297088227152694
Test error at (after) epoch 70: 0.04790869755741364
----------
Error at epoch 80 is 15.107920839810866
Train mean error at (after) epoch 80: 0.03776980209952716
Test error at (after) epoch 80: 0.04379715205335928
----------
Error at epoch 90 is 13.96081828615997
Train mean error at (after) epoch 90: 0.034902045715399926
Test error at (after) epoch 90: 0.04160852991094911
----------
Error at epoch 100 is 13.29357282185541
Train mean error at (after) epoch 100: 0.033233932054638524
Test error at (after) epoch 100: 0.04031992359610749
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.36433958153336415
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.5557919517146254
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.6333778131147394
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.25768702422847556
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.6276452129163101
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -1.0573732870917552
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.5701038123563991
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.7235050483568098
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.06545858750951208
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.24645027615972626
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.6832756449950873
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.07968980143493933
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.3575426972927405
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.9483333677787803
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.56829277848584
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.48771540499363913
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.3853191136095484
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.9500371269961395
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.06613412150548145
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.9712511636323743
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 1.0514856214692347
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.14821797810228987
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.36710494411397443
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.9238645333396597
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.3283707828496615
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.6317765957221646
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 1.1311339312480517
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 1.0217971302641973
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.5911731981032412
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.6022686255913692
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.32730490306669274
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -1.0798065501421272
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.9602968812054424
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.7515918332620478
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.20624276611452935
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.7212599828657338
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.23071988768794688
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 1.0186691738022435
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.8134626968417876
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.27786419336454793
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.30009495540647285
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 1.2426834570963574
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 1.2928131065459891
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.11640084016252088
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.8045016483410062
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.5129421393175336
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -1.1888649947289074
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.13099786203214225
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.3886081298599444
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.5135881242726045
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.29099138496889554
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.7548574106470288
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.37754284503239616
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.3406520321820745
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.11889114359082568
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.1095288137025316
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.5566237012197253
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.3858572040320926
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.7075048709056188
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: -0.02690806814763109
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.8124707674712278
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.4482238189963522
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.4869849084852586
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.1625451242002904
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.03153061291516293
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.16888305646514146
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.6229119747948099
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.03407937424433703
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.5784295876013914
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 1.1503454192305387
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.025449646998906447
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.07329950313105699
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.40255584187185783
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.5902429478205614
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.14883992297488782
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.41549964851460036
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.5384903613078276
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 1.1188601066148713
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.4963975278765526
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.5161115330337152
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.41247651311205524
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.8494708272084753
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.7782014897383306
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.2565353293746797
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.38039747816261155
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.08765001173483906
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.7106783793099608
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.36909442762242833
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.7040062360169101
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.4447947547201988
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.1501824078630774
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.478270682523989
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.12731190197279385
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.44236878989475764
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -1.342010151488356
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.1639708528428741
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.06209284088808027
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.6820811216723673
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.1612669248526862
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -1.2073194613555749
---------------------------------------------------------

Hidden units: 5
Epochs: 1000
Learning rate: 0.1

Errors during training:
Error at epoch 1 is 123.85390852617778
Train mean error at (after) epoch 1: 0.3096347713154444
Test error at (after) epoch 1: 0.2988788155081279
----------
Error at epoch 100 is 13.382695128156636
Train mean error at (after) epoch 100: 0.03345673782039159
Test error at (after) epoch 100: 0.04218982702335346
----------
Error at epoch 200 is 11.077210338131687
Train mean error at (after) epoch 200: 0.02769302584532922
Test error at (after) epoch 200: 0.03517821029508887
----------
Error at epoch 300 is 9.247887809756799
Train mean error at (after) epoch 300: 0.023119719524392
Test error at (after) epoch 300: 0.02939858332051702
----------
Error at epoch 400 is 7.720358415618218
Train mean error at (after) epoch 400: 0.019300896039045546
Test error at (after) epoch 400: 0.024540106262376703
----------
Error at epoch 500 is 6.49899616981733
Train mean error at (after) epoch 500: 0.016247490424543324
Test error at (after) epoch 500: 0.020604044251177515
----------
Error at epoch 600 is 5.5467261031101245
Train mean error at (after) epoch 600: 0.01386681525777531
Test error at (after) epoch 600: 0.017479396030097186
----------
Error at epoch 700 is 4.816296140626705
Train mean error at (after) epoch 700: 0.012040740351566763
Test error at (after) epoch 700: 0.015026413005055578
----------
Error at epoch 800 is 4.262418044526733
Train mean error at (after) epoch 800: 0.010656045111316832
Test error at (after) epoch 800: 0.013113815183624254
----------
Error at epoch 900 is 3.845385344561384
Train mean error at (after) epoch 900: 0.00961346336140346
Test error at (after) epoch 900: 0.011628482491837814
----------
Error at epoch 1000 is 3.53191809351333
Train mean error at (after) epoch 1000: 0.008829795233783326
Test error at (after) epoch 1000: 0.01047615416962613
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.5763343233274792
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.7390781552247107
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.7869213957796669
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.42997477750047436
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.762580149459888
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.9363092403518809
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.7215076288208014
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.8550340798914546
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.08876353282298129
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.4642534090071979
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.8446711031398653
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.07596306301995626
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.5049990051060558
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.8998432342859215
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.7433107866046508
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.6425093347889642
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.5180800438557164
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.9444054202721228
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.11562085426014128
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.8684092991816299
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.8664650623437413
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.3096196158848652
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.6192738900494942
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.8371898553558793
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.4912357031786752
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.8029972007149306
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 0.912836224750325
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.9713780532271101
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.7556128037676249
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.7864002099005636
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.5350791266035025
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -0.9316504459156232
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.9805133012486018
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.8199933018220655
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.33806791292941796
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.8795323553827867
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.39038515480513575
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.9641899473550731
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.8996667725046332
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.5200014535747226
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.4561524383055373
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 0.9181586348175816
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 0.8779857293870731
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.2830992065800936
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.8810181820517514
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.6711075681096573
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -0.8558437995083025
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.13368869376449932
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.5558257151721935
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.676844702996155
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.410387796381632
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.8134072818364202
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.5988245401264995
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.564788560093015
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.0978162289735277
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.08828385871100673
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.7505901502490827
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.5734394391476733
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.8519239929732288
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.053721241820509205
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.9031732784603729
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.5272512917184062
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.7171395838955841
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.2638653625678077
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.13514113955698484
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.2363551429896683
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.8014691185299402
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.08928033909071409
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.7797076884854092
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 0.9691736425642475
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.05572767719727235
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.14159499037849085
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.549915320555998
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.7308095351981867
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.3322559113136633
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.5023376491111124
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.7503897474337122
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 0.8755952982267987
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.795771217977647
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.6760316076843915
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.6347144891520414
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.9332285827347578
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.9005979618235025
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.2910289922409945
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.605752968030345
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.18402190489978293
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.898413897234886
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.5129725891538218
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.9402799082891349
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.6124694532202996
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.26596870683827784
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.6329326193417606
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.2604708633144814
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.6374747879107147
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -0.8979870038862166
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.31174458067787014
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.24445622924368304
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.8154996492256857
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.35209066406907497
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -0.8691573211554297
---------------------------------------------------------

Hidden units: 5
Epochs: 3000
Learning rate: 0.1

Errors during training:
Error at epoch 1 is 75.5043685032337
Train mean error at (after) epoch 1: 0.18876092125808427
Test error at (after) epoch 1: 0.17637650443862188
----------
Error at epoch 300 is 13.206106281362704
Train mean error at (after) epoch 300: 0.03301526570340676
Test error at (after) epoch 300: 0.04173056976071114
----------
Error at epoch 600 is 9.309103457509359
Train mean error at (after) epoch 600: 0.023272758643773397
Test error at (after) epoch 600: 0.029352092799445995
----------
Error at epoch 900 is 6.186046782097082
Train mean error at (after) epoch 900: 0.015465116955242705
Test error at (after) epoch 900: 0.01915408187113972
----------
Error at epoch 1200 is 4.217927576006446
Train mean error at (after) epoch 1200: 0.010544818940016115
Test error at (after) epoch 1200: 0.012496620724959401
----------
Error at epoch 1500 is 3.103453766579701
Train mean error at (after) epoch 1500: 0.007758634416449253
Test error at (after) epoch 1500: 0.008636801946725144
----------
Error at epoch 1800 is 2.4770859321003535
Train mean error at (after) epoch 1800: 0.006192714830250884
Test error at (after) epoch 1800: 0.006513239769354897
----------
Error at epoch 2100 is 2.131650518742289
Train mean error at (after) epoch 2100: 0.005329126296855723
Test error at (after) epoch 2100: 0.00540474284318236
----------
Error at epoch 2400 is 1.9391653710999557
Train mean error at (after) epoch 2400: 0.004847913427749889
Test error at (after) epoch 2400: 0.00482395066661504
----------
Error at epoch 2700 is 1.817638053400181
Train mean error at (after) epoch 2700: 0.004544095133500453
Test error at (after) epoch 2700: 0.004480870320187286
----------
Error at epoch 3000 is 1.7255911586529247
Train mean error at (after) epoch 3000: 0.004313977896632312
Test error at (after) epoch 3000: 0.004237511243102613
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.6321586858357225
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.7748757707759325
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.806059698790515
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.4705998067269998
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.8297700038896552
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.8199675542106176
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.7845628354942576
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.9028218549898464
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.09633038350797068
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.5240180674742544
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.8758627620657994
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.0863636638845105
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.5751056854936536
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.8600986696372506
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.8445924492258289
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.6924701253327811
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.5774252130017755
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.9200160306754951
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.12680400515277288
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.838641461926862
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.7884616601554135
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.35488621993534125
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.6649347926819654
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.8447393016746846
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.5355224125184994
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.8344527790794245
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 0.7252045666680457
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.8608134502098287
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.7839585325724819
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.8133624517045965
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.5831127546652074
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -0.797057298136513
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.8739623266889381
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.9055949815587607
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.3717401589284293
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.8954753327706836
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.443902794273718
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.8170293065772595
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.8678744718217458
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.5888889419166176
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.5184457398223877
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 0.6459921726268961
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 0.5825505351760564
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.30781936059658815
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.9399040923250676
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.7226496265719348
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -0.6744032518606176
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.15988443779303893
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.6216833935324934
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.7239292791625854
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.44876477963872724
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.8661404358626444
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.6612636672346782
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.6522982460445624
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.11768729340089135
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.10378556273608769
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.869921260257535
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.6351815318306434
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.9238103438241475
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.05443381894366891
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.926106029720133
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.5970888889807171
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.7367510767340781
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.2954103505882751
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.1446118096011615
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.2723992171399072
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.8317321464522959
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.10317870076634367
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.817701503136971
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 0.7714017989230135
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.07320105157241827
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.16090494417607717
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.5990997449543635
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.8159219409918431
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.3864534549275425
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.5679452610309854
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.8410690954676389
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 0.7370493915114469
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.8120062093666135
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.7489058509151091
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.6731546586678565
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.9146832300197422
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.8712719275051725
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.34071613601736916
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.7248226068999662
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.20393080099851543
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.878496710577068
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.5685694824364017
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.8878098845183852
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.6635400867036599
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.2945083526458317
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.6774248065200853
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.28517376288507185
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.6813313260627789
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -0.5852551579272961
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.34236670063161506
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.27686445538231985
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.9215539261397948
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.39767759912949835
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -0.6859461010291893
---------------------------------------------------------

Hidden units: 5
Epochs: 10000
Learning rate: 0.1

Errors during training:
Error at epoch 1 is 104.43288889808163
Train mean error at (after) epoch 1: 0.26108222224520405
Test error at (after) epoch 1: 0.2573149623790963
----------
Error at epoch 1000 is 3.328630672956591
Train mean error at (after) epoch 1000: 0.008321576682391477
Test error at (after) epoch 1000: 0.00992836148406004
----------
Error at epoch 2000 is 2.2827886922242286
Train mean error at (after) epoch 2000: 0.005706971730560572
Test error at (after) epoch 2000: 0.0059289856287207425
----------
Error at epoch 3000 is 1.9399902298693548
Train mean error at (after) epoch 3000: 0.004849975574673387
Test error at (after) epoch 3000: 0.004825259425577639
----------
Error at epoch 4000 is 1.6844535857415468
Train mean error at (after) epoch 4000: 0.004211133964353867
Test error at (after) epoch 4000: 0.004137811281961791
----------
Error at epoch 5000 is 1.4807895355314316
Train mean error at (after) epoch 5000: 0.003701973838828579
Test error at (after) epoch 5000: 0.0036232636109638223
----------
Error at epoch 6000 is 1.3176765041343454
Train mean error at (after) epoch 6000: 0.0032941912603358637
Test error at (after) epoch 6000: 0.0032316166654158623
----------
Error at epoch 7000 is 1.1859470185019385
Train mean error at (after) epoch 7000: 0.0029648675462548464
Test error at (after) epoch 7000: 0.002930683734293954
----------
Error at epoch 8000 is 1.0791567510592917
Train mean error at (after) epoch 8000: 0.0026978918776482293
Test error at (after) epoch 8000: 0.0026965825200874365
----------
Error at epoch 9000 is 0.9924149576128027
Train mean error at (after) epoch 9000: 0.002481037394032007
Test error at (after) epoch 9000: 0.002510570010449581
----------
Error at epoch 10000 is 0.9213540569673967
Train mean error at (after) epoch 10000: 0.0023033851424184917
Test error at (after) epoch 10000: 0.0023578227997951813
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.6108621146651829
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.7785348013318233
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.8246899113482191
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.44572763444870706
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.836937932955977
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.8236393364196063
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.7771472897601924
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.9005600267208566
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.09735646706004539
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.49242080016950823
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.9076762047697334
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.09102906381006404
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.5860075566159039
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.8743567714635324
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.8414694773913595
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.6791451881066355
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.5893951632941001
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.9218890572668064
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.13390535028061692
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.8597064870021668
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.7840619672717491
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.3513915200103574
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.6609658637443749
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.865912838977731
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.5085238421582637
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.8229567246456414
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 0.7054041771451912
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.8573554376518308
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.7826063522068526
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.8153189542989295
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.5624108114732868
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -0.7713106308299248
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.8951501370189784
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.9230616268080309
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.38432270268585705
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.9407228603838453
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.43168459440556634
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.8320980119191975
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.8911605679568035
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.5984327262773369
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.5029125326765407
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 0.5612717827283448
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 0.44023869330426985
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.2865299237122093
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.9456787667394889
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.7323519653964216
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -0.6041925818102724
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.14389433608713673
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.6396156720366565
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.7347905969517067
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.445761519644398
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.8830800399397344
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.635399966066316
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.6455013891431179
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.12885973988585664
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.11732086874853684
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.8567098026545937
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.6066867550076505
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.9266054970324045
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.04147264450914124
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.93049696507203
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.5898913204430348
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.7296633086246941
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.27748284891670694
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.14630811803972388
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.26452221425219374
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.8320294738814742
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.09261087203972707
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.8079634132677403
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 0.7532917507402715
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.04194160215813683
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.1482214618136298
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.5776650530381723
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.8744297079907489
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.3956998661744395
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.5388730233427054
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.8262427610768623
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 0.7121884193676503
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.8547377899937498
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.7379198391775603
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.6736994139151137
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.9584487188600538
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.9083840440592572
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.32990826813570234
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.708470859682064
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.2023426017147585
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.8933023692501411
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.5450234473589544
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.9495891290341837
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.6812369114872867
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.2811639389066404
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.6721647522420023
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.26839411334460156
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.6498998575689064
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -0.44115784013393183
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.32161095462859224
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.29945019112361765
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.9335953536523607
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.4020421514031914
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -0.6062047949351591
---------------------------------------------------------

Hidden units: 5
Epochs: 100
Learning rate: 0.3

Errors during training:
Error at epoch 1 is 144.72356199235853
Train mean error at (after) epoch 1: 0.3618089049808963
Test error at (after) epoch 1: 0.3169851342432393
----------
Error at epoch 10 is 72.81710113143548
Train mean error at (after) epoch 10: 0.1820427528285887
Test error at (after) epoch 10: 0.16709229166565198
----------
Error at epoch 20 is 34.14142808536507
Train mean error at (after) epoch 20: 0.08535357021341268
Test error at (after) epoch 20: 0.07864367360177564
----------
Error at epoch 30 is 16.70485687875182
Train mean error at (after) epoch 30: 0.04176214219687955
Test error at (after) epoch 30: 0.04656535624910151
----------
Error at epoch 40 is 13.359186550722107
Train mean error at (after) epoch 40: 0.03339796637680527
Test error at (after) epoch 40: 0.04145845206012526
----------
Error at epoch 50 is 12.447846188317442
Train mean error at (after) epoch 50: 0.031119615470793605
Test error at (after) epoch 50: 0.039451390829049006
----------
Error at epoch 60 is 11.800299164483642
Train mean error at (after) epoch 60: 0.029500747911209105
Test error at (after) epoch 60: 0.037533273635743714
----------
Error at epoch 70 is 11.19440369059663
Train mean error at (after) epoch 70: 0.027986009226491575
Test error at (after) epoch 70: 0.03562608025210104
----------
Error at epoch 80 is 10.61139486966747
Train mean error at (after) epoch 80: 0.026528487174168672
Test error at (after) epoch 80: 0.03377129093928087
----------
Error at epoch 90 is 10.052361125542472
Train mean error at (after) epoch 90: 0.02513090281385618
Test error at (after) epoch 90: 0.03198847030508131
----------
Error at epoch 100 is 9.51969145029275
Train mean error at (after) epoch 100: 0.023799228625731875
Test error at (after) epoch 100: 0.030287034915743152
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.44474222946434244
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.625483318951598
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.6803478054154052
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.32529395648475595
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.7049649985377282
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -1.1037087239480121
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.5646388169091208
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.7874217955296294
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.056338177220585504
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.358830868399411
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.6578301752050144
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.07034345696291956
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.4075999481679217
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.9791762735517637
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.6620343474907644
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.5156955822853527
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.41042763125052956
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.9690322664416224
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.08771213400989863
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 1.0111992515707702
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 1.0860454951511116
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.22575951133230593
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.4874008701654094
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -1.0212662775582448
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.37707536840738043
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.6898267117637669
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 1.1452519110127894
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 1.0181802587632482
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.6328115187568559
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.6702531761411631
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.4101014457758234
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -1.0900327555334806
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.9766235382931433
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.8526675565904864
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.24432197602802957
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.7957150198444953
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.29266302683336654
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 1.0252243745958873
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.8551083385185815
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.376629389036384
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.34024754873705854
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 1.1796611104715051
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 1.2388705067765013
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.20604088942494952
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.871568551935299
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.5729984800055375
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -1.192404343387483
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.11522760338702603
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.45907809268072003
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.5778021483193999
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.319903019786856
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.8462303205116521
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.45554921779362784
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.4488931696374939
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.07801053728092894
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.06567546473854627
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.6552745856719293
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.4531170900093668
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.7871889668159585
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.03760616617336569
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.8620312898541125
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.4116227331146947
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.5552881718234075
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.18709672450303902
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.0850265797898895
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.19270999939124098
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.6953892174346826
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.07591796249673062
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.6555928073857926
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 1.102575628502979
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.042923278943593095
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.11303978642702898
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.43401106214042706
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.7089965419379063
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.23706333140937977
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.3934144219197748
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.622288455225045
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 1.1418568334887647
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.6340761653018125
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.5862794796474936
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.5019009160683029
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.9082234374805508
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.8044757949438499
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.23003962396435046
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.49497935192026693
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.12937519921985965
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.7674030015025923
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.4053118359062575
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.7932222678270398
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.5136602297979699
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.19186013710971433
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.5170876150722057
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.18036400601348787
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.49602439627945605
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -1.244065224983751
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.20870467774443677
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.17647954581436365
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.7705702676564683
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.2410220332217437
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -1.1945926254236259
---------------------------------------------------------

Hidden units: 5
Epochs: 1000
Learning rate: 0.3

Errors during training:
Error at epoch 1 is 115.51643212942018
Train mean error at (after) epoch 1: 0.28879108032355044
Test error at (after) epoch 1: 0.2642544314773618
----------
Error at epoch 100 is 14.71514611997441
Train mean error at (after) epoch 100: 0.03678786529993602
Test error at (after) epoch 100: 0.046263433223558276
----------
Error at epoch 200 is 10.87508831327541
Train mean error at (after) epoch 200: 0.027187720783188526
Test error at (after) epoch 200: 0.03457022820962481
----------
Error at epoch 300 is 8.045611830972796
Train mean error at (after) epoch 300: 0.02011402957743199
Test error at (after) epoch 300: 0.025767113648965823
----------
Error at epoch 400 is 5.989396549233981
Train mean error at (after) epoch 400: 0.014973491373084952
Test error at (after) epoch 400: 0.01917024827788198
----------
Error at epoch 500 is 4.41566488504608
Train mean error at (after) epoch 500: 0.0110391622126152
Test error at (after) epoch 500: 0.013917149978432776
----------
Error at epoch 600 is 3.317026573717782
Train mean error at (after) epoch 600: 0.008292566434294456
Test error at (after) epoch 600: 0.010102244201037652
----------
Error at epoch 700 is 2.663799962299771
Train mean error at (after) epoch 700: 0.006659499905749428
Test error at (after) epoch 700: 0.0077302861483751605
----------
Error at epoch 800 is 2.3158883231008596
Train mean error at (after) epoch 800: 0.005789720807752149
Test error at (after) epoch 800: 0.006404159650027191
----------
Error at epoch 900 is 2.127693925905072
Train mean error at (after) epoch 900: 0.00531923481476268
Test error at (after) epoch 900: 0.005668762135625767
----------
Error at epoch 1000 is 2.0099637792643543
Train mean error at (after) epoch 1000: 0.005024909448160886
Test error at (after) epoch 1000: 0.005223355471016707
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.6280160172678622
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.7695234843216204
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.835592845384015
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.4797155103558443
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.8117357725437687
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.8643997806283588
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.7476401212529518
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.8742163134993937
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.09134382533173235
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.5096641449958511
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.8310742782820143
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.09174614326813892
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.5689045190995115
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.850448806358473
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.8055688432585956
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.6884243023814509
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.5701491819767993
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.9160380714396589
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.13423951888229857
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.811676918639488
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.7870941494321085
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.35008293843509064
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.6542390339805404
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.8353586857980627
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.5347740854392528
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.83727687434618
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 0.7717778883223286
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.8840612533234707
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.7887628950585857
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.8011148199821133
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.5817322621003862
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -0.8273953934103059
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.8909716325621638
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.8757140221363474
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.3698561036169148
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.9138030310266646
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.4398080370368958
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.8476536724388838
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.8821193130602657
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.5792618868818019
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.5154193784456096
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 0.70030763753575
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 0.6479429996929804
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.323720400977435
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.9321346166709001
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.7353017104586094
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -0.7148559671829187
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.1478333840068744
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.6281095165632512
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.764364649489794
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.4620462171543614
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.8569988786443793
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.6608919670511485
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.6240022642515822
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.09638331406709127
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.08269893353702343
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.8239043824754034
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.6317639646190724
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.9302003886185399
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.07717771659081782
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.9012629979587575
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.5683363777310234
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.7393256938046936
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.29139296282066257
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.1565625363034509
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.27174472280842804
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.8193292996643563
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.1149511896056743
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.8095441381295134
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 0.8042253006536645
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.0674888612107161
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.17084055086778038
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.5972759882041867
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.8192757817086703
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.37629658097537555
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.542958280446702
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.8391977745976938
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 0.7631179799354345
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.8020043345409689
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.7460982101663681
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.6674532271874519
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.9110868373767248
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.8873742200700957
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.31490078873114613
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.6915871577340704
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.20943799262869192
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.8770275090300874
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.565704157641534
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.8775479116380356
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.7001614556682386
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.3006948055072786
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.6981746037124313
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.29866079859403866
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.6871867038286776
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -0.6526043515522479
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.3484413981934422
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.2987378666479358
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.8711079804375267
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.39173083959859173
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -0.7237977599178902
---------------------------------------------------------

Hidden units: 5
Epochs: 3000
Learning rate: 0.3

Errors during training:
Error at epoch 1 is 119.85335219602972
Train mean error at (after) epoch 1: 0.2996333804900743
Test error at (after) epoch 1: 0.23894175227268505
----------
Error at epoch 300 is 2.8876707317469785
Train mean error at (after) epoch 300: 0.007219176829367446
Test error at (after) epoch 300: 0.00856923504217123
----------
Error at epoch 600 is 1.8954106767044179
Train mean error at (after) epoch 600: 0.004738526691761045
Test error at (after) epoch 600: 0.004961989415104359
----------
Error at epoch 900 is 1.656629947552115
Train mean error at (after) epoch 900: 0.0041415748688802875
Test error at (after) epoch 900: 0.0042594613449400106
----------
Error at epoch 1200 is 1.4781868673435037
Train mean error at (after) epoch 1200: 0.0036954671683587592
Test error at (after) epoch 1200: 0.0037864755088216732
----------
Error at epoch 1500 is 1.3365602191473096
Train mean error at (after) epoch 1500: 0.003341400547868274
Test error at (after) epoch 1500: 0.0034192668163889684
----------
Error at epoch 1800 is 1.2192552839240276
Train mean error at (after) epoch 1800: 0.003048138209810069
Test error at (after) epoch 1800: 0.0031182060657785424
----------
Error at epoch 2100 is 1.1187830443647542
Train mean error at (after) epoch 2100: 0.0027969576109118854
Test error at (after) epoch 2100: 0.002860710573035955
----------
Error at epoch 2400 is 1.030868856910548
Train mean error at (after) epoch 2400: 0.00257717214227637
Test error at (after) epoch 2400: 0.0026342291587987967
----------
Error at epoch 2700 is 0.9529810396721501
Train mean error at (after) epoch 2700: 0.002382452599180375
Test error at (after) epoch 2700: 0.0024319316520042956
----------
Error at epoch 3000 is 0.8834512615258501
Train mean error at (after) epoch 3000: 0.0022086281538146253
Test error at (after) epoch 3000: 0.0022497715054978244
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.6090567095353208
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.7909541162778885
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.8482999769293819
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.4551538096911828
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.8503187060105429
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.8314773562359831
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.78879955507989
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.894266331479465
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.09692467956064232
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.5166806012281104
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.9173333217717645
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.05885216789019257
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.5602841729814081
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.8788082158319851
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.8144186939664105
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.6829192865689601
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.5555045696021625
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.924199815905144
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.11910682390566435
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.8924814452629622
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.7978393032633736
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.346570824947323
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.6510054643852177
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.8666898000129767
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.5168025293602091
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.8357687592368693
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 0.6735826040801964
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.874098215724655
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.7987344674685124
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.8308790199197404
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.5645965592809233
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -0.7939419986944162
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.9160159727727404
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.9046472880289589
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.3692313772798278
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.9012379533625702
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.41789441533399596
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.8494060173972369
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.9082280139972317
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.5855687819909368
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.5141862298933151
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 0.5758466757633808
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 0.42395248102973115
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.29514894162522154
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.9688122754727859
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.7507874794995024
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -0.6164699846400304
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.14073158984524564
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.6428779333010285
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.7609890833409719
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.44087523589136535
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.8954042650931017
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.6430457448194979
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.612096950801804
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.11286216845150049
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.0956726692166716
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.8428075981882157
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.6077548128762582
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.9743658140313006
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.056915265886050226
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.9208961606317064
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.5818146183259648
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.7402137297555366
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.28724788667081386
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.13022368517159416
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.26051611855081686
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.8365436353761356
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.1018549656267802
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.8097757395943775
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 0.7526148564322581
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.06883101656435162
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.15671011335155785
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.5858123287619117
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.8669034490339482
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.37119178931116936
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.5559466893277946
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.8777949936781613
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 0.6916806085942543
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.8145192907455691
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.7342460238768348
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.6694028386674243
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.9351421307719332
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.9268860665904158
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.3112471731271681
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.6926438920894249
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.1892261828848959
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.9075452596708673
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.5437131662787286
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.9280047612095689
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.7126529064443022
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.28024074974385726
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.685315226835714
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.2759824552518295
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.6632851154800657
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -0.455861672589258
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.3390954432477449
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.27591375041121213
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.8968555088450342
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.41548203733641037
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -0.6090556954013869
---------------------------------------------------------

Hidden units: 5
Epochs: 10000
Learning rate: 0.3

Errors during training:
Error at epoch 1 is 69.71176198603959
Train mean error at (after) epoch 1: 0.17427940496509897
Test error at (after) epoch 1: 0.17668685715819277
----------
Error at epoch 1000 is 1.9774767983699357
Train mean error at (after) epoch 1000: 0.004943691995924839
Test error at (after) epoch 1000: 0.0051427647104504304
----------
Error at epoch 2000 is 1.3084861156746486
Train mean error at (after) epoch 2000: 0.0032712152891866213
Test error at (after) epoch 2000: 0.003359463890925768
----------
Error at epoch 3000 is 0.9844814021145692
Train mean error at (after) epoch 3000: 0.0024612035052864233
Test error at (after) epoch 3000: 0.00249125900224135
----------
Error at epoch 4000 is 0.7808944618513006
Train mean error at (after) epoch 4000: 0.0019522361546282516
Test error at (after) epoch 4000: 0.0019590331487862695
----------
Error at epoch 5000 is 0.7354122787084778
Train mean error at (after) epoch 5000: 0.0018385306967711945
Test error at (after) epoch 5000: 0.0018172108054603142
----------
Error at epoch 6000 is 0.6926353730922692
Train mean error at (after) epoch 6000: 0.001731588432730673
Test error at (after) epoch 6000: 0.001673281947610132
----------
Error at epoch 7000 is 0.650289722176698
Train mean error at (after) epoch 7000: 0.001625724305441745
Test error at (after) epoch 7000: 0.0015335999533301087
----------
Error at epoch 8000 is 0.6119058728410391
Train mean error at (after) epoch 8000: 0.0015297646821025978
Test error at (after) epoch 8000: 0.0014171335451592998
----------
Error at epoch 9000 is 0.5832294274913956
Train mean error at (after) epoch 9000: 0.001458073568728489
Test error at (after) epoch 9000: 0.0013305025188272027
----------
Error at epoch 10000 is 0.5653933289209071
Train mean error at (after) epoch 10000: 0.0014134833223022677
Test error at (after) epoch 10000: 0.001269557298441995
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.6209533507807841
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.805407590380474
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.8372026870531779
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.472650249188549
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.8783458942542235
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.8792763516812225
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.679696471582516
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.9368123376097608
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.09320278412626201
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.4391568748802744
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.8234298245244089
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.07192713613526075
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.5768149964098663
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.9156277499725134
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.8299010199585857
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.6771449383475252
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.5527940873813266
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.9334714441341432
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.11921232145840105
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.9678348547324953
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.8213615977409168
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.2915168796535806
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.6472097864560009
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.9010223799800527
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.5351122908783725
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.8741576772610977
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 0.681401726619228
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.8715568913610565
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.8128019792172687
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.8613730392899235
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.5710619768730643
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -0.7801064234042199
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.8931901866108856
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.9407293448883105
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.3534136781493818
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.9512654252284465
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.41147561469160104
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.865141941399175
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.9304186381412087
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.5494101542208227
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.5263970361939978
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 0.49317695496925923
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 0.3359193573963207
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.2784334554294326
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.9622452124148528
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.7581037617565316
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -0.5682473563367472
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.14899552265878752
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.6303615828057059
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.7341017225736801
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.44828560286360325
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.923792039197074
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.6629463055629272
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.5512917743081596
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.10626395176264009
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.09792797119773128
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.8375623277670385
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.6341472043245755
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.9589370249911187
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.0450273506426207
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.9602907582273925
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.5331137169527842
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.7613763658347779
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.2694568498810704
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.11562644627278512
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.26466210055555656
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.8643016986704697
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.09729026194321627
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.8407795631933279
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 0.7210975919877907
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.0685957051536476
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.15552178209983003
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.5975477605267732
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.8670362008645345
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.2930889298084692
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.48114743674262844
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.860128213518123
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 0.6627217692654763
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.8306326738340293
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.7669283090377192
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.6830275279987499
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.96907824781944
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.9269658005063395
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.2951186767725544
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.6552708186317262
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.1790642125006951
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.9078336529308684
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.5653987266803668
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.9464931633519529
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.6871438954539848
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.2817228103207296
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.6859529214771585
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.28733531921236494
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.6830222477790442
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -0.356009352372821
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.3408323399628628
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.2680686430416469
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.9179949492065593
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.38887058536898317
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -0.5682306603628857
---------------------------------------------------------

Hidden units: 5
Epochs: 100
Learning rate: 0.5

Errors during training:
Error at epoch 1 is 112.56130623613097
Train mean error at (after) epoch 1: 0.2814032655903274
Test error at (after) epoch 1: 0.23977235231828042
----------
Error at epoch 10 is 27.044230087212913
Train mean error at (after) epoch 10: 0.06761057521803228
Test error at (after) epoch 10: 0.059444313097373636
----------
Error at epoch 20 is 12.22777818480758
Train mean error at (after) epoch 20: 0.030569445462018948
Test error at (after) epoch 20: 0.03757116184817078
----------
Error at epoch 30 is 10.750998266447501
Train mean error at (after) epoch 30: 0.026877495666118755
Test error at (after) epoch 30: 0.033961672358287724
----------
Error at epoch 40 is 9.601014871203297
Train mean error at (after) epoch 40: 0.024002537178008244
Test error at (after) epoch 40: 0.0304473685912017
----------
Error at epoch 50 is 8.590268392667447
Train mean error at (after) epoch 50: 0.021475670981668617
Test error at (after) epoch 50: 0.027300011640929777
----------
Error at epoch 60 is 7.71912718940039
Train mean error at (after) epoch 60: 0.019297817973500976
Test error at (after) epoch 60: 0.024569774153679315
----------
Error at epoch 70 is 6.978490846309926
Train mean error at (after) epoch 70: 0.017446227115774815
Test error at (after) epoch 70: 0.022232756312318358
----------
Error at epoch 80 is 6.353706927165373
Train mean error at (after) epoch 80: 0.015884267317913432
Test error at (after) epoch 80: 0.020244277572176016
----------
Error at epoch 90 is 5.828241271776399
Train mean error at (after) epoch 90: 0.014570603179440998
Test error at (after) epoch 90: 0.01855404437508917
----------
Error at epoch 100 is 5.385851937488433
Train mean error at (after) epoch 100: 0.013464629843721083
Test error at (after) epoch 100: 0.017113163675419752
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.5103338889170504
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.6550906400745757
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.7420853979818446
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.4020376622801423
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.723304663701386
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -1.106340003513448
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.6713939650893159
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.8020125325510365
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.05670491820414589
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.4020704662980996
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.7850576713485418
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.0811337168873973
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.4477537670936578
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.8870159037947959
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.6822020826760663
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.5981683782446049
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.4661057998311188
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.9517306637726503
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.11960873176687413
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.8778572563454161
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.9441924067189148
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.2986381625605372
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.5314070791199084
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.9288995310099223
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.4424811941904174
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.7678257318666231
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 1.0601264709317597
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.9838492476848829
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.7068436228260168
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.7021326211932976
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.4709604973184287
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -1.0219029177370427
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.9672631000690097
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.8565631761718983
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.29299610511164087
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.9142096402451848
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.34229947523785237
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 1.0152734641609487
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.8979658976512573
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.46667428813735595
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.3792384907149396
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 1.0000753899449024
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 1.0429411525278802
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.2630839246098503
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.9105477191826427
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.6238748244601695
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -0.9960324318951816
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.11723434598452298
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.5249110258971856
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.6381262322339608
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.3680959576922119
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.8287297392687933
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.5437898291474036
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.48462013571181006
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.06346448191084705
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.04751656415951351
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.7024351883316304
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.510282583836599
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.8826305807447005
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.07922800190015716
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.8624583086654058
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.4944704434541714
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.6524531352066936
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.2139020411368547
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.11641990686642603
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.24213998903843809
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.7241524339464197
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.11442421946226838
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.7088150406321119
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 0.981697571293062
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.022126898594680585
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.15406795533720294
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.5007746950457566
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.7470770572581121
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.3228063416739186
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.46222653276106884
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.7284102687154979
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 1.0057546286397003
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.7116203341704185
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.6380275457425978
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.5535642379398878
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.9774580800639356
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.875568553026896
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.2319226541340968
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.5517414838931913
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.16018559054021844
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.8356926416861509
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.4594184707702056
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.841084972949723
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.5845451521139173
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.23391238168970258
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.5768088374204431
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.23183032461941666
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.585768774216624
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -1.01055473109976
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.25396330720889665
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.2532124976499649
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.7715029437525236
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.31077660754635533
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -1.0096941549527183
---------------------------------------------------------

Hidden units: 5
Epochs: 1000
Learning rate: 0.5

Errors during training:
Error at epoch 1 is 102.37361463578557
Train mean error at (after) epoch 1: 0.25593403658946395
Test error at (after) epoch 1: 0.20044014288383785
----------
Error at epoch 100 is 5.23103206455533
Train mean error at (after) epoch 100: 0.013077580161388325
Test error at (after) epoch 100: 0.016310599631628005
----------
Error at epoch 200 is 3.064046414254745
Train mean error at (after) epoch 200: 0.007660116035636862
Test error at (after) epoch 200: 0.008889098938968802
----------
Error at epoch 300 is 2.2747876086921566
Train mean error at (after) epoch 300: 0.005686969021730392
Test error at (after) epoch 300: 0.0060791088692726345
----------
Error at epoch 400 is 2.0075526857218065
Train mean error at (after) epoch 400: 0.005018881714304516
Test error at (after) epoch 400: 0.005227455209121149
----------
Error at epoch 500 is 1.844777124105938
Train mean error at (after) epoch 500: 0.004611942810264846
Test error at (after) epoch 500: 0.0048014639566739655
----------
Error at epoch 600 is 1.7129920038476012
Train mean error at (after) epoch 600: 0.004282480009619003
Test error at (after) epoch 600: 0.004483356450366722
----------
Error at epoch 700 is 1.600927327878569
Train mean error at (after) epoch 700: 0.0040023183196964225
Test error at (after) epoch 700: 0.0042179792235973075
----------
Error at epoch 800 is 1.503646160025755
Train mean error at (after) epoch 800: 0.0037591154000643874
Test error at (after) epoch 800: 0.003988297337003299
----------
Error at epoch 900 is 1.4179077998045533
Train mean error at (after) epoch 900: 0.0035447694995113833
Test error at (after) epoch 900: 0.0037857081587144513
----------
Error at epoch 1000 is 1.3415902012393022
Train mean error at (after) epoch 1000: 0.0033539755030982553
Test error at (after) epoch 1000: 0.003605029651014476
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.6134541732817443
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.7726013959658045
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.8094306125356406
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.4564917354520296
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.8207640020786886
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.7932254327243962
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.8111825154428549
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.8770173798411303
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.1002254168115059
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.5049875513692689
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.9691940058718975
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.07173072457907154
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.6141611217098969
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.8505935379848809
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.8304868960481141
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.6759064035108716
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.5646891163514095
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.8960427918884749
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.123044285143464
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.8181724125931056
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.7841758847977641
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.3508505887373604
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.6549203147662556
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.8691600774380036
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.5222042454712389
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.8170594235559118
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 0.6993434590506612
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.8497324284192982
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.7801104112564122
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.8043465556406012
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.5662430214552021
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -0.7800656392995667
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.9061017499915841
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.9336720674810486
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.43414004508124027
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.879964609873586
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.4384439989287391
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.8394503530359488
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.8737621672815772
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.591318256222289
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.527324646309016
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 0.6174976378160248
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 0.5118458594821075
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.30145821488934277
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.9421435165801725
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.7175954925240713
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -0.6356950485764898
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.13864398637190098
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.6464449908714502
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.7162838945806045
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.4325711077643528
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.8693822194357661
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.6452740064718548
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.6394040579030059
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.11198384163296585
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.0984074194351887
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.850242110272125
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.6181463180257458
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.9268325865912843
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.05551921234591041
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.9002058122181502
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.6548466101890794
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.7447735577167365
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.2885319390224288
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.15003221588961846
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.27361453929384116
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.8251007627155323
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.09518233731556985
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.8060789753372631
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 0.7668162534583729
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.06554828403097622
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.15239156069465956
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.5800923652904864
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.8930842883051285
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.3846294148123677
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.5804742888167332
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.8389388358963408
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 0.7310632591782309
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.813531818322065
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.740349893933236
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.6731081263643066
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.9236082468139466
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.9128999673105654
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.30734482321966594
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.7160169500690092
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.20316158985842284
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.9014693225936242
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.547350590046398
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.928284068703211
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.6661415824994711
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.2876318640163016
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.6624540032759864
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.283424665382385
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.6603417498012283
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -0.5338087309395992
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.3390754194882629
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.27662662025462015
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.9120367961439706
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.4086822931595028
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -0.6459207183481255
---------------------------------------------------------

Hidden units: 5
Epochs: 3000
Learning rate: 0.5

Errors during training:
Error at epoch 1 is 65.41725628966022
Train mean error at (after) epoch 1: 0.16354314072415055
Test error at (after) epoch 1: 0.13875329897163005
----------
Error at epoch 300 is 2.601415835381678
Train mean error at (after) epoch 300: 0.006503539588454194
Test error at (after) epoch 300: 0.006923572354212994
----------
Error at epoch 600 is 1.8508791223662588
Train mean error at (after) epoch 600: 0.004627197805915647
Test error at (after) epoch 600: 0.004675600990729587
----------
Error at epoch 900 is 1.4911359365233725
Train mean error at (after) epoch 900: 0.003727839841308431
Test error at (after) epoch 900: 0.0037479342927519326
----------
Error at epoch 1200 is 1.2501381808636725
Train mean error at (after) epoch 1200: 0.003125345452159181
Test error at (after) epoch 1200: 0.003149517492548836
----------
Error at epoch 1500 is 1.0826250772686346
Train mean error at (after) epoch 1500: 0.0027065626931715866
Test error at (after) epoch 1500: 0.0027464080740756862
----------
Error at epoch 1800 is 1.1751418593257874
Train mean error at (after) epoch 1800: 0.0029378546483144687
Test error at (after) epoch 1800: 0.0030064387283160548
----------
Error at epoch 2100 is 1.0364459917854139
Train mean error at (after) epoch 2100: 0.002591114979463535
Test error at (after) epoch 2100: 0.002675372697527196
----------
Error at epoch 2400 is 1.1310306672070534
Train mean error at (after) epoch 2400: 0.0028275766680176334
Test error at (after) epoch 2400: 0.0029328289857791416
----------
Error at epoch 2700 is 1.0105177668030374
Train mean error at (after) epoch 2700: 0.0025262944170075935
Test error at (after) epoch 2700: 0.0026403026955805187
----------
Error at epoch 3000 is 1.101968553503253
Train mean error at (after) epoch 3000: 0.0027549213837581325
Test error at (after) epoch 3000: 0.002887611347602023
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.6050788030002516
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.8186421674351996
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.8404088913746062
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.4420441935370781
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.8225511052945209
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.8288018852642184
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.7640062293112567
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.8748054375122024
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.10204551246832468
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.4832299733158145
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.9311022008279014
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.09939293848354998
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.5988068773943895
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.8800631828650216
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.8372180614715787
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.6675868497783395
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.5961023917404711
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.8802900516135892
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.11812666887057797
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.8539201221708986
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.7720425329565357
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.31787706686358597
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.6917029721731289
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.8524813041069078
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.5157601738007722
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.8061333956118214
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 0.7062785655946189
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.810958732808021
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.779659910685332
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.8208984229318984
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.5598262198004225
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -0.7555018774757751
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.8740047912941193
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.9366887759849907
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.39152879059011336
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.9469307682308059
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.42818863440330324
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.8232948200858192
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.8766213445217874
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.5843905948837407
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.5142025358733483
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 0.5828560876932156
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 0.46823180187308355
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.28415580163693205
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.9328140775233948
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.7247105919027467
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -0.6151767680130642
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.1381682775286917
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.6206548162664324
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.7337026435372289
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.45252279260485273
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.8675461399514317
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.6287291027756766
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.6495293978303971
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.13386059441089898
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.12415732067186087
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.8567237945053253
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.6043362703946265
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.92110407318496
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.03919554293103626
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.8939602955910179
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.6063950283312258
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.7244894822933369
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.28969678350831507
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.1459008748884401
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.27343378605732366
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.8424128560418314
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.09288071900489896
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.8000422608982488
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 0.7320519097794866
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.06442968978674508
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.14915503500580346
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.5727653158996032
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.8635798310284534
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.37877194693607896
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.5204697711874501
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.8125132173978216
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 0.7180048853798451
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.8564437270693182
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.7303262568425357
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.7155718695728062
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.9611567367835788
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.9306320941826385
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.32080560491607113
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.7242259882339945
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.19840466631390408
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.8853193306352122
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.5403224033383377
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.953089001576187
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.6665178807146429
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.28395341458667045
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.676510971824599
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.2719376123325476
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.6441063711655863
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -0.474198740906432
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.32531056244676126
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.29643057954417623
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.9240962454935314
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.3791418854451873
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -0.6155520432197162
---------------------------------------------------------

Hidden units: 5
Epochs: 10000
Learning rate: 0.5

Errors during training:
Error at epoch 1 is 76.53413684321585
Train mean error at (after) epoch 1: 0.19133534210803962
Test error at (after) epoch 1: 0.15549784305952857
----------
Error at epoch 1000 is 1.4960246848950087
Train mean error at (after) epoch 1000: 0.003740061712237522
Test error at (after) epoch 1000: 0.003994018737235579
----------
Error at epoch 2000 is 1.1901285429875943
Train mean error at (after) epoch 2000: 0.002975321357468986
Test error at (after) epoch 2000: 0.003274444062167622
----------
Error at epoch 3000 is 1.2335608350271678
Train mean error at (after) epoch 3000: 0.0030839020875679194
Test error at (after) epoch 3000: 0.003399353203017743
----------
Error at epoch 4000 is 1.0371627998481119
Train mean error at (after) epoch 4000: 0.0025929069996202796
Test error at (after) epoch 4000: 0.002940679125315046
----------
Error at epoch 5000 is 1.0734842751152838
Train mean error at (after) epoch 5000: 0.0026837106877882094
Test error at (after) epoch 5000: 0.0030283427735542314
----------
Error at epoch 6000 is 1.1144701316102232
Train mean error at (after) epoch 6000: 0.002786175329025558
Test error at (after) epoch 6000: 0.00310730545304259
----------
Error at epoch 7000 is 1.164812302921083
Train mean error at (after) epoch 7000: 0.002912030757302708
Test error at (after) epoch 7000: 0.003192310208098901
----------
Error at epoch 8000 is 1.010594813395185
Train mean error at (after) epoch 8000: 0.0025264870334879624
Test error at (after) epoch 8000: 0.002764662668662892
----------
Error at epoch 9000 is 1.04220540385473
Train mean error at (after) epoch 9000: 0.0026055135096368248
Test error at (after) epoch 9000: 0.0028038124277780414
----------
Error at epoch 10000 is 1.1048937852551013
Train mean error at (after) epoch 10000: 0.002762234463137753
Test error at (after) epoch 10000: 0.0029318441093637714
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.6066150905731426
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.8177279471210794
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.8428111624293011
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.450507886547303
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.813582492666184
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.8104909749379653
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.7423488685275643
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.8738882161377952
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.08791918933916487
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.4816829983529154
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.9197094151296753
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.08971598889231666
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.5979807877501319
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.8763543947587326
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.8361997836235527
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.6698699264079752
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.5949543300843357
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.8823848746269777
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.1311034568043027
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.8371454558776793
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.7630741035347003
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.34243653292828846
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.6785958980177712
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.8548931153005999
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.526717972564418
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.7947721313732209
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 0.7065858958475432
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.8147665416259734
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.776689753719746
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.8190047164224674
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.5611801936779419
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -0.748463942308344
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.8969495091363888
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.9381090032009266
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.3782661011639514
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.9174576221812506
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.4229690521714672
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.8220349210181743
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.8741353178076484
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.6020460274351175
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.533754421970118
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 0.5808406424457118
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 0.4626823229043495
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.279485079438312
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.9333809773237524
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.7202120393575714
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -0.6142102404212084
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.13524941024984957
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.6150836864839677
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.7364621516362698
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.44407734966662726
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.8602786398356491
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.6287950474543368
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.6505262968240586
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.13238371137189345
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.1255300850690984
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.8564398974331086
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.6025269407458846
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.9260324647680943
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.033353602903301534
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.8969445936994854
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.5912282111840801
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.735361340574531
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.2735115183363723
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.15640805299908916
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.2788625572383314
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.8461808227816222
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.09680142093731914
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.8067827907816726
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 0.7473225750913148
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.05610790040513595
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.1552171425647815
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.5693605819119866
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.8806824221408751
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.38608993497375615
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.5174280402419755
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.8247668928149136
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 0.7215434790478562
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.8454151325496853
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.7250563657611736
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.7181693954486027
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.9702958006694749
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.9268886920259991
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.34074173677014363
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.7190852565666241
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.20519657805399016
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.9094894575986184
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.5337786146024606
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.9474835670674989
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.6588878826295055
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.28404983802895534
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.6788375521942689
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.27603387997761014
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.6318552084557993
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -0.48361529479633025
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.3232644283679834
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.27553481180698886
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.9277153214705195
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.4087895476074135
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -0.6143614070221667
---------------------------------------------------------

Hidden units: 5
Epochs: 100
Learning rate: 1

Errors during training:
Error at epoch 1 is 85.63575922799761
Train mean error at (after) epoch 1: 0.21408939806999402
Test error at (after) epoch 1: 0.15261357865150657
----------
Error at epoch 10 is 14.53586617438672
Train mean error at (after) epoch 10: 0.036339665435966804
Test error at (after) epoch 10: 0.04509848023403247
----------
Error at epoch 20 is 12.784772026961821
Train mean error at (after) epoch 20: 0.031961930067404554
Test error at (after) epoch 20: 0.04015242569496257
----------
Error at epoch 30 is 11.483085505942118
Train mean error at (after) epoch 30: 0.028707713764855293
Test error at (after) epoch 30: 0.036102953163037854
----------
Error at epoch 40 is 10.349060117781404
Train mean error at (after) epoch 40: 0.02587265029445351
Test error at (after) epoch 40: 0.03256315139143005
----------
Error at epoch 50 is 9.36077089981405
Train mean error at (after) epoch 50: 0.023401927249535125
Test error at (after) epoch 50: 0.029460561344610347
----------
Error at epoch 60 is 8.492309213301795
Train mean error at (after) epoch 60: 0.021230773033254487
Test error at (after) epoch 60: 0.026711456397090688
----------
Error at epoch 70 is 7.718371632400823
Train mean error at (after) epoch 70: 0.019295929081002056
Test error at (after) epoch 70: 0.02423628294744924
----------
Error at epoch 80 is 7.017692310680267
Train mean error at (after) epoch 80: 0.017544230776700667
Test error at (after) epoch 80: 0.02197012133294403
----------
Error at epoch 90 is 6.37473361310637
Train mean error at (after) epoch 90: 0.015936834032765926
Test error at (after) epoch 90: 0.01986753268445969
----------
Error at epoch 100 is 5.780210429032029
Train mean error at (after) epoch 100: 0.014450526072580072
Test error at (after) epoch 100: 0.017903747937186593
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.5053664461697434
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.7062630550923241
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.7544401265581474
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.3734497112551586
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.7652830288073756
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.9691681510095335
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.624878343391199
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.8320893987033817
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.07685976721181824
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.3999550475199525
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.7355801129125549
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.06100598052347124
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.45850041372148354
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.9875788204525245
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.7219917146354123
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.5735650260652868
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.45914163272266506
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.9443190460570795
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.08222947328594178
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 1.0188958732929312
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 1.0242793959974739
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.24535754146943092
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.5583869368105431
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.9795902623818602
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.4315901814679586
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.7385054433010797
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 1.0045799724527416
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.9832670492343745
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.6975151728947412
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.7479831071373043
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.4681811252820594
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -1.0045874576407114
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.9770121521961611
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.8517828522367362
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.28304921608150646
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.7955445375609439
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.33735398183593085
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.9894422122515013
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.883326075855564
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.4293143223133057
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.39735016409732704
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 1.0546783660831596
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 1.030801328142303
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.23010982699472585
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.8621782195601474
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.640691336824842
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -1.0489072811864388
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.12694910672479884
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.5177550508336592
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.6505117112285611
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.3605152335548967
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.8758247583194881
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.5134660104566663
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.5113964411512498
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.09874977440625433
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.08809076908893515
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.7045340182193347
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.5135597790535081
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.7926459456817142
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.03410792100566482
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.8874234220483207
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.4685408552838395
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.6286810245527367
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.2356196088364725
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.09393799003477106
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.21308680797184912
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.7686999367612029
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.0787805251045918
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.7238790291210665
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 1.0398192202696386
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.06897375397866455
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.12404444535885055
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.4895965733033513
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.7520894142176574
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.26838438945066817
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.443595261001684
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.6661394288777877
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 1.0151106131809804
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.720233653187366
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.6406882906378152
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.5751133704053594
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.9172034061072213
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.8646042333440241
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.2696589872401873
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.5550427074974503
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.1445733342399468
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.8314097859129791
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.45862952455100503
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.8805426447797208
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.582286952937532
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.22222315745711166
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.5852977660869619
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.21434713429544935
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.5534085406315842
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -1.0585918240674124
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.2545024812589619
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.20019556839920705
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.8106414723470182
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.28747130721945263
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -1.0368452855413481
---------------------------------------------------------

Hidden units: 5
Epochs: 1000
Learning rate: 1

Errors during training:
Error at epoch 1 is 94.52971141861778
Train mean error at (after) epoch 1: 0.23632427854654445
Test error at (after) epoch 1: 0.1369291478249323
----------
Error at epoch 100 is 2.579663514035062
Train mean error at (after) epoch 100: 0.0064491587850876555
Test error at (after) epoch 100: 0.007324643858852169
----------
Error at epoch 200 is 1.896897784367927
Train mean error at (after) epoch 200: 0.0047422444609198176
Test error at (after) epoch 200: 0.004925558107019971
----------
Error at epoch 300 is 2.7561586705066707
Train mean error at (after) epoch 300: 0.006890396676266677
Test error at (after) epoch 300: 0.007668652489309431
----------
Error at epoch 400 is 2.082329608747025
Train mean error at (after) epoch 400: 0.005205824021867562
Test error at (after) epoch 400: 0.00540431642553506
----------
Error at epoch 500 is 1.7413657732713048
Train mean error at (after) epoch 500: 0.004353414433178262
Test error at (after) epoch 500: 0.004509854239503841
----------
Error at epoch 600 is 2.609589399149079
Train mean error at (after) epoch 600: 0.006523973497872697
Test error at (after) epoch 600: 0.007172053861661135
----------
Error at epoch 700 is 2.004802855591889
Train mean error at (after) epoch 700: 0.0050120071389797224
Test error at (after) epoch 700: 0.0052252361721966
----------
Error at epoch 800 is 1.6910629021348353
Train mean error at (after) epoch 800: 0.004227657255337088
Test error at (after) epoch 800: 0.004433601350024381
----------
Error at epoch 900 is 2.3806294189233057
Train mean error at (after) epoch 900: 0.005951573547308265
Test error at (after) epoch 900: 0.006449823670137671
----------
Error at epoch 1000 is 1.899670597941017
Train mean error at (after) epoch 1000: 0.0047491764948525425
Test error at (after) epoch 1000: 0.005006746412915795
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.6188161751084803
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.7974535872849562
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.807380057759903
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.4705135147986367
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.8121797282060818
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.8426988976894193
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.7769144956902828
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.8513929883497099
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.092606426177718
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.5341613496701023
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.8902270766247444
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.06247062442851303
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.5919792114250413
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.8403355169408261
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.7934152688803631
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.6948435935919508
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.5779139593432012
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.8904928651852058
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.1281976209499487
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.8324241196011767
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.7776270487029816
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.37437671903540815
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.6910379473773134
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.8354142702682305
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.5452177269250343
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.8163511717947378
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 0.718827172858495
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.8425896989269422
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.7833820650579661
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.8068622201208719
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.5789079961692154
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -0.7882928486038729
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.8789671824353567
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.8723386926762892
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.4396281014383552
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.9057224565750265
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.4436737413257317
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.8204676788308729
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.8556630495961954
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.6263980768656072
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.5153919621208802
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 0.6628890513031258
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 0.5894140900732704
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.31435831399746483
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.9360464613614635
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.7302965426747595
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -0.685095969971254
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.15971550804131715
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.6567775217437816
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.7306355658520086
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.4516309755035841
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.8518887787428118
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.6792495324881018
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.6221638401174286
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.1192076306960467
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.10109280170317075
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.8265998865945855
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.6189827262382379
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.963598860833382
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.059950329124322174
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.8749754917895736
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.6158562637767183
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.740370091381583
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.3238588684264081
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.14287240308808186
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.28876687985797844
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.8261335662861153
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.11267119936456985
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.8010005331380622
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 0.7637778990703024
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.08168012387231577
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.16929642370590256
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.6023532852551667
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.8507696220177646
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.40956700434022597
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.5737187306113763
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.8850989309291774
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 0.7253463377832052
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.8280856349082523
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.7335319756113576
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.7108602909900708
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.9044614702643975
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.8834949451055369
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.3422733512575188
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.6972961291246949
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.20642606829306537
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.8811086417895594
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.5633720433663375
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.9010709378132805
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.6903796267212904
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.29544320230916976
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.6759291537846369
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.2872567852592096
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.6828996285788168
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -0.6122854980408422
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.34232035118829174
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.288704716765668
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.8582114497124191
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.4693603215127983
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -0.6794418421352778
---------------------------------------------------------

Hidden units: 5
Epochs: 3000
Learning rate: 1

Errors during training:
Error at epoch 1 is 99.98928902299545
Train mean error at (after) epoch 1: 0.24997322255748863
Test error at (after) epoch 1: 0.1742231175321817
----------
Error at epoch 300 is 3.091907188280148
Train mean error at (after) epoch 300: 0.007729767970700369
Test error at (after) epoch 300: 0.008534323204762453
----------
Error at epoch 600 is 14.162891284281304
Train mean error at (after) epoch 600: 0.03540722821070326
Test error at (after) epoch 600: 0.013794124671449035
----------
Error at epoch 900 is 70.90669778755911
Train mean error at (after) epoch 900: 0.17726674446889779
Test error at (after) epoch 900: 0.2543823319563425
----------
Error at epoch 1200 is 21.564254942168322
Train mean error at (after) epoch 1200: 0.05391063735542081
Test error at (after) epoch 1200: 0.10207653060028703
----------
Error at epoch 1500 is 10.458455835276412
Train mean error at (after) epoch 1500: 0.02614613958819103
Test error at (after) epoch 1500: 0.04855496636133995
----------
Error at epoch 1800 is 65.74559416571121
Train mean error at (after) epoch 1800: 0.16436398541427802
Test error at (after) epoch 1800: 0.17609035226529954
----------
Error at epoch 2100 is 1.6814302468713809
Train mean error at (after) epoch 2100: 0.004203575617178452
Test error at (after) epoch 2100: 0.004539576959222273
----------
Error at epoch 2400 is 1.4669037057889662
Train mean error at (after) epoch 2400: 0.0036672592644724157
Test error at (after) epoch 2400: 0.0038227819711469553
----------
Error at epoch 2700 is 1.3545981123023332
Train mean error at (after) epoch 2700: 0.003386495280755833
Test error at (after) epoch 2700: 0.0035227016415168267
----------
Error at epoch 3000 is 1.446594145801315
Train mean error at (after) epoch 3000: 0.0036164853645032874
Test error at (after) epoch 3000: 0.0038210242839217634
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.6146132009846134
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.8152662189085117
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.8363075183337194
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.45319747211934347
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.8113563847667562
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.7890954443135034
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.7051620159949562
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.8381245380389033
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.08881734110493714
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.49472827979048
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.7418565757727194
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.07435464127954544
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.5555549665593181
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.8545298267222002
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.8148515028349896
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.6843093844840133
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.5746410971878068
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.8349180555640571
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.10181094585384584
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.7913518966988169
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.7647649267455214
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.31460912103240135
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.6644619081310605
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.8940412766377823
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.5208083762019639
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.8021176554294396
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 0.6597174821875798
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.7807934108920018
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.7908827153027406
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.8271013389458558
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.5702004999845489
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -0.7493469544944313
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.9603004746662561
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.9906044582168021
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.34304165010797044
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.8684638627485468
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.4330776411370843
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.8630518579462998
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.866191200708643
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.5735898415865456
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.406497662727148
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 0.661536939627658
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 0.510729082016923
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.300035983445057
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.9618180168236604
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.7202918276183716
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -0.6239402094388131
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.15122935978807234
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.6292717369770322
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.730676088582343
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.43996431881986126
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.8608057958339619
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.6507325302625027
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.6156359721541427
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.11854673346985713
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.10284599977709172
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.8621667456365917
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.6236285578793543
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.9396376701601612
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.0562245931931844
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.840519888076676
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.44558218585001697
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.7253246646629186
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.2899223612711155
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.13502319525469164
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.24475283807278075
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.8563931451455671
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.10491847374645336
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.8134637247418794
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 0.7689880057633236
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.10804747393694374
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.15999092792449626
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.5951535226091416
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.8815036404559957
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.35879772189506737
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.4983853079921577
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.8022137577508152
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 0.7491041228318626
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.8150246622199273
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.7479267784527441
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.6692368379577546
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.9598869412811217
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.9489981447858405
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.33352675785544955
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.6885482275894472
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.19258490670554346
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.9337531097930949
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.566406624401296
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.9729187375208251
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.6650527698863006
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.2969734517015838
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.6801840799950487
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.2914533082102149
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.6726886921540833
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -0.5770072068224095
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.3165333709930744
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.28418381576532475
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.892670786789443
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.3810526039122846
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -0.6336455656816404
---------------------------------------------------------

Hidden units: 5
Epochs: 10000
Learning rate: 1

Errors during training:
Error at epoch 1 is 100.04646517688037
Train mean error at (after) epoch 1: 0.25011616294220096
Test error at (after) epoch 1: 0.19974706585128332
----------
Error at epoch 1000 is 1.5387593960751946
Train mean error at (after) epoch 1000: 0.0038468984901879866
Test error at (after) epoch 1000: 0.003622773269425425
----------
Error at epoch 2000 is 1.574190147550796
Train mean error at (after) epoch 2000: 0.00393547536887699
Test error at (after) epoch 2000: 0.00371776326945056
----------
Error at epoch 3000 is 1.5555054550269638
Train mean error at (after) epoch 3000: 0.0038887636375674094
Test error at (after) epoch 3000: 0.0036520981999546647
----------
Error at epoch 4000 is 1.4132464675535574
Train mean error at (after) epoch 4000: 0.0035331161688838936
Test error at (after) epoch 4000: 0.0032287881846017434
----------
Error at epoch 5000 is 2.0330126213933672
Train mean error at (after) epoch 5000: 0.005082531553483418
Test error at (after) epoch 5000: 0.004664523796110349
----------
Error at epoch 6000 is 2.377563719327365
Train mean error at (after) epoch 6000: 0.005943909298318412
Test error at (after) epoch 6000: 0.005477674373105282
----------
Error at epoch 7000 is 2.4393902047651568
Train mean error at (after) epoch 7000: 0.006098475511912892
Test error at (after) epoch 7000: 0.005621409761642032
----------
Error at epoch 8000 is 2.440808803756283
Train mean error at (after) epoch 8000: 0.006102022009390707
Test error at (after) epoch 8000: 0.005628117016530268
----------
Error at epoch 9000 is 2.437924155036826
Train mean error at (after) epoch 9000: 0.006094810387592064
Test error at (after) epoch 9000: 0.005629426484997694
----------
Error at epoch 10000 is 2.435699290496027
Train mean error at (after) epoch 10000: 0.006089248226240067
Test error at (after) epoch 10000: 0.005636845157125501
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.7028962388741148
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.7556132996371169
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.9234811930472945
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.5573193231172259
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.8993538791834602
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.6878532603242721
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.6110624415783972
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.9420638015318633
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.19201949875005359
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.5760632270574174
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.6917601491062825
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.1414576809453862
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.6655183578793342
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.7839821181443033
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.7778996117393139
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.7505049778898415
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.662044851131276
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.9736582353336164
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.17524404754633915
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.8907075441696957
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.8136100891985237
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.39203793871535986
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.6011028273642168
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.8048275080886135
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.45265507573010794
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.8682129711316123
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 0.6714636283116948
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.8212417310828491
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.8747310870517453
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.9068039156693966
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.6589307322177274
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -0.6628894977972722
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.7983958103259575
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 1.0337732424085857
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.45245944514273334
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.8899631024816751
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.35157552724138846
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.9382189443029496
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.955535287775994
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.5688004114213072
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.38694977037174527
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 0.6954311091776342
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 0.5186252196118337
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.37900722431904604
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.9379752851412958
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.8198112918236836
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -0.5557214956363133
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.22714054878630335
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.7091453193400514
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.6798823247681126
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.5089269134579848
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.8032385046611515
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.7111146407929393
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.5549158442517761
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.234498828895585
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.043844889848170844
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.907186635035057
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.553045305895855
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.876025997015658
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.12688003165482725
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.9557416396733089
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.48642087386202165
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.8186232524171919
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.379490196430996
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.21087111681565357
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.329743473288491
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.7794160714247709
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.1828945779898546
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.7317116558420548
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 0.7466672380318197
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.02535365126366363
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.24407875891664493
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.6739710094075001
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.9126323179308156
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.2641994685858094
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.5395267726892751
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.6977751638393646
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 0.7440603072126792
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.762089921419319
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.6768196710762971
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.6191401822063516
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.9549720239181873
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 1.0371727207145705
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.23843354933114985
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.5860169153504314
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.2731839765365759
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.8401906047361138
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.4915848617529461
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 1.0169573309831599
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.6103775635603206
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.38092561408651854
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.7488197750212462
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.20446598777707062
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.7432837357976537
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -0.4405435387716294
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.23871115407117655
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.19470317877040386
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.8783245781765351
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.37416334129222406
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -0.5558914818811844
=========================================================

---------------------------------------------------------

Hidden units: 6
Epochs: 100
Learning rate: 0.05

Errors during training:
Error at epoch 1 is 108.0033465653879
Train mean error at (after) epoch 1: 0.27000836641346976
Test error at (after) epoch 1: 0.2614047936648418
----------
Error at epoch 10 is 96.09476560363187
Train mean error at (after) epoch 10: 0.24023691400907968
Test error at (after) epoch 10: 0.23191373597418216
----------
Error at epoch 20 is 85.23427426445988
Train mean error at (after) epoch 20: 0.21308568566114972
Test error at (after) epoch 20: 0.20492904372436857
----------
Error at epoch 30 is 75.60472206488315
Train mean error at (after) epoch 30: 0.18901180516220786
Test error at (after) epoch 30: 0.18106112123313725
----------
Error at epoch 40 is 66.57233532350813
Train mean error at (after) epoch 40: 0.1664308383087703
Test error at (after) epoch 40: 0.15886290327839328
----------
Error at epoch 50 is 57.93307732373955
Train mean error at (after) epoch 50: 0.1448326933093489
Test error at (after) epoch 50: 0.13791400457180994
----------
Error at epoch 60 is 49.75219281351857
Train mean error at (after) epoch 60: 0.12438048203379642
Test error at (after) epoch 60: 0.11841367669758887
----------
Error at epoch 70 is 42.232900888187245
Train mean error at (after) epoch 70: 0.10558225222046812
Test error at (after) epoch 70: 0.1008477868376685
----------
Error at epoch 80 is 35.59874191872264
Train mean error at (after) epoch 80: 0.0889968547968066
Test error at (after) epoch 80: 0.0857028906853902
----------
Error at epoch 90 is 30.004936200422527
Train mean error at (after) epoch 90: 0.07501234050105632
Test error at (after) epoch 90: 0.0732658701966667
----------
Error at epoch 100 is 25.495652026686297
Train mean error at (after) epoch 100: 0.06373913006671575
Test error at (after) epoch 100: 0.06354285448242707
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.20492632991426024
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.39789180698389376
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.4690244978055885
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.145680073086855
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.4175812166663188
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.7277314757966531
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.3887962367129672
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.4258109397209406
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.005940951833150141
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.18368994626747093
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.4517905918486493
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.12909169384807873
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.23743928947570603
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.6313259951903083
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.3239600182735456
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.3456170481202699
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.24472551170782827
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.5653358574286691
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.09435899906677526
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.6636040350363811
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.7306210141247304
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.12271516841297912
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.27217367158371325
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.6481039689983986
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.2290190548751125
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.38912888042513144
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 0.8117640492833517
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.6498340501995226
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.410248187879437
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.40178638832893426
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.20350399612976275
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -0.7447997381517055
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.6251259845874112
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.475231047720229
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.17326617529446306
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.44647635809090214
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.15422506477900708
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.7088037872728007
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.5569259513358432
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.08335201694991208
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.13957008704228402
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 0.8840880348623505
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 0.9431605523771045
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.0791763150927489
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.451006587571127
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.37499353238274297
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -0.8588373440232686
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.13027750454903544
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.299743804446657
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.39477386430790923
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.2488259558041525
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.5177610027078994
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.16904871967472945
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.19824214473388846
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.06611208382246568
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.06157429186366517
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.2782085219303093
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.23067950193599268
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.375794201498643
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: -0.01863056875158439
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.4779643177949455
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.3254437864238211
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.3068535228239593
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.029755612814808045
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.0032003639091942662
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.13576932371875047
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.4106788505102653
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.03223297027379282
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.36003991338808783
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 0.7683738284249761
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: 0.05496754368246176
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.05133101928956997
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.27943523823268435
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.43278249103406524
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.1230172060676134
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.29173033174230795
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.2466012620260587
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 0.7927019042255865
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.3436271457229097
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.3388032109871239
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.3105647219885355
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.6165043619920201
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.5567498360579007
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.20212515841496975
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.1883428727281547
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.05619234783448042
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.45491877811521164
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.24889065107118097
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.4778783479158585
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.3559950081373821
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.0740730986992432
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.3650673806312317
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.03958962187554761
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.2513397937812725
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -0.9586163634907796
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.047697168592318595
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.011252491246920526
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.37473457396394966
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.0021995661138072865
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -0.8575112432527856
---------------------------------------------------------

Hidden units: 6
Epochs: 1000
Learning rate: 0.05

Errors during training:
Error at epoch 1 is 93.08224193861079
Train mean error at (after) epoch 1: 0.23270560484652697
Test error at (after) epoch 1: 0.23378275820638872
----------
Error at epoch 100 is 20.837157541460734
Train mean error at (after) epoch 100: 0.05209289385365183
Test error at (after) epoch 100: 0.057137444260081265
----------
Error at epoch 200 is 16.364367939776486
Train mean error at (after) epoch 200: 0.040910919849441216
Test error at (after) epoch 200: 0.05096974735577814
----------
Error at epoch 300 is 15.341730900314385
Train mean error at (after) epoch 300: 0.03835432725078596
Test error at (after) epoch 300: 0.04833376352366261
----------
Error at epoch 400 is 14.341735563649646
Train mean error at (after) epoch 400: 0.035854338909124116
Test error at (after) epoch 400: 0.04528482635570838
----------
Error at epoch 500 is 13.342299905274741
Train mean error at (after) epoch 500: 0.03335574976318685
Test error at (after) epoch 500: 0.04218992669035213
----------
Error at epoch 600 is 12.354949696777732
Train mean error at (after) epoch 600: 0.03088737424194433
Test error at (after) epoch 600: 0.03911790446491049
----------
Error at epoch 700 is 11.393721760187455
Train mean error at (after) epoch 700: 0.02848430440046864
Test error at (after) epoch 700: 0.036116775309967174
----------
Error at epoch 800 is 10.472798289323993
Train mean error at (after) epoch 800: 0.026181995723309984
Test error at (after) epoch 800: 0.03323196278562704
----------
Error at epoch 900 is 9.604634092245222
Train mean error at (after) epoch 900: 0.024011585230613055
Test error at (after) epoch 900: 0.030502679460106513
----------
Error at epoch 1000 is 8.79865591443024
Train mean error at (after) epoch 1000: 0.0219966397860756
Test error at (after) epoch 1000: 0.02795842244986208
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.4438543206275089
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.641195305587695
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.694961249135787
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.32649456912468655
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.7203412517016015
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -1.1041226449551695
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.5645951360655327
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.7718817196584705
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.047841192186931294
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.372963608599644
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.6797260788848216
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.09828540834414139
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.4199334919408832
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.9613442793183237
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.6583093144713253
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.5222464698228227
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.4112193264122355
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.9388959677222336
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.11722835843013514
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.9921070015785349
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 1.0724240388552955
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.2578262902200698
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.49213504717615414
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -1.0260986257111793
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.39076596291090715
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.6960430699818876
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 1.1234773126654807
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.9892360369857347
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.6467155571649797
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.6750865882998962
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.41424101991899986
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -1.074917663973786
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.957342251442655
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.866492518307932
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.2577440431839644
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.8003414671698871
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.314582150174881
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 1.0075039143248548
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.8586267528612931
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.3508051826687074
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.33833802688781617
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 1.1330999989763055
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 1.200315676256245
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.2120872433561493
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.8655055511492338
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.5990162602593574
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -1.1696582546415093
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.1249687990841052
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.4902581373228238
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.6073154139112807
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.35136937809105406
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.8592019315783488
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.4434289134089565
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.45108116230882944
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.06768441489585979
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.05735448226695998
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.651541293450933
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.46270549116163107
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.7893418077624427
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.04107446220730511
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.8348902946536613
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.4222171847936664
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.563788614118073
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.16632675528508087
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.0994683685718682
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.20657891692561045
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.6962560420263191
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.08122772099467235
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.6513692196176653
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 1.0599572393551109
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.011380159916231657
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.11703984857630294
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.4460791722655887
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.7294209525267653
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.2696958569482731
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.38723806166699054
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.6179432690030707
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 1.1291329392105647
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.6201145874001507
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.6052807098733692
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.5198025792549735
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.8998696699403685
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.8076962867510566
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.22923671617074756
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.5071180701071957
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.1457388042681611
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.7677659565337311
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.4177051222506762
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.7779713458613998
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.5509167808495322
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.1971151352031503
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.5380008289181317
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.1738600414131953
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.49684282336606295
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -1.1966570578951694
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.20945134707513297
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.1577675031485787
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.7534148915767104
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.21492759430951142
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -1.1766567173760978
---------------------------------------------------------

Hidden units: 6
Epochs: 3000
Learning rate: 0.05

Errors during training:
Error at epoch 1 is 76.59011644631659
Train mean error at (after) epoch 1: 0.19147529111579145
Test error at (after) epoch 1: 0.20260521907004103
----------
Error at epoch 300 is 15.565057647803807
Train mean error at (after) epoch 300: 0.03891264411950952
Test error at (after) epoch 300: 0.04873192498302879
----------
Error at epoch 600 is 12.809501099807004
Train mean error at (after) epoch 600: 0.03202375274951751
Test error at (after) epoch 600: 0.04034626366317401
----------
Error at epoch 900 is 10.302296816853413
Train mean error at (after) epoch 900: 0.025755742042133534
Test error at (after) epoch 900: 0.03255958864963549
----------
Error at epoch 1200 is 8.217436650036984
Train mean error at (after) epoch 1200: 0.02054359162509246
Test error at (after) epoch 1200: 0.02594310420476276
----------
Error at epoch 1500 is 6.56647998308423
Train mean error at (after) epoch 1500: 0.016416199957710577
Test error at (after) epoch 1500: 0.020591773104998257
----------
Error at epoch 1800 is 5.290812994806885
Train mean error at (after) epoch 1800: 0.013227032487017211
Test error at (after) epoch 1800: 0.01637394604391479
----------
Error at epoch 2100 is 4.311977210625764
Train mean error at (after) epoch 2100: 0.010779943026564409
Test error at (after) epoch 2100: 0.013088528538772468
----------
Error at epoch 2400 is 3.5588097685288713
Train mean error at (after) epoch 2400: 0.008897024421322178
Test error at (after) epoch 2400: 0.010549521339918601
----------
Error at epoch 2700 is 2.9810775973801507
Train mean error at (after) epoch 2700: 0.0074526939934503765
Test error at (after) epoch 2700: 0.008620904069551663
----------
Error at epoch 3000 is 2.546723755625373
Train mean error at (after) epoch 3000: 0.006366809389063433
Test error at (after) epoch 3000: 0.007201339434046173
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.5820333934051535
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.7816825857473214
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.8389262954732205
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.4376052403982735
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.8057743533093249
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.855053623036615
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.7193238531710335
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.8354123961954651
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.10722288981496121
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.4699909528919293
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.8404898827966366
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.017510234283309025
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.5396528939226927
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.9092497390263542
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.7433205324136734
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.6553164860506419
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.5375015018405371
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.8742550999152039
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.07921731696903869
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.9200408308747834
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.8653290445914479
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.31564477797005114
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.6453056111774463
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.8732540887853824
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.4995960058287832
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.8070913981437041
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 0.8487566394251249
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.9137742456788462
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.7789357308170048
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.8132670839143756
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.5437314971511161
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -0.8765182179591986
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.962230550017991
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.8108590812946199
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.39100447114974546
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.8985414939107393
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.40940239787160143
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.9592461525765933
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.922753184643607
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.5514185118920208
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.46651689386207545
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 0.8353224479516149
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 0.7464618384123678
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.2869915226945278
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.8104362153359816
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.7192749839069921
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -0.8059333883542532
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.11957061108296937
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.6182737677575443
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.7398688138480942
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.3987149182059561
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.874383439246221
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.622458759433988
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.5851124218035093
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.10948270343893982
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.09623051105284426
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.7176544215565903
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.5835473719336639
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.8131260503519309
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.05767669638768509
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.8659561662355993
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.5081335827343701
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.7236803846966067
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.3449665110602453
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.13185107832591314
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.22851973660262304
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.8324271625306642
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.08832520525529369
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.7939238764334868
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 0.8941527627220114
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.1095311750058639
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.14233468727613
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.5584403289196577
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.8315286833102636
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.3632064066343334
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.4911899923167847
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.7369889383143788
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 0.8191388384614836
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.8339013759056461
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.7034311408927939
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.6572914300150648
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.9878791524128501
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.9498361260421051
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.2860948230610278
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.5993771202153064
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.1804920999773379
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.9146570394549606
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.5274414799818272
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.9707693283510868
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.6775520257227753
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.27044666332715905
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.6581167554091678
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.2772755230790307
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.6540733884258707
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -0.7379499783873451
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.31959826775248895
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.28813658868547726
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.7780877082605279
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.4330971938054298
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -0.7694082899750486
---------------------------------------------------------

Hidden units: 6
Epochs: 10000
Learning rate: 0.05

Errors during training:
Error at epoch 1 is 105.41359408758122
Train mean error at (after) epoch 1: 0.26353398521895305
Test error at (after) epoch 1: 0.27216223857016525
----------
Error at epoch 1000 is 7.270122912245564
Train mean error at (after) epoch 1000: 0.01817530728061391
Test error at (after) epoch 1000: 0.023102293028768806
----------
Error at epoch 2000 is 3.950226343530339
Train mean error at (after) epoch 2000: 0.009875565858825848
Test error at (after) epoch 2000: 0.012038040636229383
----------
Error at epoch 3000 is 2.4653367078031714
Train mean error at (after) epoch 3000: 0.006163341769507929
Test error at (after) epoch 3000: 0.006922380877631398
----------
Error at epoch 4000 is 1.9977412208308503
Train mean error at (after) epoch 4000: 0.004994353052077126
Test error at (after) epoch 4000: 0.0053493357494065795
----------
Error at epoch 5000 is 1.7868185887746777
Train mean error at (after) epoch 5000: 0.004467046471936694
Test error at (after) epoch 5000: 0.0047463566487638475
----------
Error at epoch 6000 is 1.6333302475112694
Train mean error at (after) epoch 6000: 0.004083325618778173
Test error at (after) epoch 6000: 0.0043513406032905915
----------
Error at epoch 7000 is 1.5103280384354107
Train mean error at (after) epoch 7000: 0.003775820096088527
Test error at (after) epoch 7000: 0.004040714175645654
----------
Error at epoch 8000 is 1.4079427610202289
Train mean error at (after) epoch 8000: 0.003519856902550572
Test error at (after) epoch 8000: 0.0037797278565975616
----------
Error at epoch 9000 is 1.3198802083019419
Train mean error at (after) epoch 9000: 0.0032997005207548546
Test error at (after) epoch 9000: 0.003551816083217035
----------
Error at epoch 10000 is 1.2421197572780054
Train mean error at (after) epoch 10000: 0.0031052993931950136
Test error at (after) epoch 10000: 0.0033474908026750855
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.5998060738546954
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.8151397718049982
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.8175642575710304
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.45185036022161595
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.8209582703504875
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.8531811723870631
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.7603026863817207
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.8506353114852113
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.09881044260181576
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.4944254934482218
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.9369745719854093
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.04684685689568288
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.5979515165720892
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.865365045673857
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.8108747799395123
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.6634465109405566
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.5589195246812427
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.857296114421416
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.09036215473118235
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.8543879925875756
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.7825469521718158
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.3449936183255488
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.7003625626960384
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.8610180059181718
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.5317120681995992
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.8030901635334112
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 0.6989004718931627
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.8209113347188022
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.775337584803765
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.8164025503735152
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.562102483091716
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -0.778535195097319
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.9122543051716547
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.9278747158504
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.4314283368089887
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.9223979717308467
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.4345283784091637
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.8362260605001794
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.8659713051317531
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.5561217474016263
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.526221137734329
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 0.6063056923002296
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 0.4975136034010195
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.30046466838460434
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.9227725264377977
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.7150345629078988
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -0.6198002777151724
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.13995772566494036
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.6447892921319015
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.7181117987925776
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.421152237467146
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.8703500656205501
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.6332474332009205
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.6412561555770647
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.10921561463282338
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.10348035411848792
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.8228682381912295
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.6092501186944406
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.9590182350834328
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.057169997179025246
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.8643690441411838
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.643239690428811
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.7428832253309157
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.3332608188301169
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.14701353880915174
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.2788945754971131
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.8481475398503064
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.10024602467224732
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.8077131700481187
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 0.7443047564528978
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.09946374796244473
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.1549279974919435
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.5723054614105864
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.8853440191148413
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.40160719904209957
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.5446311780437928
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.8532889085448278
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 0.7186689625108732
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.8710290743918312
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.7311865876931611
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.7204100212834366
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.9311064818822895
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.9231222411978287
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.30020379913684475
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.6945996979706376
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.19586077120366835
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.9148669316322716
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.5433383261064677
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.9783115115068322
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.6653098725954055
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.27953652658043276
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.6625950053713024
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.2773699027989956
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.6515970958063416
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -0.5082208672753166
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.3328616990887514
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.27491636029369876
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.8711257034432005
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.40123918018696664
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -0.6216338073272392
---------------------------------------------------------

Hidden units: 6
Epochs: 100
Learning rate: 0.1

Errors during training:
Error at epoch 1 is 120.44461920745933
Train mean error at (after) epoch 1: 0.3011115480186483
Test error at (after) epoch 1: 0.2692445626127421
----------
Error at epoch 10 is 90.39565824431882
Train mean error at (after) epoch 10: 0.22598914561079705
Test error at (after) epoch 10: 0.20021230889133088
----------
Error at epoch 20 is 68.38438300401634
Train mean error at (after) epoch 20: 0.17096095751004087
Test error at (after) epoch 20: 0.1487499908932286
----------
Error at epoch 30 is 50.85729186296481
Train mean error at (after) epoch 30: 0.127143229657412
Test error at (after) epoch 30: 0.10946282462042739
----------
Error at epoch 40 is 36.995862765467216
Train mean error at (after) epoch 40: 0.09248965691366803
Test error at (after) epoch 40: 0.08097675397689173
----------
Error at epoch 50 is 27.416642661362427
Train mean error at (after) epoch 50: 0.06854160665340607
Test error at (after) epoch 50: 0.06357060114418195
----------
Error at epoch 60 is 21.798535976897252
Train mean error at (after) epoch 60: 0.05449633994224313
Test error at (after) epoch 60: 0.05500266904765102
----------
Error at epoch 70 is 18.914960903573032
Train mean error at (after) epoch 70: 0.04728740225893258
Test error at (after) epoch 70: 0.051658352397729895
----------
Error at epoch 80 is 17.532279410200108
Train mean error at (after) epoch 80: 0.04383069852550027
Test error at (after) epoch 80: 0.050649784347625015
----------
Error at epoch 90 is 16.853840279693085
Train mean error at (after) epoch 90: 0.042134600699232715
Test error at (after) epoch 90: 0.05040969264047193
----------
Error at epoch 100 is 16.475139817218416
Train mean error at (after) epoch 100: 0.04118784954304604
Test error at (after) epoch 100: 0.05029423774997813
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.3758361213226815
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.5643502272251794
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.6326540360062273
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.24374636419832696
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.6101090107069608
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -1.1450705744955372
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.4443810187059671
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.7182817090759397
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.025338850983394726
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.3390613933740877
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.5393475783470133
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.12354379040942562
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.29888064516680585
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.9591574751877661
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.5671620203042501
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.43389788541470425
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.3126113710527693
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.9481467774200955
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.11821229217008634
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.9582350974925865
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 1.0493387259964806
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.2173288658208492
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.4312656091621095
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.8917906544800505
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.31770471865428174
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.60706856895398
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 1.2383518219144054
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 1.0571564381741354
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.5629589934635624
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.608283375569104
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.35378003751427683
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -1.1492426390160209
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.986144536918893
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.7126420963803056
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.17137759843345218
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.6896457560107979
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.2412125639522082
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 1.0778297833131456
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.8142423774330876
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.2415585181723433
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.23870334204432822
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 1.3569294477116514
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 1.4434469698531833
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.18719793366120369
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.7651141130782173
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.5006388304980467
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -1.2353786490670648
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.11033093913333936
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.3686860515380704
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.5131402573022531
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.3093584217357223
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.7261285184621113
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.3361909981769289
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.3933847561514516
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.035513725042381324
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.027502662810123518
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.536610683278913
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.38174762916610255
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.6392475812315014
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.04421489685960258
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.8082547543930627
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.3200875326681354
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.4607532043221468
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.08607341136940155
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.09154019016561851
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.1556441381706558
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.6281539424608904
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.06539647844005284
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.5786764761620242
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 1.2270741486514434
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: 0.03197858319771122
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.09219683774734566
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.36526368424279165
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.5332000803296554
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.20001634084197506
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.2934675167084027
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.45994882722544483
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 1.163678722626799
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.532726874382589
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.48213216720330526
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.4413835511060873
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.8735717549172399
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.7691209265435528
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.17440641865361065
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.37896797767687507
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.12368155138340091
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.6918409829370482
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.3299276998869541
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.7175489041110461
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.44334404598613003
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.15637066624749332
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.4706910109673873
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.12816465931627463
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.3951921132889948
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -1.4981285778083595
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.1490917584956421
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.09575119604922275
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.670240524722495
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.0938113413624396
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -1.2762324134376037
---------------------------------------------------------

Hidden units: 6
Epochs: 1000
Learning rate: 0.1

Errors during training:
Error at epoch 1 is 75.46275327619738
Train mean error at (after) epoch 1: 0.18865688319049345
Test error at (after) epoch 1: 0.1991448769719776
----------
Error at epoch 100 is 17.10157423749541
Train mean error at (after) epoch 100: 0.042753935593738523
Test error at (after) epoch 100: 0.05344518607968066
----------
Error at epoch 200 is 15.600955824751942
Train mean error at (after) epoch 200: 0.039002389561879854
Test error at (after) epoch 200: 0.04905193050527738
----------
Error at epoch 300 is 13.815472129075717
Train mean error at (after) epoch 300: 0.034538680322689294
Test error at (after) epoch 300: 0.0436047538675733
----------
Error at epoch 400 is 11.858127663249993
Train mean error at (after) epoch 400: 0.02964531915812498
Test error at (after) epoch 400: 0.0375641825333407
----------
Error at epoch 500 is 9.91545947071951
Train mean error at (after) epoch 500: 0.024788648676798773
Test error at (after) epoch 500: 0.03149703327114397
----------
Error at epoch 600 is 8.146452184083866
Train mean error at (after) epoch 600: 0.020366130460209665
Test error at (after) epoch 600: 0.025894448273607512
----------
Error at epoch 700 is 6.6336999845966185
Train mean error at (after) epoch 700: 0.016584249961491545
Test error at (after) epoch 700: 0.021025490921065773
----------
Error at epoch 800 is 5.3976838600763175
Train mean error at (after) epoch 800: 0.013494209650190794
Test error at (after) epoch 800: 0.016976090728269447
----------
Error at epoch 900 is 4.428163322111579
Train mean error at (after) epoch 900: 0.011070408305278947
Test error at (after) epoch 900: 0.013738349969817749
----------
Error at epoch 1000 is 3.699663348481445
Train mean error at (after) epoch 1000: 0.009249158371203613
Test error at (after) epoch 1000: 0.011253395254049255
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.5542392679796753
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.7238716274174224
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.7746894747342248
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.42154174883459794
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.7761700977239114
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.9588606931347339
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.6762340117744423
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.8329860880656075
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.07704160227653314
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.457121110277144
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.7690313511922333
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.07937646992844444
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.5016873553044264
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.9076277078740153
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.7440571984437632
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.6166277900855559
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.5039683186393064
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.9207417257925105
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.11579410369723364
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.9161955329217771
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.9201083366471029
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.306473220473497
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.5983402385475005
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.9161801992661845
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.4734225625851897
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.7707410279400394
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 0.929116406074545
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.9313754218865231
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.7273989536779092
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.7584395316347972
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.515736428974868
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -0.9333054706228294
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.9259745347203749
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.8556667607459167
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.31874706684263
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.8545461475848828
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.3829096141218487
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.9260852008890202
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.8728922006723046
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.5036145024866181
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.44567610867035073
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 0.9063204944565914
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 0.8983148720782912
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.2765590977852306
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.8835801318744045
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.6764489445245614
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -0.9188932396003885
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.13229722189803866
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.566532503747393
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.684894757204191
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.4075134259182386
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.8581901505791402
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.5730145198784712
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.5585092506201456
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.091430898391042
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.08070954959862127
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.7432134572501189
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.5580270500611527
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.8496534929408774
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.06019916978810672
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.8759044014638881
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.507793803606101
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.6716034722135434
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.2506132816339918
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.12526559793293204
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.24136491908614163
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.7754399080840214
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.09931011613899655
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.7476691985425937
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 0.9284976597114936
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.05817167716084052
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.147866614162467
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.5303770537581007
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.7798282117518041
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.3289361792247334
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.483531796786631
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.7349575241686169
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 0.920934115224027
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.7502377756031058
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.6794423078515283
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.612315981736016
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.9103620929726374
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.8593546819474499
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.27736108486420974
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.6066656655843428
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.17640454252153587
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.8365343075879385
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.49945102882606196
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.864830743314252
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.6290297159812905
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.2550852209997459
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.6230276354074377
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.25066071268100637
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.603992165277971
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -0.8976822908046218
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.29037468111529463
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.2641777016190195
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.8185528530769529
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.3432252203882928
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -0.9176685729673228
---------------------------------------------------------

Hidden units: 6
Epochs: 3000
Learning rate: 0.1

Errors during training:
Error at epoch 1 is 109.55219443933443
Train mean error at (after) epoch 1: 0.2738804860983361
Test error at (after) epoch 1: 0.25487136233694074
----------
Error at epoch 300 is 9.81150034121123
Train mean error at (after) epoch 300: 0.024528750853028077
Test error at (after) epoch 300: 0.030902702065177468
----------
Error at epoch 600 is 5.480751455263441
Train mean error at (after) epoch 600: 0.013701878638158603
Test error at (after) epoch 600: 0.01728378999565397
----------
Error at epoch 900 is 3.7360017260320753
Train mean error at (after) epoch 900: 0.009340004315080188
Test error at (after) epoch 900: 0.011448696633014243
----------
Error at epoch 1200 is 2.813622114328988
Train mean error at (after) epoch 1200: 0.007034055285822471
Test error at (after) epoch 1200: 0.008189250004226559
----------
Error at epoch 1500 is 2.3700863629373963
Train mean error at (after) epoch 1500: 0.0059252159073434904
Test error at (after) epoch 1500: 0.006546028745780665
----------
Error at epoch 1800 is 2.1588161107140427
Train mean error at (after) epoch 1800: 0.005397040276785107
Test error at (after) epoch 1800: 0.005756759982157401
----------
Error at epoch 2100 is 2.0272129084150565
Train mean error at (after) epoch 2100: 0.005068032271037641
Test error at (after) epoch 2100: 0.005303717711129005
----------
Error at epoch 2400 is 1.9218885151473544
Train mean error at (after) epoch 2400: 0.004804721287868386
Test error at (after) epoch 2400: 0.004979053286244564
----------
Error at epoch 2700 is 1.8291871674390163
Train mean error at (after) epoch 2700: 0.004572967918597541
Test error at (after) epoch 2700: 0.00471412305271682
----------
Error at epoch 3000 is 1.745801656563357
Train mean error at (after) epoch 3000: 0.004364504141408393
Test error at (after) epoch 3000: 0.00448526121126388
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.6267547906203019
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.7596597190218101
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.8055301240255509
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.4800322188775346
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.814554997050058
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.8304974070084676
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.8162157088616664
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.8742069738812701
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.09839077566744132
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.5384383076399147
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.8801032428369703
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.10278305600659056
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.5980921546650642
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.8336134108569951
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.8097171414912283
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.6965844758918006
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.575550651567814
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.9040677652673533
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.14128956757955285
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.8189021537932885
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.781576629881143
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.35577860575422465
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.669575429656221
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.8445362556272709
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.5285371250111385
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.8205524912524161
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 0.7287604399580015
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.8620015016706577
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.7787614624514657
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.798390991665485
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.5833849402108318
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -0.792674306177172
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.8891085821307991
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.9079408669498599
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.4110802974210972
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.8877765128504239
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.4338302545951784
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.8193221704921897
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.8584289695415245
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.5935302474413761
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.540068430193144
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 0.6399204336179559
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 0.5780491099174357
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.3251010019905105
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.9177060173097654
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.7252906911151787
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -0.660979726400704
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.16032949475933128
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.6430572952160275
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.7228075707603799
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.4616585644005577
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.8520553008887771
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.6553593833393626
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.6320019857613997
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.10939560168256308
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.0925139151608912
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.8335376159213137
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.619697070606455
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.903825870546532
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.07264953667768449
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.9018235189382727
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.6126762002307722
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.7369343451781061
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.28119511633525024
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.13387199328365557
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.2714671702683615
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.8140342583588177
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.1104125061592756
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.8066330106113876
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 0.780134373984189
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.057202345404761046
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.1678725446860382
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.5984753988602449
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.8592564238810384
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.37748094513333985
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.5972647810327523
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.8177240195555756
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 0.7390380932537501
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.8304323663833398
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.737985386755151
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.6641252991325762
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.922760619652291
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.875471042376473
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.3289074316933619
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.6990180537803327
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.19936494542813463
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.8767690752038443
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.5624304864453323
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.8994940372030119
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.6795967914356249
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.2922017684662778
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.6761954063359252
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.28802301377330863
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.67827748781563
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -0.5920302830615265
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.33261594989591814
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.3356865391212944
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.8814359227712134
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.4015168383714652
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -0.673234710861839
---------------------------------------------------------

Hidden units: 6
Epochs: 10000
Learning rate: 0.1

Errors during training:
Error at epoch 1 is 134.03284684511002
Train mean error at (after) epoch 1: 0.335082117112775
Test error at (after) epoch 1: 0.32557438472209443
----------
Error at epoch 1000 is 2.417350187645174
Train mean error at (after) epoch 1000: 0.006043375469112935
Test error at (after) epoch 1000: 0.006820055667533972
----------
Error at epoch 2000 is 1.8291072715632293
Train mean error at (after) epoch 2000: 0.004572768178908073
Test error at (after) epoch 2000: 0.004694334155420709
----------
Error at epoch 3000 is 1.5771190976566019
Train mean error at (after) epoch 3000: 0.003942797744141505
Test error at (after) epoch 3000: 0.004044355707855799
----------
Error at epoch 4000 is 1.3843927039343793
Train mean error at (after) epoch 4000: 0.003460981759835948
Test error at (after) epoch 4000: 0.003560391982652376
----------
Error at epoch 5000 is 1.2317470720263322
Train mean error at (after) epoch 5000: 0.0030793676800658304
Test error at (after) epoch 5000: 0.003177232958901908
----------
Error at epoch 6000 is 1.109466600133479
Train mean error at (after) epoch 6000: 0.0027736665003336974
Test error at (after) epoch 6000: 0.0028725439093043254
----------
Error at epoch 7000 is 1.0112720788226501
Train mean error at (after) epoch 7000: 0.0025281801970566255
Test error at (after) epoch 7000: 0.0026302596923083316
----------
Error at epoch 8000 is 0.9315951911516626
Train mean error at (after) epoch 8000: 0.0023289879778791564
Test error at (after) epoch 8000: 0.0024349076789969277
----------
Error at epoch 9000 is 0.8655682085814022
Train mean error at (after) epoch 9000: 0.0021639205214535055
Test error at (after) epoch 9000: 0.0022730971990775027
----------
Error at epoch 10000 is 0.8095667726738424
Train mean error at (after) epoch 10000: 0.002023916931684606
Test error at (after) epoch 10000: 0.0021352386537149774
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.6094400737349943
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.7824780067845158
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.8493813191033114
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.4493231167356958
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.8430104839188706
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.8372687333674539
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.7824243608332402
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.8892231030622442
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.09726285175171355
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.4902950078932298
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.9102766495798942
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.0665594125756818
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.5752751485774006
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.8787127542950466
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.8142998893355732
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.673526910580887
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.5526662197021011
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.9072938778983678
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.10782744140392074
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.8744694682666472
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.797660810192375
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.3301328677502221
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.6840573933119711
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.8672283335505999
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.5091408438874502
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.8285532966604967
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 0.6843531957117654
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.8593931946750857
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.7859409642431863
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.8185796780378616
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.5652872215088256
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -0.7803028857856928
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.9183469587112493
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.9199486561566528
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.4041587997034539
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.9421550966313428
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.4194316031802767
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.8352779633427503
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.8978500007836161
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.5615856324135315
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.5170495484259434
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 0.5550162836556938
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 0.4106862732444184
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.30650816279956633
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.943759793933632
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.7441121624072085
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -0.6007896546133826
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.1405144389990664
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.6562392640856242
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.7551743330796646
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.4371640240380703
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.887857403735436
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.63770902102908
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.6308495264486955
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.09317069575413363
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.08954528740919133
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.8204917925853501
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.6026752178685394
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.9635594791938746
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.07004561843281142
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.9154369095944905
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.5974813404071561
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.7324595619150057
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.31170516071222276
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.13902010747479426
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.25439938847520194
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.8407088200312529
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.10096672310249387
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.8155034573059703
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 0.7452242162407071
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.06725936708610451
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.15424551328333952
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.5747018225914395
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.8975892513913378
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.37142136956125305
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.5501659438918218
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.8544680267726705
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 0.7054111645980432
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.88749322812335
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.7304110257023545
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.679610324215806
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.944464827986355
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.9234565365408811
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.2947473480354774
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.6725813165908712
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.19456794418862172
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.911737509508143
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.5349879141329535
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.9637214459421226
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.6995683331625702
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.2811550312694788
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.6874680433250967
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.273399702774566
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.6594953626211161
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -0.42826473526439357
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.32791720527071777
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.3139128662562629
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.889679781082372
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.38583535602936714
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -0.5924532050298039
---------------------------------------------------------

Hidden units: 6
Epochs: 100
Learning rate: 0.3

Errors during training:
Error at epoch 1 is 136.06246825042103
Train mean error at (after) epoch 1: 0.3401561706260526
Test error at (after) epoch 1: 0.2941577279724954
----------
Error at epoch 10 is 40.155748236023264
Train mean error at (after) epoch 10: 0.10038937059005816
Test error at (after) epoch 10: 0.08987626183422498
----------
Error at epoch 20 is 17.94592988800139
Train mean error at (after) epoch 20: 0.04486482472000348
Test error at (after) epoch 20: 0.0512926022124601
----------
Error at epoch 30 is 15.874376302023716
Train mean error at (after) epoch 30: 0.03968594075505929
Test error at (after) epoch 30: 0.049141808474642425
----------
Error at epoch 40 is 15.252257783319491
Train mean error at (after) epoch 40: 0.03813064445829873
Test error at (after) epoch 40: 0.04771886553630015
----------
Error at epoch 50 is 14.681824234516059
Train mean error at (after) epoch 50: 0.036704560586290146
Test error at (after) epoch 50: 0.04605172602353614
----------
Error at epoch 60 is 14.106966228844183
Train mean error at (after) epoch 60: 0.03526741557211046
Test error at (after) epoch 60: 0.04431962184523611
----------
Error at epoch 70 is 13.527563400111042
Train mean error at (after) epoch 70: 0.033818908500277606
Test error at (after) epoch 70: 0.04256240931202018
----------
Error at epoch 80 is 12.94655575551537
Train mean error at (after) epoch 80: 0.03236638938878842
Test error at (after) epoch 80: 0.040793044730259895
----------
Error at epoch 90 is 12.367202088774476
Train mean error at (after) epoch 90: 0.03091800522193619
Test error at (after) epoch 90: 0.039021748661344724
----------
Error at epoch 100 is 11.792753801538463
Train mean error at (after) epoch 100: 0.02948188450384616
Test error at (after) epoch 100: 0.037258618657136505
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.4121710236838744
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.5869809767537227
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.6643606764330049
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.3029760321812894
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.6741959328084974
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -1.1246332453813082
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.5461633558646455
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.7510071917895463
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.045682374218119916
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.2851473391910655
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.6656714780667508
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.0778183173910914
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.37614277629014614
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.9533009972325974
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.6182225575112337
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.5009768719718742
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.3846016605395722
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.9565174392000332
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.09352663435248469
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.9709804364930106
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 1.091211733213021
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.20587820602101414
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.4253595010688156
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -1.0085810792186576
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.3580609217687485
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.6672934714185808
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 1.217747954382776
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 1.019214378738712
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.6226644494369573
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.6290778393470389
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.37478773632770823
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -1.128268008856359
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.9721246566971002
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.814943746825604
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.23224021156099356
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.7615904789219877
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.27861068664043603
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 1.0758997254425555
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.8642368094658377
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.3705614745566267
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.2852117203854666
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 1.2429571855697679
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 1.3396410538966812
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.17972568817264795
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.8344073885021382
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.5523926451492414
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -1.245102381321838
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.1111551195917513
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.4435785923288732
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.5444517270032301
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.3075927102732598
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.8211715455489964
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.42535862449125217
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.39870825979984925
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.07462636769064453
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.06283752398930204
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.6192339650771954
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.42397593320062843
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.7276847614474374
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.032669270467156585
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.8309340558394841
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.40697324800703305
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.5304492476784257
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.15248934048036727
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.07862158982519418
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.19048235902113675
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.6557158879118036
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.07308799041481567
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.6179979084345979
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 1.1101480751274635
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.012985609957941291
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.1066084951073717
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.4190540383162466
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.6775433815629036
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.2354012244209613
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.3751800265723362
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.5661186307247232
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 1.1838131146099147
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.583370680768688
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.5573906540497771
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.4599231756384954
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.9290406021324407
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.8178526737968815
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.20283840087399782
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.45653292311894095
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.12281007062834479
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.7450063443111529
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.3832989643740233
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.7466945670808554
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.49051648218137256
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.17795104221254585
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.4936145516424645
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.16302303494817943
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.46483300511363584
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -1.3148395193757874
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.18240256463182344
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.17758435486212387
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.7280139609096786
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.23700170584248154
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -1.2471163619990184
---------------------------------------------------------

Hidden units: 6
Epochs: 1000
Learning rate: 0.3

Errors during training:
Error at epoch 1 is 116.63920930039082
Train mean error at (after) epoch 1: 0.29159802325097706
Test error at (after) epoch 1: 0.26394293217634496
----------
Error at epoch 100 is 11.644017766149021
Train mean error at (after) epoch 100: 0.029110044415372554
Test error at (after) epoch 100: 0.03697616699532019
----------
Error at epoch 200 is 7.788864439410447
Train mean error at (after) epoch 200: 0.019472161098526116
Test error at (after) epoch 200: 0.024838921727010844
----------
Error at epoch 300 is 5.635038261774198
Train mean error at (after) epoch 300: 0.014087595654435493
Test error at (after) epoch 300: 0.017799881542332686
----------
Error at epoch 400 is 4.254027021809038
Train mean error at (after) epoch 400: 0.010635067554522594
Test error at (after) epoch 400: 0.013055042161560414
----------
Error at epoch 500 is 3.275845993319846
Train mean error at (after) epoch 500: 0.008189614983299615
Test error at (after) epoch 500: 0.009545012718097877
----------
Error at epoch 600 is 2.652971440749484
Train mean error at (after) epoch 600: 0.00663242860187371
Test error at (after) epoch 600: 0.007265368027835295
----------
Error at epoch 700 is 2.310693425147941
Train mean error at (after) epoch 700: 0.005776733562869852
Test error at (after) epoch 700: 0.006021293290702961
----------
Error at epoch 800 is 2.121091537675187
Train mean error at (after) epoch 800: 0.005302728844187967
Test error at (after) epoch 800: 0.005364389498785918
----------
Error at epoch 900 is 1.997895210033791
Train mean error at (after) epoch 900: 0.004994738025084477
Test error at (after) epoch 900: 0.004973447456751811
----------
Error at epoch 1000 is 1.9028773815147746
Train mean error at (after) epoch 1000: 0.004757193453786937
Test error at (after) epoch 1000: 0.004696821356886573
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.6326332912167941
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.7675644744887087
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.8536086190810042
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.472737365662119
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.8088707921551644
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.8076228215572732
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.7667947968042429
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.8923227487072157
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.09961779071628549
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.5055811270216497
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.8432573990185551
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.08509068314154808
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.575489172830676
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.8451660387065641
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.8140018001652035
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.6946512832742677
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.5755098233344733
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.9579740828690841
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.13139633826199423
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.8182803498627076
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.7766980299008278
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.3412294152489871
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.6573589414928607
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.824467077050906
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.5245560698779589
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.8205301792041886
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 0.7290209667890304
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.8968001546877729
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.7852568927742198
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.8024637765479717
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.5828898679219986
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -0.7910405967016618
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.8832595484069832
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.8560727271807835
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.38793120005074155
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.876853099697718
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.437268931003552
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.8269272155166847
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.8682218672189317
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.630244795591191
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.5124481324517808
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 0.6702467464155608
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 0.595618304886447
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.31488538518799236
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.9516139189210038
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.7422185348092524
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -0.6941065802898851
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.15497828477515477
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.6390775208525401
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.7886925647741482
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.46614252770891595
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.8503863457141039
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.6786207003902984
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.6268623624823867
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.11684371819643252
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.10303207183760026
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.8485752218171387
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.6233314567121009
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.9415693690769101
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.06028251320534396
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.9344522047960515
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.5847596792157156
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.734566790817681
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.2968009513391131
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.14394024876244263
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.2660389167207763
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.8147564681946418
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.1037424036123962
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.8075961488697196
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 0.8133274314272897
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.0690807860573804
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.16124506358320478
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.5964847780660221
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.8264629883710248
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.37102607569104573
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.5619711800009201
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.8666001498269187
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 0.7304215967952477
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.8318154125146444
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.7356432548841383
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.6637383174940189
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.9494467931131546
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.9048895554568919
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.3461009596323301
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.6943332315713246
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.20406012664561815
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.8664058882921233
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.5647110907742262
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.9133809643930287
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.720668408297463
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.2962791339324701
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.7101357759468873
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.2949445404775135
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.674092728929209
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -0.6138633654741411
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.3471831271593786
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.3207135113480095
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.8989854742453525
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.434885359318645
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -0.6874680188768962
---------------------------------------------------------

Hidden units: 6
Epochs: 3000
Learning rate: 0.3

Errors during training:
Error at epoch 1 is 104.4812660111478
Train mean error at (after) epoch 1: 0.2612031650278695
Test error at (after) epoch 1: 0.23213516219637143
----------
Error at epoch 300 is 3.872932425352301
Train mean error at (after) epoch 300: 0.009682331063380753
Test error at (after) epoch 300: 0.011370596151484677
----------
Error at epoch 600 is 2.0059301102271196
Train mean error at (after) epoch 600: 0.005014825275567799
Test error at (after) epoch 600: 0.005246226785095981
----------
Error at epoch 900 is 1.701422821145311
Train mean error at (after) epoch 900: 0.004253557052863278
Test error at (after) epoch 900: 0.00447930870480693
----------
Error at epoch 1200 is 1.489818874733721
Train mean error at (after) epoch 1200: 0.0037245471868343027
Test error at (after) epoch 1200: 0.003967573980468635
----------
Error at epoch 1500 is 1.320679672376086
Train mean error at (after) epoch 1500: 0.003301699180940215
Test error at (after) epoch 1500: 0.003545031451325212
----------
Error at epoch 1800 is 1.1818444077645383
Train mean error at (after) epoch 1800: 0.0029546110194113456
Test error at (after) epoch 1800: 0.0031868821570621934
----------
Error at epoch 2100 is 1.066231882293408
Train mean error at (after) epoch 2100: 0.00266557970573352
Test error at (after) epoch 2100: 0.00287902077767788
----------
Error at epoch 2400 is 0.9685982585912422
Train mean error at (after) epoch 2400: 0.0024214956464781055
Test error at (after) epoch 2400: 0.002612171833807092
----------
Error at epoch 2700 is 0.8846026313745174
Train mean error at (after) epoch 2700: 0.0022115065784362935
Test error at (after) epoch 2700: 0.002378621550846523
----------
Error at epoch 3000 is 0.8110525346957712
Train mean error at (after) epoch 3000: 0.0020276313367394282
Test error at (after) epoch 3000: 0.0021723631868092114
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.5977818666401133
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.8025626448204861
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.861878159372832
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.45920673263696027
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.8406590148592643
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.8201623877038493
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.7368346534859305
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.8753096898024153
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.08798461090234747
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.48859627735615957
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.8968886925940587
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.033111144500472145
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.5834237096550581
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.8624173417587315
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.7904638647114353
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.6757838018224516
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.5568316314227351
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.9135977271887528
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.09324454539444921
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.8612512273472062
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.7958895708354787
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.3197269737740976
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.6738902725876992
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.8658059962682363
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.5201302081928485
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.8233123334549457
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 0.6585746125933469
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.8577507944026279
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.795313728097077
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.825495664226884
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.5580805226874808
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -0.7785980850476961
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.9523667928238488
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.9255384579080386
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.3949200260232227
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.8995446199645021
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.4104586579123508
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.845367669985785
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.9029239725950697
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.5701067147530983
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.48693227830510144
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 0.559798367712528
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 0.3987688928430471
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.29448831684509647
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.9768581372507954
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.745545222588123
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -0.5962645387588059
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.1431632010146448
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.6465744516720306
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.776549503213372
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.420278264483888
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.8807801303330416
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.6376796069109896
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.5897452424924969
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.11246671748731715
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.09116954033061458
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.8328607321597608
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.5929503669992457
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.9942943604032999
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.054830926351764564
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.9030550745661918
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.548596186105885
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.7528457964930935
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.2982912115531147
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.1403490379534307
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.2659445394170716
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.8407114024278548
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.10539570579788865
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.8117449282416487
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 0.7421845521901396
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.1170600281044547
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.15818046692051185
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.5806906211826766
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.9161291520344568
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.35960917374331686
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.5137118045299409
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.8893843535872341
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 0.7030026807909455
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.8816979286870545
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.7250991574080785
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.6999910966174898
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.9559331912623679
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.9472500183905193
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.31760832124828164
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.6798056660352327
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.19219680843421866
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.9471243839274213
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.5357044417526666
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.986746164800923
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.703757440099144
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.2776251034137716
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.6897906305235952
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.2719209868037315
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.6608620298615311
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -0.4449078914206392
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.3268012629891912
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.27151513120418314
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.8779050342417813
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.41211514086217593
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -0.5874488497890054
---------------------------------------------------------

Hidden units: 6
Epochs: 10000
Learning rate: 0.3

Errors during training:
Error at epoch 1 is 128.39540938922758
Train mean error at (after) epoch 1: 0.32098852347306894
Test error at (after) epoch 1: 0.29486570835421644
----------
Error at epoch 1000 is 1.7046730260869143
Train mean error at (after) epoch 1000: 0.0042616825652172854
Test error at (after) epoch 1000: 0.004263588791967671
----------
Error at epoch 2000 is 1.1190639609690216
Train mean error at (after) epoch 2000: 0.002797659902422554
Test error at (after) epoch 2000: 0.002667251907799169
----------
Error at epoch 3000 is 0.8071670043502089
Train mean error at (after) epoch 3000: 0.002017917510875522
Test error at (after) epoch 3000: 0.0019089036670134184
----------
Error at epoch 4000 is 0.6357907130436204
Train mean error at (after) epoch 4000: 0.0015894767826090512
Test error at (after) epoch 4000: 0.001514647657706897
----------
Error at epoch 5000 is 0.6021046269227925
Train mean error at (after) epoch 5000: 0.0015052615673069813
Test error at (after) epoch 5000: 0.0014283596258891018
----------
Error at epoch 6000 is 0.5777238571909027
Train mean error at (after) epoch 6000: 0.0014443096429772567
Test error at (after) epoch 6000: 0.0013563660120397567
----------
Error at epoch 7000 is 0.5602882643796955
Train mean error at (after) epoch 7000: 0.0014007206609492387
Test error at (after) epoch 7000: 0.00129473872490395
----------
Error at epoch 8000 is 0.5451659070719395
Train mean error at (after) epoch 8000: 0.0013629147676798487
Test error at (after) epoch 8000: 0.0012388044713097911
----------
Error at epoch 9000 is 0.5315263726208781
Train mean error at (after) epoch 9000: 0.0013288159315521953
Test error at (after) epoch 9000: 0.0011882174157367906
----------
Error at epoch 10000 is 0.5208273946214376
Train mean error at (after) epoch 10000: 0.0013020684865535938
Test error at (after) epoch 10000: 0.0011462555158398857
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.602962688481408
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.7981634311353833
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.847787700925362
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.46473278007674157
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.8649896904697052
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.8646124600254199
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.6851588049751388
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.9323251534783519
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.08233295299368545
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.40442878583618636
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.8399821999930668
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.08960898443660473
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.5620779330405287
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.9022571781854555
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.8433634975746858
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.6764963726969435
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.5476470094371079
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.9525287456909257
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.11086921013362694
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.9224450411558637
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.7956873386718653
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.27821329863604005
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.6435398731931222
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.874532793204354
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.5351431340052446
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.8607115871789511
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 0.7008210509086049
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.8735589254899097
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.8123635758504859
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.8369360322972157
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.5505717571360326
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -0.7731271642205921
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.8900931269727954
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.9493203148946883
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.34562116335700677
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.9616019709550137
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.4215241107108853
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.841078410178466
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.9276536062164379
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.5339273964929641
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.49306209127345324
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 0.48452187052840046
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 0.3426167794184034
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.25654449311696004
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.9453573860216269
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.7529172484111032
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -0.5501282009558351
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.15175337666140157
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.6324633985850249
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.7480583711971865
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.4509321867645836
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.9113553941711994
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.637576358876722
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.5928197486010495
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.1028762264578218
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.10248587799352438
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.8632918787219447
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.622419950549068
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.9295379475565162
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.037718137045987817
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.9677802558334865
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.5411104375682201
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.747550555628205
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.2833571210721174
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.12130872479512367
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.2783613788588038
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.8571363801681455
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.10228203862057855
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.8301541036210475
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 0.7549325623875202
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.07527030838748466
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.15878402614037423
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.5978423442738413
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.8740791753197599
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.3332241399051451
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.49255050117047916
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.8239882424904181
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 0.6851894253375613
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.839574910655807
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.7609406142195556
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.6788621029219014
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -1.0010486419737827
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.9287736417169052
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.27914731328539333
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.6974425037927092
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.1839966385541224
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.9099964586029232
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.5549721224430216
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.9552852609789979
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.6872313517414155
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.2795353110384833
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.686689971782032
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.27112437790411426
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.6841065301660954
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -0.3186252432790617
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.3195291172188961
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.25253480818211627
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.9382461241406552
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.36512365854155027
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -0.5511932881501219
---------------------------------------------------------

Hidden units: 6
Epochs: 100
Learning rate: 0.5

Errors during training:
Error at epoch 1 is 108.74481935361405
Train mean error at (after) epoch 1: 0.2718620483840351
Test error at (after) epoch 1: 0.2301356394423536
----------
Error at epoch 10 is 48.17147311149278
Train mean error at (after) epoch 10: 0.12042868277873195
Test error at (after) epoch 10: 0.10760431752231028
----------
Error at epoch 20 is 17.464800194739244
Train mean error at (after) epoch 20: 0.04366200048684811
Test error at (after) epoch 20: 0.05190854257500235
----------
Error at epoch 30 is 14.759517339842963
Train mean error at (after) epoch 30: 0.03689879334960741
Test error at (after) epoch 30: 0.0469948883285912
----------
Error at epoch 40 is 13.659441253174565
Train mean error at (after) epoch 40: 0.03414860313293641
Test error at (after) epoch 40: 0.04358345271261757
----------
Error at epoch 50 is 12.633284452402977
Train mean error at (after) epoch 50: 0.03158321113100744
Test error at (after) epoch 50: 0.04032232954507227
----------
Error at epoch 60 is 11.643567191392975
Train mean error at (after) epoch 60: 0.02910891797848244
Test error at (after) epoch 60: 0.03718220094570221
----------
Error at epoch 70 is 10.69959867623164
Train mean error at (after) epoch 70: 0.026748996690579098
Test error at (after) epoch 70: 0.03418303464295393
----------
Error at epoch 80 is 9.810134107738094
Train mean error at (after) epoch 80: 0.024525335269345236
Test error at (after) epoch 80: 0.031349530323865074
----------
Error at epoch 90 is 8.98147567863948
Train mean error at (after) epoch 90: 0.0224536891965987
Test error at (after) epoch 90: 0.028701113469729526
----------
Error at epoch 100 is 8.21776157243263
Train mean error at (after) epoch 100: 0.020544403931081576
Test error at (after) epoch 100: 0.026250883762608777
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.4611414172017968
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.6309491066532161
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.6973833297965472
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.34200873434096113
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.7006505732695186
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -1.1038904955877433
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.6037635942881815
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.7853615943351946
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.047877560662228376
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.399745396323356
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.710702623165075
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.10123511312756733
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.42575911833964036
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.9385299158789843
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.6591626773771091
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.5484685066600442
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.4243809076284569
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.9557362542861272
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.12565299998163465
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.9344943126288088
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 1.0153093734857161
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.2751172514845486
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.5050984887803648
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.9609113111631529
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.3991021480950981
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.7165724579737222
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 1.1400330753967856
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 1.01326408731804
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.6623743611117836
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.6778270999924305
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.42859652194944364
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -1.0803811687774039
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.984767894381692
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.8444096372522201
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.2638344937862304
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.8213174593356207
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.31292780275288457
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 1.0497950499461401
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.8812956021534623
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.37976534085053576
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.3449875371172887
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 1.1399341385799528
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 1.191019495808842
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.22854620582474441
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.8626212267750133
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.5834952022060973
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -1.1145591208856045
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.1271508423313943
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.472795486969074
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.587006178278916
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.34372510807209744
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.8232522581906531
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.46413657075117526
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.4660334790029885
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.06445599408253411
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.0514899051131207
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.6577602515808227
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.470242054608163
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.7829368083378946
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.04916874370195055
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.8547510176933255
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.4390610215828698
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.5870032559132752
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.15543418918286783
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.10535766934156811
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.20688627626352532
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.7025274585353897
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.08363972671527878
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.6702325736600064
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 1.0720530370749792
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.0027695383445719614
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.12112471781596217
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.45927037026245765
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.7048679509923637
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.2768291393911999
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.41545544386534583
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.6167251860500822
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 1.0944317039598166
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.650994006073403
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.603976149933724
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.5182871705794706
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.952203610990203
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.8367946321900888
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.2365511312826131
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.5044643419615897
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.14833857535264808
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.7958611457589561
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.4264557964529105
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.8076085875595891
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.5215515345607092
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.20218252567106898
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.5374007659965665
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.1832697400580267
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.5175519941575168
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -1.1770948846247609
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.21153534191170875
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.17595491790926276
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.7545064078169675
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.2291064687703077
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -1.1263130532069598
---------------------------------------------------------

Hidden units: 6
Epochs: 1000
Learning rate: 0.5

Errors during training:
Error at epoch 1 is 103.72450549367508
Train mean error at (after) epoch 1: 0.2593112637341877
Test error at (after) epoch 1: 0.24640570062313238
----------
Error at epoch 100 is 8.848643214051979
Train mean error at (after) epoch 100: 0.02212160803512995
Test error at (after) epoch 100: 0.0280432593357246
----------
Error at epoch 200 is 4.852507599171033
Train mean error at (after) epoch 200: 0.012131268997927581
Test error at (after) epoch 200: 0.015244411783396552
----------
Error at epoch 300 is 2.8494724380015852
Train mean error at (after) epoch 300: 0.007123681095003963
Test error at (after) epoch 300: 0.008392640983528566
----------
Error at epoch 400 is 2.1178067536344796
Train mean error at (after) epoch 400: 0.005294516884086199
Test error at (after) epoch 400: 0.005755775266437713
----------
Error at epoch 500 is 1.8694109890128248
Train mean error at (after) epoch 500: 0.004673527472532062
Test error at (after) epoch 500: 0.004878601827156453
----------
Error at epoch 600 is 1.7088000434384985
Train mean error at (after) epoch 600: 0.004272000108596246
Test error at (after) epoch 600: 0.0043894295237277055
----------
Error at epoch 700 is 1.57627634569502
Train mean error at (after) epoch 700: 0.00394069086423755
Test error at (after) epoch 700: 0.004019213579467669
----------
Error at epoch 800 is 1.4624307145021773
Train mean error at (after) epoch 800: 0.0036560767862554434
Test error at (after) epoch 800: 0.0037110919617722653
----------
Error at epoch 900 is 1.3629557832208647
Train mean error at (after) epoch 900: 0.003407389458052162
Test error at (after) epoch 900: 0.00344483125333158
----------
Error at epoch 1000 is 1.2747859779983657
Train mean error at (after) epoch 1000: 0.003186964944995914
Test error at (after) epoch 1000: 0.003209792713296709
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.6145747326855848
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.7949410881830954
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.8634430993025516
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.4686162449084874
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.834310507868519
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.8681675444337926
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.738479187919171
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.8748153440546791
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.08851786306978518
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.5403974233078271
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.8321168742346593
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.023947131062596515
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.5555697545872108
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.874690792595398
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.8146660226966116
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.6851868232009934
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.5559060987509561
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.9074754460182094
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.08841468174582098
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.8938617368304347
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.7895195633860426
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.3474277883002363
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.6909794449769882
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.8433413758783104
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.5241003054523526
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.8303378469866358
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 0.7016012598403949
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.864328902282257
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.7896342715604698
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.8204282847551193
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.5754869959185174
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -0.7838235172207648
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.8883802624754652
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.8627770674388184
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.36112997203726654
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.9563865616397913
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.4346509816414814
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.8287760281839869
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.8856488873370806
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.5701200076487252
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.4950675402046749
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 0.6092006454345491
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 0.49243017155284896
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.3186147745011755
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.9468824761812084
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.7402820403020842
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -0.6442151115947559
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.14621155944681177
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.6244068151120585
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.7811706940046508
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.4223077824240469
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.8808171256074128
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.668532035906837
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.6636980107872392
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.08879156834414517
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.07984923242536532
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.814197592254408
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.617794994224439
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -1.001235708910842
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.07018854139738012
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.8985687113030975
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.562211057753055
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.7322565251540322
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.34914114626604575
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.15728514041966385
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.26560015005521287
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.8369577756465727
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.1120789383412113
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.8098930405828094
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 0.7606937688667732
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.1457450653355312
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.1655591959501865
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.5865568159890057
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.8439701264514718
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.39694680822756656
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.5266253915811727
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.906338919857106
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 0.693490519852986
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.8194065680932959
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.732460652550065
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.6859518409327926
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.9465732314648939
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.9171890765417847
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.3314270754606822
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.6793563072229676
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.20365795427751113
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.8841805227564726
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.5501958968386635
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.9026939834739296
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.6971707503006397
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.28822014658675554
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.7042895281246061
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.2896261195094993
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.6867402941389571
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -0.5082643345985527
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.3377827127639347
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.2689301696502648
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.87295906953866
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.43378963223138806
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -0.6254021887628309
---------------------------------------------------------

Hidden units: 6
Epochs: 3000
Learning rate: 0.5

Errors during training:
Error at epoch 1 is 109.89090440016227
Train mean error at (after) epoch 1: 0.2747272610004057
Test error at (after) epoch 1: 0.22038135386901925
----------
Error at epoch 300 is 2.5097257842340444
Train mean error at (after) epoch 300: 0.006274314460585111
Test error at (after) epoch 300: 0.006935353764778796
----------
Error at epoch 600 is 1.7987770887506747
Train mean error at (after) epoch 600: 0.004496942721876686
Test error at (after) epoch 600: 0.004507282694043652
----------
Error at epoch 900 is 1.4351882810710317
Train mean error at (after) epoch 900: 0.003587970702677579
Test error at (after) epoch 900: 0.0035538439398690113
----------
Error at epoch 1200 is 1.2006820491088965
Train mean error at (after) epoch 1200: 0.0030017051227722415
Test error at (after) epoch 1200: 0.002966642618695063
----------
Error at epoch 1500 is 1.0353539814172001
Train mean error at (after) epoch 1500: 0.002588384953543
Test error at (after) epoch 1500: 0.0025694254884632093
----------
Error at epoch 1800 is 1.1280617900430447
Train mean error at (after) epoch 1800: 0.0028201544751076117
Test error at (after) epoch 1800: 0.0028300120452743817
----------
Error at epoch 2100 is 2.8095079611073612
Train mean error at (after) epoch 2100: 0.0070237699027684035
Test error at (after) epoch 2100: 0.0048525700882139705
----------
Error at epoch 2400 is 1.0719322479843552
Train mean error at (after) epoch 2400: 0.002679830619960888
Test error at (after) epoch 2400: 0.002733874810366446
----------
Error at epoch 2700 is 1.2027404250712836
Train mean error at (after) epoch 2700: 0.003006851062678209
Test error at (after) epoch 2700: 0.003077012097288469
----------
Error at epoch 3000 is 1.0395387489595311
Train mean error at (after) epoch 3000: 0.002598846872398828
Test error at (after) epoch 3000: 0.002695042944973146
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.6149836256886358
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.7665033263342335
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.832324332804439
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.45989807867787913
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.8336814578563178
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.8311612937054969
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.7999706076704322
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.8935692916556695
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.09373385439403271
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.5282910515318323
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.8908464731253112
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.05523546682147347
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.5907641127297123
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.8608941640978036
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.8171367432773271
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.6839145759074168
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.55834326551393
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.9300689032527858
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.10985629818052549
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.8594642774726665
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.7921484058964862
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.3391895550176273
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.6820402248490445
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.8621402598785508
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.5109331019999134
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.8356997259170552
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 0.6991212795630968
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.8781568432363314
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.7855266557967628
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.8136382261290234
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.569942734974886
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -0.783514799282818
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.9057164457476723
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.9070314627484072
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.4194359149646222
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.9223698968757426
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.41643301398593285
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.8316693262259891
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.8906755948371363
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.5921218104046074
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.4987187195151148
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 0.5720124483461441
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 0.45925149854044456
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.3081693975455845
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.9470918955120132
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.7365671082529256
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -0.6221129459706104
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.14200358508729516
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.651011036828221
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.7516055322115305
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.4292865801292698
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.8770591560875047
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.6600039872888788
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.6410192276469409
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.09551787987854986
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.0911963733441405
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.8309816127714372
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.6055548158716981
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.9507491849700532
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.06229285039480707
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.9261313060583469
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.5887743634084279
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.7362560093828565
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.3034255087751051
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.1296528588907751
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.26456201440684485
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.8269718649040065
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.10565500675289587
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.8111299122897626
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 0.7609676398269464
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.08652547963377749
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.1608853419545589
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.5839907637933257
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.9038480385593205
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.3804686296479969
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.5622987761001399
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.8594194126473373
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 0.7118362720458458
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.8380608058552397
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.7285250518136709
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.669215408084735
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.9432466695794588
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.9005748727602787
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.3285425613076709
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.6786722131028727
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.18847244967842736
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.8914361077989708
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.542929543107378
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.9248203395588106
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.6922744866069565
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.2832280589845087
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.6815269546902663
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.2813665730838559
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.6782927341130451
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -0.47984301200840274
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.3262897596322277
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.29024143842410105
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.8992309650138592
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.4243489923339605
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -0.6167031436755739
---------------------------------------------------------

Hidden units: 6
Epochs: 10000
Learning rate: 0.5

Errors during training:
Error at epoch 1 is 114.47797720275692
Train mean error at (after) epoch 1: 0.2861949430068923
Test error at (after) epoch 1: 0.2505647421407769
----------
Error at epoch 1000 is 1.2709351022724615
Train mean error at (after) epoch 1000: 0.0031773377556811536
Test error at (after) epoch 1000: 0.0033069572193905024
----------
Error at epoch 2000 is 1.0372373375458668
Train mean error at (after) epoch 2000: 0.002593093343864667
Test error at (after) epoch 2000: 0.0027731481687483695
----------
Error at epoch 3000 is 1.067519668739721
Train mean error at (after) epoch 3000: 0.0026687991718493025
Test error at (after) epoch 3000: 0.002882067786418195
----------
Error at epoch 4000 is 1.1066415902162379
Train mean error at (after) epoch 4000: 0.0027666039755405948
Test error at (after) epoch 4000: 0.0030036749013290453
----------
Error at epoch 5000 is 1.1587994406405164
Train mean error at (after) epoch 5000: 0.002896998601601291
Test error at (after) epoch 5000: 0.0031406808184195624
----------
Error at epoch 6000 is 0.9624394663619263
Train mean error at (after) epoch 6000: 0.002406098665904816
Test error at (after) epoch 6000: 0.0026989706182134034
----------
Error at epoch 7000 is 0.9941570070650163
Train mean error at (after) epoch 7000: 0.0024853925176625408
Test error at (after) epoch 7000: 0.0027963105100625167
----------
Error at epoch 8000 is 1.0489899580358244
Train mean error at (after) epoch 8000: 0.002622474895089561
Test error at (after) epoch 8000: 0.0029411410215419266
----------
Error at epoch 9000 is 1.0942157055151245
Train mean error at (after) epoch 9000: 0.0027355392637878114
Test error at (after) epoch 9000: 0.0030507026604599543
----------
Error at epoch 10000 is 1.1594255197005245
Train mean error at (after) epoch 10000: 0.0028985637992513112
Test error at (after) epoch 10000: 0.0031888391984150467
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.6041203136723562
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.8058754320472569
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.8384970756436309
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.4566302906450247
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.8236025026471683
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.824389156636753
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.760614395764403
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.86125178910344
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.08905535053259217
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.49806503880307806
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.9123978079253247
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.036647099829934665
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.5976542249033914
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.8572002587078417
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.8019563831747492
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.6769092912295948
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.562431574212823
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.8856573988943807
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.09489998752309017
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.8274362645507247
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.7744685459851987
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.326329489216137
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.7092309710848869
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.8557879072736213
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.5292990488645639
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.8169657903821407
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 0.6793928615053625
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.8358210939545401
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.7838826558323122
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.8180074340325725
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.565453896849668
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -0.7744488883108144
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.9156289037310357
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.9202284290432591
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.4321781301683467
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.908650862396018
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.4233973157575127
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.8203398069735893
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.8759182093987347
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.5767346531350225
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.5056626072830679
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 0.582813597678639
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 0.46172320094441444
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.30546595143773053
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.9619032394960559
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.7305652542722966
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -0.625720876334987
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.13889021535812965
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.6537766855952366
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.7514592015685694
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.4211264503419505
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.8667597896462108
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.6524712148104989
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.6127191542914722
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.10214827468172585
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.0942373413373814
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.8278119129621411
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.606404200113339
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.984601897323344
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.059280479286239335
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.8832492182965287
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.6102978572943906
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.7441745671914581
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.3191113265814449
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.1381009718592759
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.275908241569806
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.8427961804553787
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.10719671944983725
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.8126687369661005
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 0.7414684211874774
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.1084551511481066
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.16019468064879716
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.5805175469564826
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.9091379168795942
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.37087239011273143
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.5432574034815227
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.8919970245909379
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 0.7103451826658097
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.8840230592474485
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.7319443722420945
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.7224921816520388
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.9349857367075421
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.9220526188555359
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.33236880812740016
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.7009902446797828
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.1938581541048549
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.9137687304262616
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.5441792431003194
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.968795875453449
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.6816594358152008
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.2834264865626279
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.6800274788576889
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.2847596711988899
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.6645281644472508
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -0.5130031412800631
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.3396947466951058
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.28578452930718545
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.8801241663132893
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.42098553280521467
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -0.6230114141078326
---------------------------------------------------------

Hidden units: 6
Epochs: 100
Learning rate: 1

Errors during training:
Error at epoch 1 is 93.1650254310216
Train mean error at (after) epoch 1: 0.23291256357755402
Test error at (after) epoch 1: 0.17505669401150586
----------
Error at epoch 10 is 13.041174182236963
Train mean error at (after) epoch 10: 0.03260293545559241
Test error at (after) epoch 10: 0.039248074481095276
----------
Error at epoch 20 is 10.729198470621082
Train mean error at (after) epoch 20: 0.026822996176552705
Test error at (after) epoch 20: 0.033352610280792706
----------
Error at epoch 30 is 9.159672209251939
Train mean error at (after) epoch 30: 0.022899180523129847
Test error at (after) epoch 30: 0.028476654815629127
----------
Error at epoch 40 is 7.862281159860799
Train mean error at (after) epoch 40: 0.019655702899651996
Test error at (after) epoch 40: 0.024417434523724326
----------
Error at epoch 50 is 6.774574477263446
Train mean error at (after) epoch 50: 0.016936436193158613
Test error at (after) epoch 50: 0.020982406240482362
----------
Error at epoch 60 is 5.8377483212658685
Train mean error at (after) epoch 60: 0.01459437080316467
Test error at (after) epoch 60: 0.017998107616372508
----------
Error at epoch 70 is 5.016334009678666
Train mean error at (after) epoch 70: 0.012540835024196666
Test error at (after) epoch 70: 0.015364294709900963
----------
Error at epoch 80 is 4.299356306110198
Train mean error at (after) epoch 80: 0.010748390765275496
Test error at (after) epoch 80: 0.013055123948456116
----------
Error at epoch 90 is 3.6908566229953355
Train mean error at (after) epoch 90: 0.009227141557488338
Test error at (after) epoch 90: 0.011088217958716493
----------
Error at epoch 100 is 3.1965518015344894
Train mean error at (after) epoch 100: 0.007991379503836223
Test error at (after) epoch 100: 0.009483158592483977
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.5450574058876518
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.7489772194025467
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.788043433258803
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.4152551031278192
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.790761200880074
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.9352268835109258
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.7073047897840522
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.8189707290723234
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.09363592138059942
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.4988129873268689
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.8200294065007648
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.052299842079961065
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.502549075384246
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.9237347619145686
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.7511925936866316
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.6217030859389856
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.5101368655659622
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.8921302147867116
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.10588529814627387
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.9640977859080625
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.9168086262910097
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.3246694006209851
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.6149040923068293
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.927933443797426
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.4786624531983252
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.7592050467842715
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 0.8910269977670673
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.8868721120640598
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.7310164744815317
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.7719455089703032
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.5129450149919776
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -0.9045448111402322
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.9031750845501081
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.8672432646387062
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.30488764568766724
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.8441176279770827
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.38271346716571036
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.9002560745307749
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.8641060473006981
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.5115922971550244
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.476996140220339
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 0.8565897860201294
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 0.8408962814448289
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.2698912812041033
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.8911971474313496
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.6899782453306758
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -0.8903509249777138
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.13334156748855744
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.5746677736228549
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.7017360906504158
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.4043724971226576
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.8792524122681262
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.5764017334248251
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.5804958026368142
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.10547049843890231
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.09193892257994075
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.7482884882158973
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.5598982031613223
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.872809568492691
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.04719308917532599
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.8518032286875002
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.539292108936383
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.6646418994868205
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.28808694475574204
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.1145654168969886
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.23905814243074924
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.7913910541968631
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.09061961672540998
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.7485276205929959
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 0.8762475284423473
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.0748120180611715
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.14135733720478624
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.5327398640538469
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.7851261644616642
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.3344343995152506
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.5085692765901778
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.7681475509974718
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 0.8926883314142455
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.7471766667099183
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.6843811993347803
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.62247829267575
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.9185981529939763
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.8718740085929892
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.2955845983530209
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.6093541752570162
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.16872252225792783
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.8361629979962214
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.5055819374744726
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.854045273930017
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.6476594085426908
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.24865889454049553
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.6308700637710593
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.24971222462240422
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.5985689699436821
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -0.8322964905327216
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.3033112310378005
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.2467629791167952
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.8191340826146725
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.3838172376372518
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -0.8817448961870895
---------------------------------------------------------

Hidden units: 6
Epochs: 1000
Learning rate: 1

Errors during training:
Error at epoch 1 is 86.96783515764882
Train mean error at (after) epoch 1: 0.21741958789412205
Test error at (after) epoch 1: 0.15518368135596705
----------
Error at epoch 100 is 3.3147559171130037
Train mean error at (after) epoch 100: 0.008286889792782508
Test error at (after) epoch 100: 0.009807833665225271
----------
Error at epoch 200 is 2.0741381409995987
Train mean error at (after) epoch 200: 0.005185345352498997
Test error at (after) epoch 200: 0.005275743819659276
----------
Error at epoch 300 is 1.7478818265999128
Train mean error at (after) epoch 300: 0.004369704566499782
Test error at (after) epoch 300: 0.004311006774509576
----------
Error at epoch 400 is 2.3044187368654336
Train mean error at (after) epoch 400: 0.005761046842163584
Test error at (after) epoch 400: 0.0059627546672606155
----------
Error at epoch 500 is 1.9024321799947734
Train mean error at (after) epoch 500: 0.004756080449986933
Test error at (after) epoch 500: 0.004714064728585104
----------
Error at epoch 600 is 1.6348944430269747
Train mean error at (after) epoch 600: 0.004087236107567437
Test error at (after) epoch 600: 0.003992055964779725
----------
Error at epoch 700 is 2.1780866950784143
Train mean error at (after) epoch 700: 0.0054452167376960355
Test error at (after) epoch 700: 0.0055373068901937135
----------
Error at epoch 800 is 1.8223638587667734
Train mean error at (after) epoch 800: 0.0045559096469169336
Test error at (after) epoch 800: 0.0044865678928596294
----------
Error at epoch 900 is 1.5760891753098236
Train mean error at (after) epoch 900: 0.003940222938274559
Test error at (after) epoch 900: 0.0038318903633926373
----------
Error at epoch 1000 is 2.067978462782545
Train mean error at (after) epoch 1000: 0.005169946156956362
Test error at (after) epoch 1000: 0.005192866111479972
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.6320199057725624
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.7626880961976716
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.8157228038532612
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.4761166840240581
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.8088330975430693
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.8334699062953722
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.7795756746189236
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.8739743448424645
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.10357816459312318
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.5593272259069771
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.8511827461766652
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.0770563503668078
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.5770937077205006
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.8470588638449764
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.8395034877110675
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.6978919385752883
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.5879065664066879
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.8888250201230712
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.11721472609341917
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.838405918099275
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.7849513621513168
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.3635824227017943
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.6864264937536559
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.833954393490405
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.530643215990109
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.8136626824321266
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 0.7539888679895285
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.8344187966709866
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.7768827183318145
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.7961205133272268
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.5879732553049833
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -0.7897600849575808
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.8398261697000102
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.8765911181908699
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.36871673256224274
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.8955143635438929
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.44363311780304643
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.8222446156704852
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.8552283699761555
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.593961604227084
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.5328309803609156
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 0.6699414119235994
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 0.6238797169962007
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.3262747518656824
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.9155545835167634
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.7175852667611033
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -0.6950414735499547
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.1597908270339034
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.6159696309635682
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.7334142042152059
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.448042795721454
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.84660947268048
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.6582216940150764
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.6804268207536026
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.11503569700068185
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.10446790534967373
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.849291453353182
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.6306931629908952
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.9105334577015246
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.0628341386739366
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.8939450454569594
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.5941139557821721
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.7224887650525086
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.3172901048112956
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.14852182627455685
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.2747802904064997
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.812901074572684
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.10691522563188417
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.7988252812645713
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 0.7672661820096869
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.09177261457449272
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.1655425569242039
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.6007516354421746
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.8040867638592182
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.39637318906159397
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.5700124814612845
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.8357989971179053
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 0.743975694290605
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.8107884919436984
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.7387128941672743
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.6723697296774644
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.930198293341771
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.8765198965462776
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.3466376984486403
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.725538242284548
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.2033431623971389
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.8409223667976522
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.5716817354769111
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.8624365237845525
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.6654291395173688
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.2980244722158515
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.6872215384908337
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.292836373769465
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.6800520873891277
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -0.6190766985895322
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.3508320868969577
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.3010744355057376
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.9116052981991819
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.40784726934931864
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -0.7028217376101341
---------------------------------------------------------

Hidden units: 6
Epochs: 3000
Learning rate: 1

Errors during training:
Error at epoch 1 is 91.59894654018377
Train mean error at (after) epoch 1: 0.22899736635045945
Test error at (after) epoch 1: 0.12858684607324658
----------
Error at epoch 300 is 1.9824358776726285
Train mean error at (after) epoch 300: 0.004956089694181571
Test error at (after) epoch 300: 0.005189041346797018
----------
Error at epoch 600 is 1.8009707120622582
Train mean error at (after) epoch 600: 0.004502426780155645
Test error at (after) epoch 600: 0.0046968063922514635
----------
Error at epoch 900 is 1.6288976616324584
Train mean error at (after) epoch 900: 0.004072244154081146
Test error at (after) epoch 900: 0.004201350119336211
----------
Error at epoch 1200 is 1.4800129576750458
Train mean error at (after) epoch 1200: 0.0037000323941876146
Test error at (after) epoch 1200: 0.0037614654675069987
----------
Error at epoch 1500 is 1.3424965308434478
Train mean error at (after) epoch 1500: 0.0033562413271086195
Test error at (after) epoch 1500: 0.0033734460670139703
----------
Error at epoch 1800 is 1.5103348871518905
Train mean error at (after) epoch 1800: 0.003775837217879726
Test error at (after) epoch 1800: 0.0038242602275269837
----------
Error at epoch 2100 is 1.679122212924548
Train mean error at (after) epoch 2100: 0.00419780553231137
Test error at (after) epoch 2100: 0.004211303613138934
----------
Error at epoch 2400 is 1.3836872440144556
Train mean error at (after) epoch 2400: 0.003459218110036139
Test error at (after) epoch 2400: 0.0034238266239223943
----------
Error at epoch 2700 is 2.8540846836211857
Train mean error at (after) epoch 2700: 0.007135211709052965
Test error at (after) epoch 2700: 0.0074870511612821124
----------
Error at epoch 3000 is 2.0696117890303825
Train mean error at (after) epoch 3000: 0.005174029472575956
Test error at (after) epoch 3000: 0.005078723768627944
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.5804007487268318
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.8737302474800843
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.7984816877695289
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.33653381780629443
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.7849926377555564
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.9456916115399849
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.8486514556180047
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.8331744868666031
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.029038654328784108
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.3423337351508632
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.9843654182588016
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.004683333807255552
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.5353393645890165
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.8977588332964052
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.8758631270577423
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.6456270114799817
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.54102142104655
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.9056285573283568
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.03828315740533264
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.8470162985187462
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.7453696657512402
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.18919278750904794
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.7516088806386149
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.9061560254742336
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.6212242216658617
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.7726723989544979
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 0.6407474938189622
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.8357658931929475
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.7592687342420581
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.7868241546550387
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.5418393454104465
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -0.8044924203138846
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.9439557874545034
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.814502620863579
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.35194454691686794
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.8771752774381226
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.49018219890118936
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.7704284254351734
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.8370437090914851
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.4361886392624179
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.575559216581941
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 0.5596540044499356
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 0.45726136322911015
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.2647222271024884
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -1.0362084679214798
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.6859736110465886
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -0.7132797679656264
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.0698024316929346
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.5575642771687901
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.7736067559078946
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.3424715006513178
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.9401084809925963
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.5165298468742605
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.6772230235484611
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.05690677356308427
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.1739143591196292
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.7913797611878574
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.6952025245072163
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -1.013710566148295
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.0077732281164529515
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.8680059233625526
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.5694570873948626
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.6687418153953405
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.16690399376955867
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.07585256205288585
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.23189193504325983
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.9074986953803463
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.04534302763947819
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.8811572134523538
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 0.7229015606754378
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.08245292458348269
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.10089081387459364
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.552542033254348
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.8358225694867746
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.36986536758379845
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.5079035692771824
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.8571622116805764
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 0.6396612758161925
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.9248257772582805
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.8049748826626314
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.7771608223284941
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.9924066335551933
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.8939092297503095
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.3457535074983199
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.7634169872987603
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.13391216223264044
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.9463116615196349
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.6327861275291137
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.899787209460675
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.6898347167790566
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.23819420364017585
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.6013904716056484
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.34072048769392843
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.5736258062486685
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -0.5713077203115269
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.4082842385249412
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.3003743162882867
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.9535813278628438
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.21101317782346268
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -0.6567249439013231
---------------------------------------------------------

Hidden units: 6
Epochs: 10000
Learning rate: 1

Errors during training:
Error at epoch 1 is 69.83719934341673
Train mean error at (after) epoch 1: 0.1745929983585418
Test error at (after) epoch 1: 0.1072772883549586
----------
Error at epoch 1000 is 2.154520343004754
Train mean error at (after) epoch 1000: 0.005386300857511885
Test error at (after) epoch 1000: 0.0055207025516783624
----------
Error at epoch 2000 is 1.6159052224276353
Train mean error at (after) epoch 2000: 0.004039763056069089
Test error at (after) epoch 2000: 0.0040549480769096645
----------
Error at epoch 3000 is 2.2252769131624346
Train mean error at (after) epoch 3000: 0.005563192282906086
Test error at (after) epoch 3000: 0.006032619627142067
----------
Error at epoch 4000 is 1.6015512366693274
Train mean error at (after) epoch 4000: 0.004003878091673319
Test error at (after) epoch 4000: 0.004096385531686705
----------
Error at epoch 5000 is 1.5084979655436106
Train mean error at (after) epoch 5000: 0.0037712449138590266
Test error at (after) epoch 5000: 0.003906890564861995
----------
Error at epoch 6000 is 1.8921502537718278
Train mean error at (after) epoch 6000: 0.00473037563442957
Test error at (after) epoch 6000: 0.00551096863913186
----------
Error at epoch 7000 is 4.472927755487514
Train mean error at (after) epoch 7000: 0.011182319388718784
Test error at (after) epoch 7000: 0.011876651858459758
----------
Error at epoch 8000 is 2.3302683675665006
Train mean error at (after) epoch 8000: 0.005825670918916251
Test error at (after) epoch 8000: 0.006707752090342003
----------
Error at epoch 9000 is 2.6062115235452565
Train mean error at (after) epoch 9000: 0.006515528808863141
Test error at (after) epoch 9000: 0.007649744453782704
----------
Error at epoch 10000 is 2.529460676483497
Train mean error at (after) epoch 10000: 0.006323651691208743
Test error at (after) epoch 10000: 0.007547094472936941
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.503860042277554
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.95073309091848
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.7867060254083323
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.38306377396346736
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.6858059023841855
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.8927086935654303
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.8129540746530383
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.7850887222780455
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: -0.013791978538837547
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.4424096504360281
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.9145488326472194
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: -0.024019847643683735
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.5273856206628904
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.9294159442224953
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.94986605702223
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.6103159776506473
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.49568604027783664
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.7932003533647738
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: -0.023080907153723136
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.8556977188543821
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.7021234384358449
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.30101257257156006
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.7703468878025482
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.9187137890516005
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.6337563322682984
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.6475633395633893
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 0.6598072306390448
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.6760085228519612
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.6888358887391417
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.7424553848731342
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.45803909739404497
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -0.7500824502245632
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.9924208286703723
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.9106915252148879
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.28820095758907305
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.8126755146832686
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.5033786441840232
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.7814371202686838
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.7759212642206388
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.4982169970855517
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.5961963847822449
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 0.5633695735362152
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 0.4219740709391513
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.1877500747471546
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.953800478476795
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.5686133052226161
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -0.6185414494274075
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.05372029702373753
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.4655942301423784
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.7978581285874118
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.3223537127957235
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.8697881025364058
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.5303432464587243
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.8142874591644357
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.041149369531733614
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.22270477960102822
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.7689537084934138
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.6581008572054218
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.9697714332945143
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: -0.06618739535320792
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.8119644616518935
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.507701660053793
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.6861350775946462
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.19981591768994564
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.07738477587219941
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.21716878347864363
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.9198577950101953
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.008049489207501918
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.8505460440832316
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 0.7024598337597507
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.2601514767572617
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.06271402054675823
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.4824508478159398
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.8344938424501833
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.5226642999525535
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.4626849404911269
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.8659527171031279
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 0.6778318765827223
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.9204719382663694
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.7647619252231351
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.8560603530326357
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -1.047368485612148
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.855015884033646
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.40965764350777983
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.7791552970671333
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.0931192926097423
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -1.006618646019533
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.6184198838421895
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.9356543499384232
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.6587173151021299
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.1675296215120829
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.613190345374471
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.36379811643721705
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.5413428015017329
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -0.6178946334114127
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.40305969568269295
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.3482657037190999
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -1.02686740300088
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.3128990677752465
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -0.6288390053031198
=========================================================

---------------------------------------------------------

Hidden units: 7
Epochs: 100
Learning rate: 0.05

Errors during training:
Error at epoch 1 is 85.48099877979541
Train mean error at (after) epoch 1: 0.21370249694948854
Test error at (after) epoch 1: 0.20909194951669785
----------
Error at epoch 10 is 71.83811182664884
Train mean error at (after) epoch 10: 0.1795952795666221
Test error at (after) epoch 10: 0.17791015422453504
----------
Error at epoch 20 is 59.822915821897524
Train mean error at (after) epoch 20: 0.14955728955474382
Test error at (after) epoch 20: 0.15009272738664972
----------
Error at epoch 30 is 50.03167742850232
Train mean error at (after) epoch 30: 0.1250791935712558
Test error at (after) epoch 30: 0.12719574403280015
----------
Error at epoch 40 is 41.97140273332946
Train mean error at (after) epoch 40: 0.10492850683332365
Test error at (after) epoch 40: 0.10824914729896663
----------
Error at epoch 50 is 35.40953037112021
Train mean error at (after) epoch 50: 0.08852382592780053
Test error at (after) epoch 50: 0.09282621809254905
----------
Error at epoch 60 is 30.188148007987998
Train mean error at (after) epoch 60: 0.07547037001996999
Test error at (after) epoch 60: 0.08061990344831814
----------
Error at epoch 70 is 26.146983826431157
Train mean error at (after) epoch 70: 0.0653674595660779
Test error at (after) epoch 70: 0.0712730209787221
----------
Error at epoch 80 is 23.105736578488283
Train mean error at (after) epoch 80: 0.05776434144622071
Test error at (after) epoch 80: 0.0643508842391327
----------
Error at epoch 90 is 20.874383615111515
Train mean error at (after) epoch 90: 0.05218595903777879
Test error at (after) epoch 90: 0.05938032063345003
----------
Error at epoch 100 is 19.270896957298604
Train mean error at (after) epoch 100: 0.04817724239324651
Test error at (after) epoch 100: 0.05590340191069064
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.2511831987466857
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.39276037338800024
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.5463977815596764
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.1301028593767037
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.5324616769887179
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.8772785233527443
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.42955825608730286
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.5552319494820767
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.10701674192288003
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.11065138564703068
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.4775751626768436
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.03645061974273214
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.39130151953162084
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.7957377608636707
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.46271161859419263
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.41573680869731566
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.36549841842951103
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.6993834824653841
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.021787121319141466
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.8322490038641627
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.9938237559451778
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.08137370794448258
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.20956437441243775
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.9074158969064321
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.21348711441065613
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.5022716718243883
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 1.0763891015150897
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.7900760180756479
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.4882446255535259
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.43592395555539276
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.20618497570577443
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -0.9656885317128013
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.7527388722518723
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.7110418542415942
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.2603605318722293
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.5547944284546544
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.21676044097398958
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.9223096248989877
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.7142427126099947
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.18622790734512254
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.33682279128493947
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 1.1579204853871314
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 1.2421341693808934
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.025107661983884668
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.5985858207703669
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.4291835253392745
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -1.1758939099022827
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.10919345861754118
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.35060532210264606
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.4414019114846216
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.20003333938204365
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.6937810640301627
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.2599134075937887
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.2343040433173365
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.15240869754206493
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.15183494914011436
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.4603995634364372
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.307590267087585
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.48923383763200096
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: -0.08786157262267938
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.6099560607169275
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.2642808191596439
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.3131098526053564
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.13100474337356816
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.008564022350107479
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.047188311643798116
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.46267929562026516
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: -0.04849808143968128
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.42425492980175866
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 0.9452389036797707
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.01956306386228911
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: -0.010248062514478355
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.3247881223997081
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.6051832231746002
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.1301225899894413
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.28749156169125034
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.3717337083986153
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 1.0854283002739598
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.32146065085542813
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.48045729809794013
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.2483238151093169
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.8275705605587012
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.6829889192442683
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.26398861194108714
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.3862180753495003
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.05699907752594352
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.5179846213649325
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.3382820176034552
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.4883281037009437
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.3577253356661424
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.10689140526508753
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.4017231695077469
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.07906726900263265
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.3219298795243388
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -1.2242875413525125
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.1796928064499247
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.011803328639748329
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.5483814302915933
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.10758204228716754
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -1.150647357458996
---------------------------------------------------------

Hidden units: 7
Epochs: 1000
Learning rate: 0.05

Errors during training:
Error at epoch 1 is 127.58851081053278
Train mean error at (after) epoch 1: 0.31897127702633193
Test error at (after) epoch 1: 0.2957558485990334
----------
Error at epoch 100 is 18.17652627756763
Train mean error at (after) epoch 100: 0.04544131569391907
Test error at (after) epoch 100: 0.05438891682722358
----------
Error at epoch 200 is 14.288974295051004
Train mean error at (after) epoch 200: 0.03572243573762751
Test error at (after) epoch 200: 0.04523988662923432
----------
Error at epoch 300 is 13.14727801501419
Train mean error at (after) epoch 300: 0.03286819503753548
Test error at (after) epoch 300: 0.041544163281293664
----------
Error at epoch 400 is 12.055251813101922
Train mean error at (after) epoch 400: 0.030138129532754805
Test error at (after) epoch 400: 0.03801066812227487
----------
Error at epoch 500 is 10.97023001689703
Train mean error at (after) epoch 500: 0.027425575042242575
Test error at (after) epoch 500: 0.03452070882859902
----------
Error at epoch 600 is 9.91702723529281
Train mean error at (after) epoch 600: 0.024792568088232027
Test error at (after) epoch 600: 0.031129955413236557
----------
Error at epoch 700 is 8.919365075281473
Train mean error at (after) epoch 700: 0.02229841268820368
Test error at (after) epoch 700: 0.027908929883213883
----------
Error at epoch 800 is 7.995769309813991
Train mean error at (after) epoch 800: 0.019989423274534977
Test error at (after) epoch 800: 0.02491603356035464
----------
Error at epoch 900 is 7.158540197450593
Train mean error at (after) epoch 900: 0.017896350493626482
Test error at (after) epoch 900: 0.022190937667296327
----------
Error at epoch 1000 is 6.413760841836243
Train mean error at (after) epoch 1000: 0.016034402104590607
Test error at (after) epoch 1000: 0.019754019498938305
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.5036080169770697
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.6689848212367476
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.6813962543410277
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.3692376902600586
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.723120127748959
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -1.0282187767959121
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.5970166043056574
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.8561207651162329
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.05957135558686313
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.4133780572485807
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.6892253261092801
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.09212128579464961
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.4276062964379918
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.9649025194000975
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.7225024311073541
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.5468623704660128
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.4364106167520949
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 1.0332785064012495
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.10689823356629276
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.9486579893195413
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.9723113215343214
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.2637190851671698
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.5572551087589579
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.9139116227473617
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.4225903556879733
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.7405287929016124
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 1.0086232817701082
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 1.061285114810535
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.6606574089059255
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.7298238648793106
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.4670352469387516
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -1.015181224764771
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -1.0203510049425453
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.8435432008685798
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.26872573299850183
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.8205929568732787
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.3298119137677276
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.9679513405747712
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.8453948270203361
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.3984952139458466
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.3763624930892045
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 1.0572147397823657
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 1.055712029399419
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.23500669430890497
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.9283673740021439
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.5894565354243054
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -1.0019625622799775
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.13443747246876683
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.47785735947566804
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.5892393402915034
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.3543316726804773
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.8131565502267689
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.509346153216954
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.5086786506370242
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.08360783090430393
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.07316509223495725
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.7231787542348987
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.5040214386049525
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.8503707616886439
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.03747037893381005
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.9367941273795234
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.4401501328132215
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.6321133695909594
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.20009965470323163
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.10124170454739595
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.2137264125397541
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.7538955091667224
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.08480169610242877
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.7270743706066052
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 1.1070949067787177
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.03491525368019216
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.12671577975470205
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.4704194307495177
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.6733937577475596
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.27806786563206337
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.4231986259008765
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.6921068035358394
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 0.9976152429052777
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.7348176313067206
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.608813004255146
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.562727984506787
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.8479627940037878
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.7891342686268868
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.27432013612145706
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.5562420230574829
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.1511865718341976
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.8425763805939015
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.4375221825963845
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.9081406179939074
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.5294799517940244
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.2169939538811902
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.5430714517580837
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.20024661912107689
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.5517609579702127
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -1.1109283065794011
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.23917595215178816
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.16034151592631693
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.836337427282132
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.23288678800900917
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -1.0351059431925635
---------------------------------------------------------

Hidden units: 7
Epochs: 3000
Learning rate: 0.05

Errors during training:
Error at epoch 1 is 61.77951256864317
Train mean error at (after) epoch 1: 0.15444878142160792
Test error at (after) epoch 1: 0.1361704494946937
----------
Error at epoch 300 is 14.909664668636426
Train mean error at (after) epoch 300: 0.03727416167159106
Test error at (after) epoch 300: 0.047037287319859684
----------
Error at epoch 600 is 12.461837312579664
Train mean error at (after) epoch 600: 0.03115459328144916
Test error at (after) epoch 600: 0.039629456359492214
----------
Error at epoch 900 is 10.123919480486274
Train mean error at (after) epoch 900: 0.025309798701215684
Test error at (after) epoch 900: 0.032390991799054816
----------
Error at epoch 1200 is 8.178082310899836
Train mean error at (after) epoch 1200: 0.02044520577724959
Test error at (after) epoch 1200: 0.026274835403421522
----------
Error at epoch 1500 is 6.6496878400700545
Train mean error at (after) epoch 1500: 0.016624219600175138
Test error at (after) epoch 1500: 0.02139161515236725
----------
Error at epoch 1800 is 5.435546015606785
Train mean error at (after) epoch 1800: 0.013588865039016962
Test error at (after) epoch 1800: 0.01743112008553883
----------
Error at epoch 2100 is 4.438686734056863
Train mean error at (after) epoch 2100: 0.011096716835142158
Test error at (after) epoch 2100: 0.014103331237757111
----------
Error at epoch 2400 is 3.6182620248251665
Train mean error at (after) epoch 2400: 0.009045655062062917
Test error at (after) epoch 2400: 0.011305893254532118
----------
Error at epoch 2700 is 2.974314017167502
Train mean error at (after) epoch 2700: 0.007435785042918756
Test error at (after) epoch 2700: 0.009067501897441323
----------
Error at epoch 3000 is 2.506039284812263
Train mean error at (after) epoch 3000: 0.006265098212030657
Test error at (after) epoch 3000: 0.007404999223173898
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.5798802313115954
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.725960088708271
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.8089249476943338
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.43732702941188994
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.7859095950287356
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.9389620933790477
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.7209374439228282
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.8442285894610515
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.07518267822338691
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.47347643165186537
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.8125411489790804
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.09026583416188874
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.5344461458071186
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.8654990916330635
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.7664588048776123
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.6524204497249886
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.5304712172585146
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.9170950136193575
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.1318087124488211
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.8408533273560166
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.8519565597726877
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.32814449585223665
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.6031427506160488
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.8868736041535018
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.49470331485854147
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.8041277055158698
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 0.8735356745635323
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.903198356785369
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.7581056324185531
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.7591260388075431
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.5363661630909837
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -0.8914775053167499
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.9001070888106909
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.8827741961179628
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.343202855339952
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.9074291492258734
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.4050462330909951
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.9055133973803138
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.8904216793589845
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.5413973317280569
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.46949966714462854
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 0.7952016101349138
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 0.7722571247079271
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.30141315883223846
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.9187908059005288
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.7006470763823704
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -0.815537945982831
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.13552639316444812
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.5940464737167261
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.7256223024381072
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.42809482193411064
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.8611946707249105
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.6082686107047593
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.5806869982364036
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.07903082131531525
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.06618062057069075
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.7828364100073191
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.586749527232055
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.9035082931925317
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.07852830982957094
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.8801765735802133
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.5374468500010822
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.6874401909391437
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.2545710632000165
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.14676922703276687
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.25452623829811727
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.7798626507556794
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.10959935701892977
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.7642732923857939
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 0.8514111442365437
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.05029064000590031
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.15919110555766386
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.5581680347238684
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.815636625906515
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.3472788427390307
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.5110107847287868
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.7897056764437888
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 0.8564621076235935
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.7413803424114003
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.7149660444113429
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.6172379046938465
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.9488428828895344
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.8886864135667609
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.2742696051571487
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.6433712609302055
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.19410475556254908
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.8434299802171157
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.5275415035681665
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.8334612237184834
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.6604398136179084
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.2736107771604568
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.6569563175585993
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.26951752684365304
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.6381030639299415
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -0.7513453955225242
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.3095586499760711
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.281187295398502
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.8411854462486559
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.36581500710019027
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -0.82091114718616
---------------------------------------------------------

Hidden units: 7
Epochs: 10000
Learning rate: 0.05

Errors during training:
Error at epoch 1 is 129.21498777095465
Train mean error at (after) epoch 1: 0.32303746942738665
Test error at (after) epoch 1: 0.29105665651967355
----------
Error at epoch 1000 is 7.609588277283417
Train mean error at (after) epoch 1000: 0.019023970693208544
Test error at (after) epoch 1000: 0.02411330437990854
----------
Error at epoch 2000 is 3.2557311518518075
Train mean error at (after) epoch 2000: 0.008139327879629519
Test error at (after) epoch 2000: 0.009627913296038921
----------
Error at epoch 3000 is 2.1765447962646123
Train mean error at (after) epoch 3000: 0.005441361990661531
Test error at (after) epoch 3000: 0.005737032651010744
----------
Error at epoch 4000 is 1.8502272663257933
Train mean error at (after) epoch 4000: 0.004625568165814483
Test error at (after) epoch 4000: 0.0046418845271392496
----------
Error at epoch 5000 is 1.6594664741890164
Train mean error at (after) epoch 5000: 0.004148666185472541
Test error at (after) epoch 5000: 0.004100436069820535
----------
Error at epoch 6000 is 1.507991633099167
Train mean error at (after) epoch 6000: 0.0037699790827479176
Test error at (after) epoch 6000: 0.0037016500903409156
----------
Error at epoch 7000 is 1.3815983090266186
Train mean error at (after) epoch 7000: 0.0034539957725665464
Test error at (after) epoch 7000: 0.0033753560655014224
----------
Error at epoch 8000 is 1.2753255599190798
Train mean error at (after) epoch 8000: 0.0031883138997976994
Test error at (after) epoch 8000: 0.003102789780745382
----------
Error at epoch 9000 is 1.185380485507042
Train mean error at (after) epoch 9000: 0.002963451213767605
Test error at (after) epoch 9000: 0.002873097994365499
----------
Error at epoch 10000 is 1.108578900193837
Train mean error at (after) epoch 10000: 0.002771447250484593
Test error at (after) epoch 10000: 0.0026776326915311306
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.6102865051445134
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.8092526935517802
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.8643464251240525
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.4599715258828244
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.8460369559398412
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.8508756635054872
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.7608745693023562
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.8810338774927473
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.09084473820515823
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.509095781285271
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.8559849802769088
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.06621268722230284
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.5574167176520297
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.8843365868815264
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.8134365472688867
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.6814143222509056
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.5561741535216074
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.927260121212257
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.11251572344411256
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.89499910491781
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.7991534825524549
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.3310159371151846
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.664705352479629
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.863382496648611
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.5227557820386063
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.8405707280106933
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 0.687938255581034
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.8850779448196116
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.7960874866519082
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.8200731387365933
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.5660310628225559
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -0.7912395168796947
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.9080866260820069
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.8696526560372211
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.359129498413295
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.9640133256935473
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.4368337026221285
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.8413468335720534
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.8990858905365597
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.5836255823287357
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.4867822130877912
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 0.6036819310892122
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 0.46542103419616077
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.30576588998578763
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.9530374370547938
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.7599406393409663
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -0.6487395393228589
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.14701645458713514
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.6396637858267736
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.7893073083606382
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.4563505688241568
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.9031799090798476
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.6634537136977658
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.6340910308618627
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.09962162107759154
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.08190978830978671
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.8200839410274641
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.6212209306274717
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.9843925901682335
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.0685315988363677
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.9100747773533704
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.5573795131798098
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.7275449459059589
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.31791309566913156
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.14769565019781425
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.25789548393308137
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.8415613149449914
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.10505744278420304
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.8139379826220677
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 0.7631913100223929
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.10657611095207756
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.15808964953521798
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.5877582769562272
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.8472769520006974
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.3722942702480508
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.5386089546075528
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.8833989070079904
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 0.6926229345646834
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.7967343683792887
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.7419623347495092
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.6812514829175182
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.922247402219031
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.9168398608256256
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.2998224478765745
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.6765051003711362
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.20216455292694316
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.8979162706930195
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.5511561647869507
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.8827640940321608
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.7263572544562373
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.2865802086841329
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.706398431826205
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.2842227843831743
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.68765550961631
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -0.4760424083779743
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.33353369311973974
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.28897266060989046
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.8759399090275805
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.41773888515328633
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -0.6176622178599401
---------------------------------------------------------

Hidden units: 7
Epochs: 100
Learning rate: 0.1

Errors during training:
Error at epoch 1 is 78.51578621696078
Train mean error at (after) epoch 1: 0.19628946554240195
Test error at (after) epoch 1: 0.17198540998145007
----------
Error at epoch 10 is 60.93473657877552
Train mean error at (after) epoch 10: 0.1523368414469388
Test error at (after) epoch 10: 0.13302091706636704
----------
Error at epoch 20 is 44.671263874888524
Train mean error at (after) epoch 20: 0.1116781596872213
Test error at (after) epoch 20: 0.09808883871729936
----------
Error at epoch 30 is 32.17631497783361
Train mean error at (after) epoch 30: 0.08044078744458404
Test error at (after) epoch 30: 0.07311336202298993
----------
Error at epoch 40 is 24.03052869679267
Train mean error at (after) epoch 40: 0.06007632174198167
Test error at (after) epoch 40: 0.05846840839033747
----------
Error at epoch 50 is 19.507947989590992
Train mean error at (after) epoch 50: 0.04876986997397748
Test error at (after) epoch 50: 0.051497480837183085
----------
Error at epoch 60 is 17.24745768155438
Train mean error at (after) epoch 60: 0.04311864420388595
Test error at (after) epoch 60: 0.048712885579703
----------
Error at epoch 70 is 16.13204420513073
Train mean error at (after) epoch 70: 0.040330110512826825
Test error at (after) epoch 70: 0.047655552271716424
----------
Error at epoch 80 is 15.519466074852104
Train mean error at (after) epoch 80: 0.03879866518713026
Test error at (after) epoch 80: 0.04710159792631143
----------
Error at epoch 90 is 15.108037042349665
Train mean error at (after) epoch 90: 0.03777009260587416
Test error at (after) epoch 90: 0.04658511568905405
----------
Error at epoch 100 is 14.772135327613649
Train mean error at (after) epoch 100: 0.03693033831903412
Test error at (after) epoch 100: 0.04597905244383543
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.3775625971254109
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.5722687856844797
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.6259919150484615
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.2717920173095992
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.6488753228312283
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -1.087770330415556
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.5224512940857768
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.702826483266426
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.04449180351193697
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.2630263042089415
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.6111214257281197
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.059874234558707114
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.337269563165551
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.9649865132566207
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.5837148797846645
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.46972787661152776
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.3585219220060132
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.867400524648964
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.06344827811637033
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 1.012703855643894
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 1.1445346804417869
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.1359095596009482
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.41851693163752685
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -1.0347923549538351
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.3321991286407285
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.6152835220240145
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 1.2337629523008582
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.9413569252005631
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.5905030109637148
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.6072198080138428
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.35005072598469095
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -1.121196944952984
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.9010327187505276
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.8134246513915505
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.15713279979091985
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.7048354768158374
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.24172841252316843
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 1.050188050906274
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.8339003972771534
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.3181372089805434
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.28810361400756973
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 1.2953064540696293
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 1.412219007205935
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.1753869398349952
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.7641303085375645
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.5087475659919188
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -1.3346028750109378
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.10182834755403153
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.3648636806927273
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.4684291406544413
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.27107192045053236
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.8058751510620514
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.3678982552279058
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.36615764074746415
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.0658236839975301
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.05441756280668777
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.5672942994472584
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.39364430224609703
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.6551271200760699
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.03968499874308592
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.7676982569699512
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.3819609429071245
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.471116762382546
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.15062453575745133
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.05633187341956795
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.1700005283981352
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.6285860307161142
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.06683160816803473
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.5747619194722356
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 1.0821376093330122
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.05052380437441258
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.09666738833212914
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.39218534731011245
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.6086391482316259
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.14549867567028496
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.36345558190745375
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.4991746413969285
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 1.2425008628274241
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.5477060891057086
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.5297519428885951
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.44427085713271597
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.8924932003170875
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.7888153176780377
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.16782368234712255
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.4240457934667435
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.10105993373171064
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.6749861199060004
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.3598466078582036
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.6925620252133975
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.39546055649567363
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.15887433362808562
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.448157769432371
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.1485330563056839
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.4174950188619584
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -1.3737669158791568
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.16789854061612036
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.1944169159122362
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.6862764782680174
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.2047334924443828
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -1.3254015215861616
---------------------------------------------------------

Hidden units: 7
Epochs: 1000
Learning rate: 0.1

Errors during training:
Error at epoch 1 is 100.5907746835998
Train mean error at (after) epoch 1: 0.2514769367089995
Test error at (after) epoch 1: 0.21770969084411718
----------
Error at epoch 100 is 14.270028094523157
Train mean error at (after) epoch 100: 0.03567507023630789
Test error at (after) epoch 100: 0.043968907890798145
----------
Error at epoch 200 is 12.200847896270856
Train mean error at (after) epoch 200: 0.03050211974067714
Test error at (after) epoch 200: 0.03842164251886657
----------
Error at epoch 300 is 10.25001568925536
Train mean error at (after) epoch 300: 0.0256250392231384
Test error at (after) epoch 300: 0.03242736352164677
----------
Error at epoch 400 is 8.473603451530689
Train mean error at (after) epoch 400: 0.021184008628826724
Test error at (after) epoch 400: 0.026887294783330063
----------
Error at epoch 500 is 6.953984599499403
Train mean error at (after) epoch 500: 0.01738496149874851
Test error at (after) epoch 500: 0.02208201015887047
----------
Error at epoch 600 is 5.7108811642380966
Train mean error at (after) epoch 600: 0.01427720291059524
Test error at (after) epoch 600: 0.018091043262944542
----------
Error at epoch 700 is 4.729571048220682
Train mean error at (after) epoch 700: 0.011823927620551703
Test error at (after) epoch 700: 0.014885829012427038
----------
Error at epoch 800 is 3.980018648425068
Train mean error at (after) epoch 800: 0.00995004662106267
Test error at (after) epoch 800: 0.012388207311551415
----------
Error at epoch 900 is 3.4253000146841814
Train mean error at (after) epoch 900: 0.008563250036710454
Test error at (after) epoch 900: 0.010496117390517635
----------
Error at epoch 1000 is 3.026092970742351
Train mean error at (after) epoch 1000: 0.007565232426855878
Test error at (after) epoch 1000: 0.009097176313668198
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.5698438093518262
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.7305988869157687
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.794152431599134
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.42834004917213103
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.7771664456925635
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.960925604089331
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.7211881824432309
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.8248396657852034
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.08625716936394202
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.5028520341997751
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.7908611157697001
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.07410037945612694
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.5317617291318563
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.8768471665674296
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.7491376872919528
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.6501121128940262
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.5351127032237131
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.8796838050319837
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.11012573607931266
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.8745593730694562
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.8704553516829132
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.3143790973652027
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.6431740846781093
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.8873908262281152
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.48452274278482577
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.7831277947151212
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 0.9115412495076372
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.8851225306440397
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.7466293275768213
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.7648366678757763
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.5359316735763395
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -0.8994302794169577
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.8897458711158446
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.8642072537951719
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.3450051758002893
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.902391064330156
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.3941481925265722
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.9079694519024228
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.8791590589307785
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.514912168777411
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.4752137165349051
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 0.8372166470724733
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 0.8367638474797039
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.307903692530901
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.8671332559995955
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.6894716953246788
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -0.8538018391787767
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.137796047241374
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.5848052438430797
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.7046071313037486
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.4139628243770962
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.8497242055777281
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.582760549701769
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.587680032441767
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.08548148399548737
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.0732314291874447
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.7459458371866972
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.5712004777110335
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.8586185267387987
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.07760058132992877
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.8562828477649027
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.5283557108278651
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.6774424024519629
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.27608119319728114
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.1317056051051252
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.24464874558435795
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.7799173326256418
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.1028616982077238
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.7531237700355957
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 0.8702560231807416
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.06975451737347861
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.15150420255117839
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.5528147573750282
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.8045191948193552
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.33266494784082684
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.515598377533118
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.7486340302444526
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 0.8831938337131655
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.7852113317279983
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.7020191446960642
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.6362199101997713
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.9460169992552131
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.8755747928463697
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.27446671354602226
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.6206982404933306
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.1808145911766218
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.8282315742781942
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.5250145918254592
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.8751706928849445
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.6414637193440904
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.26441485401160336
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.6447359275984366
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.25964296947762083
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.6253932560131601
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -0.8129420567530323
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.3080533042410767
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.2957530328852641
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.812749204038992
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.35157602511408964
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -0.8571904315485503
---------------------------------------------------------

Hidden units: 7
Epochs: 3000
Learning rate: 0.1

Errors during training:
Error at epoch 1 is 117.0297404968944
Train mean error at (after) epoch 1: 0.292574351242236
Test error at (after) epoch 1: 0.27209367195546386
----------
Error at epoch 300 is 10.845896108902643
Train mean error at (after) epoch 300: 0.027114740272256608
Test error at (after) epoch 300: 0.034369028205967565
----------
Error at epoch 600 is 6.060146574626896
Train mean error at (after) epoch 600: 0.01515036643656724
Test error at (after) epoch 600: 0.019089751167340203
----------
Error at epoch 900 is 3.9955181334174537
Train mean error at (after) epoch 900: 0.009988795333543634
Test error at (after) epoch 900: 0.012076894636919348
----------
Error at epoch 1200 is 3.1323674099638836
Train mean error at (after) epoch 1200: 0.007830918524909709
Test error at (after) epoch 1200: 0.008912110117803318
----------
Error at epoch 1500 is 2.663347924293973
Train mean error at (after) epoch 1500: 0.006658369810734932
Test error at (after) epoch 1500: 0.007170831310814971
----------
Error at epoch 1800 is 2.3611870905637007
Train mean error at (after) epoch 1800: 0.005902967726409252
Test error at (after) epoch 1800: 0.006121832256728885
----------
Error at epoch 2100 is 2.151071319453508
Train mean error at (after) epoch 2100: 0.00537767829863377
Test error at (after) epoch 2100: 0.005463009117039427
----------
Error at epoch 2400 is 1.9939327853771898
Train mean error at (after) epoch 2400: 0.004984831963442974
Test error at (after) epoch 2400: 0.005015009825847496
----------
Error at epoch 2700 is 1.8671472258278008
Train mean error at (after) epoch 2700: 0.004667868064569502
Test error at (after) epoch 2700: 0.0046763786710729525
----------
Error at epoch 3000 is 1.7588385003377516
Train mean error at (after) epoch 3000: 0.004397096250844379
Test error at (after) epoch 3000: 0.004396956609293956
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.6273663536856477
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.8001419512339892
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.8230656918171751
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.4844530006959173
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.8138120418419269
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.8338355827965616
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.7635199916458715
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.8710968550178693
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.0962120706705798
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.5248732071560482
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.8407627733472032
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.09480436263658101
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.5701537311750053
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.8582124715621382
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.8033282325893615
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.6942999494630913
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.5829649392961539
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.8976641762589495
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.14086720961823324
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.830747396948957
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.7699048307576399
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.3538185450212233
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.6814942543257195
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.8272403315994189
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.5419723855177616
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.8331363459948815
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 0.7242889376334615
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.8594950750653912
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.7919067929861419
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.8222760847469438
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.5855227221155856
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -0.7959834724477552
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.8888293441688419
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.867901229973462
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.3750184639574983
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.9152175974991246
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.44001983107299686
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.8328178292046674
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.8759668786249049
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.6015890742073897
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.5320601963312943
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 0.6631427544975625
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 0.5719824239456666
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.31316833706261726
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.9276793151554137
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.7375107763918431
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -0.6838359873402402
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.156725870089038
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.6299756007047324
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.760586870158712
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.4711030200959449
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.8576837874237643
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.6642025999359568
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.6252299442591015
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.11842823247381762
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.10497947809497427
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.8305851390715804
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.6285058432603783
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.9426782788466859
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.05826710969805474
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.8947347658502707
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.5679178124145525
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.7588518563582404
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.2906110728878154
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.14062625213232596
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.27640925694476987
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.8377537420964002
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.10991953147107378
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.8166723401917261
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 0.7777605892487988
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.05836080906698977
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.167891781797391
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.6028458114517697
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.8072104787504542
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.38425718177767826
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.5595352147561282
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.8586447561920412
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 0.720938060478541
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.8358903409843889
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.7423369757083904
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.6973446337044925
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.8987707684946922
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.8808819552911522
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.34103892515599415
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.6948948987957291
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.20299183754841657
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.8950901887143939
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.5692472882383808
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.9253210783919956
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.7132260501257597
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.29543759526924396
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.6903797658933486
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.2892077724549131
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.6877271100948292
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -0.5857185828814767
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.34812799360490915
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.2908963132338844
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.8667335046003313
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.4172894515535905
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -0.6761882275852149
---------------------------------------------------------

Hidden units: 7
Epochs: 10000
Learning rate: 0.1

Errors during training:
Error at epoch 1 is 166.49137368628737
Train mean error at (after) epoch 1: 0.4162284342157184
Test error at (after) epoch 1: 0.3586303267112182
----------
Error at epoch 1000 is 3.294182327559758
Train mean error at (after) epoch 1000: 0.008235455818899395
Test error at (after) epoch 1000: 0.009946978758751689
----------
Error at epoch 2000 is 1.9899091975637069
Train mean error at (after) epoch 2000: 0.004974772993909267
Test error at (after) epoch 2000: 0.005164850428298424
----------
Error at epoch 3000 is 1.6340633772146338
Train mean error at (after) epoch 3000: 0.004085158443036584
Test error at (after) epoch 3000: 0.004185873893885913
----------
Error at epoch 4000 is 1.3789047913359387
Train mean error at (after) epoch 4000: 0.0034472619783398467
Test error at (after) epoch 4000: 0.0035490470977374367
----------
Error at epoch 5000 is 1.1969191519265479
Train mean error at (after) epoch 5000: 0.0029922978798163696
Test error at (after) epoch 5000: 0.0031040240570794782
----------
Error at epoch 6000 is 1.0638466727243823
Train mean error at (after) epoch 6000: 0.002659616681810956
Test error at (after) epoch 6000: 0.002782783121344717
----------
Error at epoch 7000 is 0.9626706267338315
Train mean error at (after) epoch 7000: 0.002406676566834579
Test error at (after) epoch 7000: 0.0025407204588123945
----------
Error at epoch 8000 is 0.8830829996786557
Train mean error at (after) epoch 8000: 0.002207707499196639
Test error at (after) epoch 8000: 0.0023507442034216637
----------
Error at epoch 9000 is 0.818770492413485
Train mean error at (after) epoch 9000: 0.0020469262310337123
Test error at (after) epoch 9000: 0.002196024811930889
----------
Error at epoch 10000 is 0.7654956342603386
Train mean error at (after) epoch 10000: 0.0019137390856508465
Test error at (after) epoch 10000: 0.0020655787573526808
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.6045434939798275
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.7964983763535206
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.8576674540984504
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.4498399344142737
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.8392357448100592
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.8359129361536694
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.7486946856332464
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.8839639805502449
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.09293765372753676
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.4759940043560674
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.9123500020974434
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.0610400406564105
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.57256406778402
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.8738098581772117
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.8075516338913181
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.6692332376343637
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.5642302046653767
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.9102111405757008
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.11018915052018377
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.8702659211075692
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.7887372360465655
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.3338191987483624
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.6749637146772787
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.8594867183046232
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.5134454910454014
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.8234516600340431
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 0.6787442273147628
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.8567004643705775
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.7856089136352798
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.8220833312713696
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.5600307235750844
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -0.7747143194771364
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.9271623080878031
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.9141143200731688
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.39343446493657575
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.93692981444686
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.41546758807747675
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.837466222357507
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.8988774253475856
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.5772236073032617
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.5005618338458158
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 0.5525514938973689
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 0.39718247646602756
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.2943417851858533
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.9650538023111398
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.7467467504344935
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -0.5914277151748356
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.1343333022119154
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.6548841964185478
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.7747501734057644
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.43792511460139116
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.8834282522873639
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.6395016091127901
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.6071802559172261
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.1105608463845981
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.0983507832521412
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.8341518355605035
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.5980550994117307
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.986003688334918
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.0580600290158626
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.9118963831103157
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.57951865904015
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.73925380968219
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.3023223202269971
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.1434270084719091
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.2631562739422404
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.8420439156513172
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.10301367449826263
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.8139404626875628
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 0.7453491982685071
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.07001822391039124
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.1558584491871009
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.5711265614449875
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.8995231002617464
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.3708648222817156
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.5237892258144858
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.879441712612111
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 0.6983839458628566
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.8880422393318017
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.7268944327661078
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.6940824373606986
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.9539160776260978
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.9332812984134503
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.3103118260873678
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.6855677381902378
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.1958251512811627
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.9234811895096371
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.5319856930038589
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.9782043780487638
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.714526136740477
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.28095041585661173
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.6891673773368435
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.2758281088849599
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.6540448972505333
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -0.42099808905750147
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.3321187327402396
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.29483413298470407
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.893035195871582
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.39887056883560024
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -0.5800979671133875
---------------------------------------------------------

Hidden units: 7
Epochs: 100
Learning rate: 0.3

Errors during training:
Error at epoch 1 is 134.23890968230643
Train mean error at (after) epoch 1: 0.33559727420576607
Test error at (after) epoch 1: 0.30533578827819247
----------
Error at epoch 10 is 70.17013627082463
Train mean error at (after) epoch 10: 0.17542534067706156
Test error at (after) epoch 10: 0.16319096304593997
----------
Error at epoch 20 is 29.71897868217179
Train mean error at (after) epoch 20: 0.07429744670542948
Test error at (after) epoch 20: 0.07203666342605425
----------
Error at epoch 30 is 17.66596707865018
Train mean error at (after) epoch 30: 0.04416491769662545
Test error at (after) epoch 30: 0.05218228932106633
----------
Error at epoch 40 is 16.271268678802564
Train mean error at (after) epoch 40: 0.04067817169700641
Test error at (after) epoch 40: 0.05053477937096341
----------
Error at epoch 50 is 15.746833073927784
Train mean error at (after) epoch 50: 0.039367082684819456
Test error at (after) epoch 50: 0.049253161626310556
----------
Error at epoch 60 is 15.25406103229609
Train mean error at (after) epoch 60: 0.038135152580740225
Test error at (after) epoch 60: 0.04778645107445288
----------
Error at epoch 70 is 14.750206273745073
Train mean error at (after) epoch 70: 0.03687551568436268
Test error at (after) epoch 70: 0.04625024388858186
----------
Error at epoch 80 is 14.2354507923341
Train mean error at (after) epoch 80: 0.03558862698083525
Test error at (after) epoch 80: 0.0446748631367901
----------
Error at epoch 90 is 13.712966676676261
Train mean error at (after) epoch 90: 0.03428241669169065
Test error at (after) epoch 90: 0.04307207507224318
----------
Error at epoch 100 is 13.18626511676217
Train mean error at (after) epoch 100: 0.03296566279190542
Test error at (after) epoch 100: 0.04145207016509089
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.3980395064318115
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.5792159699098649
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.6514304666624977
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.29040040317339955
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.6612797616712154
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -1.1303059712441876
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.5342294919231845
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.749462211684632
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.04404650367076309
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.30436671532548865
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.6370106192768067
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.06750629547873632
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.3454199572556588
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.9837246855392491
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.6089486815084872
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.48077422302953055
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.3611449487811647
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.9679967700953646
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.07888139735196231
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 1.022169541902981
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 1.1200433620937853
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.19559428012473287
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.4266695914921486
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -1.0060282651527142
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.3421558608248519
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.6509158575895819
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 1.217312397308594
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 1.0434291512590514
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.5993816146411665
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.6236945583683634
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.3638784940460461
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -1.1384680105623068
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.9901624459994627
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.7940129855854093
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.1976789763334035
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.7474722886913331
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.25571792829021883
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 1.070107665055157
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.8459670788287225
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.3274682866628785
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.2677865954829477
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 1.2880004158465082
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 1.3659306758960585
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.1762574743170181
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.8237198574019894
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.5316070477664084
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -1.2748752091810123
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.10801409701993189
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.4110502785989329
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.5340642868339668
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.2902966760184808
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.8065878386888196
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.4060407361926534
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.3983103882323273
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.06617722610201163
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.053856245454399224
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.5968720652456218
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.40801679591957696
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.7129229414794144
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.03246628169685429
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.8351931190844831
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.3827546528303077
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.5090198471722255
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.15798898331585134
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.07245127091926531
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.17574590113952443
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.6515494125166358
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.0699561278757673
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.6091663414778282
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 1.1656255435320968
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.03356045919581813
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.1020510164681096
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.39973220196079795
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.6373678186649299
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.20412778817116975
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.3670961443660693
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.5464986463476962
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 1.1969478292109887
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.5658793877336097
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.529641700288895
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.44885589331778264
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.9079116846552882
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.7965698410755674
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.20202063899411962
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.4298678850445813
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.113064883838325
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.7356969168624499
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.3631198253186994
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.7374355575430481
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.4681554887591515
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.16882894135858295
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.4816456606808946
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.15557687865108935
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.45501263580296436
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -1.3816599633938065
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.1741804184753933
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.14382464547440837
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.7212830855467198
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.202947358856768
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -1.2786342657910477
---------------------------------------------------------

Hidden units: 7
Epochs: 1000
Learning rate: 0.3

Errors during training:
Error at epoch 1 is 58.567247949297084
Train mean error at (after) epoch 1: 0.1464181198732427
Test error at (after) epoch 1: 0.12726534603579062
----------
Error at epoch 100 is 6.7105893045556435
Train mean error at (after) epoch 100: 0.01677647326138911
Test error at (after) epoch 100: 0.021155909461363188
----------
Error at epoch 200 is 4.079096413644644
Train mean error at (after) epoch 200: 0.010197741034111609
Test error at (after) epoch 200: 0.012399045659862851
----------
Error at epoch 300 is 2.8870083092911214
Train mean error at (after) epoch 300: 0.007217520773227804
Test error at (after) epoch 300: 0.008191916799933358
----------
Error at epoch 400 is 2.37106734022765
Train mean error at (after) epoch 400: 0.0059276683505691255
Test error at (after) epoch 400: 0.006304436029951543
----------
Error at epoch 500 is 2.133624067170271
Train mean error at (after) epoch 500: 0.0053340601679256775
Test error at (after) epoch 500: 0.005463947690544149
----------
Error at epoch 600 is 1.9872375770002406
Train mean error at (after) epoch 600: 0.004968093942500602
Test error at (after) epoch 600: 0.005004994475171218
----------
Error at epoch 700 is 1.8701337262458648
Train mean error at (after) epoch 700: 0.004675334315614662
Test error at (after) epoch 700: 0.004678570595242685
----------
Error at epoch 800 is 1.7669188282140893
Train mean error at (after) epoch 800: 0.004417297070535223
Test error at (after) epoch 800: 0.004408542223447303
----------
Error at epoch 900 is 1.6741192623703092
Train mean error at (after) epoch 900: 0.004185298155925773
Test error at (after) epoch 900: 0.004172372201417817
----------
Error at epoch 1000 is 1.5905948166751076
Train mean error at (after) epoch 1000: 0.003976487041687769
Test error at (after) epoch 1000: 0.0039623520872356585
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.6250627685795305
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.7843730316498683
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.8183982723078544
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.483385058595897
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.8200082001753004
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.8231388086427144
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.7675234992827644
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.876439319700639
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.09199449289395291
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.5101714935633069
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.8625424722083095
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.08957515080162617
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.5978968929077466
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.8451304129970817
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.8082226739223981
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.6944801578972385
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.575961857888507
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.9067562755075499
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.13050996696033784
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.813769400612932
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.7854233255936297
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.3524727732954107
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.6677923416273823
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.8528364949649193
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.5402736951991184
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.8351938631205311
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 0.7233129812066573
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.8663265098936259
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.7912887892172569
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.8099414612873027
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.5803533341303675
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -0.7969797749983555
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.9034214445082779
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.9036328547003128
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.41429870641486055
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.9031947698900203
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.4384303640418249
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.8275210672462537
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.8755477901965021
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.5922053678546194
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.5228858046511035
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 0.6347601366900514
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 0.560822669786685
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.31353855696390387
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.9291082311094375
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.7293219601275962
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -0.6716887557251572
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.1610078207384829
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.6369211757545195
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.7293437730707497
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.4546145181457567
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.8656922542704193
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.6655221809026725
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.6192560766118704
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.11381103478359718
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.0975330875098738
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.8278273857872103
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.6265877655850712
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.9280374531003076
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.06300776794040366
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.9031589209817451
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.5987392790136434
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.7548473755163695
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.2925811627768702
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.14244194181592237
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.2779280330096853
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.8324423485999308
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.10878171028647789
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.8200331638742364
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 0.7667084402697705
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.07770693362692963
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.1662658581630231
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.6020420807997808
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.8567785329264573
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.3826966036239885
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.5627766984415952
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.8377212781199287
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 0.7416376969052759
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.8379336940208391
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.7481448839329672
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.6860228964419484
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.90790637322988
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.8880673659720163
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.3296145919969884
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.6969036081573541
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.20288055205097247
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.9027594746277059
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.5677218419677145
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.9199546653910204
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.6711333696925057
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.2917508644438306
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.6824526969681433
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.2876737216286777
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.6887413450451668
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -0.554339596404384
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.3311359604477691
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.3126682718015079
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.8751398498177759
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.40917426849358624
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -0.6693842869563177
---------------------------------------------------------

Hidden units: 7
Epochs: 3000
Learning rate: 0.3

Errors during training:
Error at epoch 1 is 91.74144506384428
Train mean error at (after) epoch 1: 0.2293536126596107
Test error at (after) epoch 1: 0.2045840615071975
----------
Error at epoch 300 is 3.3984330520174018
Train mean error at (after) epoch 300: 0.008496082630043504
Test error at (after) epoch 300: 0.010188032591409426
----------
Error at epoch 600 is 2.183299555606036
Train mean error at (after) epoch 600: 0.0054582488890150905
Test error at (after) epoch 600: 0.005759826616672202
----------
Error at epoch 900 is 1.7812941657717403
Train mean error at (after) epoch 900: 0.004453235414429351
Test error at (after) epoch 900: 0.004559687980286342
----------
Error at epoch 1200 is 1.5191290972380567
Train mean error at (after) epoch 1200: 0.0037978227430951416
Test error at (after) epoch 1200: 0.0038711644561031603
----------
Error at epoch 1500 is 1.323943839220376
Train mean error at (after) epoch 1500: 0.00330985959805094
Test error at (after) epoch 1500: 0.0033699749053987677
----------
Error at epoch 1800 is 1.175474812925597
Train mean error at (after) epoch 1800: 0.0029386870323139924
Test error at (after) epoch 1800: 0.002988576840989835
----------
Error at epoch 2100 is 1.059887055540269
Train mean error at (after) epoch 2100: 0.0026497176388506727
Test error at (after) epoch 2100: 0.0026908452826771294
----------
Error at epoch 2400 is 0.9677708961535463
Train mean error at (after) epoch 2400: 0.0024194272403838656
Test error at (after) epoch 2400: 0.0024532242762095717
----------
Error at epoch 2700 is 0.8928522180423861
Train mean error at (after) epoch 2700: 0.0022321305451059653
Test error at (after) epoch 2700: 0.0022600118076802375
----------
Error at epoch 3000 is 0.8307828254971885
Train mean error at (after) epoch 3000: 0.0020769570637429713
Test error at (after) epoch 3000: 0.002100253134771159
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.6090457591957111
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.8008364438258637
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.8507936036598721
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.4556829737047041
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.8401704299206803
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.8345316160629019
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.7669101399285407
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.8872535240488234
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.09426222245763365
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.4864363323665609
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.901771464806326
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.08713180197440086
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.5642867355728205
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.8884872931721262
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.8245658436646819
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.6738851329556949
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.564933768828003
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.8889375803894481
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.11383787585112314
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.8777559132425619
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.7882882173281595
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.32410381991562076
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.6803900057470337
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.8656537198447214
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.5177684896271222
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.8215140322536271
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 0.688709601920189
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.8386103418378493
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.7901521739870703
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.8266648410500516
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.5668213161044676
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -0.7747241915914272
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.9017705609267238
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.9265025198943264
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.35252317732988264
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.9405482639894094
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.42131246752790397
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.8352442849695747
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.8975147423076693
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.5573317040123753
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.5344892104021158
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 0.5595033830020598
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 0.41455371092784987
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.2990001016462439
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.9282788750582984
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.7406781480696581
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -0.6043326924524581
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.14742850795358564
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.6262294888487745
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.7527864147836295
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.44940601786334633
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.8884059159009272
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.6215269861668982
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.6418301710687342
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.10549779467738844
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.10168367134685517
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.8373014012622322
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.6043273997825032
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.9458603419801508
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.05958412458976532
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.9078901110635765
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.5760632555635421
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.7354663516133113
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.2977052048192833
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.1420975272394457
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.2612884493121622
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.8477275182237116
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.10098398411796093
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.8135973566927621
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 0.7378059497327651
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.06631303560380626
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.15620024357235507
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.5786248394498174
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.8563330204245561
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.37137245469986774
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.5304671375588259
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.8335502605920584
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 0.7031910282942933
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.8743974043170223
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.7329121038365721
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.6881439827268989
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.9525629699261633
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.9258149720576838
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.3035301604913391
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.6949273799944848
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.1957366809072268
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.9081024558086873
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.5400357999876857
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.9557063787404361
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.690100624772363
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.2793636187922002
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.6895780433926072
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.2669296078571135
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.6520203583758776
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -0.42449908832561756
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.3225083397156138
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.30991945926671643
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.9001650240657074
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.36848257742256746
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -0.5969608075460103
---------------------------------------------------------

Hidden units: 7
Epochs: 10000
Learning rate: 0.3

Errors during training:
Error at epoch 1 is 132.60910181418865
Train mean error at (after) epoch 1: 0.33152275453547164
Test error at (after) epoch 1: 0.2690134284638857
----------
Error at epoch 1000 is 1.6736637427104846
Train mean error at (after) epoch 1000: 0.004184159356776212
Test error at (after) epoch 1000: 0.004364503110217366
----------
Error at epoch 2000 is 1.0488083191803022
Train mean error at (after) epoch 2000: 0.0026220207979507555
Test error at (after) epoch 2000: 0.0026660498429255624
----------
Error at epoch 3000 is 0.7223209971994803
Train mean error at (after) epoch 3000: 0.0018058024929987007
Test error at (after) epoch 3000: 0.001771419133948778
----------
Error at epoch 4000 is 0.5710022859005841
Train mean error at (after) epoch 4000: 0.0014275057147514602
Test error at (after) epoch 4000: 0.00138935772816643
----------
Error at epoch 5000 is 0.47845908947112753
Train mean error at (after) epoch 5000: 0.001196147723677819
Test error at (after) epoch 5000: 0.001177338413788265
----------
Error at epoch 6000 is 0.46244131902852476
Train mean error at (after) epoch 6000: 0.001156103297571312
Test error at (after) epoch 6000: 0.001159164070750675
----------
Error at epoch 7000 is 0.4513280903481287
Train mean error at (after) epoch 7000: 0.0011283202258703217
Test error at (after) epoch 7000: 0.001148047303193156
----------
Error at epoch 8000 is 0.44453699562418436
Train mean error at (after) epoch 8000: 0.001111342489060461
Test error at (after) epoch 8000: 0.0011427867361183822
----------
Error at epoch 9000 is 0.4420356666923817
Train mean error at (after) epoch 9000: 0.0011050891667309542
Test error at (after) epoch 9000: 0.0011445466707913302
----------
Error at epoch 10000 is 0.44160869608485187
Train mean error at (after) epoch 10000: 0.0011040217402121296
Test error at (after) epoch 10000: 0.0011487516251933987
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.6152783560456827
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.7846421617840585
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.846907924236278
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.4546317242057645
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.8695793279724747
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.8648053878163678
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.7425353548781184
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.8978059355796502
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.09340260405244957
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.47083829344596095
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.835335013178753
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.07288530064005774
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.5836220260236029
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.9231473896741589
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.8270561614103762
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.6903978132039701
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.5746980122036631
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.9252175605367852
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.1031744549005317
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.9315333012135709
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.7871822611742099
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.30881037217278506
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.6542227634354127
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.8600848504695291
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.514170550652891
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.850064122451673
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 0.6346791692675624
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.8301602882494807
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.8095593952129901
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.8427295337053525
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.568076775832653
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -0.7532959740623938
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.9190928848211132
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.9624007163077319
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.3659588346647735
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.9443154350552794
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.4259361402242918
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.8554394033800787
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.9383792589865694
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.4961455281714171
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.44264628101710746
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 0.5148678029985285
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 0.28547802017253376
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.292965557120881
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.9832114699692163
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.7380377382372605
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -0.5569991043493031
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.13528483558439527
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.6192443427185121
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.7186462012288471
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.3929255414038134
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.9178435366864539
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.6130680005600901
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.6296184427542189
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.1108249002158101
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.09693085647202068
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.8309869600524535
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.6238231377329624
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.9270901725296944
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.053038787925277525
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.9149127966369031
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.5160905879227933
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.734647574111922
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.24068667937908803
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.13650559964888717
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.24416726409727443
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.8732229887599237
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.09577529666292386
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.840012576744879
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 0.6802181004122219
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.0833478052704387
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.15079058466643505
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.588006480337141
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.895028905022365
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.35133041707494783
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.5260395065998067
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.7461236758370031
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 0.6663314920648853
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.8725051319125255
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.754004644302483
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.6484598259754453
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.9893327259034107
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.9657417952428458
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.32297451579412684
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.6666981550761928
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.19038243361862692
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.9364111981285057
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.5558601320759639
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.9512890073682372
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.639515794033281
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.2840374866091103
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.6599264366626703
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.2824813265777747
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.6711414061850586
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -0.31183770107497666
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.3006030815941646
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.3028583307536344
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.8969009390093738
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.2869558889396169
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -0.5213141925861119
---------------------------------------------------------

Hidden units: 7
Epochs: 100
Learning rate: 0.5

Errors during training:
Error at epoch 1 is 108.27623797954047
Train mean error at (after) epoch 1: 0.27069059494885117
Test error at (after) epoch 1: 0.1704608014909364
----------
Error at epoch 10 is 19.237675157993756
Train mean error at (after) epoch 10: 0.04809418789498439
Test error at (after) epoch 10: 0.05100133416200837
----------
Error at epoch 20 is 16.39433815518643
Train mean error at (after) epoch 20: 0.04098584538796607
Test error at (after) epoch 20: 0.05103315401518813
----------
Error at epoch 30 is 15.586071633593665
Train mean error at (after) epoch 30: 0.03896517908398416
Test error at (after) epoch 30: 0.048852622223475466
----------
Error at epoch 40 is 14.725522851243689
Train mean error at (after) epoch 40: 0.03681380712810922
Test error at (after) epoch 40: 0.04625346459468266
----------
Error at epoch 50 is 13.809959054915106
Train mean error at (after) epoch 50: 0.03452489763728776
Test error at (after) epoch 50: 0.0434502907561651
----------
Error at epoch 60 is 12.849279095144771
Train mean error at (after) epoch 60: 0.03212319773786193
Test error at (after) epoch 60: 0.04048678498639111
----------
Error at epoch 70 is 11.859056036583594
Train mean error at (after) epoch 70: 0.029647640091458986
Test error at (after) epoch 70: 0.037413282176365394
----------
Error at epoch 80 is 10.859226006156206
Train mean error at (after) epoch 80: 0.027148065015390514
Test error at (after) epoch 80: 0.03429286450841904
----------
Error at epoch 90 is 9.871918716123727
Train mean error at (after) epoch 90: 0.024679796790309315
Test error at (after) epoch 90: 0.031195416435644246
----------
Error at epoch 100 is 8.918820456798173
Train mean error at (after) epoch 100: 0.02229705114199543
Test error at (after) epoch 100: 0.028189559743740152
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.44839359814099744
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.6188642285181811
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.6948196807512788
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.3384969365057052
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.6872933590389474
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -1.103417552899906
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.5919573184988572
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.769974707131519
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.05394515108328523
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.37302250371507
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.6954293989134059
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.06125678549129863
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.4067481776397875
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.9361469376711065
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.6454258329069039
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.5317855184513891
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.4114020992908391
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.944453000604567
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.08831410719847764
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.9407760212630685
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 1.0316119976439193
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.2304160950286113
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.4931388250187673
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.9758671079243995
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.3834499864199536
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.6999423231261185
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 1.149857973057793
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.9986529000291111
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.6463979603583302
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.6627622996947045
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.414304105368846
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -1.0790151859616015
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.9633806284754163
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.8409295263079201
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.23613236896731113
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.8090424837946382
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.2898854869259236
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 1.0404123877973637
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.8697424772967268
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.39311226351015377
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.3355232985017897
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 1.146042921647442
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 1.2166269688060893
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.2217874726908434
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.855753490449096
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.5666379207977074
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -1.1424576905185977
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.10703064560163253
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.44589423481145146
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.5732880826298815
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.31292248488167124
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.8195455086673757
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.46900449819823126
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.4443454219024842
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.06331207717498308
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.04912900227532258
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.6487377647839343
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.45507425275760094
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.7786883079777341
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.053401174091402284
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.8395751488802042
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.4264595922041125
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.5677171838809882
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.18822903026790874
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.09148565348195634
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.1989451790366973
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.6858978420037559
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.08477975126606757
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.6517623886698797
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 1.0649536769315096
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.052848058149393674
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.12082263118338141
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.44232847883620935
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.698699656813351
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.23369985164522264
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.40642583537243265
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.6229632794216116
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 1.115518947093727
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.6345766074334351
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.586870939536863
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.5069605364799061
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.9531732360998972
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.8358314326813421
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.21742799227706808
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.4962892954245078
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.1308443909757098
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.7710239263613202
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.40960349852094696
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.7863157547754938
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.4967100046214374
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.1977258682790098
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.5208604334282936
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.19284457516913614
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.5118014559584643
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -1.196436883331009
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.21732298940950426
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.1957197272910313
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.7456515069680716
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.2631722162601164
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -1.1521423521849272
---------------------------------------------------------

Hidden units: 7
Epochs: 1000
Learning rate: 0.5

Errors during training:
Error at epoch 1 is 75.02752683423928
Train mean error at (after) epoch 1: 0.1875688170855982
Test error at (after) epoch 1: 0.15476596617251784
----------
Error at epoch 100 is 5.532201044373183
Train mean error at (after) epoch 100: 0.013830502610932958
Test error at (after) epoch 100: 0.017443744326273304
----------
Error at epoch 200 is 2.949186362618301
Train mean error at (after) epoch 200: 0.007372965906545752
Test error at (after) epoch 200: 0.008696021149699123
----------
Error at epoch 300 is 2.3436466290489637
Train mean error at (after) epoch 300: 0.005859116572622409
Test error at (after) epoch 300: 0.006325616719401916
----------
Error at epoch 400 is 2.1313697908787916
Train mean error at (after) epoch 400: 0.005328424477196979
Test error at (after) epoch 400: 0.005491770569854955
----------
Error at epoch 500 is 1.9783889488333495
Train mean error at (after) epoch 500: 0.0049459723720833735
Test error at (after) epoch 500: 0.005003164687831371
----------
Error at epoch 600 is 1.844257996511552
Train mean error at (after) epoch 600: 0.00461064499127888
Test error at (after) epoch 600: 0.004625391932607958
----------
Error at epoch 700 is 1.724204629733434
Train mean error at (after) epoch 700: 0.0043105115743335845
Test error at (after) epoch 700: 0.004305633761325321
----------
Error at epoch 800 is 1.6160623630409474
Train mean error at (after) epoch 800: 0.004040155907602368
Test error at (after) epoch 800: 0.0040269859849287985
----------
Error at epoch 900 is 1.5181482769513808
Train mean error at (after) epoch 900: 0.003795370692378452
Test error at (after) epoch 900: 0.0037813500136393186
----------
Error at epoch 1000 is 1.429197258331762
Train mean error at (after) epoch 1000: 0.003572993145829405
Test error at (after) epoch 1000: 0.0035634482587717587
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.612121456994281
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.7774292830375373
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.7904697849303741
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.45803670586206907
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.8187678581729053
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.8691227834148615
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.8129060070693419
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.8745201038593439
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.09585266114904012
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.5836034710745418
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.8493485813669233
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.07774218027211585
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.5754323201557868
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.8686949725122967
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.8184139783725086
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.6973258392856125
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.5815177003643945
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.8773662929096181
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.12403916963959671
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.8835173404417406
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.7905396549475078
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.3513787439074475
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.7319531395421688
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.8531770172458946
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.510995344575356
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.8162645874721067
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 0.734339718553847
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.8353313911468134
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.767804480996234
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.8123441811357331
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.5770908108299853
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -0.7775345176761586
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.8688603911139151
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.9085574638920636
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.3824820457851521
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.9465041028764579
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.4176872553551851
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.8146051643561367
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.8627162933155147
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.558092468255421
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.5294624928002689
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 0.6002054941318454
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 0.5213007892094916
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.3239764086582936
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.9012028269581204
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.7073507706345071
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -0.6369710682081127
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.15275419202219367
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.6190292285480142
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.6991133305271013
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.4321381238259924
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.8603125469178484
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.6332168882441479
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.6618528436682175
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.10249688161538878
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.09620534134477854
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.8222849623113396
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.60478431092121
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.9105761288189725
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.06539859544362933
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.8956444780826546
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.5816406434563044
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.7162389249794149
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.29227325440173846
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.12511852488014633
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.25626527886278966
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.8292247030235435
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.10390646854820024
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.8034783717515503
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 0.7587353200756105
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.07447640530752786
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.1585447479976864
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.5844502534545314
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.8454515612774905
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.368165124595457
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.5945470764268543
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.8123090886167984
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 0.723650226010492
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.870153681397797
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.7279886899816597
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.6960836392230824
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.9440264663598297
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.8662920629637156
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.3458482600106412
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.6873754614699651
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.18751256113723178
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.86342640619232
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.55239885487184
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.9309620211746009
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.6535436657152782
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.2795590655483779
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.6561973644565416
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.2748405718015495
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.6717560181832118
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -0.5206019379516076
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.32747288316374595
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.3124847664974755
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.8868115098648656
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.38701446224506797
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -0.641409561892888
---------------------------------------------------------

Hidden units: 7
Epochs: 3000
Learning rate: 0.5

Errors during training:
Error at epoch 1 is 112.55212083355353
Train mean error at (after) epoch 1: 0.2813803020838838
Test error at (after) epoch 1: 0.22577925499869386
----------
Error at epoch 300 is 2.807141916049791
Train mean error at (after) epoch 300: 0.007017854790124477
Test error at (after) epoch 300: 0.007989085422411724
----------
Error at epoch 600 is 1.9321391918793103
Train mean error at (after) epoch 600: 0.004830347979698276
Test error at (after) epoch 600: 0.005047309061867515
----------
Error at epoch 900 is 1.4945073877332977
Train mean error at (after) epoch 900: 0.003736268469333244
Test error at (after) epoch 900: 0.003903368404344792
----------
Error at epoch 1200 is 1.2151170816370975
Train mean error at (after) epoch 1200: 0.003037792704092744
Test error at (after) epoch 1200: 0.0032109664560891287
----------
Error at epoch 1500 is 1.0311636985989723
Train mean error at (after) epoch 1500: 0.0025779092464974307
Test error at (after) epoch 1500: 0.0027627865683891263
----------
Error at epoch 1800 is 1.1218687062932653
Train mean error at (after) epoch 1800: 0.0028046717657331634
Test error at (after) epoch 1800: 0.0030066087335694556
----------
Error at epoch 2100 is 0.9747366307767659
Train mean error at (after) epoch 2100: 0.0024368415769419147
Test error at (after) epoch 2100: 0.002651466639938253
----------
Error at epoch 2400 is 1.0668846608356624
Train mean error at (after) epoch 2400: 0.0026672116520891557
Test error at (after) epoch 2400: 0.0028961816636928405
----------
Error at epoch 2700 is 0.9450604125278296
Train mean error at (after) epoch 2700: 0.002362651031319574
Test error at (after) epoch 2700: 0.002609989121661071
----------
Error at epoch 3000 is 1.0221516674313254
Train mean error at (after) epoch 3000: 0.002555379168578313
Test error at (after) epoch 3000: 0.0028064940929896955
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.5965567192804054
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.7910206264583682
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.8403524287987623
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.4527289477439803
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.8255903351144581
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.8071559198343675
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.7791988675706525
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.8651450960302866
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.09785552249397121
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.48932480074057016
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.9251881735819523
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.08327948186047003
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.592977496369572
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.8568160385502479
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.8043356121954688
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.6760848820814412
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.5704238512078469
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.8923026988969136
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.13228672455716095
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.8367593467044583
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.7794993423674675
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.3422444327555108
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.6778617985493736
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.8592677233654062
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.5164064323477349
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.8112443416787536
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 0.6833887140239019
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.8358760476757942
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.7851968940425151
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.8123219130456304
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.5540951203793185
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -0.7685060842492575
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.9258118658227774
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.9304705602011938
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.40824940404270554
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.9016552815249337
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.41702665302897685
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.8340661995499543
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.884317517890864
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.5910200411550931
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.512572393441976
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 0.5788611429887959
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 0.4461554386195975
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.2881002658081283
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.9601047968826109
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.7388911567298769
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -0.6128987336232857
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.14330997235789372
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.6540394215881663
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.7507204974286072
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.45065831898571096
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.8676144334951454
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.6355537842837827
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.6039442264644309
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.11780045527615467
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.10589585764184808
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.8441827818553455
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.5955859304977001
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.9619363686165876
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.04807424189001605
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.8912433600821741
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.6012992750088848
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.742789552483109
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.28403609078780634
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.13474444117964562
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.2706222051780833
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.8336383643994387
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.09912567885617472
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.8068260146472452
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 0.7429518198516087
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.047636043274948185
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.15355558845787337
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.5787077418438583
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.9019912118205267
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.3683236254646346
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.5510719483334431
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.8649568434107354
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 0.7141751032897969
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.8941922494071204
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.7268758945676943
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.6948236733659034
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.945349313057954
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.9271310629929346
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.3220042233698543
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.7021791311202193
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.19457090558238205
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.9233209318447326
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.5376169640974083
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.9768853866681981
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.6963788346093241
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.2786813024867392
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.6809730823668637
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.27152222333021236
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.6489780100622994
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -0.48205377591813164
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.32989160988027005
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.30821296458564384
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.895824842346318
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.4098666388201673
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -0.6082164667621394
---------------------------------------------------------

Hidden units: 7
Epochs: 10000
Learning rate: 0.5

Errors during training:
Error at epoch 1 is 93.51510923740126
Train mean error at (after) epoch 1: 0.23378777309350315
Test error at (after) epoch 1: 0.15376910158041107
----------
Error at epoch 1000 is 1.1931317686822673
Train mean error at (after) epoch 1000: 0.0029828294217056684
Test error at (after) epoch 1000: 0.00302752791968007
----------
Error at epoch 2000 is 0.8248564093654783
Train mean error at (after) epoch 2000: 0.002062141023413696
Test error at (after) epoch 2000: 0.0021316567406753782
----------
Error at epoch 3000 is 0.7684813193521595
Train mean error at (after) epoch 3000: 0.0019212032983803987
Test error at (after) epoch 3000: 0.0019641194498831623
----------
Error at epoch 4000 is 0.765550431848139
Train mean error at (after) epoch 4000: 0.0019138760796203475
Test error at (after) epoch 4000: 0.0019133371599129917
----------
Error at epoch 5000 is 0.6347436649343043
Train mean error at (after) epoch 5000: 0.0015868591623357609
Test error at (after) epoch 5000: 0.0015639449808515643
----------
Error at epoch 6000 is 0.6767722732781546
Train mean error at (after) epoch 6000: 0.0016919306831953865
Test error at (after) epoch 6000: 0.0016251078562376034
----------
Error at epoch 7000 is 0.7421245559406213
Train mean error at (after) epoch 7000: 0.0018553113898515533
Test error at (after) epoch 7000: 0.0017893203203492994
----------
Error at epoch 8000 is 0.6482198025949865
Train mean error at (after) epoch 8000: 0.001620549506487466
Test error at (after) epoch 8000: 0.0015239455735318467
----------
Error at epoch 9000 is 0.7161688921635704
Train mean error at (after) epoch 9000: 0.001790422230408926
Test error at (after) epoch 9000: 0.0016953341815313658
----------
Error at epoch 10000 is 0.6357856925837138
Train mean error at (after) epoch 10000: 0.0015894642314592843
Test error at (after) epoch 10000: 0.0014911852586372712
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.626324767172824
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.8186143202780314
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.8471929545504917
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.4229219287800946
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.8565820149567176
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.9242310536162444
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.7045717494268732
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.8959117708889364
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.098186640645365
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.4282719655804129
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.8635280232498187
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.055789422300068725
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.5796394021307303
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.8902451629104258
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.8339793966432324
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.6896745143294484
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.5775033903627366
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.9168615923051496
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.09594314067343696
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.9632239654043983
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.8403497963471211
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.23574863681485908
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.7025947785386603
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.9557003553764977
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.5307622731343488
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.8536163056040448
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 0.6641837919486016
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.9001418989844384
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.8110498495820931
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.8558609375109784
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.585659640131623
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -0.7767641512207396
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.9674927265802578
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.9252420371048334
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.3414413851092176
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.9352524253530382
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.4000734842927809
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.8656607364048373
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.9116668331507819
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.5617302773967806
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.5230069031753339
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 0.5061359753558535
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 0.34497153881477727
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.30725164043154013
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.9601473494441782
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.737354956265221
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -0.6022843559892302
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.14630907860873668
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.5793583999090705
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.7364502965586993
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.41051569886927886
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.9320375504558465
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.6325005795954949
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.6109457650598132
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.11174041692302006
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.09994761972989591
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.8301219387346084
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.6241392995069952
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.9787085252788813
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.05589552980246057
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.9151006917577976
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.5706090566861818
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.7368030882729206
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.2527236459220744
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.1268291942102705
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.2722309386098729
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.8635164475000262
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.10280110029532735
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.8318281705731952
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 0.7482105054338427
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.060401009254731575
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.15923924200067907
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.5993280888471028
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.888609248402461
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.2669994801171326
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.494963779952982
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.8585281919185784
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 0.6595994289479997
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.8441124673199537
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.7499953332459626
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.7134415327963077
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.9084182223556614
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.9249478219560049
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.31917722234628804
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.6762943657857595
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.18308183676947082
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.9330015187183721
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.5556792250154725
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.9631507295980258
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.6293810948224662
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.28943220654411417
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.685931103981206
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.28069125886252344
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.6482978678525659
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -0.39123861329902976
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.33409496930883964
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.25773790197109253
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.9017412656846373
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.3711830670950732
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -0.5497669219742359
---------------------------------------------------------

Hidden units: 7
Epochs: 100
Learning rate: 1

Errors during training:
Error at epoch 1 is 77.6564085702684
Train mean error at (after) epoch 1: 0.194141021425671
Test error at (after) epoch 1: 0.11978983660904989
----------
Error at epoch 10 is 15.217024608584596
Train mean error at (after) epoch 10: 0.03804256152146149
Test error at (after) epoch 10: 0.04739272153484027
----------
Error at epoch 20 is 13.952337978076747
Train mean error at (after) epoch 20: 0.03488084494519186
Test error at (after) epoch 20: 0.04348687691513571
----------
Error at epoch 30 is 12.58874271891776
Train mean error at (after) epoch 30: 0.031471856797294404
Test error at (after) epoch 30: 0.03925095095168016
----------
Error at epoch 40 is 11.136021700584791
Train mean error at (after) epoch 40: 0.02784005425146198
Test error at (after) epoch 40: 0.03469504939848719
----------
Error at epoch 50 is 9.64306325397485
Train mean error at (after) epoch 50: 0.024107658134937125
Test error at (after) epoch 50: 0.029980694657844257
----------
Error at epoch 60 is 8.181013973662864
Train mean error at (after) epoch 60: 0.02045253493415716
Test error at (after) epoch 60: 0.025342658666328476
----------
Error at epoch 70 is 6.825477380909122
Train mean error at (after) epoch 70: 0.017063693452272807
Test error at (after) epoch 70: 0.021027037286793133
----------
Error at epoch 80 is 5.634762949217295
Train mean error at (after) epoch 80: 0.014086907373043238
Test error at (after) epoch 80: 0.017221725450771243
----------
Error at epoch 90 is 4.638902247444563
Train mean error at (after) epoch 90: 0.011597255618611408
Test error at (after) epoch 90: 0.014023920719324736
----------
Error at epoch 100 is 3.841465938022
Train mean error at (after) epoch 100: 0.009603664845055
Test error at (after) epoch 100: 0.011447530767233781
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.5416758317859346
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.7376690494221406
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.7862340284283388
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.40961414816293484
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.7912977449046737
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.8883515299851787
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.6662724254091873
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.8389295231517938
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.08717288327640951
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.43625728214734155
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.7626803248491889
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.05308284116801267
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.49732668789917467
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.9560774956979637
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.752098388056041
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.6118582216394655
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.4933005504911556
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.9025246536215809
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.08473524641027758
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.9814487519624336
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.9646767069963403
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.2649351224762704
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.5935671216506884
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.9577207303287554
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.4634569619603565
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.7592000648054779
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 0.9093763609202942
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.9241869520501215
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.7304640472606118
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.773883859530034
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.5035767236352686
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -0.9351507351335747
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.9398619667845464
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.8694955607157807
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.30118635892956036
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.7947303480014564
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.3636577335289115
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.9419113839479931
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.8852169687079985
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.4811604034455551
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.45391460715415427
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 0.9328230750807297
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 0.876973322147886
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.2554702861755709
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.8576226395958455
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.6739511868685617
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -0.9462368242424821
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.12975247436936893
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.5466162921745535
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.6785710139709605
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.3826138687209573
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.8871889561242678
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.5515284071475202
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.5487231794727413
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.10501983529735943
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.09319899769609472
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.7420987523564068
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.5483483916101238
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.8034745446591541
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.04457800048191808
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.8772874637221156
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.4970881416021007
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.661283235549753
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.25958374453057187
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.10313872802882446
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.22804179898536617
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.7914108388826172
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.08854223628025365
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.7495795675164434
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 0.9477522665438121
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.08790883273426359
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.1386851868404369
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.5246266090486248
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.7884002678058668
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.28823108497217625
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.48115346881747495
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.7031782954306207
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 0.9311269032641397
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.7471650171532458
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.6759236008666288
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.6080835188086554
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.9216987557067017
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.8821246839254445
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.28335673489921814
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.611097497076203
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.1561754389948905
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.8420984266340692
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.49137467360021153
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.881457102923019
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.60870281800553
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.2442238389889609
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.6181886976395244
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.2425450870271497
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.5866927941942931
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -0.9007602269421285
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.28790014091541216
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.24931927348459645
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.829114452596202
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.3366651458357661
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -0.9264172779670313
---------------------------------------------------------

Hidden units: 7
Epochs: 1000
Learning rate: 1

Errors during training:
Error at epoch 1 is 83.76759507056397
Train mean error at (after) epoch 1: 0.20941898767640993
Test error at (after) epoch 1: 0.11426123629726785
----------
Error at epoch 100 is 3.551501428495555
Train mean error at (after) epoch 100: 0.008878753571238887
Test error at (after) epoch 100: 0.010727504272464806
----------
Error at epoch 200 is 2.214306119400877
Train mean error at (after) epoch 200: 0.005535765298502192
Test error at (after) epoch 200: 0.005899455840939365
----------
Error at epoch 300 is 1.8152902834385565
Train mean error at (after) epoch 300: 0.0045382257085963915
Test error at (after) epoch 300: 0.004789761037398098
----------
Error at epoch 400 is 2.146533561016299
Train mean error at (after) epoch 400: 0.005366333902540748
Test error at (after) epoch 400: 0.005581415352512584
----------
Error at epoch 500 is 1.7187580877390563
Train mean error at (after) epoch 500: 0.004296895219347641
Test error at (after) epoch 500: 0.004409353988190751
----------
Error at epoch 600 is 2.7704008805616445
Train mean error at (after) epoch 600: 0.006926002201404111
Test error at (after) epoch 600: 0.00786488877610587
----------
Error at epoch 700 is 1.7597379033043894
Train mean error at (after) epoch 700: 0.0043993447582609735
Test error at (after) epoch 700: 0.00456624350776993
----------
Error at epoch 800 is 1.4616982608657565
Train mean error at (after) epoch 800: 0.003654245652164391
Test error at (after) epoch 800: 0.003828543770436351
----------
Error at epoch 900 is 2.1901976123626423
Train mean error at (after) epoch 900: 0.005475494030906605
Test error at (after) epoch 900: 0.006136193387567641
----------
Error at epoch 1000 is 1.570184750040334
Train mean error at (after) epoch 1000: 0.003925461875100835
Test error at (after) epoch 1000: 0.004155996321679036
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.6165663681775659
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.7616253301385555
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.8225044489643397
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.4862009661420678
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.8051630036370291
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.7987007975443494
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.803364969354599
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.8612820651354198
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.10577417167880845
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.5354979921363104
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.9209324535351466
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.08350881768601454
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.6133987415862053
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.8300715252791072
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.8019510811999943
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.6816170859476876
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.5804061032775724
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.8945251095896647
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.14350950908022797
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.8042579497901026
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.7725571248671717
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.37466765688653153
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.6634843955454531
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.8636645305878217
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.5218597046415677
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.8029728644109405
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 0.7026973124390162
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.8562235887807036
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.7721101578143125
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.7967807011009326
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.5732173532254046
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -0.7622938480935041
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.9198254467431708
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.920915478756514
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.3884798434369475
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.8697028594188482
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.4323638768858861
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.8114243670892661
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.8510979185923444
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.5899827052669652
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.5591496445835534
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 0.6216362928122452
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 0.5354891442647243
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.3090472864783044
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.9341098777693188
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.7241759866423342
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -0.6581813276350318
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.1491360707532058
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.6386430081569652
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.750176461559848
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.4496882014159849
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.8539932494089024
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.6519754236244354
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.6301218161505725
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.11750493716327465
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.10241413884094806
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.8328197619944672
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.6080094708944376
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.9415912752682961
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.05515084839253258
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.8914626815929088
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.6312074520478805
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.7583781092924162
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.2837663605642546
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.1547812811389781
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.2706960223436392
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.8154813085881485
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.09983745314689213
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.8056945576953553
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 0.7887130181096199
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.06512185453349077
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.1595932715013448
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.5831202751955458
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.8884628562652017
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.3809249872160644
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.5833870972238089
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.855007936248012
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 0.7353231566896663
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.8674485158519006
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.7353056143519677
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.6685004069892787
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.9267006937178237
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.8988276823318377
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.33564718194057624
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.6982520402445016
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.21062649303600262
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.9126958229979406
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.5486772988374622
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.9583746105676978
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.6904930182183108
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.2920237348267204
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.6816915965200173
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.28720710037706787
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.6613594330844056
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -0.5691996581360996
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.34190562374717026
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.313731620673208
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.8793270529109004
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.4111372550661694
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -0.6545320787148147
---------------------------------------------------------

Hidden units: 7
Epochs: 3000
Learning rate: 1

Errors during training:
Error at epoch 1 is 88.2303298465843
Train mean error at (after) epoch 1: 0.22057582461646075
Test error at (after) epoch 1: 0.09183494067332056
----------
Error at epoch 300 is 1.881746504302707
Train mean error at (after) epoch 300: 0.0047043662607567675
Test error at (after) epoch 300: 0.004919769383806456
----------
Error at epoch 600 is 1.6362633146185481
Train mean error at (after) epoch 600: 0.0040906582865463705
Test error at (after) epoch 600: 0.004222083496850834
----------
Error at epoch 900 is 1.4543642682483875
Train mean error at (after) epoch 900: 0.003635910670620969
Test error at (after) epoch 900: 0.003771581974787209
----------
Error at epoch 1200 is 1.3207345608972711
Train mean error at (after) epoch 1200: 0.003301836402243178
Test error at (after) epoch 1200: 0.0034843693062647976
----------
Error at epoch 1500 is 46.43595876103988
Train mean error at (after) epoch 1500: 0.11608989690259969
Test error at (after) epoch 1500: 0.05555991221620401
----------
Error at epoch 1800 is 1.395538405973478
Train mean error at (after) epoch 1800: 0.0034888460149336948
Test error at (after) epoch 1800: 0.003664907954557605
----------
Error at epoch 2100 is 4.188472521454251
Train mean error at (after) epoch 2100: 0.010471181303635628
Test error at (after) epoch 2100: 0.008231576038569235
----------
Error at epoch 2400 is 1.309898101166892
Train mean error at (after) epoch 2400: 0.00327474525291723
Test error at (after) epoch 2400: 0.003434247205228815
----------
Error at epoch 2700 is 2.091929817315271
Train mean error at (after) epoch 2700: 0.005229824543288178
Test error at (after) epoch 2700: 0.0051776826611191875
----------
Error at epoch 3000 is 1.689001389270076
Train mean error at (after) epoch 3000: 0.00422250347317519
Test error at (after) epoch 3000: 0.004411574371107203
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.6701772847357519
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.7494097162982312
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.9238218672828196
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.5515378529790583
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.8614893285777159
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.7232083089280106
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.6106009552218717
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.9243921459614041
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.1684357430714729
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.5822705211669332
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.7544306173470382
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.11893842195074174
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.714818820341999
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.784839859779613
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.7660558715434778
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.706802678557261
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.6507718094287959
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.9761021039396985
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.1362096934933053
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.8475268834617842
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.7987837526912843
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.370372624593474
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.6330246767588628
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.8284172074648178
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.47742603594633326
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.8555174624444752
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 0.6996924476208095
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.8891102022434775
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.8330942465207062
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.8687493745509944
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.6306832692830927
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -0.6800542521953611
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.8814431090127558
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.9925589278025381
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.47274021723089177
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.9274512650530047
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.3654754289738342
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.8813416183073415
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.919574380944188
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.5403870012459334
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.45498284014007473
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 0.6221018424918581
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 0.49099364721727534
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.35182061629094785
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.9281126863340662
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.7823689046208746
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -0.5582925073567879
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.2014848777786727
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.6824011269269796
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.7091069897319808
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.479675328819679
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.8155982070966805
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.7029525105262752
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.561741725938228
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.19939961762825997
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.06064460013342392
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.87433431429894
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.5584908919541569
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.8975566896899332
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.09489638921955841
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.9579511306720644
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.5248842756104934
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.8214359828935542
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.387372152254492
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.20574318908865852
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.3303407662422384
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.7882181849437571
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.1558590923449062
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.768732944255102
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 0.8094783918204588
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.10769495663560978
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.21920662233537147
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.630410172064126
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 1.0001523838063076
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.2936225773374515
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.4955002642805714
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.7535971392098774
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 0.7416663047791942
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.8159357219121204
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.6958915821675227
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.6556817991018695
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.9682191618181923
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 1.0182473755991392
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.25032015829437054
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.6116569797786289
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.25295755691323185
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.8871227390683554
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.4987093774856599
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 1.0291200967349463
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.6122366248189386
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.35091318566168167
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.7377580920858481
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.2309957546743553
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.7364588464552229
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -0.45740668579618005
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.2559482715440242
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.20312971599864227
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.8584262994777503
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.36990005673595383
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -0.5488621122663491
---------------------------------------------------------

Hidden units: 7
Epochs: 10000
Learning rate: 1

Errors during training:
Error at epoch 1 is 65.98829648641204
Train mean error at (after) epoch 1: 0.1649707412160301
Test error at (after) epoch 1: 0.10930923900605935
----------
Error at epoch 1000 is 1.8795038209048005
Train mean error at (after) epoch 1000: 0.004698759552262001
Test error at (after) epoch 1000: 0.004839168335088758
----------
Error at epoch 2000 is 1.4417260026460141
Train mean error at (after) epoch 2000: 0.003604315006615035
Test error at (after) epoch 2000: 0.003876923364746036
----------
Error at epoch 3000 is 1.7716914533646826
Train mean error at (after) epoch 3000: 0.004429228633411706
Test error at (after) epoch 3000: 0.004776804312614188
----------
Error at epoch 4000 is 1.448759169604423
Train mean error at (after) epoch 4000: 0.0036218979240110576
Test error at (after) epoch 4000: 0.004050295282291256
----------
Error at epoch 5000 is 1.5479587693374293
Train mean error at (after) epoch 5000: 0.0038698969233435733
Test error at (after) epoch 5000: 0.004264269694820418
----------
Error at epoch 6000 is 1.615444960886364
Train mean error at (after) epoch 6000: 0.0040386124022159095
Test error at (after) epoch 6000: 0.0043823450644334926
----------
Error at epoch 7000 is 2.5177502336648288
Train mean error at (after) epoch 7000: 0.006294375584162072
Test error at (after) epoch 7000: 0.006015163634822765
----------
Error at epoch 8000 is 2.526333736670981
Train mean error at (after) epoch 8000: 0.006315834341677452
Test error at (after) epoch 8000: 0.006351419941578956
----------
Error at epoch 9000 is 2.6238815176553087
Train mean error at (after) epoch 9000: 0.006559703794138272
Test error at (after) epoch 9000: 0.006776413472483548
----------
Error at epoch 10000 is 2.485188887434142
Train mean error at (after) epoch 10000: 0.006212972218585355
Test error at (after) epoch 10000: 0.0065316264927419345
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.4937127040876887
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.8936701396895549
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.7888181061086813
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.40227974009957673
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.6927508870515688
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.9375514510484254
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.8157124689026379
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.762189458838509
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: -0.006565831268141344
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.4244867185055767
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.9062944419547275
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.005946890814066727
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.5371749030146901
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.8821353120715005
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.8892809883088789
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.5774057947159447
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.49000828575897
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.85536340719689
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.013657789143458568
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.8111954191392592
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.7141058720872765
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.2491616799365013
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.7709236498218409
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.9382902104024504
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.6074928707431434
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.6689125929788848
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 0.6269337570813552
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.8401279625982677
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.6856173021587305
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.7384525617612288
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.45738107195179584
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -0.7459104895073547
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -1.0080310135991473
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.8389014974252204
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.2694979351324869
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.863576018315111
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.50991874985011
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.7988090883229416
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.7676192230579671
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.5034721706177238
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.6071099684887267
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 0.5596792220218573
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 0.39110548553589225
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.18611326938269063
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -1.0170565386930124
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.6104571693195171
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -0.6540971926099538
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.0443745666976096
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.5278919400431475
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.8350400048161544
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.3471036545933533
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.8956141473500125
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.5446052438957726
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.712766307122252
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.03467560480892787
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.22307179549203615
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.8194303316477644
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.6481691394343322
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.9743567266712642
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: -0.06828411238333351
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.819928906189823
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.48596509391020565
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.673743308696789
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.18277190828316192
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.047464586602613504
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.19931310331139812
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.8909903605114994
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: -0.010113236517022027
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.8584450105815576
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 0.8163691952860516
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.19467948891775155
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.05424602798778089
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.4672980753484542
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.8430320824718135
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.4817525250931573
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.4352479925519262
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.8861822803167669
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 0.6484204869052014
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.8860747960870766
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.7716224147457278
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.7989973645354597
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -1.0361337529994252
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.9098875343322925
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.41226575380573655
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.8320852579856712
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.09024055401420782
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.9692985061221441
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.6073099021169037
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.8757336143817026
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.7507436789380434
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.1648252491860791
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.6011854203481248
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.37252739211404223
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.577814281805788
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -0.6071297916215682
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.3934715305200706
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.3938446887524732
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.991840835630713
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.3064010166972249
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -0.6137578204613908
=========================================================

---------------------------------------------------------

Hidden units: 10
Epochs: 100
Learning rate: 0.05

Errors during training:
Error at epoch 1 is 65.9592979362675
Train mean error at (after) epoch 1: 0.16489824484066876
Test error at (after) epoch 1: 0.14158513525332178
----------
Error at epoch 10 is 52.073044245245306
Train mean error at (after) epoch 10: 0.13018261061311326
Test error at (after) epoch 10: 0.11346274232083038
----------
Error at epoch 20 is 40.68771127834633
Train mean error at (after) epoch 20: 0.10171927819586582
Test error at (after) epoch 20: 0.0909316037450223
----------
Error at epoch 30 is 32.6062697944661
Train mean error at (after) epoch 30: 0.08151567448616526
Test error at (after) epoch 30: 0.07558809611641638
----------
Error at epoch 40 is 27.08357971221982
Train mean error at (after) epoch 40: 0.06770894928054955
Test error at (after) epoch 40: 0.06574212296407128
----------
Error at epoch 50 is 23.461810035836482
Train mean error at (after) epoch 50: 0.05865452508959121
Test error at (after) epoch 50: 0.05985427321822704
----------
Error at epoch 60 is 21.17249320808968
Train mean error at (after) epoch 60: 0.0529312330202242
Test error at (after) epoch 60: 0.056606121156933246
----------
Error at epoch 70 is 19.76517818507755
Train mean error at (after) epoch 70: 0.04941294546269387
Test error at (after) epoch 70: 0.05498235225045321
----------
Error at epoch 80 is 18.91347079765565
Train mean error at (after) epoch 80: 0.04728367699413912
Test error at (after) epoch 80: 0.05427763919690243
----------
Error at epoch 90 is 18.398003827573937
Train mean error at (after) epoch 90: 0.04599500956893485
Test error at (after) epoch 90: 0.0540445722440688
----------
Error at epoch 100 is 18.079780359183136
Train mean error at (after) epoch 100: 0.04519945089795784
Test error at (after) epoch 100: 0.05402166685082501
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.336664937436129
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.4986313337312355
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.5849696709316055
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.230155436854803
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.5694703793307028
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -1.0509758212779021
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.500605309516366
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.6626493991043176
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.03319276393556215
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.2571056424591221
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.5457408285474806
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.07278711296288098
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.2997183226361739
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.9030558487872815
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.513573100699083
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.4437927415512668
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.3106510986599307
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.8781528558580716
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.06290992121751063
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.9248778319920565
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 1.0504054456471617
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.13073822615805986
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.3561655861470902
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.8996177322241969
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.2940456132732385
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.5829320961261624
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 1.2135875848116953
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.9824102484756758
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.5450032148889289
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.5485150828064866
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.3090200054247894
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -1.10947312402918
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.9067541097705445
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.6906622875184125
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.17566190556066621
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.6425287192677769
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.19618412244169992
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 1.045349810857845
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.789855278618678
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.23675323113492444
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.22640657027549457
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 1.3176995440892707
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 1.435716213672186
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.1455896526358121
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.6973834104971719
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.45059705376010545
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -1.25616036504403
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.10652999373065065
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.3197923625011651
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.441095555933917
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.24593066973171795
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.7009266562267205
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.3281944904243285
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.3196921695436641
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.05871114798172896
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.047437585208658366
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.48924187397866
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.3466739708000671
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.5586842936485408
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.02099817612707123
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.7447591331203613
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.33535134529879035
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.42208187197121
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.11419530923963446
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.040606190001840646
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.14373172708986373
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.5673807586969798
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.05238988545462421
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.5268462992550162
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 1.134912306155357
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.038436243557900214
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.08196374208601646
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.36156520677509985
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.5313421562770528
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.11591758006288937
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.35105548069314324
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.4067738993562562
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 1.1649876231409237
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.4405901635059541
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.45836843915139563
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.37657134775897366
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.8654873949040455
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.7428033396469351
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.18647316634327546
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.3438480827755456
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.08191481724030736
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.6333497082558257
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.3201849957409813
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.6073682108637362
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.35816327364306355
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.13857022850761078
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.42297735980966095
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.12362993191087585
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.40163682463562583
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -1.4441683395737386
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.1314254976185139
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.09492665163390418
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.6135159162707652
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.1272703433632701
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -1.2742942805958253
---------------------------------------------------------

Hidden units: 10
Epochs: 1000
Learning rate: 0.05

Errors during training:
Error at epoch 1 is 87.37793346747357
Train mean error at (after) epoch 1: 0.21844483366868392
Test error at (after) epoch 1: 0.1888969392420218
----------
Error at epoch 100 is 19.927969348703318
Train mean error at (after) epoch 100: 0.04981992337175829
Test error at (after) epoch 100: 0.05522916345307661
----------
Error at epoch 200 is 17.279588421931216
Train mean error at (after) epoch 200: 0.04319897105482804
Test error at (after) epoch 200: 0.05335089154032073
----------
Error at epoch 300 is 16.54958546656522
Train mean error at (after) epoch 300: 0.04137396366641305
Test error at (after) epoch 300: 0.05147583313236493
----------
Error at epoch 400 is 15.763274244412836
Train mean error at (after) epoch 400: 0.03940818561103209
Test error at (after) epoch 400: 0.04916270252773877
----------
Error at epoch 500 is 14.920026226545703
Train mean error at (after) epoch 500: 0.037300065566364254
Test error at (after) epoch 500: 0.04665179944645525
----------
Error at epoch 600 is 14.032681770734747
Train mean error at (after) epoch 600: 0.03508170442683687
Test error at (after) epoch 600: 0.04398943803817028
----------
Error at epoch 700 is 13.117901083343742
Train mean error at (after) epoch 700: 0.032794752708359354
Test error at (after) epoch 700: 0.041224601395028745
----------
Error at epoch 800 is 12.194134366892426
Train mean error at (after) epoch 800: 0.030485335917231064
Test error at (after) epoch 800: 0.03841243479825698
----------
Error at epoch 900 is 11.279351201196468
Train mean error at (after) epoch 900: 0.02819837800299117
Test error at (after) epoch 900: 0.035607702815339926
----------
Error at epoch 1000 is 10.389042341039737
Train mean error at (after) epoch 1000: 0.02597260585259934
Test error at (after) epoch 1000: 0.03285858865590151
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.42488520523426254
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.6225058558021818
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.6977979871994281
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.3228935900124444
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.6973654866417079
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -1.0451753262020567
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.5681706546307408
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.7593077377258629
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.060329012827944055
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.31010654265892135
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.67955965071372
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.035589265104106836
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.3816460575146935
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.9901879165811738
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.638292099933162
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.5142222469741358
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.3966356638709307
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.9157645348762126
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.05664961900061646
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 1.0442145550408648
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 1.118313628792086
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.17925902022508203
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.4612735386407493
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -1.032679828465995
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.36802007797434105
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.6721278026285722
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 1.1542238547089791
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.9839285624309914
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.6377400573668762
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.6639136447863488
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.38973966401225735
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -1.0917012976377756
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.9646194604484504
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.826748962538784
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.20234307043774416
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.7477765238547877
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.2729570062148068
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 1.0591183580058798
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.8723985342847828
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.372148571182603
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.3260140269575892
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 1.2186396857401998
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 1.2543327653680354
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.18510051738728078
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.8156743073942004
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.5617125826336412
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -1.2399681309190835
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.10232551154726376
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.42486060207609067
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.5570059700004478
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.28974879235895223
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.8463420671325893
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.44035419754810606
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.41826081280715083
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.08212137050256363
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.0718299064371746
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.626650688003918
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.4376233621613953
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.7268751840002234
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.029901741633780884
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.8250431444170621
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.41425436381680825
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.5481040543192199
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.19958087837373564
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.06960696772976264
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.18609890617335442
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.6867671813123943
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.07223819745187443
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.6380279184443877
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 1.089985294265142
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.0786844023923084
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.10910923390182911
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.427294326128755
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.684907675818351
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.19818296947053068
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.3944001907453709
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.5876228979714813
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 1.1583234679721053
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.6137919056999881
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.5696666934539438
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.4879861704554551
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.9505937107282572
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.8502556583343532
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.22250625965459184
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.4802097595209308
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.11299473509574927
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.7607813401753418
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.3936282215350658
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.7842930327007096
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.4766175041802801
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.1837567111185455
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.5074526165119316
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.18200624396062598
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.4825943900231489
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -1.2502434933199735
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.2088551959804984
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.18674976473066793
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.7382633213145169
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.2613937715408846
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -1.2113666823975517
---------------------------------------------------------

Hidden units: 10
Epochs: 3000
Learning rate: 0.05

Errors during training:
Error at epoch 1 is 89.06909330334707
Train mean error at (after) epoch 1: 0.22267273325836767
Test error at (after) epoch 1: 0.2232369299956447
----------
Error at epoch 300 is 17.56187008208582
Train mean error at (after) epoch 300: 0.04390467520521455
Test error at (after) epoch 300: 0.05544373034696079
----------
Error at epoch 600 is 15.460369345057787
Train mean error at (after) epoch 600: 0.03865092336264447
Test error at (after) epoch 600: 0.04906999375973573
----------
Error at epoch 900 is 12.991248012936856
Train mean error at (after) epoch 900: 0.03247812003234214
Test error at (after) epoch 900: 0.041380010964123776
----------
Error at epoch 1200 is 10.447725614581854
Train mean error at (after) epoch 1200: 0.026119314036454636
Test error at (after) epoch 1200: 0.033324074695699896
----------
Error at epoch 1500 is 8.036655236712612
Train mean error at (after) epoch 1500: 0.02009163809178153
Test error at (after) epoch 1500: 0.025562699234668678
----------
Error at epoch 1800 is 5.877764250580038
Train mean error at (after) epoch 1800: 0.014694410626450095
Test error at (after) epoch 1800: 0.018510998878408024
----------
Error at epoch 2100 is 4.123088345231238
Train mean error at (after) epoch 2100: 0.010307720863078096
Test error at (after) epoch 2100: 0.012711004793129546
----------
Error at epoch 2400 is 2.8843498991141647
Train mean error at (after) epoch 2400: 0.007210874747785412
Test error at (after) epoch 2400: 0.00857393410293699
----------
Error at epoch 2700 is 2.124248483376902
Train mean error at (after) epoch 2700: 0.005310621208442255
Test error at (after) epoch 2700: 0.006011527452302492
----------
Error at epoch 3000 is 1.7027938659082305
Train mean error at (after) epoch 3000: 0.004256984664770576
Test error at (after) epoch 3000: 0.00458280775811645
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.5800792794862862
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.7440367828131119
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.826849994583153
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.4205665798145902
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.7748768249951131
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.8732504478463842
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.7587938339469761
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.8759854594867509
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.07673283785379693
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.509227845042587
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.8722810498871361
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.07954357571087256
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.5205134270149201
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.8709343569739033
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.7813912081424765
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.6480894887913632
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.5026011985039199
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.9717253981839936
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.122671171048462
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.834193640116106
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.7983753405477217
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.325502094059711
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.6489733351570209
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.8381427868526324
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.4892117370921487
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.7881316819873501
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 0.779644207197236
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.925508327141244
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.7531487070280255
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.7845679980556671
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.5416673546632057
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -0.8380507298016281
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.9305575601106804
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.8841339776631082
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.3525111715627001
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.8715974515517061
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.39567139953238994
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.8887209440549695
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.8792125570706268
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.5423822832534948
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.4904680976348273
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 0.7153039765280795
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 0.6249343800101609
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.3046287470380135
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.9593446642928186
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.6878716769826635
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -0.7002901777179567
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.1381076823517816
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.5807017723444462
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.7348760382735574
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.41787044146778624
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.8341396909068408
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.6051054827692098
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.5990648344109446
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.07222016965854823
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.0652064117528808
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.8239744706049177
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.5745409876506852
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.9446132095845934
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.07197295137241956
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.9280320189057236
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.5559020657598004
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.6991652239628127
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.2589729169344726
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.13700957777086425
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.238705943037664
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.8031091055574019
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.09902213368871389
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.7797931244870568
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 0.8621230582447013
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.04624787662349361
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.14741048217570696
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.5439065005372051
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.7890477620750992
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.34468905255041266
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.5274220688039551
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.8298722212622556
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 0.771126974422662
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.8129821119980774
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.6875310584303581
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.6424611184157286
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.9876642189690908
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.9244134126129727
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.29830641557506427
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.6613055406253154
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.18477245781812354
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.8778084928041953
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.5094487584905676
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.9357868884936161
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.6597164898546961
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.2604618413176182
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.6627812385997428
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.25583348826697183
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.6155705980328646
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -0.6343526063975015
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.31400862597005685
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.24643030462567284
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.8801522516294618
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.36231056564945713
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -0.7117428144431969
---------------------------------------------------------

Hidden units: 10
Epochs: 10000
Learning rate: 0.05

Errors during training:
Error at epoch 1 is 112.59432235381281
Train mean error at (after) epoch 1: 0.28148580588453204
Test error at (after) epoch 1: 0.24141407865170986
----------
Error at epoch 1000 is 7.1923231060383355
Train mean error at (after) epoch 1000: 0.01798080776509584
Test error at (after) epoch 1000: 0.022834525453470474
----------
Error at epoch 2000 is 2.5244382405522554
Train mean error at (after) epoch 2000: 0.006311095601380639
Test error at (after) epoch 2000: 0.007517007704184353
----------
Error at epoch 3000 is 1.40406016552908
Train mean error at (after) epoch 3000: 0.0035101504138227
Test error at (after) epoch 3000: 0.003777302437707224
----------
Error at epoch 4000 is 1.2187884612533397
Train mean error at (after) epoch 4000: 0.003046971153133349
Test error at (after) epoch 4000: 0.0031673094133937096
----------
Error at epoch 5000 is 1.121402236822751
Train mean error at (after) epoch 5000: 0.0028035055920568775
Test error at (after) epoch 5000: 0.002903187831199992
----------
Error at epoch 6000 is 1.0367257160642809
Train mean error at (after) epoch 6000: 0.0025918142901607023
Test error at (after) epoch 6000: 0.0026951743014398248
----------
Error at epoch 7000 is 0.9602802276944054
Train mean error at (after) epoch 7000: 0.0024007005692360133
Test error at (after) epoch 7000: 0.002511914103983799
----------
Error at epoch 8000 is 0.8921585957799172
Train mean error at (after) epoch 8000: 0.002230396489449793
Test error at (after) epoch 8000: 0.002349154230895337
----------
Error at epoch 9000 is 0.8327950135671485
Train mean error at (after) epoch 9000: 0.0020819875339178713
Test error at (after) epoch 9000: 0.002206820501862143
----------
Error at epoch 10000 is 0.7819227716985216
Train mean error at (after) epoch 10000: 0.001954806929246304
Test error at (after) epoch 10000: 0.002083635517504879
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.611946055271742
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.8161945638508934
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.8608769515883145
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.46440848473926644
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.836970668280184
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.8677827805594508
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.745950666385957
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.8787439636859206
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.08045151164366868
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.46299552266853716
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.8660785694745096
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.04815511493888486
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.601869209958423
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.8813721248334329
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.7956285790912121
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.6794948639737675
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.5401041995250595
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.9023461473556169
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.08479171103688285
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.8739361097223738
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.7884382502700652
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.26972449053057446
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.7032473350024867
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.8726570910912277
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.5340932470772319
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.834234418838653
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 0.6852099133637555
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.864227797901363
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.799730311179548
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.8373988147532797
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.5736197739283998
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -0.7774839556324965
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.927610267488362
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.9281438180403109
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.4270320285347191
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.9254004541583168
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.40372788483788824
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.8348412450681116
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.9014919783576366
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.5659523713990087
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.5147464304424498
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 0.5449291211288437
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 0.41002995288694843
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.3137423017821316
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.9448059016057704
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.7432214969579928
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -0.5946343124520016
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.14521744134888695
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.6396617089733309
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.7620471836631589
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.42232213756354176
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.8923868029141148
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.6425032686404257
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.5964707030249023
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.08262165102206555
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.08091767101180705
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.816464461928324
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.609929658195824
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.9727104565295942
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.07257877581262237
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.9030243798391275
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.5813513973674402
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.7545229589792358
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.2881656823180444
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.12683852182424837
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.2719575245272151
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.8614437361666384
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.11124818411596951
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.8288886535384085
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 0.7432516649991391
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.1105792235091812
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.16512356394357744
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.5868122594783474
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.9230449842418479
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.3032235550663225
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.5339165467164254
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.8597980871532767
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 0.6999391182380946
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.880736906137202
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.7419163726621341
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.7156631750276111
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.9369297801838102
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.9298107339749574
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.3035471014428278
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.6692568682471614
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.18237096702212452
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.9280340393885933
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.549823330164302
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.9846333019916022
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.6740173193289466
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.2798678453488749
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.6964943058375973
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.28201371368636663
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.6675621720065362
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -0.40917120523647244
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.3258594663026093
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.28797714569305066
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.8624801757586837
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.39800448107901343
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -0.5768493962894112
---------------------------------------------------------

Hidden units: 10
Epochs: 100
Learning rate: 0.1

Errors during training:
Error at epoch 1 is 98.25758495908845
Train mean error at (after) epoch 1: 0.24564396239772113
Test error at (after) epoch 1: 0.20619727576429617
----------
Error at epoch 10 is 57.00459082339252
Train mean error at (after) epoch 10: 0.1425114770584813
Test error at (after) epoch 10: 0.11800573986716463
----------
Error at epoch 20 is 34.42971839598588
Train mean error at (after) epoch 20: 0.0860742959899647
Test error at (after) epoch 20: 0.0737306945382411
----------
Error at epoch 30 is 23.899259487062494
Train mean error at (after) epoch 30: 0.059748148717656234
Test error at (after) epoch 30: 0.05639137238504408
----------
Error at epoch 40 is 19.337811560786154
Train mean error at (after) epoch 40: 0.04834452890196538
Test error at (after) epoch 40: 0.050751983357943044
----------
Error at epoch 50 is 17.42190672031337
Train mean error at (after) epoch 50: 0.04355476680078343
Test error at (after) epoch 50: 0.049300865415790866
----------
Error at epoch 60 is 16.576761603515244
Train mean error at (after) epoch 60: 0.04144190400878811
Test error at (after) epoch 60: 0.04903024507811343
----------
Error at epoch 70 is 16.151570559069935
Train mean error at (after) epoch 70: 0.04037892639767484
Test error at (after) epoch 70: 0.0489660536419239
----------
Error at epoch 80 is 15.893789050568998
Train mean error at (after) epoch 80: 0.0397344726264225
Test error at (after) epoch 80: 0.048858320851169194
----------
Error at epoch 90 is 15.705343862866412
Train mean error at (after) epoch 90: 0.03926335965716603
Test error at (after) epoch 90: 0.04867001275507775
----------
Error at epoch 100 is 15.546570097307892
Train mean error at (after) epoch 100: 0.038866425243269734
Test error at (after) epoch 100: 0.048413649826357305
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.3761533556647184
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.5615436359555434
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.6159802927473454
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.2682295226557441
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.6377376469382527
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -1.1310426052240736
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.4827982249136389
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.7100174316558793
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.031864602574966136
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.323087111166171
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.60009020692064
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.07704240046636893
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.331596190298407
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.9642663493541278
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.5779083520817119
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.43779483022502413
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.32075038915594317
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.9244188101403713
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.09501818647435437
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 1.0209555187309864
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 1.1368027920862602
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.21432930647788748
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.4252465869311731
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -1.0139108948150233
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.32237313069133805
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.6087425451993494
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 1.2469564513611158
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 1.0168007954282385
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.5647877908596576
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.6032588225371633
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.35114512320917074
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -1.1386008714275708
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.96157320856155
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.779603813495229
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.20003800086499868
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.6970355843079221
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.2537514306001428
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 1.0644234065710314
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.8152887190873934
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.297013073312513
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.26501049491942086
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 1.3386255484400358
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 1.45131701642983
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.1848377927610035
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.7818291211750347
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.5071107430220605
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -1.3275963702407672
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.09637539312005722
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.39700840987771524
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.4992953816509927
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.28313497915714264
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.7888635038853696
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.3664555321799528
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.3907242194481351
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.040228967356007395
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.031523387694195354
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.5571038693322243
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.3849189871266806
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.673276469839531
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.04741151108335237
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.79201678011018
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.3572868277286808
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.4816789529535658
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.12441327927201098
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.08449775553563892
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.16424699816192073
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.6238718055158919
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.0692044766426909
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.5758913136805909
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 1.1678092628232395
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.011369801069606786
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.09709988244902801
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.3679251460758192
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.6246472116182139
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.22075162370862092
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.3237828299288939
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.5042533592177031
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 1.232444768384006
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.5530440006562025
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.5044270738981026
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.4405829982925838
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.870760738640845
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.7670030491053564
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.16020370769871442
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.41415576991000635
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.11871593603408154
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.6999659986780896
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.3347460419699958
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.7288108245623353
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.44773219138594916
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.15846833629657495
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.4480727845189003
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.14410319252208367
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.410638746545206
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -1.4524024518870509
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.161642508630414
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.15708471411088443
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.6803799711128545
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.17680043519036362
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -1.327472880639812
---------------------------------------------------------

Hidden units: 10
Epochs: 1000
Learning rate: 0.1

Errors during training:
Error at epoch 1 is 98.01521827357975
Train mean error at (after) epoch 1: 0.24503804568394938
Test error at (after) epoch 1: 0.23413649402142908
----------
Error at epoch 100 is 17.366326034375735
Train mean error at (after) epoch 100: 0.043415815085939335
Test error at (after) epoch 100: 0.053783994339259254
----------
Error at epoch 200 is 16.12136173116578
Train mean error at (after) epoch 200: 0.040303404327914454
Test error at (after) epoch 200: 0.05070959420473328
----------
Error at epoch 300 is 14.734186128244565
Train mean error at (after) epoch 300: 0.03683546532061141
Test error at (after) epoch 300: 0.04655827275493034
----------
Error at epoch 400 is 13.039875617828267
Train mean error at (after) epoch 400: 0.03259968904457067
Test error at (after) epoch 400: 0.04137596505820069
----------
Error at epoch 500 is 11.091424332541031
Train mean error at (after) epoch 500: 0.027728560831352576
Test error at (after) epoch 500: 0.03532113802336715
----------
Error at epoch 600 is 9.060352712333753
Train mean error at (after) epoch 600: 0.02265088178083438
Test error at (after) epoch 600: 0.028917443188969716
----------
Error at epoch 700 is 7.173184239192734
Train mean error at (after) epoch 700: 0.017932960597981835
Test error at (after) epoch 700: 0.022879510006101552
----------
Error at epoch 800 is 5.603533022247401
Train mean error at (after) epoch 800: 0.014008832555618501
Test error at (after) epoch 800: 0.017775954823655404
----------
Error at epoch 900 is 4.414534378076158
Train mean error at (after) epoch 900: 0.011036335945190394
Test error at (after) epoch 900: 0.013839286306468978
----------
Error at epoch 1000 is 3.576154137678397
Train mean error at (after) epoch 1000: 0.008940385344195993
Test error at (after) epoch 1000: 0.011006616175932307
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.5279159830940465
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.7130755761478171
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.7933723365912896
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.4097102018529369
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.7410403654591518
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.9929954154144764
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.6915561355312654
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.785187308254993
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.06899702639742199
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.4696075572709534
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.792389102141657
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.07160928754334367
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.5006812061922697
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.8658915630787787
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.7010198077473415
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.6302978294979164
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.5025195564533054
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.8711453573571494
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.11878296555875457
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.8381095698195391
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.867079826415763
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.2979289326528416
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.611932045339818
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.8805127753726487
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.46802806256720647
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.7644336732371297
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 0.9481762040987519
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.8888162227307888
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.734421070814033
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.735830608087196
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.49883892137126135
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -0.9307132726568326
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.9127083548039794
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.8672243713009704
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.3125969940208636
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.8936376979311162
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.372914517994846
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.9515786087181413
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.889485349334856
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.482962161287537
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.4458299379979425
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 0.889209247984045
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 0.8811110333744534
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.28877874434541007
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.8828599421102971
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.6623392940427445
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -0.8812261576978982
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.1288779393026438
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.548274843550277
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.6882102406326503
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.3937763604878277
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.828196158011966
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.5562774439858909
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.5278625209928602
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.06516404685994641
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.054982567532726546
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.7272475792878363
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.5413128773266527
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.8826979415791198
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.07617486593954781
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.8212518841528431
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.4925535563445787
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.6634570940049908
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.24360110024789994
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.1283634990943188
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.23920325380541177
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.7555058580942839
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.10570486214062413
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.7229156648149963
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 0.8877142679456662
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.05574054128881532
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.14819504660940097
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.5286568863684387
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.7752949972480084
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.31222080057385676
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.47589124144589917
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.7604360329890388
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 0.9101387034124954
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.7553622094330984
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.6796149252643112
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.621999997129132
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.9892116160050168
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.9000978547162135
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.270861703180206
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.6069832043807181
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.17441393258513235
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.8337499310008061
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.501152882027523
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.8668170035880468
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.6087465305446418
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.24821126031416596
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.6285000759785976
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.24165107693180893
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.596632347368294
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -0.8620415293679471
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.2974012124559697
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.2494234253839054
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.7706898923556291
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.3468944396569176
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -0.8868019387867332
---------------------------------------------------------

Hidden units: 10
Epochs: 3000
Learning rate: 0.1

Errors during training:
Error at epoch 1 is 48.350137966565775
Train mean error at (after) epoch 1: 0.12087534491641444
Test error at (after) epoch 1: 0.11659200578875441
----------
Error at epoch 300 is 13.666025989112484
Train mean error at (after) epoch 300: 0.03416506497278121
Test error at (after) epoch 300: 0.042805675889008264
----------
Error at epoch 600 is 7.1645226606572985
Train mean error at (after) epoch 600: 0.017911306651643245
Test error at (after) epoch 600: 0.022279124031819753
----------
Error at epoch 900 is 3.489821468374255
Train mean error at (after) epoch 900: 0.008724553670935638
Test error at (after) epoch 900: 0.010226031083220875
----------
Error at epoch 1200 is 2.3563636218566337
Train mean error at (after) epoch 1200: 0.005890909054641584
Test error at (after) epoch 1200: 0.0062905892866485956
----------
Error at epoch 1500 is 2.0281383987044994
Train mean error at (after) epoch 1500: 0.005070345996761249
Test error at (after) epoch 1500: 0.005133535608651163
----------
Error at epoch 1800 is 1.86999693946708
Train mean error at (after) epoch 1800: 0.0046749923486677
Test error at (after) epoch 1800: 0.004645335055089783
----------
Error at epoch 2100 is 1.7488975566314648
Train mean error at (after) epoch 2100: 0.004372243891578662
Test error at (after) epoch 2100: 0.004320974561079729
----------
Error at epoch 2400 is 1.642492939525349
Train mean error at (after) epoch 2400: 0.004106232348813372
Test error at (after) epoch 2400: 0.004053641183211662
----------
Error at epoch 2700 is 1.5467661101470596
Train mean error at (after) epoch 2700: 0.003866915275367649
Test error at (after) epoch 2700: 0.003818718185813244
----------
Error at epoch 3000 is 1.4604244279536653
Train mean error at (after) epoch 3000: 0.0036510610698841633
Test error at (after) epoch 3000: 0.0036090378326285393
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.6304291848526307
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.7844839421266169
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.8360868095285992
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.4798219870043374
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.8263315482429493
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.8333728822245019
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.7572187392171266
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.8832143673728714
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.09931023922684817
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.5254259278806775
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.8679201005839408
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.059554726759532745
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.5699600410038324
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.855281787161082
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.8262278407717395
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.6841532316877933
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.5745448451919041
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.8948144866441161
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.11179335521816856
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.8345412354548556
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.7742446640266841
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.3554990022551433
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.6837255452367152
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.8404177612066577
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.5316559573643082
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.8306619786262149
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 0.7146995552808058
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.8513669838909069
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.786102469123772
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.8223219697006974
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.5875919549941544
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -0.7835826284443852
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.8789539892460471
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.8892238604960522
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.36755098004142345
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.9152970113773586
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.44220491424350744
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.821422015018999
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.8759038478987963
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.5706039010980647
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.5241929368880985
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 0.6211662417375209
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 0.5335300104080297
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.31842038243759185
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.9348019153035966
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.7310779406691439
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -0.6502702554364749
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.1438554112473368
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.6270768373871195
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.7604759997311011
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.4394894227153321
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.8682730193962694
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.6593016928991378
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.6512106363752186
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.10712658559027984
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.09862866460241336
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.8367814737568099
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.6304513840173916
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.950404740768001
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.06371750142987578
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.9016722834122597
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.5866544957370404
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.7523021098050467
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.3219664866075008
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.15648178704511845
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.2722230042028164
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.8365339730661382
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.110610286878063
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.8177696762160618
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 0.7619449271531101
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.09326039994961918
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.16687802541098906
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.5896319377208814
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.8315157686935605
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.39328851501816897
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.5409330576788172
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.8617590291746727
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 0.7197499213485635
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.8485705606255277
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.7465721886601442
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.6875915721800377
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.930500571703895
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.8980125891625726
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.34147435104001156
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.7068102416722395
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.20836379709087732
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.8898972743159415
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.5619892508378056
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.935423778136951
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.6894153691912022
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.2977858877312986
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.6910490916478887
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.2943906432051303
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.6782735971046677
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -0.5268736562817911
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.35256237012463526
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.28274143017483233
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.889989450875944
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.40046058251447886
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -0.6525173091320645
---------------------------------------------------------

Hidden units: 10
Epochs: 10000
Learning rate: 0.1

Errors during training:
Error at epoch 1 is 76.53785725600935
Train mean error at (after) epoch 1: 0.19134464314002336
Test error at (after) epoch 1: 0.17670391139263505
----------
Error at epoch 1000 is 3.4300006386568405
Train mean error at (after) epoch 1000: 0.0085750015966421
Test error at (after) epoch 1000: 0.010202329556460926
----------
Error at epoch 2000 is 1.4147977191336187
Train mean error at (after) epoch 2000: 0.003536994297834047
Test error at (after) epoch 2000: 0.003507307333211904
----------
Error at epoch 3000 is 1.2230190148867512
Train mean error at (after) epoch 3000: 0.003057547537216878
Test error at (after) epoch 3000: 0.0029905625074078596
----------
Error at epoch 4000 is 1.0856446726199764
Train mean error at (after) epoch 4000: 0.002714111681549941
Test error at (after) epoch 4000: 0.0026468726656334847
----------
Error at epoch 5000 is 0.972353682095189
Train mean error at (after) epoch 5000: 0.0024308842052379724
Test error at (after) epoch 5000: 0.002364997403561555
----------
Error at epoch 6000 is 0.8763378938902362
Train mean error at (after) epoch 6000: 0.0021908447347255906
Test error at (after) epoch 6000: 0.0021247893990104716
----------
Error at epoch 7000 is 0.7920003231676297
Train mean error at (after) epoch 7000: 0.001980000807919074
Test error at (after) epoch 7000: 0.0019104295060276683
----------
Error at epoch 8000 is 0.7150831782170433
Train mean error at (after) epoch 8000: 0.0017877079455426081
Test error at (after) epoch 8000: 0.001711487054977508
----------
Error at epoch 9000 is 0.6438606178902174
Train mean error at (after) epoch 9000: 0.0016096515447255435
Test error at (after) epoch 9000: 0.0015268965194592163
----------
Error at epoch 10000 is 0.5796861644779712
Train mean error at (after) epoch 10000: 0.001449215411194928
Test error at (after) epoch 10000: 0.0013627308343479075
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.6027887659999966
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.8077527378063579
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.8434241784024493
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.43182048945011947
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.8493720133431832
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.8515244275762608
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.7847138131264305
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.9029598923812908
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.09608373085057179
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.5402418215720932
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.9079960336730782
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.05564462606841495
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.5732012777342552
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.8953943578737181
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.8395387721678281
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.6896729726443381
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.5671412761401194
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.9467704241515826
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.09972872197490831
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.9204077076400172
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.8052758145249223
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.32164744649479304
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.6877746198834603
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.8894330706699949
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.5102874305702211
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.8424437212641216
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 0.6680615890688463
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.8894119176731823
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.8033780855511985
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.8342099357520767
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.5618420010572478
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -0.7719171186771911
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.9111455793599893
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.9191260853734116
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.364201305247113
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.9552865461169628
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.4119724493851606
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.849559709212146
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.916685358068445
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.5354706757661724
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.4999688978434336
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 0.5182226950050711
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 0.3571580282576807
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.2970336628866455
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.9695014329783447
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.7278299749509595
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -0.5859867323571243
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.14497827741661085
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.5982791459802225
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.7232666271061665
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.41452604600469656
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.9072973869311571
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.621362248347285
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.6547421666090022
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.11167441800949443
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.09721267690269852
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.8413049232336742
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.6059843386371743
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.9666921031634214
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.050638232281455496
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.934515281189852
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.5902253061144578
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.7215582963504377
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.2821885028585557
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.13498828794725437
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.2589996537590503
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.8460940051532392
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.09149662702840802
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.8100283245368455
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 0.7409399728863684
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.10357843003233633
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.14688887935679062
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.5887022451833096
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.8621677205717438
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.3499903341351875
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.5513553554390328
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.841054566643925
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 0.6796843568439397
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.7956368689932904
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.7345594699717541
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.6886892169409397
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.9616373745382587
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.9424639317443722
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.30349039518955157
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.7005874647154491
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.18691726991558752
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.8951212419113321
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.5452487814720387
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.9135971563640483
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.6474659645744891
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.2745745888443154
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.6663932935884249
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.26372772849006326
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.6703610892415099
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -0.34843521015399287
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.31942744969591247
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.25448219287236984
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.9264877631658235
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.3557857641156167
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -0.558034987496905
---------------------------------------------------------

Hidden units: 10
Epochs: 100
Learning rate: 0.3

Errors during training:
Error at epoch 1 is 60.362297575050526
Train mean error at (after) epoch 1: 0.15090574393762632
Test error at (after) epoch 1: 0.12573648632467138
----------
Error at epoch 10 is 21.76951959223859
Train mean error at (after) epoch 10: 0.05442379898059648
Test error at (after) epoch 10: 0.05505621503812672
----------
Error at epoch 20 is 16.67972694335915
Train mean error at (after) epoch 20: 0.041699317358397874
Test error at (after) epoch 20: 0.05105664378012936
----------
Error at epoch 30 is 16.11159798425209
Train mean error at (after) epoch 30: 0.04027899496063023
Test error at (after) epoch 30: 0.05057331479919803
----------
Error at epoch 40 is 15.66941423248781
Train mean error at (after) epoch 40: 0.039173535581219526
Test error at (after) epoch 40: 0.049389513576471804
----------
Error at epoch 50 is 15.21585994320694
Train mean error at (after) epoch 50: 0.03803964985801735
Test error at (after) epoch 50: 0.048034350826187344
----------
Error at epoch 60 is 14.748777278620189
Train mean error at (after) epoch 60: 0.036871943196550475
Test error at (after) epoch 60: 0.04661410350638425
----------
Error at epoch 70 is 14.269230352826236
Train mean error at (after) epoch 70: 0.03567307588206559
Test error at (after) epoch 70: 0.04514620575814293
----------
Error at epoch 80 is 13.778585749746236
Train mean error at (after) epoch 80: 0.03444646437436559
Test error at (after) epoch 80: 0.04363648526371696
----------
Error at epoch 90 is 13.278418539174913
Train mean error at (after) epoch 90: 0.03319604634793728
Test error at (after) epoch 90: 0.042089960812029155
----------
Error at epoch 100 is 12.770474773322611
Train mean error at (after) epoch 100: 0.03192618693330653
Test error at (after) epoch 100: 0.04051210478344362
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.39584697489636134
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.5775689078016472
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.6431697740053433
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.280631990616865
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.641839819121536
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -1.140391202852138
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.5105297010598022
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.7427002088669125
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.060454762039863476
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.3384541306041872
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.6319016964698541
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.06191869026542722
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.36505620515788173
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.961902430555216
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.5957043082519617
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.4796205514168508
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.37607783883005264
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.9640188023311399
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.08808946891339911
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.9767718813333868
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 1.0654572082042146
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.22565727762973894
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.4345346964949763
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.9498345047250881
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.3356687005602716
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.6576780764815267
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 1.2218290439749317
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 1.0572323180981782
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.6006542546840253
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.628964351120846
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.36201450897085163
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -1.1417586175807675
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -1.0136975352325375
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.788623803691934
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.2145810663703204
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.7546129534353323
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.2582984387660712
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 1.098527287719491
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.8552811366833468
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.33114347354306284
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.3221834670509788
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 1.2971184112173821
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 1.3553755750500889
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.17113302134893926
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.8299356955391208
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.5160957115681123
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -1.2207548325439492
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.0997618363865443
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.3975148462825502
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.5159477310454643
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.28251913979813176
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.7735768294542232
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.40998793305821335
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.3989055812784167
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.07649345863359333
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.06697631892994284
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.5981534156202505
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.40715331382359665
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.7336514125231486
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.01774606874584184
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.8295353899959761
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.35768315619839197
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.515326772687112
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.15260756580442963
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.0806528416343717
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.1569242166580219
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.6505482291026885
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.05219022724611365
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.6088422839579527
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 1.1852620578620747
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.019445250413313592
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.08793704812049323
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.39706960912768285
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.6188494535795075
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.22666991013656307
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.3392030763287619
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.5697046260625032
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 1.1625429668369311
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.572530153147862
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.5324649583867361
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.4527876860358039
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.9260136871985547
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.8088029233332925
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.21412175682441056
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.4455031121689082
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.1156279209302612
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.7513327501962065
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.36971379718713326
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.7766039032212414
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.44741677563166354
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.1693528443344409
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.47000982410463155
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.15798854152745107
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.4550277419891409
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -1.3806050142557051
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.19950948080309416
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.12555492061130982
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.7042660157027638
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.2104121191864954
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -1.2375436471964927
---------------------------------------------------------

Hidden units: 10
Epochs: 1000
Learning rate: 0.3

Errors during training:
Error at epoch 1 is 107.51071412466885
Train mean error at (after) epoch 1: 0.26877678531167215
Test error at (after) epoch 1: 0.22108977697137822
----------
Error at epoch 100 is 10.977012180973277
Train mean error at (after) epoch 100: 0.027442530452433195
Test error at (after) epoch 100: 0.03472989578004029
----------
Error at epoch 200 is 6.120567681557533
Train mean error at (after) epoch 200: 0.015301419203893834
Test error at (after) epoch 200: 0.01923142684440924
----------
Error at epoch 300 is 3.5511472228123493
Train mean error at (after) epoch 300: 0.008877868057030874
Test error at (after) epoch 300: 0.010696442135623214
----------
Error at epoch 400 is 2.5353462805924205
Train mean error at (after) epoch 400: 0.0063383657014810515
Test error at (after) epoch 400: 0.007150248644539003
----------
Error at epoch 500 is 2.175427746307186
Train mean error at (after) epoch 500: 0.005438569365767964
Test error at (after) epoch 500: 0.005844819462722836
----------
Error at epoch 600 is 2.005447131150283
Train mean error at (after) epoch 600: 0.005013617827875707
Test error at (after) epoch 600: 0.005264168694457409
----------
Error at epoch 700 is 1.882471052220163
Train mean error at (after) epoch 700: 0.004706177630550408
Test error at (after) epoch 700: 0.004897150984931237
----------
Error at epoch 800 is 1.7750217512208541
Train mean error at (after) epoch 800: 0.004437554378052135
Test error at (after) epoch 800: 0.004605574829754357
----------
Error at epoch 900 is 1.6771637984101513
Train mean error at (after) epoch 900: 0.004192909496025379
Test error at (after) epoch 900: 0.00435188805796479
----------
Error at epoch 1000 is 1.5875310534303448
Train mean error at (after) epoch 1000: 0.003968827633575862
Test error at (after) epoch 1000: 0.0041240718358727625
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.618894815613913
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.8096031536378561
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.8499493585851163
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.47774304061404527
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.818833967317713
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.8360583552045476
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.7525136415372571
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.8574733486368948
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.0974253592937985
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.5396799265078671
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.8611644352529283
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.05064552391717596
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.5714603088607781
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.8644574385792074
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.8020221629369526
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.6887895660475789
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.570756003335006
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.8737108387128854
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.10580401232535991
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.8276531278506272
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.7676461216824385
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.3423417568122162
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.7183109759204667
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.8318020821403683
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.537675506661467
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.8226518501121175
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 0.7211732801309586
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.8433905638606688
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.7880377462436414
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.8217189086816616
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.5828687460966587
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -0.7874526835034219
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.8917922932766182
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.8933603274236946
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.36676817281139845
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.9148953561636578
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.43398349331121977
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.8196495313026672
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.8733215998080809
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.5604565463051239
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.5323466874154997
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 0.6366163751764401
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 0.5558798863642165
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.3246656463182038
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.9140227937426364
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.7347735218338455
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -0.6536770995092196
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.14418173141278973
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.6241322647380442
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.7637340750489592
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.43926930025782773
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.8626143284664999
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.6540008575517943
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.6366659207654124
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.0973965822652139
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.08869421422074224
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.8142891874859984
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.6245786140837667
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.9395924527421716
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.07182372235532712
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.8731154064627261
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.5782462231508093
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.7440168535823075
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.332923940546236
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.1476934540462804
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.2690272667319997
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.8465244391950758
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.11398426339374128
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.8162380246166795
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 0.7696363308034547
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.10899650058299876
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.16878762016414375
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.5913128871604155
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.8370690939884079
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.37096553065709087
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.5449381486474935
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.8511450553510441
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 0.7259142569782566
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.8739308115409387
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.7418621821052147
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.7197801175324744
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.92773914910413
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.9063898177728297
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.3384874991351215
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.6947154649207358
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.2021809631939173
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.8964229054343532
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.5596021942384805
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.9388668371979559
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.6859485887812208
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.29579191326792237
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.6993305682883283
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.2943496466591743
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.6769534819837341
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -0.5749648337177986
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.35494389402896387
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.292774799514691
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.8542647465745804
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.4145768757215237
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -0.6607674110933558
---------------------------------------------------------

Hidden units: 10
Epochs: 3000
Learning rate: 0.3

Errors during training:
Error at epoch 1 is 76.70979789722932
Train mean error at (after) epoch 1: 0.19177449474307331
Test error at (after) epoch 1: 0.17281518429301912
----------
Error at epoch 300 is 5.408060820530773
Train mean error at (after) epoch 300: 0.013520152051326933
Test error at (after) epoch 300: 0.016888967212096595
----------
Error at epoch 600 is 1.79959216109107
Train mean error at (after) epoch 600: 0.004498980402727675
Test error at (after) epoch 600: 0.00476575865938939
----------
Error at epoch 900 is 1.4524725218477903
Train mean error at (after) epoch 900: 0.0036311813046194757
Test error at (after) epoch 900: 0.0037210380046096107
----------
Error at epoch 1200 is 1.2176959548779038
Train mean error at (after) epoch 1200: 0.0030442398871947597
Test error at (after) epoch 1200: 0.0031105192669517484
----------
Error at epoch 1500 is 1.0407641054099916
Train mean error at (after) epoch 1500: 0.002601910263524979
Test error at (after) epoch 1500: 0.0026572914701950795
----------
Error at epoch 1800 is 0.9049531302300838
Train mean error at (after) epoch 1800: 0.0022623828255752096
Test error at (after) epoch 1800: 0.0023103043268625067
----------
Error at epoch 2100 is 0.7981130697806788
Train mean error at (after) epoch 2100: 0.001995282674451697
Test error at (after) epoch 2100: 0.0020367437936020987
----------
Error at epoch 2400 is 0.711597366109072
Train mean error at (after) epoch 2400: 0.00177899341527268
Test error at (after) epoch 2400: 0.0018140764454943632
----------
Error at epoch 2700 is 0.6394346287454147
Train mean error at (after) epoch 2700: 0.0015985865718635367
Test error at (after) epoch 2700: 0.0016272812093502062
----------
Error at epoch 3000 is 0.5776343858700657
Train mean error at (after) epoch 3000: 0.001444085964675164
Test error at (after) epoch 3000: 0.0014666054544748017
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.5915040797934206
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.7944831708477592
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.874263424813339
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.4431925929382514
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.8406288495364761
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.8240030393103632
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.7409564832234076
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.8869179788433859
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.09103497400023708
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.4676859386010289
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.9092312020810879
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.06845032726377409
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.5619900140077051
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.884196841005322
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.8343599870492614
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.6673794881294167
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.5527900093975066
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.9168346046204215
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.09616281107008703
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.8789641626020318
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.7978473184986264
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.3137483486679532
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.6630180735768464
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.8958342094506759
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.5070540482689125
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.8157128804633774
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 0.6692296275475388
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.8574641183967631
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.7898345428001968
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.8167696024649903
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.5462085778244767
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -0.7647159672637937
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.9352675502339155
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.9362146457722601
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.3498859936096198
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.9362500792665883
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.4227517693402184
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.8507102408138371
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.9052924098342475
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.5597678082527192
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.4909591714065642
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 0.5279231095034854
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 0.35379457779169166
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.2779432313332627
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.9715920249588555
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.7389379164105236
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -0.5842118658184746
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.1445718963972316
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.6207893989549059
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.7563203712859013
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.43397983764436265
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.9011846157389073
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.6255916910240629
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.6396592318373445
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.11038602265568093
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.1043591640372126
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.8502686221116799
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.5975027400673201
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.9770377799706947
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.04380241917909421
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.9170931753488842
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.5833320046135225
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.7346420440182153
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.3013463012285388
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.1458426683921554
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.2604684334377546
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.8400762195120178
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.09122820918978955
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.8084134567460717
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 0.7422926727495778
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.10297581135442986
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.1443789684900473
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.5694794218585603
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.8771697377167892
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.37306634709529085
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.5164686482754701
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.8621992606581875
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 0.6973458888662539
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.8631791332886651
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.7279156045332583
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.6825344849160505
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.9684837575719536
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.9634832371529908
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.29901337790737703
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.7074033623815766
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.19289041033619103
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.9288862054571364
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.5291588417789891
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.9835719879252897
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.6815128796905027
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.27123978003993554
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.6942938233400103
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.26462026875925226
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.6483418075418871
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -0.36455277833660904
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.3168433117733931
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.2708441236399495
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.9266933100628109
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.37977154132139335
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -0.566258095737696
---------------------------------------------------------

Hidden units: 10
Epochs: 10000
Learning rate: 0.3

Errors during training:
Error at epoch 1 is 118.94139022569901
Train mean error at (after) epoch 1: 0.2973534755642475
Test error at (after) epoch 1: 0.21140587566732416
----------
Error at epoch 1000 is 1.5311775233284899
Train mean error at (after) epoch 1000: 0.0038279438083212245
Test error at (after) epoch 1000: 0.004035266832649711
----------
Error at epoch 2000 is 1.0105058033377405
Train mean error at (after) epoch 2000: 0.0025262645083443513
Test error at (after) epoch 2000: 0.002733007534319356
----------
Error at epoch 3000 is 0.7575146004792547
Train mean error at (after) epoch 3000: 0.0018937865011981368
Test error at (after) epoch 3000: 0.0021088547158351857
----------
Error at epoch 4000 is 0.6144027201710648
Train mean error at (after) epoch 4000: 0.001536006800427662
Test error at (after) epoch 4000: 0.0017502569524121118
----------
Error at epoch 5000 is 0.5914461133082853
Train mean error at (after) epoch 5000: 0.0014786152832707133
Test error at (after) epoch 5000: 0.0016776066482589288
----------
Error at epoch 6000 is 0.5670806868098928
Train mean error at (after) epoch 6000: 0.0014177017170247319
Test error at (after) epoch 6000: 0.0016059762531167665
----------
Error at epoch 7000 is 0.5411816704742266
Train mean error at (after) epoch 7000: 0.0013529541761855665
Test error at (after) epoch 7000: 0.0015320815626125581
----------
Error at epoch 8000 is 0.5654759241580914
Train mean error at (after) epoch 8000: 0.0014136898103952287
Test error at (after) epoch 8000: 0.0015821371568034374
----------
Error at epoch 9000 is 2.596386687797495
Train mean error at (after) epoch 9000: 0.006490966719493737
Test error at (after) epoch 9000: 0.005765074434610055
----------
Error at epoch 10000 is 1.0579396135752948
Train mean error at (after) epoch 10000: 0.002644849033938237
Test error at (after) epoch 10000: 0.0029569237798156827
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.5393172429044977
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.8621191764587248
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.8072550524343989
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.39309141909912454
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.7770494268285306
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.8726742103903675
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.7928125149681053
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.8444858220273879
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.021317752324209155
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.4501712365544423
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.9511590817352236
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: -0.003385679058498292
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.5304775509811048
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.9276523879402276
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.8676240804567719
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.6079382920901057
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.5149799104157395
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.882295349029012
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.03672511075529408
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.8426986321234
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.7534666781133661
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.2675784617944949
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.729872128572874
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.907518481786302
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.5774095616385815
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.7710047912071696
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 0.6469702478628745
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.8274050247879883
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.7290540030111512
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.777791227450565
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.49506804708101965
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -0.8046290742569839
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.9732550428016533
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.8992802723599504
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.3375519232011514
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.8962617021783477
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.46285998626028957
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.8035556378375077
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.8586889895952052
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.5057202392666038
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.5577174654010331
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 0.4898663188671451
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 0.3172419477834941
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.2215613958660066
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -1.0089024873987216
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.6698921106884927
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -0.5953337821736238
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.06226625062404184
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.5631632828275086
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.813434126889168
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.3604211629136425
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.9281426477057064
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.5753179129540589
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.6785437355596502
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.058159572231256174
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.17198697913408442
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.7861245334150833
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.653978725081763
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -1.011956305489465
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: -0.01869514755057161
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.8798959350852633
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.5117424776302042
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.6874944450479752
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.21657465090824685
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.06762337330026699
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.20456155362433165
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.8992417925563219
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.03713401106816683
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.8673681789348404
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 0.7146633069980808
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.15933955541405403
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.09190943344698504
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.5035368614042957
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.8671817016282128
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.4276379047771321
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.4463607842980741
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.9028254193417671
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 0.6710743409141202
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.8930432666786392
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.777118970788677
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.7564228435785842
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -1.0189019926033847
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.8985635128219915
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.3855910661956979
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.7464043182211402
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.11425181189607309
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.9733576911461113
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.5907811242445218
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.9352715618713501
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.7406606645602942
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.20560135962387488
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.6215193514368653
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.34468501067927093
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.5968466549269515
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -0.38995886160198096
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.3826167746541234
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.3332407402853813
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.9550248842225249
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.3169380078430808
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -0.5855537711977303
---------------------------------------------------------

Hidden units: 10
Epochs: 100
Learning rate: 0.5

Errors during training:
Error at epoch 1 is 73.71171789359883
Train mean error at (after) epoch 1: 0.18427929473399707
Test error at (after) epoch 1: 0.15255205862954002
----------
Error at epoch 10 is 16.81441164515192
Train mean error at (after) epoch 10: 0.042036029112879805
Test error at (after) epoch 10: 0.04707704393207477
----------
Error at epoch 20 is 13.031007928022257
Train mean error at (after) epoch 20: 0.03257751982005564
Test error at (after) epoch 20: 0.040389079422349934
----------
Error at epoch 30 is 11.9239330864307
Train mean error at (after) epoch 30: 0.02980983271607675
Test error at (after) epoch 30: 0.037081048945313395
----------
Error at epoch 40 is 10.89901377983263
Train mean error at (after) epoch 40: 0.027247534449581577
Test error at (after) epoch 40: 0.03390431531313039
----------
Error at epoch 50 is 9.940388245951253
Train mean error at (after) epoch 50: 0.02485097061487813
Test error at (after) epoch 50: 0.030918053883832907
----------
Error at epoch 60 is 9.05382289740878
Train mean error at (after) epoch 60: 0.022634557243521952
Test error at (after) epoch 60: 0.028142782417227185
----------
Error at epoch 70 is 8.239098294258694
Train mean error at (after) epoch 70: 0.020597745735646735
Test error at (after) epoch 70: 0.025578383905202336
----------
Error at epoch 80 is 7.492043820784052
Train mean error at (after) epoch 80: 0.01873010955196013
Test error at (after) epoch 80: 0.023213076936030533
----------
Error at epoch 90 is 6.806811994344169
Train mean error at (after) epoch 90: 0.017017029985860424
Test error at (after) epoch 90: 0.02103038671278062
----------
Error at epoch 100 is 6.177617685235502
Train mean error at (after) epoch 100: 0.015444044213088754
Test error at (after) epoch 100: 0.019014360493354265
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.5017118173950534
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.6713469756479997
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.6971843658431387
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.36582042292908956
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.7321045525249059
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -1.0393873417684276
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.6017044581636389
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.8483707781047928
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.06325676636484912
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.4048576305675854
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.7015482748559922
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.07963053220066563
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.4435154428186997
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.9646852568156594
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.7197850933015104
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.5471441290374605
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.44220792700714995
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 1.0166884213425782
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.09549511831678349
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.9607500790046442
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.9896067698399873
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.2514168238102064
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.5534643876813286
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.9468251732990184
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.42183333262804035
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.7395674621959707
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 1.0112100200899767
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 1.0435661619704046
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.6631950543134026
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.7284427558409872
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.46470686844015296
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -1.0125504316032032
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -1.0033417706303522
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.8606859396210573
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.28644811783860874
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.8297707952095923
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.3295208501096961
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.9622247009697547
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.8491368844624576
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.40015313738653674
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.38312800350737636
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 1.0374584579946744
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 1.0446227874303833
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.23359673388685986
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.92191872514953
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.6019791574640759
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -1.0146817501598087
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.12592508833691382
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.4965554626697848
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.6194504674781046
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.3523105653990085
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.8340269552901213
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.5086752262478795
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.5052347739735964
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.08418657244163237
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.07564161929727006
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.7208666104225039
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.504185245245727
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.8485168401713574
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.0369860030796245
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.9228187014333769
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.44613049529739446
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.6273567029043909
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.21385224916664913
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.10087728209891036
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.21454811893926856
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.7505791289773225
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.08354017141405648
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.7200672906574032
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 1.0864871401680953
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.045735054182715444
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.12618183123143784
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.4692253631300595
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.7178052609721206
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.26832068508959334
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.4250983145927302
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.6910002523287473
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 1.0133382178271562
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.7167376042775482
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.6186365927909866
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.5626855329240106
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.8617012189185127
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.7976353434684726
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.27391052623881196
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.5552274090653675
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.14845516271349365
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.8330330673270955
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.4402156887707694
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.889174556422847
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.558006152859454
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.219023412932117
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.5532760103269447
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.20602935006857012
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.5521941167112683
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -1.0849534059880093
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.24564805340903428
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.156601827730042
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.829041854046904
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.2426016794195891
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -1.0425329637021037
---------------------------------------------------------

Hidden units: 10
Epochs: 1000
Learning rate: 0.5

Errors during training:
Error at epoch 1 is 86.62291107097747
Train mean error at (after) epoch 1: 0.21655727767744368
Test error at (after) epoch 1: 0.1644727927695986
----------
Error at epoch 100 is 12.008217429272403
Train mean error at (after) epoch 100: 0.030020543573181006
Test error at (after) epoch 100: 0.037929711434593984
----------
Error at epoch 200 is 3.6326212492411716
Train mean error at (after) epoch 200: 0.00908155312310293
Test error at (after) epoch 200: 0.011253713227015771
----------
Error at epoch 300 is 1.5372664105758498
Train mean error at (after) epoch 300: 0.0038431660264396247
Test error at (after) epoch 300: 0.004165241502260572
----------
Error at epoch 400 is 1.2923488418407942
Train mean error at (after) epoch 400: 0.0032308721046019856
Test error at (after) epoch 400: 0.003238329974014442
----------
Error at epoch 500 is 1.183677775048562
Train mean error at (after) epoch 500: 0.0029591944376214053
Test error at (after) epoch 500: 0.002901836004237536
----------
Error at epoch 600 is 1.0889696669987312
Train mean error at (after) epoch 600: 0.0027224241674968282
Test error at (after) epoch 600: 0.0026518165535005397
----------
Error at epoch 700 is 1.0004667388037565
Train mean error at (after) epoch 700: 0.002501166847009391
Test error at (after) epoch 700: 0.002431573787509906
----------
Error at epoch 800 is 0.9188683941221877
Train mean error at (after) epoch 800: 0.002297170985305469
Test error at (after) epoch 800: 0.0022349604544181514
----------
Error at epoch 900 is 0.8461470273528309
Train mean error at (after) epoch 900: 0.002115367568382077
Test error at (after) epoch 900: 0.002065197149160065
----------
Error at epoch 1000 is 0.7834014481885869
Train mean error at (after) epoch 1000: 0.0019585036204714675
Test error at (after) epoch 1000: 0.0019235960465675468
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.6094302378353562
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.8080628202340902
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.8280171105290888
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.47167402892917265
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.8554194945831576
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.8705577442364346
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.7557445732673111
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.8931966282876026
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.0995781935325734
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.4705556010158516
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.8889102933072212
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.0789832972691666
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.5746030105503712
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.8905145398135101
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.8158398630657759
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.6776459622565255
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.5504677976522946
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.9072884790832727
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.12544360280756134
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.9188560239636118
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.7984917011157587
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.29662617492545906
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.6715251330500804
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.8754343676526616
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.5243110245249957
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.8495102836805238
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 0.6933412697689263
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.8652803568914166
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.7968398069757546
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.8368204639429977
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.564377540987204
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -0.7867115223343882
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.9121899973077047
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.9162617428905523
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.3747869623314064
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.9364725912399121
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.4200191373524518
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.8504269253879057
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.9055051150949732
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.566171143508308
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.5291576184712411
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 0.5468019009478158
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 0.41390378480814916
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.28697547676822055
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.9456818379419922
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.7533745791026407
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -0.5889340482334897
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.14512375015630152
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.6473193417504077
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.7528734195839855
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.456519318307256
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.9066011841588849
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.6545739924479846
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.5930720530779305
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.10592910990527683
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.09478111998890239
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.8270792994383092
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.618604742176888
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.9581678877549186
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.05335277635185877
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.9149478585168821
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.5770463288782106
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.7547963407580304
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.28240755947025553
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.11558959771907394
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.2603426780028706
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.8520664246065003
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.09951199477144242
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.8232665048291915
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 0.7358907082437999
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.06315839226670202
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.15639165488769252
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.5892162169770606
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.8700311261957265
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.3211826341414228
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.548838062510886
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.8579338884936838
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 0.6836745460657677
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.8380971369586286
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.7472409816569884
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.6880555205977908
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.9288558082276225
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.9078075419824191
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.30032035579376226
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.6755621662074155
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.18404732069106766
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.9183563296354217
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.5501531603010178
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.9376851730495478
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.7225963109589697
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.28276601772163984
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.679250946568122
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.2801452765991983
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.6825975805738335
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -0.4093344852518077
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.3405207041797245
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.280342473080107
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.8869488086638596
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.40651633117398667
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -0.5837852541644476
---------------------------------------------------------

Hidden units: 10
Epochs: 3000
Learning rate: 0.5

Errors during training:
Error at epoch 1 is 74.14500607524097
Train mean error at (after) epoch 1: 0.18536251518810243
Test error at (after) epoch 1: 0.1564320282268545
----------
Error at epoch 300 is 1.8022656381186184
Train mean error at (after) epoch 300: 0.004505664095296546
Test error at (after) epoch 300: 0.004731411336958728
----------
Error at epoch 600 is 1.2522958410677838
Train mean error at (after) epoch 600: 0.0031307396026694595
Test error at (after) epoch 600: 0.003039723312341772
----------
Error at epoch 900 is 0.9725454139050843
Train mean error at (after) epoch 900: 0.002431363534762711
Test error at (after) epoch 900: 0.002309879869093502
----------
Error at epoch 1200 is 0.78250629495403
Train mean error at (after) epoch 1200: 0.001956265737385075
Test error at (after) epoch 1200: 0.001829904847599566
----------
Error at epoch 1500 is 0.65462573973272
Train mean error at (after) epoch 1500: 0.0016365643493317999
Test error at (after) epoch 1500: 0.0015221626164240822
----------
Error at epoch 1800 is 0.7086730746893837
Train mean error at (after) epoch 1800: 0.0017716826867234592
Test error at (after) epoch 1800: 0.0016528583978846706
----------
Error at epoch 2100 is 0.6082835172668599
Train mean error at (after) epoch 2100: 0.0015207087931671498
Test error at (after) epoch 2100: 0.0014186880197618783
----------
Error at epoch 2400 is 0.6707553730159564
Train mean error at (after) epoch 2400: 0.0016768884325398911
Test error at (after) epoch 2400: 0.0015666299506911438
----------
Error at epoch 2700 is 0.5828715898363359
Train mean error at (after) epoch 2700: 0.0014571789745908398
Test error at (after) epoch 2700: 0.0013629269902931548
----------
Error at epoch 3000 is 0.646699988203518
Train mean error at (after) epoch 3000: 0.001616749970508795
Test error at (after) epoch 3000: 0.0015100185648739286
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.6259692759072089
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.8026013379004061
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.8647604825533113
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.44990343335123534
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.8538564906106584
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.8921461964238607
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.7555824055676065
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.9096130596047243
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.09036504645638853
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.44049899290316236
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.9084112936846953
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.03469321336591012
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.5769982485795646
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.8947485033912387
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.8455634929436474
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.6943889765165049
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.5554051911973408
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.9319945462938286
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.07063132122263398
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.9321640470137279
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.8036447775782108
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.24840083191095208
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.6784927694528848
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.8865431430883618
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.5277015065446258
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.8460677054886576
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 0.6642424752949284
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.8746333661967354
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.8151117771042915
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.8465521019666715
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.582352085738098
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -0.7698211085109895
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.9059315639484081
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.9235749944782323
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.34313585316368983
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.9230256550632191
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.4242681525364176
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.843504080622073
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.9172256715681805
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.537016665834478
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.5066304350234072
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 0.5262952139865636
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 0.3660791472254002
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.31084056101244445
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.9663264542977185
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.7293932129612711
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -0.5867669148104661
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.15398459458691655
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.5814546091957759
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.7320449856485101
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.39017195224965956
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.9124259065671125
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.6185495996618039
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.6435850035500276
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.0979047642883336
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.08703040574172367
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.8598070377095255
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.6224492596977234
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.954462533227517
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.06426996892223132
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.9302842067849689
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.585829460308665
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.7496257628707269
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.27061907132619945
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.14484942662601935
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.2696899854831018
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.8571483321093026
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.10487998523171028
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.8241669397648518
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 0.7266780892268011
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.11674088709556636
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.15959158499555276
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.5989756026745922
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.8531611067075334
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.32660148362451
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.5211486121727704
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.821159894389952
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 0.6670049147142353
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.8422232535323838
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.7491665701107921
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.6857835529895394
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.9491668704351921
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.9499486364609365
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.31540221680093694
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.7229881857042263
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.1937467432944155
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.9136633774228032
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.5541061359840076
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.9513130560605475
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.626743456739944
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.2886734546842301
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.6885008241032491
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.26725176015814284
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.6539098248101799
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -0.3663669766507894
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.3290177967217132
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.24886127697704086
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.9204012828936631
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.3516609939212121
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -0.5582405842211515
---------------------------------------------------------

Hidden units: 10
Epochs: 10000
Learning rate: 0.5

Errors during training:
Error at epoch 1 is 120.64535797667142
Train mean error at (after) epoch 1: 0.30161339494167855
Test error at (after) epoch 1: 0.23482133564399083
----------
Error at epoch 1000 is 0.8494009350414933
Train mean error at (after) epoch 1000: 0.0021235023376037334
Test error at (after) epoch 1000: 0.002197779205408777
----------
Error at epoch 2000 is 0.6050026989358096
Train mean error at (after) epoch 2000: 0.001512506747339524
Test error at (after) epoch 2000: 0.0015712565199188365
----------
Error at epoch 3000 is 0.6137394834915311
Train mean error at (after) epoch 3000: 0.0015343487087288276
Test error at (after) epoch 3000: 0.0016084588750358505
----------
Error at epoch 4000 is 0.5136025052934342
Train mean error at (after) epoch 4000: 0.0012840062632335856
Test error at (after) epoch 4000: 0.0013670075762947874
----------
Error at epoch 5000 is 0.5534465701606488
Train mean error at (after) epoch 5000: 0.001383616425401622
Test error at (after) epoch 5000: 0.0014792193878488881
----------
Error at epoch 6000 is 0.484420618522241
Train mean error at (after) epoch 6000: 0.0012110515463056024
Test error at (after) epoch 6000: 0.0013162896380253114
----------
Error at epoch 7000 is 0.532874897221488
Train mean error at (after) epoch 7000: 0.0013321872430537198
Test error at (after) epoch 7000: 0.0014480807960316226
----------
Error at epoch 8000 is 0.47910473133275233
Train mean error at (after) epoch 8000: 0.0011977618283318808
Test error at (after) epoch 8000: 0.0013278853348655446
----------
Error at epoch 9000 is 0.5347533091533917
Train mean error at (after) epoch 9000: 0.0013368832728834793
Test error at (after) epoch 9000: 0.0014738834467035644
----------
Error at epoch 10000 is 0.482676657971699
Train mean error at (after) epoch 10000: 0.0012066916449292476
Test error at (after) epoch 10000: 0.0013572226522995834
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.6086787223182245
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.8002662705363875
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.8691771777591257
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.4094905231267709
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.8464921611050277
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.822072614402056
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.7463937320249886
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.9113567027998895
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.08485974051503678
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.48627040035393687
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.8612806872063947
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.0721125618101637
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.5228574583157994
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.8563999810944172
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.8389037366996777
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.6945308469603805
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.5737455922162394
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.98733066747493
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.10996811567953557
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.8455548807581623
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.7938725438646833
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.29377802025698585
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.6766555297739923
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.9551775420826898
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.5131229149319128
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.8446496620337308
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 0.6431555697984606
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.9690510823445295
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.8124424175798033
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.8380645143381296
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.5674928521356672
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -0.7554754280886065
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -1.010487523312205
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.9434867450596447
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.254858782278228
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.9490125216335563
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.4130403086981447
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.8537152372768773
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.9188115129496228
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.5131927315360311
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.4863039025349878
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 0.4995453575876181
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 0.30124807320504055
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.2973484866847934
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.994225094113556
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.7388187871508718
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -0.599821968645782
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.14681936912722857
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.5620625520831454
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.7291348188830444
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.42842816923222693
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.9242532484932876
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.606079868171477
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.6477205001401404
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.105952537531627
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.09256141632856205
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.8627727889447274
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.6085905105411146
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.9918857511022057
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.060302182998932224
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.9583386033703882
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.5495740314020715
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.7110299252599637
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.25816518816256817
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.14606499788386038
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.2630883321436429
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.8440968248178686
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.1058057349207048
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.8131333520189521
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 0.8614708929226482
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.08401768639976384
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.15659738170030044
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.5952067130893135
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.8425271082629171
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.33453143413482866
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.5143923340765079
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.8742677967547218
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 0.6851945476081507
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.7901383846145539
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.7414831685432397
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.6941545395078752
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.9782489271847636
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.9500237366946722
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.30021140711683947
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.7147768456862655
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.19879899541432564
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.9290648736494653
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.545671014714676
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.9766396652348512
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.6358380954350522
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.28305778827963823
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.6811334779511358
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.2572355348197486
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.6537950903109011
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -0.3905194533518449
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.32735005969023157
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.22380485011489618
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.9359962371241415
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.3207728226661378
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -0.5383068546840336
---------------------------------------------------------

Hidden units: 10
Epochs: 100
Learning rate: 1

Errors during training:
Error at epoch 1 is 90.75498258519846
Train mean error at (after) epoch 1: 0.22688745646299616
Test error at (after) epoch 1: 0.13753498621211876
----------
Error at epoch 10 is 14.847813381066548
Train mean error at (after) epoch 10: 0.037119533452666366
Test error at (after) epoch 10: 0.04560391915976408
----------
Error at epoch 20 is 12.25356942253019
Train mean error at (after) epoch 20: 0.030633923556325472
Test error at (after) epoch 20: 0.038109636255452405
----------
Error at epoch 30 is 9.767590775715526
Train mean error at (after) epoch 30: 0.024418976939288815
Test error at (after) epoch 30: 0.03043191174167136
----------
Error at epoch 40 is 7.631065604884026
Train mean error at (after) epoch 40: 0.019077664012210064
Test error at (after) epoch 40: 0.02379280386689296
----------
Error at epoch 50 is 5.942062099334005
Train mean error at (after) epoch 50: 0.014855155248335012
Test error at (after) epoch 50: 0.018482385917408247
----------
Error at epoch 60 is 4.671438152544664
Train mean error at (after) epoch 60: 0.011678595381361661
Test error at (after) epoch 60: 0.014424757104589434
----------
Error at epoch 70 is 3.7472855644428598
Train mean error at (after) epoch 70: 0.00936821391110715
Test error at (after) epoch 70: 0.011424326774006162
----------
Error at epoch 80 is 3.0955883270390987
Train mean error at (after) epoch 80: 0.007738970817597747
Test error at (after) epoch 80: 0.00927336005797097
----------
Error at epoch 90 is 2.6494581137157023
Train mean error at (after) epoch 90: 0.006623645284289255
Test error at (after) epoch 90: 0.007775368432770392
----------
Error at epoch 100 is 2.3507429029531433
Train mean error at (after) epoch 100: 0.005876857257382858
Test error at (after) epoch 100: 0.006753519350272619
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.5872934516925719
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.7302087952613388
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.8020085370309905
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.4552213411376383
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.7904445752284552
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.9161181577982879
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.7477422684392808
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.8216767952611501
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.07824005139289211
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.49017041819776397
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.8424016840657179
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.07406065212278128
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.5598661415788302
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.8390362947826694
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.7618143121364317
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.664757562283959
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.5445288224250828
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.8693744706198244
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.13023989072482967
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.8260698152069355
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.841243447462089
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.3430836211762186
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.621146500246189
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.8994955461588958
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.5093726151442194
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.8005611421649869
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 0.842464622475998
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.8516299786761077
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.7616125561178322
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.7571259171241992
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.5477616679204951
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -0.8592446216059465
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.8696530245635257
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.8903666210950315
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.3715635891105882
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.9055874710947005
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.4174676169691834
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.8735125953579029
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.8753988351764833
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.5598360930059957
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.4874186583148981
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 0.7462793759387153
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 0.7294849063264117
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.31729737422998666
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.9038329020179329
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.709029330591098
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -0.80216757425884
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.136785651708862
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.6199149539920238
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.7289202368558572
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.4280967602242881
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.8681014026386117
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.6223902531188702
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.5860141964278275
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.07966346981069108
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.06228184270515785
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.776823211773487
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.59445141281353
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.9103767922086036
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.08878780695968762
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.8452920283679398
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.5691150010538923
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.6999763105765471
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.2799340581492938
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.15005656035263387
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.2724114313898069
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.7776103390782035
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.12092064213605286
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.7620446403409536
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 0.7920830864225641
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.06337079575491689
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.17111629994557054
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.5705487227076345
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.854539033665146
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.3661304904087709
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.537327918157257
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.8087408038589184
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 0.8404927156219887
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.7546176396260649
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.7273822582705013
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.634812062102459
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.9393568424681916
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.8777963541649172
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.2782921847322316
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.6551477170927821
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.20027630596257243
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.8394591263270749
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.538694525659093
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.8272060349256356
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.6723755213009344
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.2832396410195602
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.6580490866610493
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.2796244258662865
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.6494463667948633
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -0.6956274855200931
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.3199164371290867
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.2994532692135925
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.8239645744983848
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.4022877501905563
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -0.7953270588292126
---------------------------------------------------------

Hidden units: 10
Epochs: 1000
Learning rate: 1

Errors during training:
Error at epoch 1 is 123.80915969688829
Train mean error at (after) epoch 1: 0.3095228992422207
Test error at (after) epoch 1: 0.17877793784986382
----------
Error at epoch 100 is 4.108699206692082
Train mean error at (after) epoch 100: 0.010271748016730205
Test error at (after) epoch 100: 0.012597972443750464
----------
Error at epoch 200 is 1.7924529544344665
Train mean error at (after) epoch 200: 0.004481132386086166
Test error at (after) epoch 200: 0.0046526978880700514
----------
Error at epoch 300 is 3.434663057201391
Train mean error at (after) epoch 300: 0.008586657643003478
Test error at (after) epoch 300: 0.009498861511252222
----------
Error at epoch 400 is 1.905653800733377
Train mean error at (after) epoch 400: 0.004764134501833443
Test error at (after) epoch 400: 0.004904964201359526
----------
Error at epoch 500 is 1.5080363051979233
Train mean error at (after) epoch 500: 0.003770090762994808
Test error at (after) epoch 500: 0.0038584956097593376
----------
Error at epoch 600 is 2.197904983078877
Train mean error at (after) epoch 600: 0.005494762457697192
Test error at (after) epoch 600: 0.006015722344867156
----------
Error at epoch 700 is 1.5947090450407941
Train mean error at (after) epoch 700: 0.003986772612601985
Test error at (after) epoch 700: 0.0040701382388212744
----------
Error at epoch 800 is 1.3046035782716672
Train mean error at (after) epoch 800: 0.003261508945679168
Test error at (after) epoch 800: 0.0033451394266780583
----------
Error at epoch 900 is 1.7593204934137743
Train mean error at (after) epoch 900: 0.004398301233534436
Test error at (after) epoch 900: 0.004604981812579171
----------
Error at epoch 1000 is 1.413750141353505
Train mean error at (after) epoch 1000: 0.0035343753533837625
Test error at (after) epoch 1000: 0.00361482621213334
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.6295133733073273
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.7734662917591631
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.7950890988403928
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.4746687455004907
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.8251554600480973
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.8463593477046983
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.791832357390374
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.878973518514237
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.0901602065673623
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.5121914531469007
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.8630377535295796
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.08454787951944313
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.595972852191876
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.8498840375991867
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.8177810977661245
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.6881205575049851
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.5876285465777872
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.8920194808346313
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.1277901725574624
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.8308016243557778
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.7799586696388138
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.34401249898074787
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.7003587992672529
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.8568571344865371
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.5326702093271243
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.8337085165897917
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 0.724878832392837
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.8607368253070652
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.7730715876508528
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.8066653934640766
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.5865505233189966
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -0.7835287341017301
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.9029125166983069
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.9068358790857975
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.4147919436219045
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.9559768713601722
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.4405780791653014
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.8214704726705885
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.8691829015097757
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.5840162985130981
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.5038250046894182
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 0.6093743740220982
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 0.5257652770072909
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.33000923708172225
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.9088314759490357
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.7294966021155824
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -0.6367313456630128
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.1497095451748686
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.6591106186047226
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.7438566893261993
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.4447629266304308
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.873183991304178
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.6560022414860689
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.6392251690015454
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.10240363105238447
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.08652720764988674
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.8283094256639496
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.626233456970692
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.9156630305313784
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.07931393995881621
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.9020421105022878
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.5649444921462501
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.7420330800087142
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.304062362918053
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.145355881575554
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.2725559608961318
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.8361333679904271
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.11875152947622615
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.823310034450615
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 0.7735587972795773
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.06175644085341852
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.17221381771003927
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.5893307207468529
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.8857444211346177
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.3824404200639447
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.5646138103790653
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.8205829886287955
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 0.7252076959784487
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.8808648061850415
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.7487845965728953
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.6917807507105674
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.9095183720429397
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.8549014113889783
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.3271865911999684
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.6918598921376768
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.20542493524456296
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.9016076089522184
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.561963997322578
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.9445089388043564
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.7015268788110073
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.2965212154273362
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.670430015316056
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.2879759634110589
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.6858761125622854
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -0.5262518048925741
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.3305987557459927
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.3110070263383745
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.8793332130196544
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.40060416386172426
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -0.6379451680111741
---------------------------------------------------------

Hidden units: 10
Epochs: 3000
Learning rate: 1

Errors during training:
Error at epoch 1 is 149.69836124226535
Train mean error at (after) epoch 1: 0.37424590310566336
Test error at (after) epoch 1: 0.18361488075498072
----------
Error at epoch 300 is 1.6731333419754302
Train mean error at (after) epoch 300: 0.0041828333549385754
Test error at (after) epoch 300: 0.004193930260879271
----------
Error at epoch 600 is 22.252257769706265
Train mean error at (after) epoch 600: 0.055630644424265664
Test error at (after) epoch 600: 0.11845910819976399
----------
Error at epoch 900 is 2.5095371981644563
Train mean error at (after) epoch 900: 0.006273842995411141
Test error at (after) epoch 900: 0.00686666962982917
----------
Error at epoch 1200 is 2.215146598473683
Train mean error at (after) epoch 1200: 0.005537866496184207
Test error at (after) epoch 1200: 0.005889062118490911
----------
Error at epoch 1500 is 2.0082547870561194
Train mean error at (after) epoch 1500: 0.005020636967640299
Test error at (after) epoch 1500: 0.005241820580067982
----------
Error at epoch 1800 is 1.8860045563994634
Train mean error at (after) epoch 1800: 0.004715011390998659
Test error at (after) epoch 1800: 0.004898489270413106
----------
Error at epoch 2100 is 1.7616409566818838
Train mean error at (after) epoch 2100: 0.0044041023917047095
Test error at (after) epoch 2100: 0.004588902042790695
----------
Error at epoch 2400 is 1.6711226971386164
Train mean error at (after) epoch 2400: 0.004177806742846541
Test error at (after) epoch 2400: 0.0043795498732865
----------
Error at epoch 2700 is 1.5867457071060953
Train mean error at (after) epoch 2700: 0.0039668642677652384
Test error at (after) epoch 2700: 0.0041910066760671265
----------
Error at epoch 3000 is 1.5039009059335675
Train mean error at (after) epoch 3000: 0.0037597522648339186
Test error at (after) epoch 3000: 0.004007514414970273
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.6113529789216772
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.7909219730021644
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.8321826908442018
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.46916226354494694
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.8053131121471031
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.8255912238941266
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.7845457824557261
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.8498127714719524
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.11400894639930009
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.5378614735191445
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.9338390266462524
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.0861868267298756
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.614042177831655
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.8376149693638295
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.8022082642057458
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.6809062811183514
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.58745332211991
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.8713111422491314
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.13097166026283358
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.8150752960041109
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.7605102727422958
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.3766457174571185
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.6731401063162791
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.8546008128663395
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.5234543896822933
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.7993272494732825
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 0.7000813629741475
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.8252775695430835
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.7770873442238808
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.8032678872365513
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.5685300993629386
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -0.7566093082564846
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.8958077786088245
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.9242392407605197
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.40536312748330183
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.9009490334203009
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.4397229536009989
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.8149703041205052
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.8530958293602092
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.5856959124621254
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.5576256766923768
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 0.6225317229701277
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 0.5214059409585148
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.3076648784478907
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.9234698515534342
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.7197562696245029
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -0.6393106684641133
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.14903777807985
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.6338682225738175
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.7314971287259033
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.45208632925457515
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.8556680544725732
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.6503277760789976
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.6377574208849778
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.1268595001193667
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.10730498821905708
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.8192195444770783
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.6089550506892041
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.9376077168469744
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.05760380388967558
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.8725704592012496
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.6481908678585372
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.7447164986631561
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.3029342678063781
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.15248578121298198
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.27348049854876766
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.8222984085461429
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.09388289012729684
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.797474244107451
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 0.762149438164663
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.0728043022318104
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.1527379568404814
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.583491957313319
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.871030405236389
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.40308020924983556
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.572549417051554
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.8367568299452272
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 0.7238636536003369
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.8502801036223057
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.7394302629963622
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.6907654678007299
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.9251001241084621
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.9180991684581041
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.3136376983977154
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.6952654945611368
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.20633908123633662
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.9002073905677594
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.5514668293155075
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.9503146977063369
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.6767673855082543
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.2898746269007699
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.6804699060275191
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.2853528342874858
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.656021719888904
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -0.5444977886374349
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.3381745149191371
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.3258526607614982
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.8689590063486378
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.40569406376843264
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -0.637858575723159
---------------------------------------------------------

Hidden units: 10
Epochs: 10000
Learning rate: 1

Errors during training:
Error at epoch 1 is 112.7427388917883
Train mean error at (after) epoch 1: 0.28185684722947074
Test error at (after) epoch 1: 0.14781592724715706
----------
Error at epoch 1000 is 1.6611984586670483
Train mean error at (after) epoch 1000: 0.004152996146667621
Test error at (after) epoch 1000: 0.004259999381200294
----------
Error at epoch 2000 is 1.9334628973984582
Train mean error at (after) epoch 2000: 0.004833657243496146
Test error at (after) epoch 2000: 0.004985466212487415
----------
Error at epoch 3000 is 1.417157945212404
Train mean error at (after) epoch 3000: 0.00354289486303101
Test error at (after) epoch 3000: 0.0035770623225402764
----------
Error at epoch 4000 is 1.656969202122205
Train mean error at (after) epoch 4000: 0.004142423005305513
Test error at (after) epoch 4000: 0.004219221288710531
----------
Error at epoch 5000 is 1.8259987937154252
Train mean error at (after) epoch 5000: 0.004564996984288563
Test error at (after) epoch 5000: 0.004810500489083644
----------
Error at epoch 6000 is 1.4247693829694916
Train mean error at (after) epoch 6000: 0.003561923457423729
Test error at (after) epoch 6000: 0.0036241263089997512
----------
Error at epoch 7000 is 1.3481909651010728
Train mean error at (after) epoch 7000: 0.003370477412752682
Test error at (after) epoch 7000: 0.003429006182089402
----------
Error at epoch 8000 is 1.6431719756230798
Train mean error at (after) epoch 8000: 0.004107929939057699
Test error at (after) epoch 8000: 0.004190895927099878
----------
Error at epoch 9000 is 3.1899563005215703
Train mean error at (after) epoch 9000: 0.007974890751303925
Test error at (after) epoch 9000: 0.007990171567460824
----------
Error at epoch 10000 is 2.49066768270359
Train mean error at (after) epoch 10000: 0.006226669206758974
Test error at (after) epoch 10000: 0.0063214259484486455
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.6731884720803114
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.723610595035517
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.8950358959134886
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.563825125995657
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.8291309512268401
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.8410933777490297
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.656080950291634
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.9099489008433415
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.2032688946227291
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.6374461626965661
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.7836419549602763
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.1900442650296008
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.6916677416057423
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.7569081329473522
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.7275048188590444
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.7370688117546343
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.6719222579312293
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.9542671650637601
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.2105847379520295
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.8972234967257469
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.8034306203774427
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.4076876824935741
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.5543737052190216
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.8251689648307565
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.4195875928410479
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.8263613921206079
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 0.7309324778943422
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.9221675823651465
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.8282476618172213
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.856175338024288
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.6276473873526149
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -0.6373989191476623
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.8719352158339791
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.9643287840644836
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.45986965450867817
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.9835406893776629
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.3256265439496204
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.8833518835796262
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.8885017700078907
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.6833965414472473
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.44029356987823076
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 0.6538741331661726
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 0.5030577692369678
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.36712165259572715
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.8920004553144028
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.7608933134159852
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -0.5496181323312439
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.22845073240966277
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.7082563823671725
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.6630892570284075
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.5278677511429164
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.766806072619332
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.708052956526178
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.5293218239525045
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.23547252136876276
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.03944640270741614
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.9592867414513289
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.4776874420336466
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.8745977427692294
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.11398426472635861
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.9557890931489909
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.6507960477535243
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.8256974383243704
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.36434334109998945
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.2287855220661651
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.3733216827765994
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.7282733668096824
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.1723686391663792
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.7095104384258534
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 0.8888204147055576
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.010590979339235362
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.23765000269401274
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.6394832074639892
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.9661852248345467
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.28249953924871596
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.6021318687692871
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.7523792963829029
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 0.7469472881746853
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.7435940047195524
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.6206073433828919
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.5800486983485679
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.9100571287100473
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 1.0089892646027108
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.24091816880408126
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.6827527712809736
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.2741575226987366
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.8345798332092403
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.4400694111832364
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.9945452436591674
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.5850825742436476
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.3610789352431512
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.7388054797490686
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.18650272797288417
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.735804331678078
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -0.4777031179158909
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.23310676947616085
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.16993827610312331
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.8586746357617046
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.48229270995156787
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -0.514232999215279
=========================================================

---------------------------------------------------------

Hidden units: 12
Epochs: 100
Learning rate: 0.05

Errors during training:
Error at epoch 1 is 59.971597199659364
Train mean error at (after) epoch 1: 0.1499289929991484
Test error at (after) epoch 1: 0.14455930189561322
----------
Error at epoch 10 is 51.00070174863782
Train mean error at (after) epoch 10: 0.12750175437159456
Test error at (after) epoch 10: 0.12337085783944866
----------
Error at epoch 20 is 42.74269746190271
Train mean error at (after) epoch 20: 0.10685674365475677
Test error at (after) epoch 20: 0.10416676618943749
----------
Error at epoch 30 is 36.0072555484537
Train mean error at (after) epoch 30: 0.09001813887113425
Test error at (after) epoch 30: 0.08884176005955118
----------
Error at epoch 40 is 30.61983688277176
Train mean error at (after) epoch 40: 0.0765495922069294
Test error at (after) epoch 40: 0.07690968569969893
----------
Error at epoch 50 is 26.42409453230376
Train mean error at (after) epoch 50: 0.0660602363307594
Test error at (after) epoch 50: 0.0679117857493443
----------
Error at epoch 60 is 23.248702293892514
Train mean error at (after) epoch 60: 0.05812175573473129
Test error at (after) epoch 60: 0.061357891172622823
----------
Error at epoch 70 is 20.909543692478156
Train mean error at (after) epoch 70: 0.05227385923119539
Test error at (after) epoch 70: 0.05674433037798243
----------
Error at epoch 80 is 19.225293939494904
Train mean error at (after) epoch 80: 0.04806323484873726
Test error at (after) epoch 80: 0.053596069979664235
----------
Error at epoch 90 is 18.032766361358775
Train mean error at (after) epoch 90: 0.045081915903396934
Test error at (after) epoch 90: 0.0515022676203216
----------
Error at epoch 100 is 17.196059788348308
Train mean error at (after) epoch 100: 0.04299014947087077
Test error at (after) epoch 100: 0.050133656522488544
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.3055605750819376
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.5362831136437192
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.6434973634059166
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.1547762716628562
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.5831067253469504
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.9946394199198585
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.42714815569748654
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.6152170678994919
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.016653643480334098
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.360579350367774
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.5341185353432589
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.17038947068525576
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.371394126738079
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.8674618972060093
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.49517594487558536
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.43482193733215885
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.2997500405385799
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.8133869885068681
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.1659544531229071
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.8846144703178748
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.994307268640338
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.27190826352714975
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.3943635129028794
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.8930924495942608
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.2908768064501339
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.5351318571112874
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 1.1462069250847435
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.9185193711577492
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.5476252899853216
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.5504426606912333
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.2973600643887759
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -1.0496388885159773
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.8691436094289062
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.6931820782489498
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.3095407386364071
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.5594436254706753
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.25626520818313414
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 1.005595073579585
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.7692080478365596
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.16139070004725745
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.2453184627098214
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 1.249107524259835
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 1.3349243865260043
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.14539134213193503
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.6620765622429364
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.5134343350388356
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -1.1828057164166978
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.15042295499790498
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.4336063687110758
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.5542687722303892
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.33570970306581227
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.7163734043634276
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.251054131593201
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.35011571176882955
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.04781412281550641
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.04231706633897613
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.4601495999794386
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.3377914681232256
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.5291701551296932
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: -0.001606929219636634
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.6878283261395355
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.3394507505854371
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.38183212888029483
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.008248704327874985
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.07888004956959968
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.1324958055833747
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.5634603063491457
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.022150955488165622
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.4985506151187996
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 1.0806688274034923
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: 0.10906760910593483
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.04890432420739048
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.3589846828685532
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.6293164737492194
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.2659664309487583
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.28928571933358277
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.3680434686834973
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 1.1040697444533876
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.42602098406983113
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.47860381318365985
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.4165340178346392
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.8649524440167861
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.7678806202501655
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.22011800440295384
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.3540732432549505
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.1223558713903825
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.6048723838227823
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.3302231012726295
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.6083842899927266
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.49653099271961726
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.12239128016836008
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.49513102055112584
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.0677829765264388
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.3210553062118899
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -1.360865967762717
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.11312846637746635
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: 0.010635242446454394
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.5763637713704765
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.03101312497656976
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -1.1927090917357073
---------------------------------------------------------

Hidden units: 12
Epochs: 1000
Learning rate: 0.05

Errors during training:
Error at epoch 1 is 81.77619798814472
Train mean error at (after) epoch 1: 0.2044404949703618
Test error at (after) epoch 1: 0.17902027186969885
----------
Error at epoch 100 is 16.643990389551913
Train mean error at (after) epoch 100: 0.04160997597387978
Test error at (after) epoch 100: 0.049443061641680386
----------
Error at epoch 200 is 14.912552637263547
Train mean error at (after) epoch 200: 0.037281381593158865
Test error at (after) epoch 200: 0.04725729071398002
----------
Error at epoch 300 is 13.565588907433902
Train mean error at (after) epoch 300: 0.03391397226858475
Test error at (after) epoch 300: 0.0432368651027834
----------
Error at epoch 400 is 12.178398714806333
Train mean error at (after) epoch 400: 0.03044599678701583
Test error at (after) epoch 400: 0.03892352240585736
----------
Error at epoch 500 is 10.802599406821573
Train mean error at (after) epoch 500: 0.02700649851705393
Test error at (after) epoch 500: 0.03460607098755664
----------
Error at epoch 600 is 9.490243173363403
Train mean error at (after) epoch 600: 0.02372560793340851
Test error at (after) epoch 600: 0.03045703311762057
----------
Error at epoch 700 is 8.28222974457083
Train mean error at (after) epoch 700: 0.020705574361427077
Test error at (after) epoch 700: 0.026608832857648302
----------
Error at epoch 800 is 7.203595402377484
Train mean error at (after) epoch 800: 0.01800898850594371
Test error at (after) epoch 800: 0.023144784312034226
----------
Error at epoch 900 is 6.264022008810079
Train mean error at (after) epoch 900: 0.015660055022025197
Test error at (after) epoch 900: 0.020100656474850445
----------
Error at epoch 1000 is 5.461462489458475
Train mean error at (after) epoch 1000: 0.013653656223646187
Test error at (after) epoch 1000: 0.017475541457633286
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.4957060431618292
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.6726641966663672
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.7541181316756953
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.3727482404774466
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.7378245040302698
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.9929698615154403
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.6415138171133217
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.7936316315640014
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.07861125218302567
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.4219133141779854
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.7177214058387542
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.0896016616628945
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.4735647638227687
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.926155155312704
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.692287347026523
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.5886064156906274
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.4777195646173986
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.8996663717146557
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.1071026645394002
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.9320008952327901
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.9693977690076113
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.268462545085901
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.5588571533022957
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.9475651723598625
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.42301992935619903
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.7322216985598112
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 1.022401710998813
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.9464665043882448
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.6932686503454042
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.7133379203219213
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.46286059703368104
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -0.9893828239802271
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.9457416451361055
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.8590109660844361
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.29107289030601013
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.8387066593470875
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.34661869028236025
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.978660977363439
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.8757368591394157
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.41914655372925363
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.41860108452066364
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 1.0233632067271023
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 1.0264170680425342
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.24915274818475094
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.8333489415422438
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.638862499286545
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -1.0162852750578721
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.1333053006340917
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.5297532392656664
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.6584833458643071
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.37610851133417195
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.849327026256892
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.49820891097160896
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.5048807341178139
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.08539734698524883
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.07433940797783203
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.6859558690949181
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.5064754193501279
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.7850929943196846
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.05171905659949707
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.8448057390182497
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.45056632062007407
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.618814328704884
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.21807107787463922
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.10133794474408236
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.20492168439844297
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.7360435890803253
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.08079796074080148
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.7015783659069809
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 0.9984537302034054
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.028898369897170442
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.12265196715601445
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.4927847859975311
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.7608689974443692
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.28694878662746715
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.447153467200867
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.6535127243933849
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 1.0025712883960125
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.7267211022223193
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.6508187860945379
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.5612959708524312
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.9503066219165321
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.8541968265078078
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.25915249019998643
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.5593445812584982
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.15082511911287266
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.8091273429865835
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.4710115525352288
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.8589537188166702
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.5926826391490718
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.22052936943734494
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.5950455586201364
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.20842576004244337
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.5499721015438788
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -1.035888661120039
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.2610990202538999
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.23779290424613836
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.7695919126161516
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.2663539044069456
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -1.0084373160176756
---------------------------------------------------------

Hidden units: 12
Epochs: 3000
Learning rate: 0.05

Errors during training:
Error at epoch 1 is 111.197048188946
Train mean error at (after) epoch 1: 0.277992620472365
Test error at (after) epoch 1: 0.2856804696854457
----------
Error at epoch 300 is 16.169337967332872
Train mean error at (after) epoch 300: 0.04042334491833218
Test error at (after) epoch 300: 0.05050725457427444
----------
Error at epoch 600 is 12.878595519232586
Train mean error at (after) epoch 600: 0.032196488798081464
Test error at (after) epoch 600: 0.04056611793903698
----------
Error at epoch 900 is 9.309303247435246
Train mean error at (after) epoch 900: 0.023273258118588113
Test error at (after) epoch 900: 0.029458036117825586
----------
Error at epoch 1200 is 6.387267470622073
Train mean error at (after) epoch 1200: 0.015968168676555185
Test error at (after) epoch 1200: 0.020153430566155203
----------
Error at epoch 1500 is 4.442527015236333
Train mean error at (after) epoch 1500: 0.011106317538090833
Test error at (after) epoch 1500: 0.013788899577381126
----------
Error at epoch 1800 is 3.288874572992509
Train mean error at (after) epoch 1800: 0.008222186432481272
Test error at (after) epoch 1800: 0.009894506157525702
----------
Error at epoch 2100 is 2.6395353986066614
Train mean error at (after) epoch 2100: 0.006598838496516653
Test error at (after) epoch 2100: 0.007634884632151184
----------
Error at epoch 2400 is 2.2767472746653263
Train mean error at (after) epoch 2400: 0.005691868186663316
Test error at (after) epoch 2400: 0.006340253850964027
----------
Error at epoch 2700 is 2.0659168063951716
Train mean error at (after) epoch 2700: 0.005164792015987929
Test error at (after) epoch 2700: 0.005578037603395591
----------
Error at epoch 3000 is 1.932508563811432
Train mean error at (after) epoch 3000: 0.00483127140952858
Test error at (after) epoch 3000: 0.005099627630818401
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.6193504859279487
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.7581789304150555
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.7675717263852038
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.4669520550366866
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.7925779394762376
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.9077515080282911
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.7655763610492959
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.8796231233662287
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.0876870882607369
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.5468313450318324
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.821426726028131
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.10802617824633023
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.5663714978390639
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.8477094992012597
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.8010608018935776
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.6908959038124128
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.5850584970494445
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.9299726991186074
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.1545196708130066
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.8059493485239304
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.7646564497765265
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.3758388160954711
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.6858894662861058
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.8092470903490714
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.5255844555262803
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.8319620893272142
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 0.7736768676858412
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.9044322287750999
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.7696120158346359
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.805244418788147
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.5809481886099249
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -0.8217981234874479
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.9122671632651294
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.8781181287988219
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.38429383852370136
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.9518171597738987
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.4411738967433336
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.8401201397884576
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.8640176142468293
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.5577661405576368
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.5108157631694521
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 0.6840863110401869
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 0.6260981230192918
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.3205721125355304
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.9275176761398366
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.6950716910682402
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -0.6683443426172035
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.16431534967927075
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.6069191456149204
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.686310063041023
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.4483626578333026
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.8246351715192086
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.6401971103875651
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.6305690582789796
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.1098619035471256
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.09690241711221899
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.8198322595082606
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.6168069851480991
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.9265610202387796
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.06091961381264516
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.9144760344212912
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.5578287341369382
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.7456636964357158
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.2651320036998804
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.14878005562183386
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.26895187322075503
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.8192780742442523
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.10726296918241833
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.8079129443621776
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 0.8367794228108869
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.03380971631207905
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.1613255095848345
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.5915639810379042
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.7800959474007222
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.4033420135002851
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.5528126855752062
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.8204118800531526
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 0.7467849077948153
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.8550226350649568
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.7308551337631045
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.681982098836554
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.8965689387982044
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.8420869638023549
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.3520299662538378
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.6885047583931445
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.21000487788939542
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.8885220848369573
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.5630471648010835
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.9541334037892555
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.6400436178845319
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.2880881207530157
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.6519228610770982
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.27137406494973954
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.6767249346692568
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -0.6377728370690512
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.33032360057420695
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.28210443265079627
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.8710448750686325
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.36926224550039394
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -0.6993238952026093
---------------------------------------------------------

Hidden units: 12
Epochs: 10000
Learning rate: 0.05

Errors during training:
Error at epoch 1 is 88.03199957154462
Train mean error at (after) epoch 1: 0.22007999892886154
Test error at (after) epoch 1: 0.22482881418618636
----------
Error at epoch 1000 is 13.62654783231393
Train mean error at (after) epoch 1000: 0.03406636958078482
Test error at (after) epoch 1000: 0.0430209679138001
----------
Error at epoch 2000 is 4.5814040948238555
Train mean error at (after) epoch 2000: 0.01145351023705964
Test error at (after) epoch 2000: 0.014160194263604644
----------
Error at epoch 3000 is 2.1737772440994787
Train mean error at (after) epoch 3000: 0.005434443110248697
Test error at (after) epoch 3000: 0.005869280899761059
----------
Error at epoch 4000 is 1.81118069083637
Train mean error at (after) epoch 4000: 0.0045279517270909245
Test error at (after) epoch 4000: 0.004613246138689259
----------
Error at epoch 5000 is 1.6094051617034275
Train mean error at (after) epoch 5000: 0.004023512904258569
Test error at (after) epoch 5000: 0.004049159065188775
----------
Error at epoch 6000 is 1.4416239603356216
Train mean error at (after) epoch 6000: 0.003604059900839054
Test error at (after) epoch 6000: 0.003614897815723249
----------
Error at epoch 7000 is 1.2988560962346098
Train mean error at (after) epoch 7000: 0.0032471402405865246
Test error at (after) epoch 7000: 0.0032528883142120125
----------
Error at epoch 8000 is 1.177028369649946
Train mean error at (after) epoch 8000: 0.002942570924124865
Test error at (after) epoch 8000: 0.0029468037540723306
----------
Error at epoch 9000 is 1.0727431574450956
Train mean error at (after) epoch 9000: 0.002681857893612739
Test error at (after) epoch 9000: 0.0026866132307173597
----------
Error at epoch 10000 is 0.9831338347256535
Train mean error at (after) epoch 10000: 0.0024578345868141336
Test error at (after) epoch 10000: 0.002464507137569536
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.6131750843390448
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.8162107935398207
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.8376037005425252
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.4526315865387377
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.8421713491825347
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.8336639468938364
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.7751683681667569
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.8887812527559766
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.08614926398665765
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.49554961652751767
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.8702685460997658
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.08254433161855913
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.5747741357648151
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.8851606202930616
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.8273630200506281
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.6873593281971715
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.572117189344185
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.9089131459546997
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.12429943206504245
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.867232066031538
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.7836125096813422
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.31393685315093517
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.6828641075772337
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.8594593201135854
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.5269589431646007
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.8277341485141999
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 0.6921506382077444
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.8547261923774211
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.7959732331040683
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.8322656323701331
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.5713626781951625
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -0.7845676572242898
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.8890710397354754
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.9098544049785657
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.3766202873728822
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.9216600010904089
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.4298653841354307
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.8368546338593154
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.8966769931564912
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.5935941890241864
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.5087777072773513
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 0.5842498204037779
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 0.4513293962510385
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.29889978053298316
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.9503869458805755
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.7446752626688803
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -0.6160366502058352
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.14779140625583842
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.6314523473288688
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.7474998440967562
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.4547668133510291
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.893404070597162
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.6397389981590406
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.6275531274929058
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.11402638193376781
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.10428461232659468
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.8471959575098162
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.6196566052947541
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.9515405759199277
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.05395332790622745
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.911949278546455
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.5813857235612641
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.7298859182060125
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.2777896744145031
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.1334142370413131
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.269855891155956
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.8491195823770176
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.1034978404445865
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.8143030577226941
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 0.7498915357145849
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.0739169102492642
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.15804280766391432
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.589198968112731
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.852035566835523
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.34988744461920085
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.5584987225482696
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.8518447981691852
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 0.7008309258441585
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.818424026244936
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.7461432360244508
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.7031978564250861
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.9318801254184881
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.9135011894886376
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.3243412300725806
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.7003201540046637
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.1957083739862872
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.8871497064351097
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.5553847399824325
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.9172230133224646
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.695392158283425
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.28297908349155393
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.6836091754760042
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.27580431193352306
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.6602425517665543
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -0.4547330909697813
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.329691037181923
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.2885348175830104
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.9044211745165933
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.4144023973585779
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -0.6130671454997098
---------------------------------------------------------

Hidden units: 12
Epochs: 100
Learning rate: 0.1

Errors during training:
Error at epoch 1 is 122.1201807156388
Train mean error at (after) epoch 1: 0.305300451789097
Test error at (after) epoch 1: 0.3234021397527985
----------
Error at epoch 10 is 80.39094757315313
Train mean error at (after) epoch 10: 0.20097736893288282
Test error at (after) epoch 10: 0.21377753382403683
----------
Error at epoch 20 is 54.33632369415055
Train mean error at (after) epoch 20: 0.13584080923537636
Test error at (after) epoch 20: 0.14538059970443848
----------
Error at epoch 30 is 37.889995969412865
Train mean error at (after) epoch 30: 0.09472498992353216
Test error at (after) epoch 30: 0.10319271656140637
----------
Error at epoch 40 is 28.0028049327422
Train mean error at (after) epoch 40: 0.07000701233185551
Test error at (after) epoch 40: 0.07872521656583158
----------
Error at epoch 50 is 22.699504002811075
Train mean error at (after) epoch 50: 0.056748760007027686
Test error at (after) epoch 50: 0.06618846577529623
----------
Error at epoch 60 is 20.124206728746955
Train mean error at (after) epoch 60: 0.050310516821867386
Test error at (after) epoch 60: 0.06041425921574004
----------
Error at epoch 70 is 18.932194246276566
Train mean error at (after) epoch 70: 0.04733048561569141
Test error at (after) epoch 70: 0.057868789789990306
----------
Error at epoch 80 is 18.365460341343052
Train mean error at (after) epoch 80: 0.04591365085335763
Test error at (after) epoch 80: 0.05667562762549912
----------
Error at epoch 90 is 18.061845078614425
Train mean error at (after) epoch 90: 0.04515461269653606
Test error at (after) epoch 90: 0.05599898709690969
----------
Error at epoch 100 is 17.864336323300705
Train mean error at (after) epoch 100: 0.044660840808251764
Test error at (after) epoch 100: 0.05550715593291886
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.34202987846839583
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.5140132239750392
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.5837542022548308
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.22788904167355334
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.605886090818571
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -1.1018804390504162
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.4729533900152452
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.6919061393299848
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.052603305524228997
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.2416890914527309
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.5716384230709295
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.07240626231297548
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.344916912545336
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.9423091496133149
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.5535955746775193
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.4466235894160018
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.3520359057127689
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.9130669176285383
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.08147950527716355
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.9500129122985245
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 1.1046749945243162
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.1662898438172939
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.338066434527016
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.9669114751406521
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.2978413899340327
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.5988354928818891
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 1.2718428725125204
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 1.0136640925247826
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.5590891356714522
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.5631828261165359
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.3063165666281083
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -1.1551779330170442
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.9415291826722528
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.7731432857998729
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.17837645281429818
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.6522984915599063
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.2333202076850388
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 1.0757694636795312
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.8144566198350057
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.26269001117390123
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.285165321633135
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 1.3730346529502022
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 1.5053729461711831
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.11539206282215939
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.7503754918592472
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.46933355837417184
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -1.316036939957462
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.10850142429582153
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.34336710560279055
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.4383927732077137
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.25355094916570975
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.7488803951556569
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.3362367569136436
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.3340277567181485
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.0943770691381479
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.08779455689982119
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.5428218515825394
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.36913080119819097
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.6033438380172925
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: -0.017744891957595755
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.7743690268159256
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.3431577228148185
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.4337207895493581
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.10627942439896385
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.05858804336593212
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.13639263310823013
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.5866790391761204
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.027836631520650305
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.5419025098087379
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 1.1832684367779236
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.01522298723590609
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.06309654970473287
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.3688290665629492
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.5678394675217044
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.1701738532036468
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.3237846578285005
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.44368742485196183
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 1.241024441204469
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.4392093806212765
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.5018216722780369
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.37726680779986294
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.8719887434916558
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.7530409961837436
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.22484787690390645
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.3979975617061325
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.10167769283555855
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.6583257722841497
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.3445854281624893
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.6291188556542383
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.36602471159919775
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.14508322650318684
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.42322938190780685
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.12099605910401832
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.3908438841468651
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -1.515725703767216
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.15698280829002956
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.08594176483237687
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.6626121542074138
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.15612570653092914
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -1.3488139748838095
---------------------------------------------------------

Hidden units: 12
Epochs: 1000
Learning rate: 0.1

Errors during training:
Error at epoch 1 is 115.2009746142734
Train mean error at (after) epoch 1: 0.2880024365356835
Test error at (after) epoch 1: 0.2453074086238502
----------
Error at epoch 100 is 16.560172512149652
Train mean error at (after) epoch 100: 0.04140043128037413
Test error at (after) epoch 100: 0.051438782380900924
----------
Error at epoch 200 is 14.766214656617905
Train mean error at (after) epoch 200: 0.03691553664154476
Test error at (after) epoch 200: 0.046240970639659616
----------
Error at epoch 300 is 12.65307219751225
Train mean error at (after) epoch 300: 0.031632680493780624
Test error at (after) epoch 300: 0.03970725231292369
----------
Error at epoch 400 is 10.38367240382571
Train mean error at (after) epoch 400: 0.025959181009564274
Test error at (after) epoch 400: 0.03260426553780589
----------
Error at epoch 500 is 8.209616713766593
Train mean error at (after) epoch 500: 0.020524041784416483
Test error at (after) epoch 500: 0.02571915252913544
----------
Error at epoch 600 is 6.339169712042385
Train mean error at (after) epoch 600: 0.015847924280105962
Test error at (after) epoch 600: 0.019719702946116288
----------
Error at epoch 700 is 4.872870211392513
Train mean error at (after) epoch 700: 0.012182175528481283
Test error at (after) epoch 700: 0.014947704127912775
----------
Error at epoch 800 is 3.8113985413353735
Train mean error at (after) epoch 800: 0.009528496353338434
Test error at (after) epoch 800: 0.011433356061848823
----------
Error at epoch 900 is 3.093107481452682
Train mean error at (after) epoch 900: 0.007732768703631705
Test error at (after) epoch 900: 0.009005419248110774
----------
Error at epoch 1000 is 2.631927471323402
Train mean error at (after) epoch 1000: 0.006579818678308505
Test error at (after) epoch 1000: 0.007407724173638351
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.5904748254094718
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.7363286059849599
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.7867571520987225
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.44558265435790334
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.7806280714486874
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.9046333399596196
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.7032601609556692
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.8611948159873318
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.08486247411820017
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.48467967573089377
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.7863065345184935
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.07452158570641658
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.528416873787882
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.8835579737382467
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.7795061545145816
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.6422147817071936
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.5316856895508641
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.9262062677595159
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.10998222172721195
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.8614978055971708
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.8475527236416339
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.31239894206363983
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.6394433394977233
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.8644858247583302
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.4986857709838532
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.7948272632643967
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 0.8426034763272028
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.912573020254378
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.7420743263710082
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.7811052884055967
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.5507110372238014
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -0.869886963473062
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.9121941280532283
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.8609276273969928
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.34062965974245374
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.8807717701792283
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.4037280905594562
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.874303508317996
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.8609527741695471
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.5196235307673414
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.4844420694094425
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 0.80490959475098
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 0.7657197417896892
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.29950216360404674
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.915136040838858
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.6849424451894851
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -0.8129829463164157
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.1449373426254614
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.5781204345651428
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.7134577287331697
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.41608853011997354
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.8424603733304709
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.6110640884520834
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.5991431600190658
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.09587212822970932
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.0866060960203309
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.7866695641960059
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.5898099593090218
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.9060474177805998
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.06086721354184811
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.8991777821106921
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.5321073604237706
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.7062797139580513
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.28407508380059104
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.13704360805845725
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.25320854491209144
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.7998307613553705
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.10382482587116679
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.7820344471611697
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 0.8819286684947806
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.07524207541187648
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.15597675974200467
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.5536843571359547
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.7798756698333221
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.3379655808862633
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.5088399014544106
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.801748820322985
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 0.8363683791926103
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.8006843856750534
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.7012410066256334
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.6394099214522153
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.9057761914202291
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.854874338023126
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.31925042032380474
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.6471728132772172
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.18896241744938283
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.8587696196214885
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.5257975752634295
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.9028759336271256
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.6420143063905496
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.27289030214739274
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.6491033069748569
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.26668408795334847
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.6381667494197576
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -0.7724251008415831
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.31749051310343734
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.250377615851419
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.854459508690156
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.3485836684764358
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -0.8149968987898276
---------------------------------------------------------

Hidden units: 12
Epochs: 3000
Learning rate: 0.1

Errors during training:
Error at epoch 1 is 157.6881212204486
Train mean error at (after) epoch 1: 0.39422030305112155
Test error at (after) epoch 1: 0.37289420702850795
----------
Error at epoch 300 is 13.913704522225602
Train mean error at (after) epoch 300: 0.03478426130556401
Test error at (after) epoch 300: 0.04375454380703058
----------
Error at epoch 600 is 7.59630834875141
Train mean error at (after) epoch 600: 0.018990770871878525
Test error at (after) epoch 600: 0.02382938824340396
----------
Error at epoch 900 is 3.442846995586394
Train mean error at (after) epoch 900: 0.008607117488965985
Test error at (after) epoch 900: 0.01034612572857842
----------
Error at epoch 1200 is 2.0700159495252644
Train mean error at (after) epoch 1200: 0.005175039873813161
Test error at (after) epoch 1200: 0.005700180906674143
----------
Error at epoch 1500 is 1.7437436192940496
Train mean error at (after) epoch 1500: 0.004359359048235124
Test error at (after) epoch 1500: 0.004544269046241757
----------
Error at epoch 1800 is 1.6123516723575908
Train mean error at (after) epoch 1800: 0.004030879180893977
Test error at (after) epoch 1800: 0.0041162640591324885
----------
Error at epoch 2100 is 1.5131912091437356
Train mean error at (after) epoch 2100: 0.003782978022859339
Test error at (after) epoch 2100: 0.0038312586533350663
----------
Error at epoch 2400 is 1.4253017281352287
Train mean error at (after) epoch 2400: 0.0035632543203380717
Test error at (after) epoch 2400: 0.0035924876688835147
----------
Error at epoch 2700 is 1.3457221627754807
Train mean error at (after) epoch 2700: 0.0033643054069387016
Test error at (after) epoch 2700: 0.0033805946777511176
----------
Error at epoch 3000 is 1.2733209251304716
Train mean error at (after) epoch 3000: 0.003183302312826179
Test error at (after) epoch 3000: 0.0031892807674999786
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.6112811652348727
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.7886231029974938
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.8275849737949729
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.4610425704724855
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.829212791278772
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.8290342086898261
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.7774512717100531
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.883598092950891
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.10464282762697147
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.5775510892514638
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.8715889366773124
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.04910569314353195
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.5618859270253832
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.8697004591640572
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.8321626693349634
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.6936991336092048
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.5761310291959575
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.9144336370529913
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.11846400682296293
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.8941057067971857
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.7857297957003961
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.3803830316128136
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.6855688506140023
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.8455058369643417
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.516896687950565
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.8163720005326787
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 0.6989279768683367
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.8489052612934823
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.7831251588095526
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.8148583151711557
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.5679259537120274
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -0.7733210861250029
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.86229609095201
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.874720524623293
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.3535049771224647
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.8924129671141069
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.42696615918574204
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.8268091305892051
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.8747127134594986
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.6010079226953009
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.5206904504536087
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 0.601315647281853
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 0.488956912616775
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.2976895076982961
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.9573557473609688
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.7308956219702992
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -0.6379552696987195
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.15184671666674054
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.6230407866581359
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.7476674944513831
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.43546094551085285
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.8762346777733316
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.661809987354316
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.665127349667794
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.12436557392032377
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.1145222261744509
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.8511144731802175
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.6138733459678475
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.9737022242778093
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.03951618834662455
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.9099818952038183
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.5886448780328334
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.7237303155111304
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.31105871433189225
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.1351160703956663
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.2636659410572586
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.8273986441892306
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.0939206022362788
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.7999599542775812
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 0.7491744588980203
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.09296511182850212
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.15189124888834057
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.5899514756529026
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.8225487894819147
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.39609694650638066
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.5648989259433664
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.8897822451466039
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 0.6929224545137743
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.8072927922881793
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.7350758244013704
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.6787368735243061
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.955516508239957
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.9015747287666346
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.3575878845043377
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.7017640188383204
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.1914911870564981
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.8640694474319744
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.5614126442814095
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.8948905750292274
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.6920098520541498
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.2807472509239555
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.6809988747446468
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.2804239952708516
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.6683896328216321
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -0.486039207482243
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.34570961641603887
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.26807468447395433
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.9119799380661728
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.44199953630207434
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -0.6240997023673656
---------------------------------------------------------

Hidden units: 12
Epochs: 10000
Learning rate: 0.1

Errors during training:
Error at epoch 1 is 73.77896264339071
Train mean error at (after) epoch 1: 0.18444740660847678
Test error at (after) epoch 1: 0.15968766301674847
----------
Error at epoch 1000 is 2.261169209827557
Train mean error at (after) epoch 1000: 0.005652923024568892
Test error at (after) epoch 1000: 0.006903385186030776
----------
Error at epoch 2000 is 1.1023981063461668
Train mean error at (after) epoch 2000: 0.0027559952658654167
Test error at (after) epoch 2000: 0.002886086367260926
----------
Error at epoch 3000 is 0.9540453919472919
Train mean error at (after) epoch 3000: 0.0023851134798682297
Test error at (after) epoch 3000: 0.0024637208285259184
----------
Error at epoch 4000 is 0.8274286150020121
Train mean error at (after) epoch 4000: 0.0020685715375050305
Test error at (after) epoch 4000: 0.0021164952314093473
----------
Error at epoch 5000 is 0.7179066741994881
Train mean error at (after) epoch 5000: 0.0017947666854987202
Test error at (after) epoch 5000: 0.001817961939060688
----------
Error at epoch 6000 is 0.6281434432266775
Train mean error at (after) epoch 6000: 0.0015703586080666938
Test error at (after) epoch 6000: 0.0015821622505454048
----------
Error at epoch 7000 is 0.5571415511723451
Train mean error at (after) epoch 7000: 0.0013928538779308627
Test error at (after) epoch 7000: 0.0014034770737924684
----------
Error at epoch 8000 is 0.5003039325512344
Train mean error at (after) epoch 8000: 0.0012507598313780859
Test error at (after) epoch 8000: 0.0012634975022970476
----------
Error at epoch 9000 is 0.4537078794982167
Train mean error at (after) epoch 9000: 0.0011342696987455417
Test error at (after) epoch 9000: 0.00114918298116094
----------
Error at epoch 10000 is 0.41483545786477954
Train mean error at (after) epoch 10000: 0.0010370886446619489
Test error at (after) epoch 10000: 0.0010538411715132715
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.62000957140968
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.8193675637355464
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.8460183784130899
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.4408959029270085
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.8557700277989404
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.847155758218634
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.6777500571810959
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.9130800198335656
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.09101348733158557
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.4658281508809478
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.822063732965143
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.054013130227105965
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.5669592443663993
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.9113994056195647
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.8242170964144862
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.6904837833244537
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.5725898493469217
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.915927170312381
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.09952274984178824
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.9106045509989769
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.8144718123433292
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.3067561315315421
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.6887541342881633
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.9152763676446651
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.5405515620530938
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.8627195733809043
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 0.6589314108356363
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.8837023759158396
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.821158371035063
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.8562708888234083
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.5775110408151887
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -0.7985215929631158
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.9586457103363211
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.9497422871352765
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.3581778980551696
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.934767585860274
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.40326603588435056
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.8741580311729924
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.9402159668455254
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.542617528005197
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.5192173693329776
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 0.5064501213072812
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 0.30951903689723254
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.29929830163150956
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.9546977803373076
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.7315008813188333
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -0.5654617534768451
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.1457518104280101
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.6037927497217661
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.7161466953401292
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.41299090438891745
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.921007577731179
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.6310737048663932
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.6097250496014435
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.10758188448348793
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.1024047912754699
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.8238988779764496
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.6251734975037824
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.9657534483864867
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.05701103881692898
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.933764115347679
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.551024887235775
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.7442393407306858
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.2839183860751809
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.1287255726462361
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.2723659709424076
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.8823839981923405
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.10673832295786317
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.8490324446325352
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 0.7449996546719846
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.06277675632469654
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.1625827420778367
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.5987696902117068
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.8758826818507197
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.3367340166098192
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.48543495809438425
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.8461935576999822
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 0.6847045960515059
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.8604568968397213
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.7577236594135217
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.7072987905522274
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.9586155712564979
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.9516371382502289
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.3085200443445349
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.6553527536903128
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.18254223129897054
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.9416755517491908
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.5626261737477578
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.9773893552720778
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.643783960683127
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.28080804184375585
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.6754849370432985
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.2772467900926986
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.6575226685438615
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -0.3330249353848259
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.3247438509589248
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.26112078817275
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.895351854479872
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.37350221807395245
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -0.5526494843641897
---------------------------------------------------------

Hidden units: 12
Epochs: 100
Learning rate: 0.3

Errors during training:
Error at epoch 1 is 120.33403498298414
Train mean error at (after) epoch 1: 0.30083508745746035
Test error at (after) epoch 1: 0.25172409648593036
----------
Error at epoch 10 is 30.264620929361147
Train mean error at (after) epoch 10: 0.07566155232340287
Test error at (after) epoch 10: 0.07203994032147791
----------
Error at epoch 20 is 18.722127706071063
Train mean error at (after) epoch 20: 0.046805319265177656
Test error at (after) epoch 20: 0.056166436915102
----------
Error at epoch 30 is 17.568099317929214
Train mean error at (after) epoch 30: 0.043920248294823036
Test error at (after) epoch 30: 0.05487651053728503
----------
Error at epoch 40 is 16.997816913248354
Train mean error at (after) epoch 40: 0.042494542283120884
Test error at (after) epoch 40: 0.053413699179247806
----------
Error at epoch 50 is 16.45330328445723
Train mean error at (after) epoch 50: 0.04113325821114308
Test error at (after) epoch 50: 0.05178312971430246
----------
Error at epoch 60 is 15.891215929505565
Train mean error at (after) epoch 60: 0.03972803982376391
Test error at (after) epoch 60: 0.05005892239522403
----------
Error at epoch 70 is 15.309172099009887
Train mean error at (after) epoch 70: 0.03827293024752472
Test error at (after) epoch 70: 0.04826142980832657
----------
Error at epoch 80 is 14.709755205250495
Train mean error at (after) epoch 80: 0.03677438801312624
Test error at (after) epoch 80: 0.046402782382815484
----------
Error at epoch 90 is 14.096692047533862
Train mean error at (after) epoch 90: 0.035241730118834656
Test error at (after) epoch 90: 0.04449536574351644
----------
Error at epoch 100 is 13.474240985036367
Train mean error at (after) epoch 100: 0.03368560246259092
Test error at (after) epoch 100: 0.04255274694774177
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.39081984387389435
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.5753345082382015
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.6468258580469427
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.2745250544896724
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.6548650439142949
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -1.165170060976322
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.5027090166027128
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.7213483945072067
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.03899649363880811
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.3217972782715468
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.6098014301406496
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.08793534923448552
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.36907003202546856
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.9508034976332758
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.5902016838986152
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.46944724348017536
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.35817678946477144
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.9250195293930816
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.10187583933190644
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.9791748727818597
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 1.104517960693422
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.21349767539438327
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.434020789136009
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -1.0131824173496804
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.3364102618297923
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.6411872291375179
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 1.2504543085496043
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 1.0080329164041242
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.5930932129467014
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.6139321593948138
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.3619321368702192
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -1.1417500361739157
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.9593895809698696
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.8061362442799878
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.23179361854310127
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.7526338286362354
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.2696921335757457
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 1.0686149212467855
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.8427310759621588
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.3192737054151906
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.27837132463231273
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 1.2704465574782036
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 1.3922281338843034
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.18576495222940184
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.7980486622943722
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.5324138252673485
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -1.2818354012213484
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.10615706833577673
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.42329931755299266
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.5275236162851734
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.30125007418051414
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.8060094589092012
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.39077673685821396
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.39301105832678723
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.054540811382081805
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.04342298000762042
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.5763920422226293
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.40479547711248026
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.6943967054810355
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.04007069735728075
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.7979949621110614
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.3632879753114575
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.4949089315887815
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.13200955147785096
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.08629453960211499
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.16941106306446108
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.6369766854640311
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.06612195822046761
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.592199303351684
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 1.1202948331902374
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.007771766269629109
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.09644437325555627
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.39246273705360885
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.6646148953168827
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.22473698473828477
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.33541971296801926
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.5214225627073076
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 1.2157894394054027
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.556572205651536
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.5395007530427408
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.4561237354867452
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.913258545284833
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.7906237697223839
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.18364336252162933
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.43210714322240695
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.12463879952324203
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.7144305845405476
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.3630841422159791
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.7220715587656011
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.4666680348684841
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.16889241996225685
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.4783791208583917
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.14933915222842875
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.43819759213586507
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -1.3632477144290553
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.17216679289340261
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.15107592694278865
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.6874731283011873
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.1946454359208189
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -1.2887780013293146
---------------------------------------------------------

Hidden units: 12
Epochs: 1000
Learning rate: 0.3

Errors during training:
Error at epoch 1 is 86.15056410155766
Train mean error at (after) epoch 1: 0.21537641025389415
Test error at (after) epoch 1: 0.18519811057530142
----------
Error at epoch 100 is 9.953912631410295
Train mean error at (after) epoch 100: 0.02488478157852574
Test error at (after) epoch 100: 0.03127668454580543
----------
Error at epoch 200 is 5.067635025074337
Train mean error at (after) epoch 200: 0.012669087562685843
Test error at (after) epoch 200: 0.015791626981641098
----------
Error at epoch 300 is 3.1231019935788837
Train mean error at (after) epoch 300: 0.007807754983947209
Test error at (after) epoch 300: 0.009260584417552717
----------
Error at epoch 400 is 2.358743627010812
Train mean error at (after) epoch 400: 0.005896859067527031
Test error at (after) epoch 400: 0.00654225823905686
----------
Error at epoch 500 is 2.0578899153091506
Train mean error at (after) epoch 500: 0.0051447247882728765
Test error at (after) epoch 500: 0.005440940104850944
----------
Error at epoch 600 is 1.8962140574017845
Train mean error at (after) epoch 600: 0.0047405351435044615
Test error at (after) epoch 600: 0.004889476356906267
----------
Error at epoch 700 is 1.7729582286828827
Train mean error at (after) epoch 700: 0.004432395571707206
Test error at (after) epoch 700: 0.004517129783230152
----------
Error at epoch 800 is 1.6656269615890351
Train mean error at (after) epoch 800: 0.004164067403972588
Test error at (after) epoch 800: 0.004218902033496326
----------
Error at epoch 900 is 1.5697236067376727
Train mean error at (after) epoch 900: 0.003924309016844182
Test error at (after) epoch 900: 0.003963725849123791
----------
Error at epoch 1000 is 1.4838239009511667
Train mean error at (after) epoch 1000: 0.0037095597523779168
Test error at (after) epoch 1000: 0.0037399987644788453
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.619372869875577
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.7895121521151302
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.8326150014309626
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.4688624863925984
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.827442697125108
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.8193901483044702
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.79700680914887
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.872473966254087
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.1049418653485672
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.5440956717807995
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.910152992216074
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.07911975557651614
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.5726932012199993
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.856710538566419
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.8251149763075177
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.6873985921304032
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.5690220165254937
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.8894127684301751
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.1311226236823294
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.8450343944810124
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.7803357695349836
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.3619181197457101
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.6720165000420533
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.8469150358221188
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.5317601517010291
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.819253977851631
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 0.7089323708278288
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.8328603500497402
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.788275954782525
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.8138169895521927
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.5758914770861505
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -0.7838901757783283
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.8681392236070299
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.8972264045914542
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.36437999865373577
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.882525602381509
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.4394557302651578
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.8235746954314541
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.872864433612886
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.599746760548246
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.5405485298557617
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 0.6189648831222344
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 0.5366225180852413
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.3097015541371642
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.9388528950476281
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.7395162955706959
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -0.6505316625549699
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.15001256780345198
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.633791630295288
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.7501535585980762
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.45876081633397214
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.8737929428999248
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.6539463267088954
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.6459953998950481
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.11332990158983813
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.10193489714363967
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.8470633832342912
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.6279601909130597
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.9405295165077882
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.05806726635337489
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.8905933410907365
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.6076756495299039
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.7371629027383516
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.30415558231193784
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.14171935681867337
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.2684043531970606
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.831587834161867
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.10022370076876651
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.8078295697805272
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 0.7406002194577153
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.06418896175217631
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.15782794688583338
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.5934251446149842
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.8255913910366517
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.3795401008404382
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.5732861721123141
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.8573709002333391
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 0.7231552274210022
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.814940084483551
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.7477030831582001
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.6795498383461133
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.9225687261287557
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.9023479583971689
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.32400299192621296
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.7099387046455373
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.20021286562699553
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.8817725037960745
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.5648939270706631
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.8923882672613191
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.6989668514766257
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.29069492461931123
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.6898183148023751
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.2863281218970968
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.6674775672059445
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -0.5226066547975899
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.3530979322268462
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.28946341438127754
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.8950495547132412
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.4282109177466467
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -0.6573504160870163
---------------------------------------------------------

Hidden units: 12
Epochs: 3000
Learning rate: 0.3

Errors during training:
Error at epoch 1 is 102.32311625650432
Train mean error at (after) epoch 1: 0.2558077906412608
Test error at (after) epoch 1: 0.23110312674785832
----------
Error at epoch 300 is 2.706781122203392
Train mean error at (after) epoch 300: 0.006766952805508481
Test error at (after) epoch 300: 0.007894745455904557
----------
Error at epoch 600 is 1.3540643382239623
Train mean error at (after) epoch 600: 0.003385160845559906
Test error at (after) epoch 600: 0.0036168586242479373
----------
Error at epoch 900 is 1.1603683816046777
Train mean error at (after) epoch 900: 0.0029009209540116943
Test error at (after) epoch 900: 0.003099052988303714
----------
Error at epoch 1200 is 1.007755003832803
Train mean error at (after) epoch 1200: 0.0025193875095820073
Test error at (after) epoch 1200: 0.002687975981703513
----------
Error at epoch 1500 is 0.8776056259444005
Train mean error at (after) epoch 1500: 0.0021940140648610013
Test error at (after) epoch 1500: 0.002330204088527091
----------
Error at epoch 1800 is 0.7652586453623469
Train mean error at (after) epoch 1800: 0.0019131466134058672
Test error at (after) epoch 1800: 0.0020207706149303955
----------
Error at epoch 2100 is 0.6730889498725642
Train mean error at (after) epoch 2100: 0.0016827223746814105
Test error at (after) epoch 2100: 0.0017724389522470916
----------
Error at epoch 2400 is 0.6017589814749572
Train mean error at (after) epoch 2400: 0.001504397453687393
Test error at (after) epoch 2400: 0.001586745834441442
----------
Error at epoch 2700 is 0.5464877344157454
Train mean error at (after) epoch 2700: 0.0013662193360393636
Test error at (after) epoch 2700: 0.0014453394120710972
----------
Error at epoch 3000 is 0.5020636082719525
Train mean error at (after) epoch 3000: 0.0012551590206798813
Test error at (after) epoch 3000: 0.0013305839591894644
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.6080308473216582
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.8154592873477181
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.8599958083605324
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.43557996526396203
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.8505547236976758
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.8211043519775629
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.6960784247258158
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.8982952794658984
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.08447390314363687
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.48166723831282915
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.8328466315254041
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.046855241006727506
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.5596782947250121
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.8874678459980037
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.8130025060761229
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.6805158152030819
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.5641788942228311
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.9227231804546238
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.10097392137256828
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.8910911667663618
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.8092751339815011
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.30790016317897995
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.6938480730024744
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.9116515415609164
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.5218679697790881
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.8363512586532529
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 0.6486849498228503
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.874343118635327
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.8008535491169319
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.839963355573068
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.5674024209169857
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -0.7770888822166214
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.9537216412666171
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.9322036818072365
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.3652886320068603
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.9278742293862406
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.40317204391793565
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.8616787437310506
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.9161817535902527
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.5813898314841566
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.4856193853302216
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 0.5195710952147367
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 0.3286893067590316
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.2996823990270833
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.9869279155754043
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.7472116848253405
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -0.5752009438762605
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.14837953865748071
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.6277187635186549
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.763972265852571
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.4281601597571184
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.9121532103629256
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.6470219681561926
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.5903531418166271
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.11130406559352488
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.09583502596751547
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.8357992756819338
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.6079014048489825
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -1.0054653304311822
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.057047121730812146
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.9261188556532765
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.5267449756222876
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.7311933637804363
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.30302391086482305
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.1310063758964559
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.2593461274120408
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.8606131675173121
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.10421665136168612
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.8280532162024357
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 0.7470444034987235
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.08970017408763953
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.1559703860217753
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.5840607167107075
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.8882485774475865
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.32673208819367555
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.491726544670587
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.9011446410545435
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 0.6884167880123807
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.8798348110749904
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.7435544276857565
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.7108662737721743
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.9669647958950918
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.9478796776639594
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.3238374911313861
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.6602455865370519
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.18778363600980133
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.9326891732006467
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.5485341225330984
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.9957929212428877
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.6845010236559976
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.2765269083229482
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.6930795951658034
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.2731660640418191
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.654348291188617
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -0.3475880710648612
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.3238000019656913
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.27865136353648073
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.9037592858019221
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.41948783559657055
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -0.5572017071476827
---------------------------------------------------------

Hidden units: 12
Epochs: 10000
Learning rate: 0.3

Errors during training:
Error at epoch 1 is 76.10719903182316
Train mean error at (after) epoch 1: 0.1902679975795579
Test error at (after) epoch 1: 0.1452724969379496
----------
Error at epoch 1000 is 0.9437014299657753
Train mean error at (after) epoch 1000: 0.0023592535749144385
Test error at (after) epoch 1000: 0.0022461996372536396
----------
Error at epoch 2000 is 0.6167373329870922
Train mean error at (after) epoch 2000: 0.0015418433324677306
Test error at (after) epoch 2000: 0.0015039102657212783
----------
Error at epoch 3000 is 0.4572994848943109
Train mean error at (after) epoch 3000: 0.0011432487122357772
Test error at (after) epoch 3000: 0.0011313364293285579
----------
Error at epoch 4000 is 0.35934482612678853
Train mean error at (after) epoch 4000: 0.0008983620653169713
Test error at (after) epoch 4000: 0.0008875790687413788
----------
Error at epoch 5000 is 0.2936237855303322
Train mean error at (after) epoch 5000: 0.0007340594638258305
Test error at (after) epoch 5000: 0.0007332641960540855
----------
Error at epoch 6000 is 0.28610448716753184
Train mean error at (after) epoch 6000: 0.0007152612179188296
Test error at (after) epoch 6000: 0.0007140399284398891
----------
Error at epoch 7000 is 0.24328310832514002
Train mean error at (after) epoch 7000: 0.0006082077708128501
Test error at (after) epoch 7000: 0.0006393401536629802
----------
Error at epoch 8000 is 0.24244069388190004
Train mean error at (after) epoch 8000: 0.0006061017347047501
Test error at (after) epoch 8000: 0.0006493111696499838
----------
Error at epoch 9000 is 0.24262248106524467
Train mean error at (after) epoch 9000: 0.0006065562026631117
Test error at (after) epoch 9000: 0.0006591338851952172
----------
Error at epoch 10000 is 0.24447611324605842
Train mean error at (after) epoch 10000: 0.0006111902831151461
Test error at (after) epoch 10000: 0.0006684119160072876
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.6279251822083548
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.8108792779829677
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.8284464755712365
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.46107476679180714
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.8873356075369707
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.8297270498803452
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.7026754825657993
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.9367152740078897
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.08967426593595237
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.42519678389837756
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.8285398775568724
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.045540946329130666
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.5856997385667164
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.9290079421193258
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.8195626077060765
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.6709885306379922
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.550468510594769
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.951051715519909
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.0854817799224768
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.9439478906539951
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.8252354637375592
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.23649463447041033
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.6739875150395935
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.9260382743661686
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.5259675273451735
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.874698082068138
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 0.6539789316931235
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.8931295587643366
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.8139417138594466
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.8670082212578984
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.5849370495007892
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -0.7794727671872381
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.9426182461890473
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.9609617360383655
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.3388588395963473
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.9125163542708514
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.4161460381137839
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.8956364328130122
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.959653724608569
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.49993802360771367
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.5039926187019562
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 0.4718275418391876
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 0.24265424869417693
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.3018451011000156
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.9922563386348273
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.7442802581296195
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -0.5408016936848803
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.14806502520206885
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.6074025348249388
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.730415851193291
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.39954353946045007
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.9483053391728092
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.6298941168478531
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.5774448857557062
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.09626558228003998
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.08386771253475525
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.8139825281705932
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.6273429079280017
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.9721126800845716
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.06448359358527728
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.9610490199626709
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.5055499756774904
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.7585980767283819
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.27363435480787013
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.12967129881012776
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.2501811347021492
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.8817140492734831
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.1042819569213067
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.85131211510771
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 0.7199931960435663
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.11282289071160337
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.1589922865911105
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.5882029073432503
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.8925988065893602
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.28700150363231747
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.48331083628643523
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.8314943788301318
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 0.6695313462560758
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.8722594786874404
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.7697915880243321
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.6876480366776795
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.9774354762201198
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.9448704003828698
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.30234102002273355
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.6243045100414066
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.1938995708778228
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.9443589287074482
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.5536380942339908
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.9815221715354285
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.6598361065098608
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.28959062406703084
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.6597319722037446
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.26766983514923454
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.66468886479399
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -0.2458648665323773
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.3145220523975848
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.2554618918976758
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.8960709176382775
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.3372591219968347
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -0.5282969473750979
---------------------------------------------------------

Hidden units: 12
Epochs: 100
Learning rate: 0.5

Errors during training:
Error at epoch 1 is 81.44646115897987
Train mean error at (after) epoch 1: 0.2036161528974497
Test error at (after) epoch 1: 0.1719480964416937
----------
Error at epoch 10 is 20.731707471105164
Train mean error at (after) epoch 10: 0.05182926867776291
Test error at (after) epoch 10: 0.05680639455101876
----------
Error at epoch 20 is 15.55749276230436
Train mean error at (after) epoch 20: 0.0388937319057609
Test error at (after) epoch 20: 0.048302552139924355
----------
Error at epoch 30 is 14.34023006907697
Train mean error at (after) epoch 30: 0.035850575172692425
Test error at (after) epoch 30: 0.044727919014087895
----------
Error at epoch 40 is 13.15125054615078
Train mean error at (after) epoch 40: 0.03287812636537695
Test error at (after) epoch 40: 0.04106441805260539
----------
Error at epoch 50 is 11.976216025643284
Train mean error at (after) epoch 50: 0.02994054006410821
Test error at (after) epoch 50: 0.03742467256087236
----------
Error at epoch 60 is 10.842196117508003
Train mean error at (after) epoch 60: 0.027105490293770008
Test error at (after) epoch 60: 0.03389568011479864
----------
Error at epoch 70 is 9.770236629401323
Train mean error at (after) epoch 70: 0.024425591573503307
Test error at (after) epoch 70: 0.030543750731742453
----------
Error at epoch 80 is 8.774233683587134
Train mean error at (after) epoch 80: 0.021935584208967837
Test error at (after) epoch 80: 0.027412846530358307
----------
Error at epoch 90 is 7.861584996073164
Train mean error at (after) epoch 90: 0.01965396249018291
Test error at (after) epoch 90: 0.024526972882931555
----------
Error at epoch 100 is 7.034563093958225
Train mean error at (after) epoch 100: 0.017586407734895563
Test error at (after) epoch 100: 0.021894826226452516
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.48842284930824525
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.6599335777803212
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.7058049572608622
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.33881019584879757
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.7179037818202304
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -1.0326252097070274
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.5994044977836996
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.825077949047526
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.055506456674462086
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.4115075824681602
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.7224970321323235
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.09921962039371371
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.43812991197058226
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.9570071482088534
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.6932698803121029
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.5481405284422148
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.42290085662257565
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.9947098313468676
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.13294047998489414
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.9434553762967713
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.9912121902125887
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.28989751440820133
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.5328745152060586
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.9240149335733655
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.409979276811461
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.7288327023083383
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 1.0570151605458515
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 1.0436719311816278
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.6722729530634688
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.7134809376682147
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.45314815904558864
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -1.0410033482210546
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -1.0154611824361786
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.8336973919764472
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.2969598376276307
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.8044720834033182
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.3389344876626772
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 1.0267132802594647
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.876860577091259
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.4128307954029187
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.37234883621512405
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 1.1102979086136462
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 1.1026871582374196
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.23947929912285845
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.8844853337758991
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.597516415082937
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -1.041559034820623
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.12494251006216019
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.49117852222984193
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.5947793027623749
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.3579316339435851
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.8167893579189008
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.4885361495497263
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.4934876614701879
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.06482679752771747
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.053518958186356984
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.6954368446321729
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.4929502985792573
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.8038144640688594
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.05005761609388704
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.9008438473147422
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.43733274336000283
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.6076238688098538
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.1631394267742225
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.12160803548517791
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.19659493415608045
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.7359418167705905
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.07586980607261155
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.7035115462084875
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 1.106503872581326
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: 0.004378541327048666
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.11522458419146729
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.4650847164506139
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.6934452052664346
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.302498648730803
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.4064954984121065
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.6551048126017612
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 1.0296898207761083
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.6984833735634544
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.6088118957558086
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.5451841366314254
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.9107904869405533
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.8431112748511965
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.23697418510656526
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.5412628024681667
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.16462428834650517
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.8287140548279961
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.4311502434004686
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.8751253504565784
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.5376695923021307
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.21438957143585496
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.5480228904881775
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.19381428506108517
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.5229083182097046
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -1.1403077456925959
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.2374209593942492
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.1818877453501233
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.7953510368904134
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.24991851446293825
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -1.0595534978726633
---------------------------------------------------------

Hidden units: 12
Epochs: 1000
Learning rate: 0.5

Errors during training:
Error at epoch 1 is 95.52764835898067
Train mean error at (after) epoch 1: 0.23881912089745166
Test error at (after) epoch 1: 0.1594508046594995
----------
Error at epoch 100 is 9.741642679598469
Train mean error at (after) epoch 100: 0.02435410669899617
Test error at (after) epoch 100: 0.03071992750241829
----------
Error at epoch 200 is 3.659572053107644
Train mean error at (after) epoch 200: 0.00914893013276911
Test error at (after) epoch 200: 0.011054539985561765
----------
Error at epoch 300 is 2.2736970402646186
Train mean error at (after) epoch 300: 0.0056842426006615465
Test error at (after) epoch 300: 0.0061533163719791895
----------
Error at epoch 400 is 1.9314168805373175
Train mean error at (after) epoch 400: 0.0048285422013432935
Test error at (after) epoch 400: 0.004991935969263023
----------
Error at epoch 500 is 1.711912867251205
Train mean error at (after) epoch 500: 0.004279782168128013
Test error at (after) epoch 500: 0.004371170228403952
----------
Error at epoch 600 is 1.5280614638265821
Train mean error at (after) epoch 600: 0.0038201536595664554
Test error at (after) epoch 600: 0.0038906014908010596
----------
Error at epoch 700 is 1.3716388657461605
Train mean error at (after) epoch 700: 0.003429097164365401
Test error at (after) epoch 700: 0.0034933026871337087
----------
Error at epoch 800 is 1.2394287409850537
Train mean error at (after) epoch 800: 0.0030985718524626344
Test error at (after) epoch 800: 0.0031622873945582174
----------
Error at epoch 900 is 1.1280524823155116
Train mean error at (after) epoch 900: 0.002820131205788779
Test error at (after) epoch 900: 0.002886326570708097
----------
Error at epoch 1000 is 1.0340500973310605
Train mean error at (after) epoch 1000: 0.002585125243327651
Test error at (after) epoch 1000: 0.0026556412584317407
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.6113549072328409
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.806308539111381
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.8435359436012265
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.4556709718724179
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.8265446816892701
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.8234337121929836
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.7604115432586058
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.8842965942398039
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.09031421719964797
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.5163480519832833
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.8524536785622391
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.07922405668328494
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.5922101737835864
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.8742345500719326
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.8060636049140749
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.6904539457859236
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.5815416724589993
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.9226435416050568
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.12765070566398626
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.8435315959052325
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.7733235599241731
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.3262951520450125
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.6962560472028917
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.8536849537141071
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.5206331593921291
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.8255891211724743
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 0.704981635548248
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.8624695236848676
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.7910272028070353
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.8219112634998534
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.5692622974256452
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -0.776030094250152
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.8982151936448532
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.904833273933442
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.3968400375915741
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.9264259143573452
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.41755063217486227
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.8256963462717715
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.8911491911521002
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.6092551543501918
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.5108452385705674
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 0.5807209758493619
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 0.45667729690470027
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.30331681906350433
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.9469083673262362
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.7421337600055105
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -0.6326092258014195
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.15181067721251976
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.6361614474824586
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.7615726993675614
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.44981272659941607
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.8813435186722661
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.654107435051469
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.6201569712876692
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.11477363821154826
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.10302582879155811
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.832050069252022
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.606817075434561
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.9544842236468414
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.053917785578980935
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.9177692380944908
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.573437061971448
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.7306879510471734
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.28184234479221404
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.130416383002768
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.2659646065077419
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.8430278426151511
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.1010224902224457
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.8139131935351195
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 0.7579456375549919
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.07263340598863896
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.15633670619406256
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.5891985714932971
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.8798347830701014
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.34913304201750284
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.5522053410734098
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.8576512555137005
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 0.7110211908078181
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.8639468937180921
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.7414481967468355
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.7031931604095002
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.9523726554549881
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.9095591749895702
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.335297894259438
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.6742840454340306
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.19248427736796273
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.8923703343497794
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.5544152463868668
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.948332543287083
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.697734298810963
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.28098995690384826
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.6890871992791037
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.2746219805861186
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.6639960653377098
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -0.4623438637675754
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.3228125277678071
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.30808842433076983
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.886627465104554
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.4312746125732335
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -0.6118783890298412
---------------------------------------------------------

Hidden units: 12
Epochs: 3000
Learning rate: 0.5

Errors during training:
Error at epoch 1 is 100.81669974872979
Train mean error at (after) epoch 1: 0.2520417493718245
Test error at (after) epoch 1: 0.20805692893814823
----------
Error at epoch 300 is 1.8562461161321708
Train mean error at (after) epoch 300: 0.004640615290330427
Test error at (after) epoch 300: 0.005283365824440245
----------
Error at epoch 600 is 1.2051021588003097
Train mean error at (after) epoch 600: 0.003012755397000774
Test error at (after) epoch 600: 0.003163459300934225
----------
Error at epoch 900 is 0.9629050452334641
Train mean error at (after) epoch 900: 0.00240726261308366
Test error at (after) epoch 900: 0.002553177530539007
----------
Error at epoch 1200 is 0.7920660543341013
Train mean error at (after) epoch 1200: 0.001980165135835253
Test error at (after) epoch 1200: 0.0021087587806336173
----------
Error at epoch 1500 is 0.6565283785294427
Train mean error at (after) epoch 1500: 0.0016413209463236066
Test error at (after) epoch 1500: 0.001741274066845807
----------
Error at epoch 1800 is 0.6876759461568346
Train mean error at (after) epoch 1800: 0.0017191898653920864
Test error at (after) epoch 1800: 0.001801313387450525
----------
Error at epoch 2100 is 0.5631610232052574
Train mean error at (after) epoch 2100: 0.0014079025580131434
Test error at (after) epoch 2100: 0.0014761370765999737
----------
Error at epoch 2400 is 0.597639998845951
Train mean error at (after) epoch 2400: 0.0014940999971148775
Test error at (after) epoch 2400: 0.0015552096827112685
----------
Error at epoch 2700 is 0.48855562796730573
Train mean error at (after) epoch 2700: 0.0012213890699182643
Test error at (after) epoch 2700: 0.0012789573697246617
----------
Error at epoch 3000 is 0.5250973847812579
Train mean error at (after) epoch 3000: 0.0013127434619531447
Test error at (after) epoch 3000: 0.0013644668706156112
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.6275554091308209
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.798125793852009
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.8557524914809335
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.45215558047184323
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.8591144353385979
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.8681496089130116
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.7409122735029097
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.9107002604749267
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.0899225953133779
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.45541348282654714
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.8560315869382692
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.059213512632130705
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.5829375091881469
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.901983175598113
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.8477679011022768
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.6886294769387225
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.5666669847838699
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.9195359677407372
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.08819706777405337
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.8834356125033604
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.78287767422187
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.28205001913007266
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.6583046353841578
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.8771285874102098
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.5174896577345873
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.8532898833386087
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 0.6631812003816767
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.8719135156217649
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.80853957679561
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.8348604248597687
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.5733584787491673
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -0.7770240034740558
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.9404822606649285
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.9429061881514508
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.3580788419181652
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.9456243253233271
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.42939812830754387
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.8614329069521789
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.9254403934736645
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.5427767618763285
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.4653592660764745
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 0.5370406519226691
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 0.3432741688472818
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.2976169252300429
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.9547981170151193
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.7361199332585199
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -0.5522970026951873
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.14244523804329098
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.6154029640963686
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.7404047830150352
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.400994537509317
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.9099027616430589
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.633938120510499
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.6566186095114496
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.09973535717847387
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.09277743339919448
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.84235258214015
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.6322167758086238
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.9370883226120962
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.05752197008643911
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.9290537661678917
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.5393265201689678
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.7248567846550257
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.26415119525300934
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.1528009239090641
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.2461532430677907
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.8656206024164234
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.09429110220182305
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.8341287225827738
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 0.7534662326077599
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.11370693593792378
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.15103451692322178
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.5918707718145237
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.9044585345841271
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.34084392261078655
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.5175543669418399
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.7905845945518851
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 0.6773452140295876
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.8038653466838134
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.7578112868377448
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.6631976792154393
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.9606719744104648
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.9483426013765078
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.3106105062990231
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.6863574782656765
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.19914182109650852
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.9161193620035109
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.5590398597007992
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.92548545834537
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.6440474586150035
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.29209543423622075
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.6844579577329984
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.2816649533183734
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.672593404967925
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -0.37488724215465696
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.3169600817227999
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.27595848470538475
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.9134836749293188
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.343145332431692
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -0.5401458748508225
---------------------------------------------------------

Hidden units: 12
Epochs: 10000
Learning rate: 0.5

Errors during training:
Error at epoch 1 is 87.42003282547584
Train mean error at (after) epoch 1: 0.21855008206368962
Test error at (after) epoch 1: 0.14297105359762288
----------
Error at epoch 1000 is 1.0727282078339513
Train mean error at (after) epoch 1000: 0.0026818205195848783
Test error at (after) epoch 1000: 0.002700804628380543
----------
Error at epoch 2000 is 0.8268265517066082
Train mean error at (after) epoch 2000: 0.0020670663792665207
Test error at (after) epoch 2000: 0.0021670352610726543
----------
Error at epoch 3000 is 0.8337314623415591
Train mean error at (after) epoch 3000: 0.002084328655853898
Test error at (after) epoch 3000: 0.0022216026960333326
----------
Error at epoch 4000 is 0.8531874017821138
Train mean error at (after) epoch 4000: 0.0021329685044552847
Test error at (after) epoch 4000: 0.0022796566269150907
----------
Error at epoch 5000 is 0.873151243146559
Train mean error at (after) epoch 5000: 0.0021828781078663973
Test error at (after) epoch 5000: 0.002320872152886288
----------
Error at epoch 6000 is 0.9040623654029837
Train mean error at (after) epoch 6000: 0.002260155913507459
Test error at (after) epoch 6000: 0.0023758855033793394
----------
Error at epoch 7000 is 17.513194272364395
Train mean error at (after) epoch 7000: 0.043782985680910984
Test error at (after) epoch 7000: 0.026874250768946246
----------
Error at epoch 8000 is 0.7483849560522388
Train mean error at (after) epoch 8000: 0.001870962390130597
Test error at (after) epoch 8000: 0.0019967319041868225
----------
Error at epoch 9000 is 0.7709945676143294
Train mean error at (after) epoch 9000: 0.0019274864190358234
Test error at (after) epoch 9000: 0.0020430462828098083
----------
Error at epoch 10000 is 0.8010297637665134
Train mean error at (after) epoch 10000: 0.0020025744094162834
Test error at (after) epoch 10000: 0.002109173859835062
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.5927080828716206
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.8070046129547954
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.8587975799694533
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.4604078620740968
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.8129237342664305
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.8440476917021031
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.7329903050344252
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.8735253021397649
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.09246845860867223
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.5253775408631065
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.9080547642692237
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.06841470115186879
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.587939997759978
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.8595140375766017
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.8103617018553119
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.6705068329796382
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.5812768809338241
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.9216132795914174
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.10449208540158789
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.8697423008534909
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.7779561009963676
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.33455203610434237
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.6677451556904196
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.862022922436967
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.5127165970944475
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.8084100296176894
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 0.67929661794942
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.8589660081128048
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.7784568493945166
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.8067467590614109
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.5463472601400188
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -0.7545560143590219
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.926986760916968
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.9253172882394622
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.3882917194251849
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.9378966901013324
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.4012378692304862
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.8307703989459232
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.8817021759776764
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.5927861024742095
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.5022124039234513
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 0.5470329239699971
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 0.4011645130560235
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.28217795552152425
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.9678530678789953
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.7268820808302722
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -0.5843386117653805
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.13640414519845448
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.6252978047574113
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.7655029271894854
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.43371109042826084
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.8690579838882903
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.6422044985702389
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.6225034920478587
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.13156851277822146
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.11251745307520347
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.8499995115185007
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.5858170242046441
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.9640411718455361
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.04123696650757083
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.9104994670222395
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.5805590528534135
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.7403428007680262
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.2793659443846396
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.13578980683486477
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.2682716150449753
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.8278001496210079
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.09578833847760793
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.7992813247918467
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 0.7513107946380823
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.10380622151522131
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.1517821561747161
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.5684376601940583
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.9040083755184685
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.3617710126773399
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.5138604337900047
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.8549661806060238
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 0.695599904818105
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.8509497506011923
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.7156419427160899
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.6958787152868298
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.9665691518008914
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.9435441264290638
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.3183753393297243
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.7069432692448321
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.17959867704439078
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.9197323933044674
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.5323640779907038
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.965357571647981
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.6941623110222643
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.2700736334381565
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.6857002549100152
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.2774838340084125
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.6623872809266657
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -0.4236535229354802
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.3203680491096955
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.26972040042448353
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.9115176763234416
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.40291601144798317
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -0.5646350081222246
---------------------------------------------------------

Hidden units: 12
Epochs: 100
Learning rate: 1

Errors during training:
Error at epoch 1 is 120.21999123085402
Train mean error at (after) epoch 1: 0.30054997807713507
Test error at (after) epoch 1: 0.1199194607127143
----------
Error at epoch 10 is 15.950426145630276
Train mean error at (after) epoch 10: 0.03987606536407569
Test error at (after) epoch 10: 0.049473956695371586
----------
Error at epoch 20 is 14.507430603872695
Train mean error at (after) epoch 20: 0.03626857650968174
Test error at (after) epoch 20: 0.04513462917859761
----------
Error at epoch 30 is 13.00194073602686
Train mean error at (after) epoch 30: 0.03250485184006715
Test error at (after) epoch 30: 0.04050903228709839
----------
Error at epoch 40 is 11.451366568952015
Train mean error at (after) epoch 40: 0.028628416422380037
Test error at (after) epoch 40: 0.035682845566914166
----------
Error at epoch 50 is 9.880614211164993
Train mean error at (after) epoch 50: 0.02470153552791248
Test error at (after) epoch 50: 0.0307393355125155
----------
Error at epoch 60 is 8.31482734663638
Train mean error at (after) epoch 60: 0.020787068366590947
Test error at (after) epoch 60: 0.025773476503854163
----------
Error at epoch 70 is 6.798518411508633
Train mean error at (after) epoch 70: 0.016996296028771583
Test error at (after) epoch 70: 0.0209472954433339
----------
Error at epoch 80 is 5.402804596524179
Train mean error at (after) epoch 80: 0.013507011491310448
Test error at (after) epoch 80: 0.016503414074364585
----------
Error at epoch 90 is 4.2069916312507765
Train mean error at (after) epoch 90: 0.01051747907812694
Test error at (after) epoch 90: 0.012698999787241903
----------
Error at epoch 100 is 3.264822102330527
Train mean error at (after) epoch 100: 0.008162055255826316
Test error at (after) epoch 100: 0.009699710623716898
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.5229565002221576
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.7054146117936911
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.749909289952751
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.392491746152905
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.7575496428434657
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.9729185258306969
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.6729004607086938
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.8314417811178184
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.07995667756272436
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.4896383950215732
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.7286070398599951
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.05902100315703414
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.4988297885367008
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.9227118835003404
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.7351102777348429
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.6087169562600848
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.49809648716397215
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.9242829337570043
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.08319839247042854
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.9332910810057827
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.9220751329359254
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.2635881692254247
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.6464542368980722
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.9517692109247229
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.44088041898776786
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.747946465127461
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 0.9054261259299646
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.9190145393826912
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.6961447920127518
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.748581958048195
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.49550908502793234
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -0.9056439551642934
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.9171645165691382
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.9014931353834449
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.31247359356829646
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.8702903558278994
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.3456746091645389
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.8816910971707304
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.8484850502650656
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.44561181018261825
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.43126593170717487
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 0.8382920320046378
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 0.8124133820427127
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.2800292958683217
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.9060283223877857
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.6434622046319658
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -0.8848253713711776
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.1442202451747321
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.5421496385188544
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.6709364799495103
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.3638473343714282
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.8648343514307131
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.5372568782027175
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.5470567264126941
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.08564201193919486
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.0716782295401353
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.7329778638048766
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.5239217039894069
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.8824810189780772
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.06048797213755418
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.8824638826888332
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.4941477933179239
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.6434815353924154
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.25982114249759936
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.08932594910197353
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.2270277072901979
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.7694011032451018
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.09294551385515219
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.73306346769428
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 0.9252881671641265
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.07915597327008903
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.1343023616887987
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.5086576661681363
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.8050676990404192
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.2696616455417192
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.49240220238244625
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.7428297361585223
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 0.9192240698542665
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.8204154239243652
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.6723762404923762
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.6217195804469063
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.9156890904292574
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.8255465943246706
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.2900569251120739
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.586287905003026
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.1436022652343954
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.8199905526140323
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.4888341277563265
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.9402268657607249
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.5940010794197506
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.22665052762701712
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.6037513617550542
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.21775335459427048
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.5773885337419724
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -0.8135696641045025
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.27233393866474975
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.2431820721700538
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.8272841139600899
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.29816410586933956
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -0.8871643802586245
---------------------------------------------------------

Hidden units: 12
Epochs: 1000
Learning rate: 1

Errors during training:
Error at epoch 1 is 102.24527494126602
Train mean error at (after) epoch 1: 0.25561318735316507
Test error at (after) epoch 1: 0.11534217324315786
----------
Error at epoch 100 is 2.7400191075683558
Train mean error at (after) epoch 100: 0.006850047768920889
Test error at (after) epoch 100: 0.007829102276086753
----------
Error at epoch 200 is 1.5967654724407043
Train mean error at (after) epoch 200: 0.003991913681101761
Test error at (after) epoch 200: 0.004005811988733048
----------
Error at epoch 300 is 72.38512316319108
Train mean error at (after) epoch 300: 0.1809628079079777
Test error at (after) epoch 300: 0.05731112653665942
----------
Error at epoch 400 is 1.6646173938992168
Train mean error at (after) epoch 400: 0.004161543484748042
Test error at (after) epoch 400: 0.0042057786543419065
----------
Error at epoch 500 is 1.3403761482415726
Train mean error at (after) epoch 500: 0.0033509403706039314
Test error at (after) epoch 500: 0.003377375154441109
----------
Error at epoch 600 is 1.952541823633088
Train mean error at (after) epoch 600: 0.00488135455908272
Test error at (after) epoch 600: 0.005256406702652768
----------
Error at epoch 700 is 1.4073549998073078
Train mean error at (after) epoch 700: 0.0035183874995182696
Test error at (after) epoch 700: 0.0035486446790849247
----------
Error at epoch 800 is 1.1733728289918823
Train mean error at (after) epoch 800: 0.002933432072479706
Test error at (after) epoch 800: 0.0029712933357844366
----------
Error at epoch 900 is 1.4850469946793878
Train mean error at (after) epoch 900: 0.0037126174866984694
Test error at (after) epoch 900: 0.0038064335136795023
----------
Error at epoch 1000 is 1.2150746395562477
Train mean error at (after) epoch 1000: 0.0030376865988906193
Test error at (after) epoch 1000: 0.0030765512135722244
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.613607545786648
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.795492160568739
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.8393037151379257
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.47018112948447366
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.8176088834581079
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.8275992557585174
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.7541145669899023
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.8651314905843419
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.09428180980015571
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.5114773357865786
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.8919463556295539
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: 0.06502940864642975
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.5826083035206788
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.8535751299650207
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.8191482383882793
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.6786317715231818
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.5719989188332558
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.8755497822283653
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.10373879628003697
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.8373596618641604
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.7653879861213415
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.338995668304892
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.700264558434441
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.8576421662175141
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.5300798477306214
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.803472590673128
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 0.6931688883215863
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.8267784607226762
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.7778151408915032
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.8169699259838965
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.5770879980845451
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -0.7562793200570861
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.894647339810632
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.9201986970300057
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.39103900628311905
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.9208050602028623
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.4307369390850154
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.8222611769826904
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.8653768942874367
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.5676239340612457
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.5305146002520335
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 0.5887716287179183
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 0.4755537316093289
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.3167369643177656
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -0.9335927493946715
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.7242759337415042
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -0.6141103001026366
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.15380771346184366
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.6346504882249141
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.7486018824248054
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.4358480313836483
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.8672975400323232
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.6414123093560334
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.6450602772487355
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.10967292390180426
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.0986491899602598
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.8370408883151068
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.6093006249112095
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -0.9585112681905138
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.06689873965236363
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.8862644954774141
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.5914352307121209
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.7456541661659054
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.3227810821020772
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.14433292749557175
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.2778662473461699
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.8404045227206519
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.11294371072935906
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.812287986350048
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 0.7495345420203334
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.09448513598134589
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.1666221196908275
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.5807354008984701
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.8713881430127677
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.38442870113258654
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.5342941667298942
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.860842539791928
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 0.7037155479860384
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.8995274466810409
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.7341720596073424
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.7057030571786209
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -0.9529883089424236
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.9171352625472479
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.3324279350999229
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.7125505340440467
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.19841999632357193
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -0.9051166178924884
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.5491975153078416
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.9846801890197878
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.6752827312194797
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.2837954209664967
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.6881863543840235
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.27773592701800204
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.6546564428136911
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -0.48230584529692844
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.332086280010897
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.3119604985623428
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.8901860223295031
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.4007356898065933
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -0.6095803730512672
---------------------------------------------------------

Hidden units: 12
Epochs: 3000
Learning rate: 1

Errors during training:
Error at epoch 1 is 96.97221600788072
Train mean error at (after) epoch 1: 0.2424305400197018
Test error at (after) epoch 1: 0.09739866980489452
----------
Error at epoch 300 is 1.8306588689581358
Train mean error at (after) epoch 300: 0.00457664717239534
Test error at (after) epoch 300: 0.004632637541729183
----------
Error at epoch 600 is 1.4860903199823794
Train mean error at (after) epoch 600: 0.0037152257999559487
Test error at (after) epoch 600: 0.0037198760324665832
----------
Error at epoch 900 is 1.211438060840747
Train mean error at (after) epoch 900: 0.0030285951521018674
Test error at (after) epoch 900: 0.0030250944261900376
----------
Error at epoch 1200 is 1.123938123634931
Train mean error at (after) epoch 1200: 0.002809845309087328
Test error at (after) epoch 1200: 0.0030710923080038526
----------
Error at epoch 1500 is 3.561576413111084
Train mean error at (after) epoch 1500: 0.00890394103277771
Test error at (after) epoch 1500: 0.007324420257088752
----------
Error at epoch 1800 is 1.349725779957097
Train mean error at (after) epoch 1800: 0.0033743144498927426
Test error at (after) epoch 1800: 0.003311235974424656
----------
Error at epoch 2100 is 1.9331671631816063
Train mean error at (after) epoch 2100: 0.004832917907954016
Test error at (after) epoch 2100: 0.004626515389985603
----------
Error at epoch 2400 is 2.07110853653382
Train mean error at (after) epoch 2400: 0.00517777134133455
Test error at (after) epoch 2400: 0.0049601337849670525
----------
Error at epoch 2700 is 1.951772869261378
Train mean error at (after) epoch 2700: 0.004879432173153445
Test error at (after) epoch 2700: 0.004699197396848946
----------
Error at epoch 3000 is 1.8785928853559697
Train mean error at (after) epoch 3000: 0.004696482213389924
Test error at (after) epoch 3000: 0.004543283683168301
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.5425521639821177
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.8883812428544247
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.7770068645081697
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.3908618679457297
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.7848766453805944
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.8942295608917765
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.789028745269837
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.8382142463998324
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.0025028765334331113
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.3667828819459382
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.844253882296526
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: -0.0014831826314155583
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.46683198104198004
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.949968641629656
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.9045288772959091
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.6226031846106447
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.4552461851563681
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.8637279474846837
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.029184654515130026
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.8121205176635251
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.6956956234833416
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.2225242453944526
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.7004011699899337
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.9297424852404533
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.6207398302875895
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.7808621002977536
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 0.6399909491650744
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.7927438675756875
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.738257199863278
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.7740391813480906
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.4906610028316491
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -0.7895023699684001
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.9880127119799036
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.8798119088919599
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.27476689749295546
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.8529864571453017
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.5121133184808347
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.7693562386235991
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.840454743717028
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.4431360993582982
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.5288629474170998
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 0.4892043506003983
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 0.35536919966220126
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.21401892001203987
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -1.0464602165959633
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.6963386676212353
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -0.6269797553724884
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.06989990680282247
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.5815038460165949
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.8387695860380874
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.3788868189538835
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.9637101777135891
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.5800987091351381
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.6732474018317378
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: -0.010118731561710392
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.14262904028062426
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.7738666230095346
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.7199770732998259
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -1.0366222010515824
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: 0.00012587205256352207
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.8710045314266874
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.42283153583451305
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.6798867358035616
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.20523399795596992
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.0399248760480181
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.17623569905263597
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.94205632206578
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.023816037087730793
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.9131700012767783
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 0.7318609292480442
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.17597546635719996
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.08097445149647049
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.5346745522261203
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.8205350005526941
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.40697493364750653
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.45108195767752385
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.9228427247000173
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 0.6396682599050025
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.8673888345259327
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.8447543103035813
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.7397224797181379
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -1.0736669231975227
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.8456569993390664
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.32044473749870145
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.7558776722841144
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.10237076198259808
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -1.0054251978488808
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.655540335629996
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.9036757274964252
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.7939465476658796
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.2103361642626126
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.6162852851177832
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.37218568494087206
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.6347422568839112
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -0.47255423103947103
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.4091284515815173
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.36149010217945116
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.9823887982565391
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.2759781816602974
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -0.6189509746526447
---------------------------------------------------------

Hidden units: 12
Epochs: 10000
Learning rate: 1

Errors during training:
Error at epoch 1 is 70.57429800972706
Train mean error at (after) epoch 1: 0.17643574502431764
Test error at (after) epoch 1: 0.07512037486559117
----------
Error at epoch 1000 is 1.439656329195493
Train mean error at (after) epoch 1000: 0.003599140822988732
Test error at (after) epoch 1000: 0.0037711543997769677
----------
Error at epoch 2000 is 1.2011847581167159
Train mean error at (after) epoch 2000: 0.0030029618952917897
Test error at (after) epoch 2000: 0.0031682875655020286
----------
Error at epoch 3000 is 2.1660369439252234
Train mean error at (after) epoch 3000: 0.0054150923598130585
Test error at (after) epoch 3000: 0.0058144172392242755
----------
Error at epoch 4000 is 2.088948931719182
Train mean error at (after) epoch 4000: 0.0052223723292979555
Test error at (after) epoch 4000: 0.005443790302575642
----------
Error at epoch 5000 is 2.0387896699070023
Train mean error at (after) epoch 5000: 0.005096974174767506
Test error at (after) epoch 5000: 0.005310990234923447
----------
Error at epoch 6000 is 1.9782583510592853
Train mean error at (after) epoch 6000: 0.004945645877648213
Test error at (after) epoch 6000: 0.005128122277551436
----------
Error at epoch 7000 is 1.926476605513493
Train mean error at (after) epoch 7000: 0.004816191513783733
Test error at (after) epoch 7000: 0.0049701211546302575
----------
Error at epoch 8000 is 1.8815200901199491
Train mean error at (after) epoch 8000: 0.004703800225299873
Test error at (after) epoch 8000: 0.004837618121641926
----------
Error at epoch 9000 is 1.8432211726178203
Train mean error at (after) epoch 9000: 0.00460805293154455
Test error at (after) epoch 9000: 0.004729081608212755
----------
Error at epoch 10000 is 1.8115367910805722
Train mean error at (after) epoch 10000: 0.004528841977701431
Test error at (after) epoch 10000: 0.00464179986898771
----------


Outputs after training:

Input: [-0.35618985 -0.13290307  0.29302646 -0.55119705] | Target: 0.5817972825108801 | Output: 0.5389413320387837
Input: [ 0.27997947  0.94042047 -0.01634833  0.23721264] | Target: -0.7919536061345994 | Output: -0.9088535327172378
Input: [ 0.55639502 -0.96733791 -0.13457886  0.36956778] | Target: 0.8518914317647387 | Output: 0.8408656302643923
Input: [-0.58547303 -0.18902776  0.81194811 -0.02467291] | Target: 0.42609846769727305 | Output: 0.41957570154538265
Input: [ 0.23687713 -0.47620813 -0.18684633 -0.52463395] | Target: 0.8678572159443485 | Output: 0.7432394475225537
Input: [-0.99687615 -0.12816357 -0.99716573  0.2708101 ] | Target: -0.844110633475548 | Output: -0.8298388292327357
Input: [-0.37300366  0.56925572 -0.85321598 -0.98879784] | Target: -0.7219923343547032 | Output: -0.6833558480984342
Input: [-0.09536509 -0.13884165  0.44905587 -0.73913178] | Target: 0.943043739345549 | Output: 0.8289790783515184
Input: [ 0.55292991  0.54047214  0.05478026 -0.01313984] | Target: 0.0802913531317514 | Output: 0.008902442563463196
Input: [-0.83294154 -0.91479657 -0.54162431 -0.94957824] | Target: 0.47045732426450726 | Output: 0.42604991904425066
Input: [ 0.01506554  0.96174942 -0.949591   -0.8956086 ] | Target: -0.8418307883389816 | Output: -0.8132529368492766
Input: [-0.04233576 -0.97087833 -0.67675213  0.18324502] | Target: 0.06849176209178288 | Output: -0.015261722692697745
Input: [ 0.92189317  0.10320048 -0.46193833 -0.19741815] | Target: 0.5262398375188012 | Output: 0.5731534661046259
Input: [-0.06617173  0.71951802 -0.28616417  0.64611338] | Target: -0.9891898856772633 | Output: -0.9088277381886276
Input: [ 0.04882248  0.10824231 -0.06646128  0.85215845] | Target: -0.8294037601096637 | Output: -0.8788061618757366
Input: [ 0.49742906 -0.43810164  0.30203575  0.52011594] | Target: 0.6574658138360202 | Output: 0.6062703510309436
Input: [0.86595849 0.18350873 0.20869752 0.33748794] | Target: 0.525803399289481 | Output: 0.5129907694947589
Input: [ 0.07895586  0.0766701   0.85806724 -0.84089492] | Target: 0.9915032509039552 | Output: 0.9014474051436377
Input: [-0.29128299 -0.76511885 -0.69905694 -0.3307402 ] | Target: 0.10532341200613429 | Output: 0.008048110300926163
Input: [ 0.18202798 -0.89710791 -0.13697587 -0.88838633] | Target: 0.9664542111403884 | Output: 0.8204289500436553
Input: [ 0.60272728 -0.64431648  0.0269585  -0.8122779 ] | Target: 0.8700543117142712 | Output: 0.705979091805855
Input: [-0.42052026 -0.68329215 -0.88384522 -0.92411222] | Target: 0.29842200228263505 | Output: 0.24195583826716094
Input: [ 0.83492204  0.86492507 -0.08154618  0.57559453] | Target: -0.6343317094615047 | Output: -0.7518592822225078
Input: [-0.77037266  0.44282882  0.16021905  0.7412955 ] | Target: -0.9751317476288999 | Output: -0.9342891774771611
Input: [ 0.27797628  0.53982434 -0.30088201 -0.05165458] | Target: -0.48911560000671606 | Output: -0.6264264808351598
Input: [ 0.22844761 -0.09033748  0.53995921 -0.17016134] | Target: 0.8567350764970396 | Output: 0.7217655018928838
Input: [ 0.96641345 -0.41275591  0.6843022  -0.32937165] | Target: 0.6807232152576927 | Output: 0.5813432406695094
Input: [ 0.05347315 -0.27059947  0.94381311 -0.61886248] | Target: 0.9505010363133691 | Output: 0.7834747063213435
Input: [ 0.27948385 -0.60099178  0.24671113  0.2020062 ] | Target: 0.7987294108802913 | Output: 0.7315492144588488
Input: [-0.31002132 -0.69659782  0.21766495 -0.39780548] | Target: 0.8425751759181288 | Output: 0.7627520042047663
Input: [-0.49956275 -0.37354306  0.19122595 -0.50095263] | Target: 0.53639424849821 | Output: 0.4960178362096486
Input: [-0.57628678  0.49217612 -0.71563759  0.33215682] | Target: -0.854888213314519 | Output: -0.7570996452970372
Input: [ 0.12304551  0.57565832 -0.96215719  0.33526319] | Target: -0.9839800302503426 | Output: -0.9802811817464427
Input: [ 0.76944945  0.18510821  0.0610683  -0.70651446] | Target: 0.9761429196277843 | Output: 0.8840277089363441
Input: [ 0.90335985 -0.04587255 -0.97031631 -0.34677585] | Target: 0.3199644327083413 | Output: 0.32176073914521014
Input: [0.82692643 0.39774705 0.90659847 0.09909061] | Target: 0.9447028396215462 | Output: 0.8270009107594769
Input: [-0.14519319  0.19188064  0.47636326  0.53982988] | Target: -0.38991608359931795 | Output: -0.4846377705824931
Input: [ 0.47856521 -0.73381577  0.71592741 -0.01695173] | Target: 0.9307038875186764 | Output: 0.8203555081835746
Input: [ 0.43383982 -0.58582151  0.41571585  0.03565695] | Target: 0.9854021399289705 | Output: 0.8309670583665572
Input: [-0.36178354  0.70804099  0.70718073 -0.90531151] | Target: 0.5164222729117669 | Output: 0.40453570953459045
Input: [-0.94249624 -0.74236315  0.07144493  0.35366877] | Target: -0.4638684745929635 | Output: -0.5946501793143453
Input: [ 0.46592231 -0.92716601  0.72385067 -0.56802291] | Target: 0.4409265730602469 | Output: 0.4834303230925516
Input: [ 0.95856736 -0.59716677  0.77999157 -0.67802421] | Target: 0.1274947953890798 | Output: 0.3035768558084803
Input: [-0.82112987 -0.40790194  0.08400607 -0.60691263] | Target: 0.27413562552398485 | Output: 0.20337543282951476
Input: [-0.40751239 -0.48191994 -0.70648827  0.78243967] | Target: -0.9878137466957025 | Output: -1.0644125840588032
Input: [ 0.39253289 -0.70239175 -0.38613412 -0.1028857 ] | Target: 0.7254419074046992 | Output: 0.6556077282437202
Input: [-0.85798732  0.78703381 -0.25422561  0.68629097] | Target: -0.5278396001310138 | Output: -0.5948154553364421
Input: [ 0.3195098  -0.46330795 -0.23169941  0.41823884] | Target: 0.1324888034258115 | Output: 0.06385857888313212
Input: [ 0.55731455 -0.50541791 -0.7586192  -0.32283378] | Target: 0.5866751318144412 | Output: 0.5698945566636681
Input: [-0.70541257  0.894693    0.59559228 -0.18860807] | Target: -0.7283461606965363 | Output: -0.8179119657351323
Input: [ 0.0877669  -0.9035185  -0.55779534  0.01578416] | Target: 0.405664668016348 | Output: 0.35636394513862735
Input: [-0.51502434  0.49232653  0.20025878  0.52601323] | Target: -0.9718842396034602 | Output: -0.9273528405275017
Input: [-0.08609236  0.49444463  0.72539452 -0.50089565] | Target: 0.6018001266982016 | Output: 0.5835273888461031
Input: [0.47956749 0.40866864 0.25235085 0.95433633] | Target: -0.5900224387833134 | Output: -0.649742265586413
Input: [0.85648082 0.35518791 0.07653216 0.48241774] | Target: 0.09526264868017462 | Output: 0.0596052830733329
Input: [-0.87929764 -0.34502466 -0.05798599 -0.50748029] | Target: -0.08467716102471158 | Output: -0.20090269947936956
Input: [ 0.14391913  0.38834524  0.23609487 -0.98331222] | Target: 0.827691213524134 | Output: 0.7538538326425326
Input: [ 0.01552965  0.14385935 -0.11152722  0.39140026] | Target: -0.5901601261093395 | Output: -0.6830159639130462
Input: [-0.60923594 -0.81701713 -0.846056    0.59259637] | Target: -0.9427796235287162 | Output: -1.04208809295507
Input: [-0.86280147 -0.23244863  0.16270406 -0.52129192] | Target: 0.05361740118599432 | Output: -0.03899362800340538
Input: [-0.11565404 -0.08774431  0.636964   -0.79895903] | Target: 0.9867800734104517 | Output: 0.8719894147958946
Input: [-0.04256141 -0.9299504   0.61091602  0.9425912 ] | Target: 0.527549830034303 | Output: 0.39367411591681517
Input: [-0.49877175 -0.47566518  0.78670904 -0.03750949] | Target: 0.7181303603479173 | Output: 0.7034241976186886
Input: [0.42070602 0.88505005 0.7798253  0.0549353 ] | Target: 0.2576081304689804 | Output: 0.2227200084022395
Input: [-0.38260462 -0.11919809 -0.35499594 -0.73994915] | Target: 0.12124761428910158 | Output: 0.045647334654756865
Input: [-0.49710456 -0.61464902  0.3825799   0.25827981] | Target: 0.23949390287202846 | Output: 0.208928332303696
Input: [ 0.28317469  0.64348022 -0.30394842  0.37960293] | Target: -0.8643502412080866 | Output: -0.9233530624538825
Input: [-0.67877712 -0.35142315  0.32877072 -0.09281214] | Target: 0.09408951247627834 | Output: 0.019336859166457325
Input: [ 0.29255039  0.38041522 -0.48221267  0.39910808] | Target: -0.824425054725006 | Output: -0.8905924497817906
Input: [-0.01551275 -0.64694316  0.9194774  -0.71655312] | Target: 0.7669866517729902 | Output: 0.7047825287797909
Input: [-0.00917201 -0.76363351 -0.99669579 -0.17155022] | Target: -0.0706252253471188 | Output: -0.2261245263320727
Input: [-0.5721914  -0.29323707  0.35630376 -0.06675318] | Target: 0.14360439040999654 | Output: 0.08475646086910224
Input: [ 0.25317066 -0.38525355  0.19784021  0.24638237] | Target: 0.5562630126663165 | Output: 0.5028116998014179
Input: [ 0.97409923 -0.30426416 -0.62488672 -0.38957615] | Target: 0.8639456039625573 | Output: 0.8865456890385143
Input: [0.10583768 0.43502178 0.95440547 0.9534156 ] | Target: -0.322334176788645 | Output: -0.4033478443242594
Input: [ 0.27275181 -0.49455548  0.71134678  0.95407869] | Target: 0.5008455336503765 | Output: 0.3708558869219129
Input: [-0.43352186 -0.91834159 -0.77629685  0.63753186] | Target: -0.8010270794433203 | Output: -0.8990085345001227
Input: [ 0.91568039 -0.41135203  0.33814805 -0.66797831] | Target: 0.7232064496497836 | Output: 0.6040730258417025
Input: [ 0.98558995  0.67089648 -0.77873114  0.48222562] | Target: -0.8112362508601103 | Output: -0.9056283030226303
Input: [-0.55476802  0.14407435  0.06526822  0.19983179] | Target: -0.740225674394749 | Output: -0.7978926671262964
Input: [ 0.63025838  0.95430843 -0.12154966  0.26183179] | Target: -0.6498837622976642 | Output: -0.8079049309835631
Input: [-0.88112103  0.85684359 -0.43498984 -0.6246841 ] | Target: -0.9997463012202492 | Output: -1.1145026452844131
Input: [ 0.45201858 -0.99000212  0.32319276  0.45594673] | Target: 0.9659956168590402 | Output: 0.9595838062587995
Input: [-0.98631225  0.21903042  0.06097852 -0.8546316 ] | Target: -0.28569592338898037 | Output: -0.3674152221129813
Input: [-0.29706922 -0.37815709  0.1674617   0.96296837] | Target: -0.6551784443566583 | Output: -0.6955097382607455
Input: [-0.21610251 -0.2273822  -0.35282035 -0.5152783 ] | Target: 0.1728649259646225 | Output: 0.10126968927167598
Input: [ 0.33317748  0.5795201  -0.8485998   0.10975125] | Target: -0.9337295993567784 | Output: -1.0007538056671326
Input: [-0.50207213  0.14837298 -0.06297599 -0.16398355] | Target: -0.5222076527548721 | Output: -0.6142102947783613
Input: [-0.86722872 -0.81730753  0.89913583 -0.44750219] | Target: 0.9626747486592373 | Output: 0.926633359992376
Input: [-0.52761406  0.88281921  0.82817904  0.12859798] | Target: -0.652479824465121 | Output: -0.7679177571422275
Input: [-0.13470864  0.03309787  0.09656123 -0.33009769] | Target: 0.255971369497432 | Output: 0.20421375138711756
Input: [ 0.54086406 -0.83599126 -0.31801636  0.34028855] | Target: 0.6582941752540641 | Output: 0.6240080857000453
Input: [ 0.29931494 -0.24268466 -0.45454416  0.34168578] | Target: -0.2515005719603337 | Output: -0.3747152610513731
Input: [0.12105222 0.11147108 0.74257069 0.05735982] | Target: 0.6402256787262499 | Output: 0.6012584226430135
Input: [-0.48532484  0.8542473  -0.96816719  0.7696074 ] | Target: -0.06420174016824519 | Output: -0.4778672694330536
Input: [-0.32303478 -0.58605111 -0.1109584   0.45368696] | Target: -0.2970760852291822 | Output: -0.38745475354265996
Input: [ 0.99655683 -0.2235921  -0.81241289  0.66280638] | Target: -0.25231348311884255 | Output: -0.35738655075396264
Input: [ 0.00373755 -0.07246145 -0.26910737  0.99696465] | Target: -0.928321767487265 | Output: -0.9659368637252136
Input: [-0.23218929  0.99449055  0.84379627 -0.73756972] | Target: 0.34729607316235445 | Output: 0.24411580414648287
Input: [-0.82656744  0.54786734 -0.49035442  0.73398587] | Target: -0.5165506207966529 | Output: -0.5834909095516045
=========================================================


==================== GLOBAL SUMMARY ====================

HU=12 | LR=0.3 | Epochs=10000 | Test Error=0.0006684119160072876
HU=12 | LR=0.1 | Epochs=10000 | Test Error=0.0010538411715132715
HU=6 | LR=0.3 | Epochs=10000 | Test Error=0.0011462555158398857
HU=7 | LR=0.3 | Epochs=10000 | Test Error=0.0011487516251933987
HU=5 | LR=0.3 | Epochs=10000 | Test Error=0.001269557298441995
HU=12 | LR=0.3 | Epochs=3000 | Test Error=0.0013305839591894644
HU=10 | LR=0.5 | Epochs=10000 | Test Error=0.0013572226522995834
HU=10 | LR=0.1 | Epochs=10000 | Test Error=0.0013627308343479075
HU=12 | LR=0.5 | Epochs=3000 | Test Error=0.0013644668706156112
HU=10 | LR=0.3 | Epochs=3000 | Test Error=0.0014666054544748017
HU=7 | LR=0.5 | Epochs=10000 | Test Error=0.0014911852586372712
HU=10 | LR=0.5 | Epochs=3000 | Test Error=0.0015100185648739286
HU=10 | LR=0.5 | Epochs=1000 | Test Error=0.0019235960465675468
HU=7 | LR=0.1 | Epochs=10000 | Test Error=0.0020655787573526808
HU=10 | LR=0.05 | Epochs=10000 | Test Error=0.002083635517504879
HU=7 | LR=0.3 | Epochs=3000 | Test Error=0.002100253134771159
HU=12 | LR=0.5 | Epochs=10000 | Test Error=0.002109173859835062
HU=6 | LR=0.1 | Epochs=10000 | Test Error=0.0021352386537149774
HU=6 | LR=0.3 | Epochs=3000 | Test Error=0.0021723631868092114
HU=5 | LR=0.3 | Epochs=3000 | Test Error=0.0022497715054978244
HU=5 | LR=0.1 | Epochs=10000 | Test Error=0.0023578227997951813
HU=12 | LR=0.05 | Epochs=10000 | Test Error=0.002464507137569536
HU=12 | LR=0.5 | Epochs=1000 | Test Error=0.0026556412584317407
HU=7 | LR=0.05 | Epochs=10000 | Test Error=0.0026776326915311306
HU=6 | LR=0.5 | Epochs=3000 | Test Error=0.002695042944973146
HU=7 | LR=0.5 | Epochs=3000 | Test Error=0.0028064940929896955
HU=5 | LR=0.5 | Epochs=3000 | Test Error=0.002887611347602023
HU=5 | LR=0.5 | Epochs=10000 | Test Error=0.0029318441093637714
HU=10 | LR=0.3 | Epochs=10000 | Test Error=0.0029569237798156827
HU=12 | LR=1 | Epochs=1000 | Test Error=0.0030765512135722244
HU=6 | LR=0.5 | Epochs=10000 | Test Error=0.0031888391984150467
HU=12 | LR=0.1 | Epochs=3000 | Test Error=0.0031892807674999786
HU=6 | LR=0.5 | Epochs=1000 | Test Error=0.003209792713296709
HU=6 | LR=0.05 | Epochs=10000 | Test Error=0.0033474908026750855
HU=7 | LR=0.5 | Epochs=1000 | Test Error=0.0035634482587717587
HU=5 | LR=0.5 | Epochs=1000 | Test Error=0.003605029651014476
HU=10 | LR=0.1 | Epochs=3000 | Test Error=0.0036090378326285393
HU=10 | LR=1 | Epochs=1000 | Test Error=0.00361482621213334
HU=12 | LR=0.3 | Epochs=1000 | Test Error=0.0037399987644788453
HU=5 | LR=1 | Epochs=3000 | Test Error=0.0038210242839217634
HU=5 | LR=0.05 | Epochs=10000 | Test Error=0.0038991485942079553
HU=7 | LR=0.3 | Epochs=1000 | Test Error=0.0039623520872356585
HU=10 | LR=1 | Epochs=3000 | Test Error=0.004007514414970273
HU=10 | LR=0.3 | Epochs=1000 | Test Error=0.0041240718358727625
HU=7 | LR=1 | Epochs=1000 | Test Error=0.004155996321679036
HU=5 | LR=0.1 | Epochs=3000 | Test Error=0.004237511243102613
HU=7 | LR=0.1 | Epochs=3000 | Test Error=0.004396956609293956
HU=7 | LR=1 | Epochs=3000 | Test Error=0.004411574371107203
HU=6 | LR=0.1 | Epochs=3000 | Test Error=0.00448526121126388
HU=12 | LR=1 | Epochs=3000 | Test Error=0.004543283683168301
HU=10 | LR=0.05 | Epochs=3000 | Test Error=0.00458280775811645
HU=12 | LR=1 | Epochs=10000 | Test Error=0.00464179986898771
HU=6 | LR=0.3 | Epochs=1000 | Test Error=0.004696821356886573
HU=5 | LR=1 | Epochs=1000 | Test Error=0.005006746412915795
HU=6 | LR=1 | Epochs=3000 | Test Error=0.005078723768627944
HU=12 | LR=0.05 | Epochs=3000 | Test Error=0.005099627630818401
HU=6 | LR=1 | Epochs=1000 | Test Error=0.005192866111479972
HU=5 | LR=0.3 | Epochs=1000 | Test Error=0.005223355471016707
HU=5 | LR=1 | Epochs=10000 | Test Error=0.005636845157125501
HU=10 | LR=1 | Epochs=10000 | Test Error=0.0063214259484486455
HU=7 | LR=1 | Epochs=10000 | Test Error=0.0065316264927419345
HU=10 | LR=1 | Epochs=100 | Test Error=0.006753519350272619
HU=6 | LR=0.05 | Epochs=3000 | Test Error=0.007201339434046173
HU=7 | LR=0.05 | Epochs=3000 | Test Error=0.007404999223173898
HU=12 | LR=0.1 | Epochs=1000 | Test Error=0.007407724173638351
HU=6 | LR=1 | Epochs=10000 | Test Error=0.007547094472936941
HU=7 | LR=0.1 | Epochs=1000 | Test Error=0.009097176313668198
HU=5 | LR=0.05 | Epochs=3000 | Test Error=0.009252782382801274
HU=6 | LR=1 | Epochs=100 | Test Error=0.009483158592483977
HU=12 | LR=1 | Epochs=100 | Test Error=0.009699710623716898
HU=5 | LR=0.1 | Epochs=1000 | Test Error=0.01047615416962613
HU=10 | LR=0.1 | Epochs=1000 | Test Error=0.011006616175932307
HU=6 | LR=0.1 | Epochs=1000 | Test Error=0.011253395254049255
HU=7 | LR=1 | Epochs=100 | Test Error=0.011447530767233781
HU=5 | LR=0.05 | Epochs=1000 | Test Error=0.013586694328888487
HU=5 | LR=0.5 | Epochs=100 | Test Error=0.017113163675419752
HU=12 | LR=0.05 | Epochs=1000 | Test Error=0.017475541457633286
HU=5 | LR=1 | Epochs=100 | Test Error=0.017903747937186593
HU=10 | LR=0.5 | Epochs=100 | Test Error=0.019014360493354265
HU=7 | LR=0.05 | Epochs=1000 | Test Error=0.019754019498938305
HU=12 | LR=0.5 | Epochs=100 | Test Error=0.021894826226452516
HU=6 | LR=0.5 | Epochs=100 | Test Error=0.026250883762608777
HU=6 | LR=0.05 | Epochs=1000 | Test Error=0.02795842244986208
HU=7 | LR=0.5 | Epochs=100 | Test Error=0.028189559743740152
HU=5 | LR=0.3 | Epochs=100 | Test Error=0.030287034915743152
HU=10 | LR=0.05 | Epochs=1000 | Test Error=0.03285858865590151
HU=6 | LR=0.3 | Epochs=100 | Test Error=0.037258618657136505
HU=5 | LR=0.1 | Epochs=100 | Test Error=0.04031992359610749
HU=10 | LR=0.3 | Epochs=100 | Test Error=0.04051210478344362
HU=7 | LR=0.3 | Epochs=100 | Test Error=0.04145207016509089
HU=12 | LR=0.3 | Epochs=100 | Test Error=0.04255274694774177
HU=7 | LR=0.1 | Epochs=100 | Test Error=0.04597905244383543
HU=10 | LR=0.1 | Epochs=100 | Test Error=0.048413649826357305
HU=12 | LR=0.05 | Epochs=100 | Test Error=0.050133656522488544
HU=6 | LR=0.1 | Epochs=100 | Test Error=0.05029423774997813
HU=10 | LR=0.05 | Epochs=100 | Test Error=0.05402166685082501
HU=12 | LR=0.1 | Epochs=100 | Test Error=0.05550715593291886
HU=7 | LR=0.05 | Epochs=100 | Test Error=0.05590340191069064
HU=5 | LR=0.05 | Epochs=100 | Test Error=0.05962438623863352
HU=6 | LR=0.05 | Epochs=100 | Test Error=0.06354285448242707
